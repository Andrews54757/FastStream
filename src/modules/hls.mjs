let hls;
let a = (function webpackUniversalModuleDefinition(root, factory) {
  hls = factory();
})(this, () => {
  return /******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./src/config.ts":
/*!***********************!*\
  !*** ./src/config.ts ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "enableStreamingMode": () => (/* binding */ enableStreamingMode),
/* harmony export */   "hlsDefaultConfig": () => (/* binding */ hlsDefaultConfig),
/* harmony export */   "mergeConfig": () => (/* binding */ mergeConfig)
            /* harmony export */
          });
/* harmony import */ var _controller_abr_controller__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./controller/abr-controller */ "./src/controller/abr-controller.ts");
/* harmony import */ var _controller_audio_stream_controller__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./controller/audio-stream-controller */ "./src/controller/audio-stream-controller.ts");
/* harmony import */ var _controller_audio_track_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./controller/audio-track-controller */ "./src/controller/audio-track-controller.ts");
/* harmony import */ var _controller_subtitle_stream_controller__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./controller/subtitle-stream-controller */ "./src/controller/subtitle-stream-controller.ts");
/* harmony import */ var _controller_subtitle_track_controller__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./controller/subtitle-track-controller */ "./src/controller/subtitle-track-controller.ts");
/* harmony import */ var _controller_buffer_controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./controller/buffer-controller */ "./src/controller/buffer-controller.ts");
/* harmony import */ var _controller_timeline_controller__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./controller/timeline-controller */ "./src/controller/timeline-controller.ts");
/* harmony import */ var _controller_cap_level_controller__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./controller/cap-level-controller */ "./src/controller/cap-level-controller.ts");
/* harmony import */ var _controller_fps_controller__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./controller/fps-controller */ "./src/controller/fps-controller.ts");
/* harmony import */ var _controller_eme_controller__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./controller/eme-controller */ "./src/controller/eme-controller.ts");
/* harmony import */ var _controller_cmcd_controller__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./controller/cmcd-controller */ "./src/controller/cmcd-controller.ts");
/* harmony import */ var _utils_xhr_loader__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./utils/xhr-loader */ "./src/utils/xhr-loader.ts");
/* harmony import */ var _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./utils/fetch-loader */ "./src/utils/fetch-loader.ts");
/* harmony import */ var _utils_cues__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./utils/cues */ "./src/utils/cues.ts");
/* harmony import */ var _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./utils/mediakeys-helper */ "./src/utils/mediakeys-helper.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./utils/logger */ "./src/utils/logger.ts");
















          // If possible, keep hlsDefaultConfig shallow
          // It is cloned whenever a new Hls instance is created, by keeping the config
          // shallow the properties are cloned, and we don't end up manipulating the default
          const hlsDefaultConfig = {
            autoStartLoad: true,
            // used by stream-controller
            startPosition: -1,
            // used by stream-controller
            defaultAudioCodec: undefined,
            // used by stream-controller
            debug: false,
            // used by logger
            capLevelOnFPSDrop: false,
            // used by fps-controller
            capLevelToPlayerSize: false,
            // used by cap-level-controller
            ignoreDevicePixelRatio: false,
            // used by cap-level-controller
            initialLiveManifestSize: 1,
            // used by stream-controller
            maxBufferLength: 30,
            // used by stream-controller
            backBufferLength: Infinity,
            // used by buffer-controller
            maxBufferSize: 60 * 1000 * 1000,
            // used by stream-controller
            maxBufferHole: 0.1,
            // used by stream-controller
            highBufferWatchdogPeriod: 2,
            // used by stream-controller
            nudgeOffset: 0.1,
            // used by stream-controller
            nudgeMaxRetry: 3,
            // used by stream-controller
            maxFragLookUpTolerance: 0.25,
            // used by stream-controller
            liveSyncDurationCount: 3,
            // used by latency-controller
            liveMaxLatencyDurationCount: Infinity,
            // used by latency-controller
            liveSyncDuration: undefined,
            // used by latency-controller
            liveMaxLatencyDuration: undefined,
            // used by latency-controller
            maxLiveSyncPlaybackRate: 1,
            // used by latency-controller
            liveDurationInfinity: false,
            // used by buffer-controller
            liveBackBufferLength: null,
            // used by buffer-controller
            maxMaxBufferLength: 600,
            // used by stream-controller
            enableWorker: true,
            // used by demuxer
            enableSoftwareAES: true,
            // used by decrypter
            manifestLoadingTimeOut: 10000,
            // used by playlist-loader
            manifestLoadingMaxRetry: 1,
            // used by playlist-loader
            manifestLoadingRetryDelay: 1000,
            // used by playlist-loader
            manifestLoadingMaxRetryTimeout: 64000,
            // used by playlist-loader
            startLevel: undefined,
            // used by level-controller
            levelLoadingTimeOut: 10000,
            // used by playlist-loader
            levelLoadingMaxRetry: 4,
            // used by playlist-loader
            levelLoadingRetryDelay: 1000,
            // used by playlist-loader
            levelLoadingMaxRetryTimeout: 64000,
            // used by playlist-loader
            fragLoadingTimeOut: 20000,
            // used by fragment-loader
            fragLoadingMaxRetry: 6,
            // used by fragment-loader
            fragLoadingRetryDelay: 1000,
            // used by fragment-loader
            fragLoadingMaxRetryTimeout: 64000,
            // used by fragment-loader
            startFragPrefetch: false,
            // used by stream-controller
            fpsDroppedMonitoringPeriod: 5000,
            // used by fps-controller
            fpsDroppedMonitoringThreshold: 0.2,
            // used by fps-controller
            appendErrorMaxRetry: 3,
            // used by buffer-controller
            loader: _utils_xhr_loader__WEBPACK_IMPORTED_MODULE_11__["default"],
            // loader: FetchLoader,
            fLoader: undefined,
            // used by fragment-loader
            pLoader: undefined,
            // used by playlist-loader
            xhrSetup: undefined,
            // used by xhr-loader
            licenseXhrSetup: undefined,
            // used by eme-controller
            licenseResponseCallback: undefined,
            // used by eme-controller
            abrController: _controller_abr_controller__WEBPACK_IMPORTED_MODULE_0__["default"],
            bufferController: _controller_buffer_controller__WEBPACK_IMPORTED_MODULE_5__["default"],
            capLevelController: _controller_cap_level_controller__WEBPACK_IMPORTED_MODULE_7__["default"],
            fpsController: _controller_fps_controller__WEBPACK_IMPORTED_MODULE_8__["default"],
            stretchShortVideoTrack: false,
            // used by mp4-remuxer
            maxAudioFramesDrift: 1,
            // used by mp4-remuxer
            forceKeyFrameOnDiscontinuity: true,
            // used by ts-demuxer
            abrEwmaFastLive: 3,
            // used by abr-controller
            abrEwmaSlowLive: 9,
            // used by abr-controller
            abrEwmaFastVoD: 3,
            // used by abr-controller
            abrEwmaSlowVoD: 9,
            // used by abr-controller
            abrEwmaDefaultEstimate: 5e5,
            // 500 kbps  // used by abr-controller
            abrBandWidthFactor: 0.95,
            // used by abr-controller
            abrBandWidthUpFactor: 0.7,
            // used by abr-controller
            abrMaxWithRealBitrate: false,
            // used by abr-controller
            maxStarvationDelay: 4,
            // used by abr-controller
            maxLoadingDelay: 4,
            // used by abr-controller
            minAutoBitrate: 0,
            // used by hls
            emeEnabled: false,
            // used by eme-controller
            widevineLicenseUrl: undefined,
            // used by eme-controller
            drmSystems: {},
            // used by eme-controller
            drmSystemOptions: {},
            // used by eme-controller
            requestMediaKeySystemAccessFunc: _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_14__.requestMediaKeySystemAccess,
            // used by eme-controller
            testBandwidth: true,
            progressive: false,
            lowLatencyMode: true,
            cmcd: undefined,
            enableDateRangeMetadataCues: true,
            enableEmsgMetadataCues: true,
            enableID3MetadataCues: true,
            // Dynamic Modules
            ...timelineConfig(),
            subtitleStreamController: true ? _controller_subtitle_stream_controller__WEBPACK_IMPORTED_MODULE_3__.SubtitleStreamController : 0,
            subtitleTrackController: true ? _controller_subtitle_track_controller__WEBPACK_IMPORTED_MODULE_4__["default"] : 0,
            timelineController: true ? _controller_timeline_controller__WEBPACK_IMPORTED_MODULE_6__.TimelineController : 0,
            audioStreamController: true ? _controller_audio_stream_controller__WEBPACK_IMPORTED_MODULE_1__["default"] : 0,
            audioTrackController: true ? _controller_audio_track_controller__WEBPACK_IMPORTED_MODULE_2__["default"] : 0,
            emeController: true ? _controller_eme_controller__WEBPACK_IMPORTED_MODULE_9__["default"] : 0,
            cmcdController: true ? _controller_cmcd_controller__WEBPACK_IMPORTED_MODULE_10__["default"] : 0
          };
          function timelineConfig() {
            return {
              cueHandler: _utils_cues__WEBPACK_IMPORTED_MODULE_13__["default"],
              // used by timeline-controller
              enableWebVTT: true,
              // used by timeline-controller
              enableIMSC1: true,
              // used by timeline-controller
              enableCEA708Captions: true,
              // used by timeline-controller
              captionsTextTrack1Label: 'English',
              // used by timeline-controller
              captionsTextTrack1LanguageCode: 'en',
              // used by timeline-controller
              captionsTextTrack2Label: 'Spanish',
              // used by timeline-controller
              captionsTextTrack2LanguageCode: 'es',
              // used by timeline-controller
              captionsTextTrack3Label: 'Unknown CC',
              // used by timeline-controller
              captionsTextTrack3LanguageCode: '',
              // used by timeline-controller
              captionsTextTrack4Label: 'Unknown CC',
              // used by timeline-controller
              captionsTextTrack4LanguageCode: '',
              // used by timeline-controller
              renderTextTracksNatively: true
            };
          }
          function mergeConfig(defaultConfig, userConfig) {
            if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {
              throw new Error("Illegal hls.js config: don't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration");
            }
            if (userConfig.liveMaxLatencyDurationCount !== undefined && (userConfig.liveSyncDurationCount === undefined || userConfig.liveMaxLatencyDurationCount <= userConfig.liveSyncDurationCount)) {
              throw new Error('Illegal hls.js config: "liveMaxLatencyDurationCount" must be greater than "liveSyncDurationCount"');
            }
            if (userConfig.liveMaxLatencyDuration !== undefined && (userConfig.liveSyncDuration === undefined || userConfig.liveMaxLatencyDuration <= userConfig.liveSyncDuration)) {
              throw new Error('Illegal hls.js config: "liveMaxLatencyDuration" must be greater than "liveSyncDuration"');
            }
            return Object.assign({}, defaultConfig, userConfig);
          }
          function enableStreamingMode(config) {
            const currentLoader = config.loader;
            if (currentLoader !== _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__["default"] && currentLoader !== _utils_xhr_loader__WEBPACK_IMPORTED_MODULE_11__["default"]) {
              // If a developer has configured their own loader, respect that choice
              _utils_logger__WEBPACK_IMPORTED_MODULE_15__.logger.log('[config]: Custom loader detected, cannot enable progressive streaming');
              config.progressive = false;
            } else {
              const canStreamProgressively = (0, _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__.fetchSupported)();
              if (canStreamProgressively) {
                config.loader = _utils_fetch_loader__WEBPACK_IMPORTED_MODULE_12__["default"];
                config.progressive = true;
                config.enableSoftwareAES = true;
                _utils_logger__WEBPACK_IMPORTED_MODULE_15__.logger.log('[config]: Progressive streaming enabled, using FetchLoader');
              }
            }
          }

          /***/
        }),

/***/ "./src/controller/abr-controller.ts":
/*!******************************************!*\
  !*** ./src/controller/abr-controller.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _utils_ewma_bandwidth_estimator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/ewma-bandwidth-estimator */ "./src/utils/ewma-bandwidth-estimator.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");





          class AbrController {
            lastLoadedFragLevel = 0;
            _nextAutoLevel = -1;
            onCheck = this._abandonRulesCheck.bind(this);
            fragCurrent = null;
            partCurrent = null;
            bitrateTestDelay = 0;
            constructor(hls) {
              this.hls = hls;
              const config = hls.config;
              this.bwEstimator = new _utils_ewma_bandwidth_estimator__WEBPACK_IMPORTED_MODULE_0__["default"](config.abrEwmaSlowVoD, config.abrEwmaFastVoD, config.abrEwmaDefaultEstimate);
              this.registerListeners();
            }
            registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOADING, this.onFragLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOADED, this.onFragLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
            }
            unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOADING, this.onFragLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOADED, this.onFragLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
            }
            destroy() {
              this.unregisterListeners();
              this.clearTimer();
              // @ts-ignore
              this.hls = this.onCheck = null;
              this.fragCurrent = this.partCurrent = null;
            }
            onFragLoading(event, data) {
              const frag = data.frag;
              if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__.PlaylistLevelType.MAIN) {
                if (!this.timer) {
                  this.fragCurrent = frag;
                  this.partCurrent = data.part ?? null;
                  this.timer = self.setInterval(this.onCheck, 100);
                }
              }
            }
            onLevelLoaded(event, data) {
              const config = this.hls.config;
              if (data.details.live) {
                this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);
              } else {
                this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);
              }
            }

            /*
                This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load
                quickly enough to prevent underbuffering
              */
            _abandonRulesCheck() {
              const {
                fragCurrent: frag,
                partCurrent: part,
                hls
              } = this;
              const {
                autoLevelEnabled,
                media
              } = hls;
              if (!frag || !media) {
                return;
              }
              const stats = part ? part.stats : frag.stats;
              const duration = part ? part.duration : frag.duration;
              // If frag loading is aborted, complete, or from lowest level, stop timer and return
              if (stats.aborted || stats.loaded && stats.loaded === stats.total || frag.level === 0) {
                this.clearTimer();
                // reset forced auto level value so that next level will be selected
                this._nextAutoLevel = -1;
                return;
              }

              // This check only runs if we're in ABR mode and actually playing
              if (!autoLevelEnabled || media.paused || !media.playbackRate || !media.readyState) {
                return;
              }
              const bufferInfo = hls.mainForwardBufferInfo;
              if (bufferInfo === null) {
                return;
              }
              const requestDelay = performance.now() - stats.loading.start;
              const playbackRate = Math.abs(media.playbackRate);
              // In order to work with a stable bandwidth, only begin monitoring bandwidth after half of the fragment has been loaded
              if (requestDelay <= 500 * duration / playbackRate) {
                return;
              }
              const loadedFirstByte = stats.loaded && stats.loading.first;
              const bwEstimate = this.bwEstimator.getEstimate();
              const {
                levels,
                minAutoLevel
              } = hls;
              const level = levels[frag.level];
              const expectedLen = stats.total || Math.max(stats.loaded, Math.round(duration * level.maxBitrate / 8));
              const loadRate = loadedFirstByte ? stats.loaded * 1000 / requestDelay : 0;

              // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the remainder of the fragment
              const fragLoadedDelay = loadRate ? (expectedLen - stats.loaded) / loadRate : expectedLen * 8 / bwEstimate;

              // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer
              const bufferStarvationDelay = bufferInfo.len / playbackRate;

              // Only downswitch if the time to finish loading the current fragment is greater than the amount of buffer left
              if (fragLoadedDelay <= bufferStarvationDelay) {
                return;
              }
              let fragLevelNextLoadedDelay = Number.POSITIVE_INFINITY;
              let nextLoadLevel;
              // Iterate through lower level and try to find the largest one that avoids rebuffering
              for (nextLoadLevel = frag.level - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {
                // compute time to load next fragment at lower level
                // 0.8 : consider only 80% of current bw to be conservative
                // 8 = bits per byte (bps/Bps)
                const levelNextBitrate = levels[nextLoadLevel].maxBitrate;
                fragLevelNextLoadedDelay = loadRate ? duration * levelNextBitrate / (8 * 0.8 * loadRate) : duration * levelNextBitrate / bwEstimate;
                if (fragLevelNextLoadedDelay < bufferStarvationDelay) {
                  break;
                }
              }
              // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing
              // to load the current one
              if (fragLevelNextLoadedDelay >= fragLoadedDelay) {
                return;
              }
              _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of level ${frag.level} is loading too slowly and will cause an underbuffer; aborting and switching to level ${nextLoadLevel}
      Current BW estimate: ${Number.isFinite(bwEstimate) ? (bwEstimate / 1024).toFixed(3) : 'Unknown'} Kb/s
      Estimated load time for current fragment: ${fragLoadedDelay.toFixed(3)} s
      Estimated load time for the next fragment: ${fragLevelNextLoadedDelay.toFixed(3)} s
      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s`);
              hls.nextLoadLevel = nextLoadLevel;
              if (loadedFirstByte) {
                // If there has been loading progress, sample bandwidth
                this.bwEstimator.sample(requestDelay, stats.loaded);
              }
              this.clearTimer();
              if (frag.loader || frag.keyLoader) {
                this.fragCurrent = this.partCurrent = null;
                frag.abortRequests();
              }
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOAD_EMERGENCY_ABORTED, {
                frag,
                part,
                stats
              });
            }
            onFragLoaded(event, {
              frag,
              part
            }) {
              if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__.PlaylistLevelType.MAIN && Number.isFinite(frag.sn)) {
                const stats = part ? part.stats : frag.stats;
                const duration = part ? part.duration : frag.duration;
                // stop monitoring bw once frag loaded
                this.clearTimer();
                // store level id after successful fragment load
                this.lastLoadedFragLevel = frag.level;
                // reset forced auto level value so that next level will be selected
                this._nextAutoLevel = -1;

                // compute level average bitrate
                if (this.hls.config.abrMaxWithRealBitrate) {
                  const level = this.hls.levels[frag.level];
                  const loadedBytes = (level.loaded ? level.loaded.bytes : 0) + stats.loaded;
                  const loadedDuration = (level.loaded ? level.loaded.duration : 0) + duration;
                  level.loaded = {
                    bytes: loadedBytes,
                    duration: loadedDuration
                  };
                  level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);
                }
                if (frag.bitrateTest) {
                  const fragBufferedData = {
                    stats,
                    frag,
                    part,
                    id: frag.type
                  };
                  this.onFragBuffered(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_BUFFERED, fragBufferedData);
                }
              }
            }
            onFragBuffered(event, data) {
              const {
                frag,
                part
              } = data;
              const stats = part ? part.stats : frag.stats;
              if (stats.aborted) {
                return;
              }
              // Only count non-alt-audio frags which were actually buffered in our BW calculations
              if (frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_3__.PlaylistLevelType.MAIN || frag.sn === 'initSegment') {
                return;
              }
              // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;
              // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch
              // is used. If we used buffering in that case, our BW estimate sample will be very large.
              const processingMs = stats.parsing.end - stats.loading.start;
              this.bwEstimator.sample(processingMs, stats.loaded);
              stats.bwEstimate = this.bwEstimator.getEstimate();
              if (frag.bitrateTest) {
                this.bitrateTestDelay = processingMs / 1000;
              } else {
                this.bitrateTestDelay = 0;
              }
            }
            onError(event, data) {
              // stop timer in case of frag loading error
              if (data.frag?.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__.PlaylistLevelType.MAIN) {
                if (data.type === _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.KEY_SYSTEM_ERROR) {
                  this.clearTimer();
                  return;
                }
                switch (data.details) {
                  case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.FRAG_LOAD_ERROR:
                  case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.FRAG_LOAD_TIMEOUT:
                  case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.KEY_LOAD_ERROR:
                  case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.KEY_LOAD_TIMEOUT:
                    this.clearTimer();
                    break;
                  default:
                    break;
                }
              }
            }
            clearTimer() {
              self.clearInterval(this.timer);
              this.timer = undefined;
            }

            // return next auto level
            get nextAutoLevel() {
              const forcedAutoLevel = this._nextAutoLevel;
              const bwEstimator = this.bwEstimator;
              // in case next auto level has been forced, and bw not available or not reliable, return forced value
              if (forcedAutoLevel !== -1 && !bwEstimator.canEstimate()) {
                return forcedAutoLevel;
              }

              // compute next level using ABR logic
              let nextABRAutoLevel = this.getNextABRAutoLevel();
              // use forced auto level when ABR selected level has errored
              if (forcedAutoLevel !== -1 && this.hls.levels[nextABRAutoLevel].loadError) {
                return forcedAutoLevel;
              }
              // if forced auto level has been defined, use it to cap ABR computed quality level
              if (forcedAutoLevel !== -1) {
                nextABRAutoLevel = Math.min(forcedAutoLevel, nextABRAutoLevel);
              }
              return nextABRAutoLevel;
            }
            getNextABRAutoLevel() {
              const {
                fragCurrent,
                partCurrent,
                hls
              } = this;
              const {
                maxAutoLevel,
                config,
                minAutoLevel,
                media
              } = hls;
              const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;

              // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as
              // if we're playing back at the normal rate.
              const playbackRate = media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;
              const avgbw = this.bwEstimator ? this.bwEstimator.getEstimate() : config.abrEwmaDefaultEstimate;
              // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.
              const bufferInfo = hls.mainForwardBufferInfo;
              const bufferStarvationDelay = (bufferInfo ? bufferInfo.len : 0) / playbackRate;

              // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all
              let bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, config.abrBandWidthFactor, config.abrBandWidthUpFactor);
              if (bestLevel >= 0) {
                return bestLevel;
              }
              _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.trace(`${bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty'}, finding optimal quality level`);
              // not possible to get rid of rebuffering ... let's try to find level that will guarantee less than maxStarvationDelay of rebuffering
              // if no matching level found, logic will return 0
              let maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;
              let bwFactor = config.abrBandWidthFactor;
              let bwUpFactor = config.abrBandWidthUpFactor;
              if (!bufferStarvationDelay) {
                // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test
                const bitrateTestDelay = this.bitrateTestDelay;
                if (bitrateTestDelay) {
                  // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value
                  // max video loading delay used in  automatic start level selection :
                  // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +
                  // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )
                  // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration
                  const maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;
                  maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;
                  _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.trace(`bitrate test took ${Math.round(1000 * bitrateTestDelay)}ms, set first fragment max fetchDuration to ${Math.round(1000 * maxStarvationDelay)} ms`);
                  // don't use conservative factor on bitrate test
                  bwFactor = bwUpFactor = 1;
                }
              }
              bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay + maxStarvationDelay, bwFactor, bwUpFactor);
              return Math.max(bestLevel, 0);
            }
            findBestLevel(currentBw, minAutoLevel, maxAutoLevel, maxFetchDuration, bwFactor, bwUpFactor) {
              const {
                fragCurrent,
                partCurrent,
                lastLoadedFragLevel: currentLevel
              } = this;
              const {
                levels
              } = this.hls;
              const level = levels[currentLevel];
              const live = !!level?.details?.live;
              const currentCodecSet = level?.codecSet;
              const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;
              for (let i = maxAutoLevel; i >= minAutoLevel; i--) {
                const levelInfo = levels[i];
                if (!levelInfo || currentCodecSet && levelInfo.codecSet !== currentCodecSet) {
                  continue;
                }
                const levelDetails = levelInfo.details;
                const avgDuration = (partCurrent ? levelDetails?.partTarget : levelDetails?.averagetargetduration) || currentFragDuration;
                let adjustedbw;
                // follow algorithm captured from stagefright :
                // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp
                // Pick the highest bandwidth stream below or equal to estimated bandwidth.
                // consider only 80% of the available bandwidth, but if we are switching up,
                // be even more conservative (70%) to avoid overestimating and immediately
                // switching back.
                if (i <= currentLevel) {
                  adjustedbw = bwFactor * currentBw;
                } else {
                  adjustedbw = bwUpFactor * currentBw;
                }
                const bitrate = levels[i].maxBitrate;
                const fetchDuration = bitrate * avgDuration / adjustedbw;
                _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.trace(`level/adjustedbw/bitrate/avgDuration/maxFetchDuration/fetchDuration: ${i}/${Math.round(adjustedbw)}/${bitrate}/${avgDuration}/${maxFetchDuration}/${fetchDuration}`);
                // if adjusted bw is greater than level bitrate AND
                if (adjustedbw > bitrate && (
                  // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches
                  // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...
                  // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1
                  fetchDuration === 0 || !Number.isFinite(fetchDuration) || live && !this.bitrateTestDelay || fetchDuration < maxFetchDuration)) {
                  // as we are looping from highest to lowest, this will return the best achievable quality level
                  return i;
                }
              }
              // not enough time budget even with quality level 0 ... rebuffering might happen
              return -1;
            }
            set nextAutoLevel(nextLevel) {
              this._nextAutoLevel = nextLevel;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AbrController);

          /***/
        }),

/***/ "./src/controller/audio-stream-controller.ts":
/*!***************************************************!*\
  !*** ./src/controller/audio-stream-controller.ts ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base-stream-controller */ "./src/controller/base-stream-controller.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
/* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
/* harmony import */ var _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../demux/chunk-cache */ "./src/demux/chunk-cache.ts");
/* harmony import */ var _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../demux/transmuxer-interface */ "./src/demux/transmuxer-interface.ts");
/* harmony import */ var _types_transmuxer__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../types/transmuxer */ "./src/types/transmuxer.ts");
/* harmony import */ var _fragment_finders__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./fragment-finders */ "./src/controller/fragment-finders.ts");
/* harmony import */ var _utils_discontinuities__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../utils/discontinuities */ "./src/utils/discontinuities.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");













          const TICK_INTERVAL = 100; // how often to tick in ms

          class AudioStreamController extends _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__["default"] {
            videoBuffer = null;
            videoTrackCC = -1;
            waitingVideoCC = -1;
            audioSwitch = false;
            trackId = -1;
            waitingData = null;
            mainDetails = null;
            bufferFlushed = false;
            cachedTrackLoadedData = null;
            constructor(hls, fragmentTracker, keyLoader) {
              super(hls, fragmentTracker, keyLoader, '[audio-stream-controller]');
              this._registerListeners();
            }
            onHandlerDestroying() {
              this._unregisterListeners();
              this.mainDetails = null;
            }
            _registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_RESET, this.onBufferReset, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_CREATED, this.onBufferCreated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
            }
            _unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_RESET, this.onBufferReset, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_CREATED, this.onBufferCreated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
            }

            // INIT_PTS_FOUND is triggered when the video track parsed in the stream-controller has a new PTS value
            onInitPtsFound(event, {
              frag,
              id,
              initPTS
            }) {
              // Always update the new INIT PTS
              // Can change due level switch
              if (id === 'main') {
                const cc = frag.cc;
                this.initPTS[frag.cc] = initPTS;
                this.log(`InitPTS for cc: ${cc} found from main: ${initPTS}`);
                this.videoTrackCC = cc;
                // If we are waiting, tick immediately to unblock audio fragment transmuxing
                if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_INIT_PTS) {
                  this.tick();
                }
              }
            }
            startLoad(startPosition) {
              if (!this.levels) {
                this.startPosition = startPosition;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.STOPPED;
                return;
              }
              const lastCurrentTime = this.lastCurrentTime;
              this.stopLoad();
              this.setInterval(TICK_INTERVAL);
              this.fragLoadError = 0;
              if (lastCurrentTime > 0 && startPosition === -1) {
                this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);
                startPosition = lastCurrentTime;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
              } else {
                this.loadedmetadata = false;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_TRACK;
              }
              this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;
              this.tick();
            }
            doTick() {
              switch (this.state) {
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE:
                  this.doTickIdle();
                  break;
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_TRACK:
                  {
                    const {
                      levels,
                      trackId
                    } = this;
                    const details = levels?.[trackId]?.details;
                    if (details) {
                      if (this.waitForCdnTuneIn(details)) {
                        break;
                      }
                      this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_INIT_PTS;
                    }
                    break;
                  }
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING_WAITING_RETRY:
                  {
                    const now = performance.now();
                    const retryDate = this.retryDate;
                    // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading
                    if (!retryDate || now >= retryDate || this.media?.seeking) {
                      this.log('RetryDate reached, switch back to IDLE state');
                      this.resetStartWhenNotLoaded(this.trackId);
                      this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                    }
                    break;
                  }
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_INIT_PTS:
                  {
                    // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS
                    const waitingData = this.waitingData;
                    if (waitingData) {
                      const {
                        frag,
                        part,
                        cache,
                        complete
                      } = waitingData;
                      if (this.initPTS[frag.cc] !== undefined) {
                        this.waitingData = null;
                        this.waitingVideoCC = -1;
                        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING;
                        const payload = cache.flush();
                        const data = {
                          frag,
                          part,
                          payload,
                          networkDetails: null
                        };
                        this._handleFragmentLoadProgress(data);
                        if (complete) {
                          super._handleFragmentLoadComplete(data);
                        }
                      } else if (this.videoTrackCC !== this.waitingVideoCC) {
                        // Drop waiting fragment if videoTrackCC has changed since waitingFragment was set and initPTS was not found
                        this.log(`Waiting fragment cc (${frag.cc}) cancelled because video is at cc ${this.videoTrackCC}`);
                        this.clearWaitingFragment();
                      } else {
                        // Drop waiting fragment if an earlier fragment is needed
                        const pos = this.getLoadPosition();
                        const bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.bufferInfo(this.mediaBuffer, pos, this.config.maxBufferHole);
                        const waitingFragmentAtPosition = (0, _fragment_finders__WEBPACK_IMPORTED_MODULE_10__.fragmentWithinToleranceTest)(bufferInfo.end, this.config.maxFragLookUpTolerance, frag);
                        if (waitingFragmentAtPosition < 0) {
                          this.log(`Waiting fragment cc (${frag.cc}) @ ${frag.start} cancelled because another fragment at ${bufferInfo.end} is needed`);
                          this.clearWaitingFragment();
                        }
                      }
                    } else {
                      this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                    }
                  }
              }
              this.onTickEnd();
            }
            clearWaitingFragment() {
              const waitingData = this.waitingData;
              if (waitingData) {
                this.fragmentTracker.removeFragment(waitingData.frag);
                this.waitingData = null;
                this.waitingVideoCC = -1;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
              }
            }
            resetLoadingState() {
              this.clearWaitingFragment();
              super.resetLoadingState();
            }
            onTickEnd() {
              const {
                media
              } = this;
              if (!media || !media.readyState) {
                // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)
                return;
              }
              this.lastCurrentTime = media.currentTime;
            }
            doTickIdle() {
              const {
                hls,
                levels,
                media,
                trackId
              } = this;
              const config = hls.config;
              if (!levels || !levels[trackId]) {
                return;
              }

              // if video not attached AND
              // start fragment already requested OR start frag prefetch not enabled
              // exit loop
              // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop
              if (!media && (this.startFragRequested || !config.startFragPrefetch)) {
                return;
              }
              const levelInfo = levels[trackId];
              const trackDetails = levelInfo.details;
              if (!trackDetails || trackDetails.live && this.levelLastLoaded !== trackId || this.waitForCdnTuneIn(trackDetails)) {
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_TRACK;
                return;
              }
              const bufferable = this.mediaBuffer ? this.mediaBuffer : this.media;
              if (this.bufferFlushed && bufferable) {
                this.bufferFlushed = false;
                this.afterBufferFlushed(bufferable, _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO);
              }
              const bufferInfo = this.getFwdBufferInfo(bufferable, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO);
              if (bufferInfo === null) {
                return;
              }
              const audioSwitch = this.audioSwitch;
              if (!audioSwitch && this._streamEnded(bufferInfo, trackDetails)) {
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_EOS, {
                  type: 'audio'
                });
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ENDED;
                return;
              }
              const mainBufferInfo = this.getFwdBufferInfo(this.videoBuffer ? this.videoBuffer : this.media, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
              const bufferLen = bufferInfo.len;
              const maxBufLen = this.getMaxBufferLength(mainBufferInfo?.len);

              // if buffer length is less than maxBufLen try to load a new fragment
              if (bufferLen >= maxBufLen && !audioSwitch) {
                return;
              }
              const fragments = trackDetails.fragments;
              const start = fragments[0].start;
              let targetBufferTime = bufferInfo.end;
              if (audioSwitch && media) {
                const pos = this.getLoadPosition();
                targetBufferTime = pos;
                // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime
                if (trackDetails.PTSKnown && pos < start) {
                  // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start
                  if (bufferInfo.end > start || bufferInfo.nextStart) {
                    this.log('Alt audio track ahead of main track, seek to start of alt audio track');
                    media.currentTime = start + 0.05;
                  }
                }
              }

              // buffer audio up to one target duration ahead of main buffer
              if (mainBufferInfo && targetBufferTime > mainBufferInfo.end + trackDetails.targetduration) {
                return;
              }
              // wait for main buffer after buffing some audio
              if ((!mainBufferInfo || !mainBufferInfo.len) && bufferInfo.len) {
                return;
              }
              const frag = this.getNextFragment(targetBufferTime, trackDetails);
              if (!frag) {
                this.bufferFlushed = true;
                return;
              }
              this.loadFragment(frag, trackDetails, targetBufferTime);
            }
            getMaxBufferLength(mainBufferLength) {
              const maxConfigBuffer = super.getMaxBufferLength();
              if (!mainBufferLength) {
                return maxConfigBuffer;
              }
              return Math.max(maxConfigBuffer, mainBufferLength);
            }
            onMediaDetaching() {
              this.videoBuffer = null;
              super.onMediaDetaching();
            }
            onAudioTracksUpdated(event, {
              audioTracks
            }) {
              this.resetTransmuxer();
              this.levels = audioTracks.map(mediaPlaylist => new _types_level__WEBPACK_IMPORTED_MODULE_4__.Level(mediaPlaylist));
            }
            onAudioTrackSwitching(event, data) {
              // if any URL found on new audio track, it is an alternate audio track
              const altAudio = !!data.url;
              this.trackId = data.id;
              const {
                fragCurrent
              } = this;
              if (fragCurrent) {
                fragCurrent.abortRequests();
              }
              this.fragCurrent = null;
              this.clearWaitingFragment();
              // destroy useless transmuxer when switching audio to main
              if (!altAudio) {
                this.resetTransmuxer();
              } else {
                // switching to audio track, start timer if not already started
                this.setInterval(TICK_INTERVAL);
              }

              // should we switch tracks ?
              if (altAudio) {
                this.audioSwitch = true;
                // main audio track are handled by stream-controller, just do something if switching to alt audio track
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
              } else {
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.STOPPED;
              }
              this.tick();
            }
            onManifestLoading() {
              this.mainDetails = null;
              this.fragmentTracker.removeAllFragments();
              this.startPosition = this.lastCurrentTime = 0;
              this.bufferFlushed = false;
            }
            onLevelLoaded(event, data) {
              this.mainDetails = data.details;
              if (this.cachedTrackLoadedData !== null) {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_LOADED, this.cachedTrackLoadedData);
                this.cachedTrackLoadedData = null;
              }
            }
            onAudioTrackLoaded(event, data) {
              if (this.mainDetails == null) {
                this.cachedTrackLoadedData = data;
                return;
              }
              const {
                levels
              } = this;
              const {
                details: newDetails,
                id: trackId
              } = data;
              if (!levels) {
                this.warn(`Audio tracks were reset while loading level ${trackId}`);
                return;
              }
              this.log(`Track ${trackId} loaded [${newDetails.startSN},${newDetails.endSN}],duration:${newDetails.totalduration}`);
              const track = levels[trackId];
              let sliding = 0;
              if (newDetails.live || track.details?.live) {
                const mainDetails = this.mainDetails;
                if (!newDetails.fragments[0]) {
                  newDetails.deltaUpdateFailed = true;
                }
                if (newDetails.deltaUpdateFailed || !mainDetails) {
                  return;
                }
                if (!track.details && newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {
                  // Make sure our audio rendition is aligned with the "main" rendition, using
                  // pdt as our reference times.
                  (0, _utils_discontinuities__WEBPACK_IMPORTED_MODULE_11__.alignMediaPlaylistByPDT)(newDetails, mainDetails);
                  sliding = newDetails.fragments[0].start;
                } else {
                  sliding = this.alignPlaylists(newDetails, track.details);
                }
              }
              track.details = newDetails;
              this.levelLastLoaded = trackId;

              // compute start position if we are aligned with the main playlist
              if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {
                this.setStartPosition(track.details, sliding);
              }
              // only switch back to IDLE state if we were waiting for track to start downloading a new fragment
              if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_TRACK && !this.waitForCdnTuneIn(newDetails)) {
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
              }

              // trigger handler right now
              this.tick();
            }
            _handleFragmentLoadProgress(data) {
              const {
                frag,
                part,
                payload
              } = data;
              const {
                config,
                trackId,
                levels
              } = this;
              if (!levels) {
                this.warn(`Audio tracks were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);
                return;
              }
              const track = levels[trackId];
              console.assert(track, 'Audio track is defined on fragment load progress');
              const details = track.details;
              console.assert(details, 'Audio track details are defined on fragment load progress');
              const audioCodec = config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2';
              let transmuxer = this.transmuxer;
              if (!transmuxer) {
                transmuxer = this.transmuxer = new _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_8__["default"](this.hls, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));
              }

              // Check if we have video initPTS
              // If not we need to wait for it
              const initPTS = this.initPTS[frag.cc];
              const initSegmentData = frag.initSegment?.data;
              if (initPTS !== undefined) {
                // this.log(`Transmuxing ${sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);
                // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)
                const accurateTimeOffset = false; // details.PTSKnown || !details.live;
                const partIndex = part ? part.index : -1;
                const partial = partIndex !== -1;
                const chunkMeta = new _types_transmuxer__WEBPACK_IMPORTED_MODULE_9__.ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);
                transmuxer.push(payload, initSegmentData, audioCodec, '', frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);
              } else {
                this.log(`Unknown video PTS for cc ${frag.cc}, waiting for video PTS before demuxing audio frag ${frag.sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);
                const {
                  cache
                } = this.waitingData = this.waitingData || {
                  frag,
                  part,
                  cache: new _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_7__["default"](),
                  complete: false
                };
                cache.push(new Uint8Array(payload));
                this.waitingVideoCC = this.videoTrackCC;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_INIT_PTS;
              }
            }
            _handleFragmentLoadComplete(fragLoadedData) {
              if (this.waitingData) {
                this.waitingData.complete = true;
                return;
              }
              super._handleFragmentLoadComplete(fragLoadedData);
            }
            onBufferReset( /* event: Events.BUFFER_RESET */
            ) {
              // reset reference to sourcebuffers
              this.mediaBuffer = this.videoBuffer = null;
              this.loadedmetadata = false;
            }
            onBufferCreated(event, data) {
              const audioTrack = data.tracks.audio;
              if (audioTrack) {
                this.mediaBuffer = audioTrack.buffer || null;
              }
              if (data.tracks.video) {
                this.videoBuffer = data.tracks.video.buffer || null;
              }
            }
            onFragBuffered(event, data) {
              const {
                frag,
                part
              } = data;
              if (frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO) {
                if (!this.loadedmetadata && frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN) {
                  if ((this.videoBuffer || this.media)?.buffered.length) {
                    this.loadedmetadata = true;
                  }
                }
                return;
              }
              if (this.fragContextChanged(frag)) {
                // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion
                // Avoid setting state back to IDLE or concluding the audio switch; otherwise, the switched-to track will not buffer
                this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}, audioSwitch: ${this.audioSwitch}`);
                return;
              }
              if (frag.sn !== 'initSegment') {
                this.fragPrevious = frag;
                if (this.audioSwitch) {
                  this.audioSwitch = false;
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_SWITCHED, {
                    id: this.trackId
                  });
                }
              }
              this.fragBufferedComplete(frag, part);
            }
            onError(event, data) {
              if (data.type === _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorTypes.KEY_SYSTEM_ERROR) {
                this.onFragmentOrKeyLoadError(_types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO, data);
                return;
              }
              switch (data.details) {
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.FRAG_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.FRAG_LOAD_TIMEOUT:
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.FRAG_PARSING_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.KEY_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.KEY_LOAD_TIMEOUT:
                  // TODO: Skip fragments that do not belong to this.fragCurrent audio-group id
                  this.onFragmentOrKeyLoadError(_types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO, data);
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.AUDIO_TRACK_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:
                  //  when in ERROR state, don't switch back to IDLE state in case a non-fatal error is received
                  if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ERROR && this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.STOPPED) {
                    // if fatal error, stop processing, otherwise move to IDLE to retry loading
                    this.state = data.fatal ? _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ERROR : _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                    this.warn(`${data.details} while loading frag, switching to ${this.state} state`);
                  }
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_12__.ErrorDetails.BUFFER_FULL_ERROR:
                  // if in appending state
                  if (data.parent === 'audio' && (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSED)) {
                    let flushBuffer = true;
                    const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO);
                    // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end
                    // reduce max buf len if current position is buffered
                    if (bufferedInfo && bufferedInfo.len > 0.5) {
                      flushBuffer = !this.reduceMaxBufferLength(bufferedInfo.len);
                    }
                    if (flushBuffer) {
                      // current position is not buffered, but browser is still complaining about buffer full error
                      // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708
                      // in that case flush the whole audio buffer to recover
                      this.warn('Buffer full error also media.currentTime is not buffered, flush audio buffer');
                      this.fragCurrent = null;
                      super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');
                    }
                    this.resetLoadingState();
                  }
                  break;
                default:
                  break;
              }
            }
            onBufferFlushed(event, {
              type
            }) {
              if (type === _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO) {
                this.bufferFlushed = true;
                if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ENDED) {
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                }
              }
            }
            _handleTransmuxComplete(transmuxResult) {
              const id = 'audio';
              const {
                hls
              } = this;
              const {
                remuxResult,
                chunkMeta
              } = transmuxResult;
              const context = this.getCurrentContext(chunkMeta);
              if (!context) {
                this.warn(`The loading context changed while buffering fragment ${chunkMeta.sn} of level ${chunkMeta.level}. This chunk will not be buffered.`);
                this.resetStartWhenNotLoaded(chunkMeta.level);
                return;
              }
              const {
                frag,
                part,
                level: {
                  details
                }
              } = context;
              const {
                audio,
                text,
                id3,
                initSegment
              } = remuxResult;

              // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.
              // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.
              if (this.fragContextChanged(frag) || !details) {
                return;
              }
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING;
              if (this.audioSwitch && audio) {
                this.completeAudioSwitch();
              }
              if (initSegment?.tracks) {
                this._bufferInitSegment(initSegment.tracks, frag, chunkMeta);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_PARSING_INIT_SEGMENT, {
                  frag,
                  id,
                  tracks: initSegment.tracks
                });
                // Only flush audio from old audio tracks when PTS is known on new audio track
              }

              if (audio) {
                const {
                  startPTS,
                  endPTS,
                  startDTS,
                  endDTS
                } = audio;
                if (part) {
                  part.elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO] = {
                    startPTS,
                    endPTS,
                    startDTS,
                    endDTS
                  };
                }
                frag.setElementaryStreamInfo(_loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);
                this.bufferFragmentData(audio, frag, part, chunkMeta);
              }
              if (id3?.samples?.length) {
                const emittedID3 = Object.assign({
                  id,
                  frag,
                  details
                }, id3);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_PARSING_METADATA, emittedID3);
              }
              if (text) {
                const emittedText = Object.assign({
                  id,
                  frag,
                  details
                }, text);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_PARSING_USERDATA, emittedText);
              }
            }
            _bufferInitSegment(tracks, frag, chunkMeta) {
              if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING) {
                return;
              }
              // delete any video track found on audio transmuxer
              if (tracks.video) {
                delete tracks.video;
              }

              // include levelCodec in audio and video tracks
              const track = tracks.audio;
              if (!track) {
                return;
              }
              track.levelCodec = track.codec;
              track.id = 'audio';
              this.log(`Init audio buffer, container:${track.container}, codecs[parsed]=[${track.codec}]`);
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_CODECS, tracks);
              const initSegment = track.initSegment;
              if (initSegment?.byteLength) {
                const segment = {
                  type: 'audio',
                  frag,
                  part: null,
                  chunkMeta,
                  parent: frag.type,
                  data: initSegment
                };
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.BUFFER_APPENDING, segment);
              }
              // trigger handler right now
              this.tick();
            }
            loadFragment(frag, trackDetails, targetBufferTime) {
              // only load if fragment is not loaded or if in audio switch
              const fragState = this.fragmentTracker.getState(frag);
              this.fragCurrent = frag;

              // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch
              if (this.audioSwitch || fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_3__.FragmentState.NOT_LOADED || fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_3__.FragmentState.PARTIAL) {
                if (frag.sn === 'initSegment') {
                  this._loadInitSegment(frag, trackDetails);
                } else if (trackDetails.live && !Number.isFinite(this.initPTS[frag.cc])) {
                  this.log(`Waiting for video PTS in continuity counter ${frag.cc} of live stream before loading audio fragment ${frag.sn} of level ${this.trackId}`);
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_INIT_PTS;
                } else {
                  this.startFragRequested = true;
                  super.loadFragment(frag, trackDetails, targetBufferTime);
                }
              }
            }
            completeAudioSwitch() {
              const {
                hls,
                media,
                trackId
              } = this;
              if (media) {
                this.log('Switching audio track : flushing all audio');
                super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');
              }
              this.audioSwitch = false;
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_SWITCHED, {
                id: trackId
              });
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AudioStreamController);

          /***/
        }),

/***/ "./src/controller/audio-track-controller.ts":
/*!**************************************************!*\
  !*** ./src/controller/audio-track-controller.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./base-playlist-controller */ "./src/controller/base-playlist-controller.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");




          class AudioTrackController extends _base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__["default"] {
            tracks = [];
            groupId = null;
            tracksInGroup = [];
            trackId = -1;
            trackName = '';
            selectDefaultTrack = true;
            constructor(hls) {
              super(hls, '[audio-track-controller]');
              this.registerListeners();
            }
            registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, this.onError, this);
            }
            unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, this.onError, this);
            }
            destroy() {
              this.unregisterListeners();
              this.tracks.length = 0;
              this.tracksInGroup.length = 0;
              super.destroy();
            }
            onManifestLoading() {
              this.tracks = [];
              this.groupId = null;
              this.tracksInGroup = [];
              this.trackId = -1;
              this.trackName = '';
              this.selectDefaultTrack = true;
            }
            onManifestParsed(event, data) {
              this.tracks = data.audioTracks || [];
            }
            onAudioTrackLoaded(event, data) {
              const {
                id,
                details
              } = data;
              const currentTrack = this.tracksInGroup[id];
              if (!currentTrack) {
                this.warn(`Invalid audio track id ${id}`);
                return;
              }
              const curDetails = currentTrack.details;
              currentTrack.details = data.details;
              this.log(`audioTrack ${id} loaded [${details.startSN}-${details.endSN}]`);
              if (id === this.trackId) {
                this.retryCount = 0;
                this.playlistLoaded(id, data, curDetails);
              }
            }
            onLevelLoading(event, data) {
              this.switchLevel(data.level);
            }
            onLevelSwitching(event, data) {
              this.switchLevel(data.level);
            }
            switchLevel(levelIndex) {
              const levelInfo = this.hls.levels[levelIndex];
              if (!levelInfo?.audioGroupIds) {
                return;
              }
              const audioGroupId = levelInfo.audioGroupIds[levelInfo.urlId];
              if (this.groupId !== audioGroupId) {
                this.groupId = audioGroupId;
                const audioTracks = this.tracks.filter(track => !audioGroupId || track.groupId === audioGroupId);

                // Disable selectDefaultTrack if there are no default tracks
                if (this.selectDefaultTrack && !audioTracks.some(track => track.default)) {
                  this.selectDefaultTrack = false;
                }
                this.tracksInGroup = audioTracks;
                const audioTracksUpdated = {
                  audioTracks
                };
                this.log(`Updating audio tracks, ${audioTracks.length} track(s) found in "${audioGroupId}" group-id`);
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACKS_UPDATED, audioTracksUpdated);
                this.selectInitialTrack();
              }
            }
            onError(event, data) {
              super.onError(event, data);
              if (data.fatal || !data.context) {
                return;
              }
              if (data.context.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__.PlaylistContextType.AUDIO_TRACK && data.context.id === this.trackId && data.context.groupId === this.groupId) {
                this.retryLoadingOrFail(data);
              }
            }
            get audioTracks() {
              return this.tracksInGroup;
            }
            get audioTrack() {
              return this.trackId;
            }
            set audioTrack(newId) {
              // If audio track is selected from API then don't choose from the manifest default track
              this.selectDefaultTrack = false;
              this.setAudioTrack(newId);
            }
            setAudioTrack(newId) {
              const tracks = this.tracksInGroup;

              // check if level idx is valid
              if (newId < 0 || newId >= tracks.length) {
                this.warn('Invalid id passed to audio-track controller');
                return;
              }

              // stopping live reloading timer if any
              this.clearTimer();
              const lastTrack = tracks[this.trackId];
              this.log(`Now switching to audio-track index ${newId}`);
              const track = tracks[newId];
              const {
                id,
                groupId = '',
                name,
                type,
                url
              } = track;
              this.trackId = newId;
              this.trackName = name;
              this.selectDefaultTrack = false;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_SWITCHING, {
                id,
                groupId,
                name,
                type,
                url
              });
              // Do not reload track unless live
              if (track.details && !track.details.live) {
                return;
              }
              const hlsUrlParameters = this.switchParams(track.url, lastTrack?.details);
              this.loadPlaylist(hlsUrlParameters);
            }
            selectInitialTrack() {
              const audioTracks = this.tracksInGroup;
              console.assert(audioTracks.length, 'Initial audio track should be selected when tracks are known');
              const currentAudioTrackName = this.trackName;
              const trackId = this.findTrackId(currentAudioTrackName) || this.findTrackId();
              if (trackId !== -1) {
                this.setAudioTrack(trackId);
              } else {
                this.warn(`No track found for running audio group-ID: ${this.groupId}`);
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.AUDIO_TRACK_LOAD_ERROR,
                  fatal: true
                });
              }
            }
            findTrackId(name) {
              const audioTracks = this.tracksInGroup;
              for (let i = 0; i < audioTracks.length; i++) {
                const track = audioTracks[i];
                if (!this.selectDefaultTrack || track.default) {
                  if (!name || name === track.name) {
                    return track.id;
                  }
                }
              }
              return -1;
            }
            loadPlaylist(hlsUrlParameters) {
              super.loadPlaylist();
              const audioTrack = this.tracksInGroup[this.trackId];
              if (this.shouldLoadTrack(audioTrack)) {
                const id = audioTrack.id;
                const groupId = audioTrack.groupId;
                let url = audioTrack.url;
                if (hlsUrlParameters) {
                  try {
                    url = hlsUrlParameters.addDirectives(url);
                  } catch (error) {
                    this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);
                  }
                }
                // track not retrieved yet, or live playlist we need to (re)load it
                this.log(`loading audio-track playlist for id: ${id}`);
                this.clearTimer();
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_LOADING, {
                  url,
                  id,
                  groupId,
                  deliveryDirectives: hlsUrlParameters || null
                });
              }
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AudioTrackController);

          /***/
        }),

/***/ "./src/controller/base-playlist-controller.ts":
/*!****************************************************!*\
  !*** ./src/controller/base-playlist-controller.ts ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BasePlaylistController)
            /* harmony export */
          });
/* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
/* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");




          class BasePlaylistController {
            timer = -1;
            requestScheduled = -1;
            canLoad = false;
            retryCount = 0;
            constructor(hls, logPrefix) {
              this.log = _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.log.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger, `${logPrefix}:`);
              this.warn = _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.warn.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger, `${logPrefix}:`);
              this.hls = hls;
            }
            destroy() {
              this.clearTimer();
              // @ts-ignore
              this.hls = this.log = this.warn = null;
            }
            onError(event, data) {
              if (data.fatal && (data.type === _errors__WEBPACK_IMPORTED_MODULE_3__.ErrorTypes.NETWORK_ERROR || data.type === _errors__WEBPACK_IMPORTED_MODULE_3__.ErrorTypes.KEY_SYSTEM_ERROR)) {
                this.stopLoad();
              }
            }
            clearTimer() {
              clearTimeout(this.timer);
              this.timer = -1;
            }
            startLoad() {
              this.canLoad = true;
              this.retryCount = 0;
              this.requestScheduled = -1;
              this.loadPlaylist();
            }
            stopLoad() {
              this.canLoad = false;
              this.clearTimer();
            }
            switchParams(playlistUri, previous) {
              const renditionReports = previous?.renditionReports;
              if (renditionReports) {
                for (let i = 0; i < renditionReports.length; i++) {
                  const attr = renditionReports[i];
                  let uri;
                  try {
                    uri = new self.URL(attr.URI, previous.url).href;
                  } catch (error) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.warn(`Could not construct new URL for Rendition Report: ${error}`);
                    uri = attr.URI || '';
                  }
                  if (uri === playlistUri.slice(-uri.length)) {
                    const msn = parseInt(attr['LAST-MSN']) || previous?.lastPartSn;
                    let part = parseInt(attr['LAST-PART']) || previous?.lastPartIndex;
                    if (this.hls.config.lowLatencyMode) {
                      const currentGoal = Math.min(previous.age - previous.partTarget, previous.targetduration);
                      if (part >= 0 && currentGoal > previous.partTarget) {
                        part += 1;
                      }
                    }
                    return new _types_level__WEBPACK_IMPORTED_MODULE_0__.HlsUrlParameters(msn, part >= 0 ? part : undefined, _types_level__WEBPACK_IMPORTED_MODULE_0__.HlsSkip.No);
                  }
                }
              }
            }
            loadPlaylist(hlsUrlParameters) {
              if (this.requestScheduled === -1) {
                this.requestScheduled = self.performance.now();
              }
            }
            shouldLoadTrack(track) {
              return this.canLoad && track && !!track.url && (!track.details || track.details.live);
            }
            playlistLoaded(index, data, previousDetails) {
              const {
                details,
                stats
              } = data;

              // Set last updated date-time
              const now = self.performance.now();
              const elapsed = stats.loading.first ? Math.max(0, now - stats.loading.first) : 0;
              details.advancedDateTime = Date.now() - elapsed;

              // if current playlist is a live playlist, arm a timer to reload it
              if (details.live || previousDetails?.live) {
                details.reloaded(previousDetails);
                if (previousDetails) {
                  this.log(`live playlist ${index} ${details.advanced ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex : 'MISSED'}`);
                }
                // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments
                if (previousDetails && details.fragments.length > 0) {
                  (0, _level_helper__WEBPACK_IMPORTED_MODULE_1__.mergeDetails)(previousDetails, details);
                }
                if (!this.canLoad || !details.live) {
                  return;
                }
                let deliveryDirectives;
                let msn = undefined;
                let part = undefined;
                if (details.canBlockReload && details.endSN && details.advanced) {
                  // Load level with LL-HLS delivery directives
                  const lowLatencyMode = this.hls.config.lowLatencyMode;
                  const lastPartSn = details.lastPartSn;
                  const endSn = details.endSN;
                  const lastPartIndex = details.lastPartIndex;
                  const hasParts = lastPartIndex !== -1;
                  const lastPart = lastPartSn === endSn;
                  // When low latency mode is disabled, we'll skip part requests once the last part index is found
                  const nextSnStartIndex = lowLatencyMode ? 0 : lastPartIndex;
                  if (hasParts) {
                    msn = lastPart ? endSn + 1 : lastPartSn;
                    part = lastPart ? nextSnStartIndex : lastPartIndex + 1;
                  } else {
                    msn = endSn + 1;
                  }
                  // Low-Latency CDN Tune-in: "age" header and time since load indicates we're behind by more than one part
                  // Update directives to obtain the Playlist that has the estimated additional duration of media
                  const lastAdvanced = details.age;
                  const cdnAge = lastAdvanced + details.ageHeader;
                  let currentGoal = Math.min(cdnAge - details.partTarget, details.targetduration * 1.5);
                  if (currentGoal > 0) {
                    if (previousDetails && currentGoal > previousDetails.tuneInGoal) {
                      // If we attempted to get the next or latest playlist update, but currentGoal increased,
                      // then we either can't catchup, or the "age" header cannot be trusted.
                      this.warn(`CDN Tune-in goal increased from: ${previousDetails.tuneInGoal} to: ${currentGoal} with playlist age: ${details.age}`);
                      currentGoal = 0;
                    } else {
                      const segments = Math.floor(currentGoal / details.targetduration);
                      msn += segments;
                      if (part !== undefined) {
                        const parts = Math.round(currentGoal % details.targetduration / details.partTarget);
                        part += parts;
                      }
                      this.log(`CDN Tune-in age: ${details.ageHeader}s last advanced ${lastAdvanced.toFixed(2)}s goal: ${currentGoal} skip sn ${segments} to part ${part}`);
                    }
                    details.tuneInGoal = currentGoal;
                  }
                  deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);
                  if (lowLatencyMode || !lastPart) {
                    this.loadPlaylist(deliveryDirectives);
                    return;
                  }
                } else {
                  deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);
                }
                const bufferInfo = this.hls.mainForwardBufferInfo;
                const position = bufferInfo ? bufferInfo.end - bufferInfo.len : 0;
                const distanceToLiveEdgeMs = (details.edge - position) * 1000;
                const reloadInterval = (0, _level_helper__WEBPACK_IMPORTED_MODULE_1__.computeReloadInterval)(details, distanceToLiveEdgeMs);
                if (!details.updated) {
                  this.requestScheduled = -1;
                } else if (now > this.requestScheduled + reloadInterval) {
                  this.requestScheduled = stats.loading.start;
                }
                if (msn !== undefined && details.canBlockReload) {
                  this.requestScheduled = stats.loading.first + reloadInterval - (details.partTarget * 1000 || 1000);
                } else {
                  this.requestScheduled = (this.requestScheduled === -1 ? now : this.requestScheduled) + reloadInterval;
                }
                let estimatedTimeUntilUpdate = this.requestScheduled - now;
                estimatedTimeUntilUpdate = Math.max(0, estimatedTimeUntilUpdate);
                this.log(`reload live playlist ${index} in ${Math.round(estimatedTimeUntilUpdate)} ms`);
                //     this.log(
                //       `live reload ${details.updated ? 'REFRESHED' : 'MISSED'}
                // reload in ${estimatedTimeUntilUpdate / 1000}
                // round trip ${(stats.loading.end - stats.loading.start) / 1000}
                // diff ${
                //   (reloadInterval -
                //     (estimatedTimeUntilUpdate + stats.loading.end - stats.loading.start)) /
                //   1000
                // }
                // reload interval ${reloadInterval / 1000}
                // target duration ${details.targetduration}
                // distance to edge ${distanceToLiveEdgeMs / 1000}`
                //     );

                this.timer = self.setTimeout(() => this.loadPlaylist(deliveryDirectives), estimatedTimeUntilUpdate);
              } else {
                this.clearTimer();
              }
            }
            getDeliveryDirectives(details, previousDeliveryDirectives, msn, part) {
              let skip = (0, _types_level__WEBPACK_IMPORTED_MODULE_0__.getSkipValue)(details, msn);
              if (previousDeliveryDirectives?.skip && details.deltaUpdateFailed) {
                msn = previousDeliveryDirectives.msn;
                part = previousDeliveryDirectives.part;
                skip = _types_level__WEBPACK_IMPORTED_MODULE_0__.HlsSkip.No;
              }
              return new _types_level__WEBPACK_IMPORTED_MODULE_0__.HlsUrlParameters(msn, part, skip);
            }
            retryLoadingOrFail(errorEvent) {
              const {
                config
              } = this.hls;
              const retry = this.retryCount < config.levelLoadingMaxRetry;
              if (retry) {
                this.requestScheduled = -1;
                this.retryCount++;
                if (errorEvent.details.indexOf('LoadTimeOut') > -1 && errorEvent.context?.deliveryDirectives) {
                  // The LL-HLS request already timed out so retry immediately
                  this.warn(`retry playlist loading #${this.retryCount} after "${errorEvent.details}"`);
                  this.loadPlaylist();
                } else {
                  // exponential backoff capped to max retry timeout
                  const delay = Math.min(Math.pow(2, this.retryCount) * config.levelLoadingRetryDelay, config.levelLoadingMaxRetryTimeout);
                  // Schedule level/track reload
                  this.timer = self.setTimeout(() => this.loadPlaylist(), delay);
                  this.warn(`retry playlist loading #${this.retryCount} in ${delay} ms after "${errorEvent.details}"`);
                }
              } else {
                this.warn(`cannot recover from error "${errorEvent.details}"`);
                // stopping live reloading timer if any
                this.clearTimer();
                // switch error to fatal
                errorEvent.fatal = true;
              }
              return retry;
            }
          }

          /***/
        }),

/***/ "./src/controller/base-stream-controller.ts":
/*!**************************************************!*\
  !*** ./src/controller/base-stream-controller.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "State": () => (/* binding */ State),
/* harmony export */   "default": () => (/* binding */ BaseStreamController)
            /* harmony export */
          });
/* harmony import */ var _task_loop__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../task-loop */ "./src/task-loop.ts");
/* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _types_transmuxer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/transmuxer */ "./src/types/transmuxer.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _utils_discontinuities__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/discontinuities */ "./src/utils/discontinuities.ts");
/* harmony import */ var _fragment_finders__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./fragment-finders */ "./src/controller/fragment-finders.ts");
/* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
/* harmony import */ var _loader_fragment_loader__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../loader/fragment-loader */ "./src/loader/fragment-loader.ts");
/* harmony import */ var _crypt_decrypter__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../crypt/decrypter */ "./src/crypt/decrypter.ts");
/* harmony import */ var _utils_time_ranges__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../utils/time-ranges */ "./src/utils/time-ranges.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");















          const State = {
            STOPPED: 'STOPPED',
            IDLE: 'IDLE',
            KEY_LOADING: 'KEY_LOADING',
            FRAG_LOADING: 'FRAG_LOADING',
            FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',
            WAITING_TRACK: 'WAITING_TRACK',
            PARSING: 'PARSING',
            PARSED: 'PARSED',
            ENDED: 'ENDED',
            ERROR: 'ERROR',
            WAITING_INIT_PTS: 'WAITING_INIT_PTS',
            WAITING_LEVEL: 'WAITING_LEVEL'
          };
          class BaseStreamController extends _task_loop__WEBPACK_IMPORTED_MODULE_0__["default"] {
            fragPrevious = null;
            fragCurrent = null;
            transmuxer = null;
            _state = State.STOPPED;
            media = null;
            mediaBuffer = null;
            bitrateTest = false;
            lastCurrentTime = 0;
            nextLoadPosition = 0;
            startPosition = 0;
            loadedmetadata = false;
            fragLoadError = 0;
            retryDate = 0;
            levels = null;
            levelLastLoaded = null;
            startFragRequested = false;
            initPTS = [];
            onvseeking = null;
            onvended = null;
            logPrefix = '';
            constructor(hls, fragmentTracker, keyLoader, logPrefix) {
              super();
              this.logPrefix = logPrefix;
              this.log = _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.log.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger, `${logPrefix}:`);
              this.warn = _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger, `${logPrefix}:`);
              this.hls = hls;
              this.fragmentLoader = new _loader_fragment_loader__WEBPACK_IMPORTED_MODULE_11__["default"](hls.config);
              this.keyLoader = keyLoader;
              this.fragmentTracker = fragmentTracker;
              this.config = hls.config;
              this.decrypter = new _crypt_decrypter__WEBPACK_IMPORTED_MODULE_12__["default"](hls.config);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_4__.Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
            }
            doTick() {
              this.onTickEnd();
            }
            onTickEnd() { }

            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            startLoad(startPosition) { }
            stopLoad() {
              this.fragmentLoader.abort();
              this.keyLoader.abort();
              const frag = this.fragCurrent;
              if (frag) {
                frag.abortRequests();
                this.fragmentTracker.removeFragment(frag);
              }
              this.resetTransmuxer();
              this.fragCurrent = null;
              this.fragPrevious = null;
              this.clearInterval();
              this.clearNextTick();
              this.state = State.STOPPED;
            }
            _streamEnded(bufferInfo, levelDetails) {
              // If playlist is live, there is another buffered range after the current range, nothing buffered, media is detached,
              // of nothing loading/loaded return false
              if (levelDetails.live || bufferInfo.nextStart || !bufferInfo.end || !this.media) {
                return false;
              }
              const partList = levelDetails.partList;
              // Since the last part isn't guaranteed to correspond to the last playlist segment for Low-Latency HLS,
              // check instead if the last part is buffered.
              if (partList?.length) {
                const lastPart = partList[partList.length - 1];

                // Checking the midpoint of the part for potential margin of error and related issues.
                // NOTE: Technically I believe parts could yield content that is < the computed duration (including potential a duration of 0)
                // and still be spec-compliant, so there may still be edge cases here. Likewise, there could be issues in end of stream
                // part mismatches for independent audio and video playlists/segments.
                const lastPartBuffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.isBuffered(this.media, lastPart.start + lastPart.duration / 2);
                return lastPartBuffered;
              }
              const playlistType = levelDetails.fragments[levelDetails.fragments.length - 1].type;
              return this.fragmentTracker.isEndListAppended(playlistType);
            }
            getLevelDetails() {
              if (this.levels && this.levelLastLoaded !== null) {
                return this.levels[this.levelLastLoaded]?.details;
              }
            }
            onMediaAttached(event, data) {
              const media = this.media = this.mediaBuffer = data.media;
              this.onvseeking = this.onMediaSeeking.bind(this);
              this.onvended = this.onMediaEnded.bind(this);
              media.addEventListener('seeking', this.onvseeking);
              media.addEventListener('ended', this.onvended);
              const config = this.config;
              if (this.levels && config.autoStartLoad && this.state === State.STOPPED) {
                this.startLoad(config.startPosition);
              }
            }
            onMediaDetaching() {
              const media = this.media;
              if (media?.ended) {
                this.log('MSE detaching and video ended, reset startPosition');
                this.startPosition = this.lastCurrentTime = 0;
              }

              // remove video listeners
              if (media && this.onvseeking && this.onvended) {
                media.removeEventListener('seeking', this.onvseeking);
                media.removeEventListener('ended', this.onvended);
                this.onvseeking = this.onvended = null;
              }
              if (this.keyLoader) {
                this.keyLoader.detach();
              }
              this.media = this.mediaBuffer = null;
              this.loadedmetadata = false;
              this.fragmentTracker.removeAllFragments();
              this.stopLoad();
            }
            onMediaSeeking() {
              const {
                config,
                fragCurrent,
                media,
                mediaBuffer,
                state
              } = this;
              const currentTime = media ? media.currentTime : 0;
              const bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.bufferInfo(mediaBuffer ? mediaBuffer : media, currentTime, config.maxBufferHole);
              this.log(`media seeking to ${Number.isFinite(currentTime) ? currentTime.toFixed(3) : currentTime}, state: ${state}`);
              if (this.state === State.ENDED) {
                this.resetLoadingState();
              } else if (fragCurrent) {
                // Seeking while frag load is in progress
                const tolerance = config.maxFragLookUpTolerance;
                const fragStartOffset = fragCurrent.start - tolerance;
                const fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;
                // if seeking out of buffered range or into new one
                if (!bufferInfo.len || fragEndOffset < bufferInfo.start || fragStartOffset > bufferInfo.end) {
                  const pastFragment = currentTime > fragEndOffset;
                  // if the seek position is outside the current fragment range
                  if (currentTime < fragStartOffset || pastFragment) {
                    if (pastFragment && fragCurrent.loader) {
                      this.log('seeking outside of buffer while fragment load in progress, cancel fragment load');
                      fragCurrent.abortRequests();
                    }
                    this.resetLoadingState();
                  }
                }
              }
              if (media) {
                this.lastCurrentTime = currentTime;
              }

              // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target
              if (!this.loadedmetadata && !bufferInfo.len) {
                this.nextLoadPosition = this.startPosition = currentTime;
              }

              // Async tick to speed up processing
              this.tickImmediate();
            }
            onMediaEnded() {
              // reset startPosition and lastCurrentTime to restart playback @ stream beginning
              this.startPosition = this.lastCurrentTime = 0;
            }
            onLevelSwitching(event, data) {
              this.fragLoadError = 0;
            }
            onHandlerDestroying() {
              this.stopLoad();
              super.onHandlerDestroying();
            }
            onHandlerDestroyed() {
              this.state = State.STOPPED;
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_4__.Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
              if (this.fragmentLoader) {
                this.fragmentLoader.destroy();
              }
              if (this.keyLoader) {
                this.keyLoader.destroy();
              }
              if (this.decrypter) {
                this.decrypter.destroy();
              }
              this.hls = this.log = this.warn = this.decrypter = this.keyLoader = this.fragmentLoader = this.fragmentTracker = null;
              super.onHandlerDestroyed();
            }
            loadFragment(frag, levelDetails, targetBufferTime) {
              this._loadFragForPlayback(frag, levelDetails, targetBufferTime);
            }
            _loadFragForPlayback(frag, levelDetails, targetBufferTime) {
              const progressCallback = data => {
                if (this.fragContextChanged(frag)) {
                  this.warn(`Fragment ${frag.sn}${data.part ? ' p: ' + data.part.index : ''} of level ${frag.level} was dropped during download.`);
                  this.fragmentTracker.removeFragment(frag);
                  return;
                }
                frag.stats.chunkCount++;
                this._handleFragmentLoadProgress(data);
              };
              this._doFragLoad(frag, levelDetails, targetBufferTime, progressCallback).then(data => {
                if (!data) {
                  // if we're here we probably needed to backtrack or are waiting for more parts
                  return;
                }
                this.fragLoadError = 0;
                const state = this.state;
                if (this.fragContextChanged(frag)) {
                  if (state === State.FRAG_LOADING || !this.fragCurrent && state === State.PARSING) {
                    this.fragmentTracker.removeFragment(frag);
                    this.state = State.IDLE;
                  }
                  return;
                }
                if ('payload' in data) {
                  this.log(`Loaded fragment ${frag.sn} of level ${frag.level}`);
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_LOADED, data);
                }

                // Pass through the whole payload; controllers not implementing progressive loading receive data from this callback
                this._handleFragmentLoadComplete(data);
              }).catch(reason => {
                if (this.state === State.STOPPED || this.state === State.ERROR) {
                  return;
                }
                this.warn(reason);
                this.resetFragmentLoading(frag);
              });
            }
            flushMainBuffer(startOffset, endOffset, type = null) {
              if (!(startOffset - endOffset)) {
                return;
              }
              // When alternate audio is playing, the audio-stream-controller is responsible for the audio buffer. Otherwise,
              // passing a null type flushes both buffers
              const flushScope = {
                startOffset,
                endOffset,
                type
              };
              // Reset load errors on flush
              this.fragLoadError = 0;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.BUFFER_FLUSHING, flushScope);
            }
            _loadInitSegment(frag, details) {
              this._doFragLoad(frag, details).then(data => {
                if (!data || this.fragContextChanged(frag) || !this.levels) {
                  throw new Error('init load aborted');
                }
                return data;
              }).then(data => {
                const {
                  hls
                } = this;
                const {
                  payload
                } = data;
                const decryptData = frag.decryptdata;

                // check to see if the payload needs to be decrypted
                if (payload && payload.byteLength > 0 && decryptData && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {
                  const startTime = self.performance.now();
                  // decrypt the subtitles
                  return this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).then(decryptedData => {
                    const endTime = self.performance.now();
                    hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_DECRYPTED, {
                      frag,
                      payload: decryptedData,
                      stats: {
                        tstart: startTime,
                        tdecrypt: endTime
                      }
                    });
                    data.payload = decryptedData;
                    return data;
                  });
                }
                return data;
              }).then(data => {
                const {
                  fragCurrent,
                  hls,
                  levels
                } = this;
                if (!levels) {
                  throw new Error('init load aborted, missing levels');
                }
                const details = levels[frag.level].details;
                console.assert(details, 'Level details are defined when init segment is loaded');
                const stats = frag.stats;
                this.state = State.IDLE;
                this.fragLoadError = 0;
                frag.data = new Uint8Array(data.payload);
                stats.parsing.start = stats.buffering.start = self.performance.now();
                stats.parsing.end = stats.buffering.end = self.performance.now();

                // Silence FRAG_BUFFERED event if fragCurrent is null
                if (data.frag === fragCurrent) {
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_BUFFERED, {
                    stats,
                    frag: fragCurrent,
                    part: null,
                    id: frag.type
                  });
                }
                this.tick();
              }).catch(reason => {
                if (this.state === State.STOPPED || this.state === State.ERROR) {
                  return;
                }
                this.warn(reason);
                this.resetFragmentLoading(frag);
              });
            }
            fragContextChanged(frag) {
              const {
                fragCurrent
              } = this;
              return !frag || !fragCurrent || frag.level !== fragCurrent.level || frag.sn !== fragCurrent.sn || frag.urlId !== fragCurrent.urlId;
            }
            fragBufferedComplete(frag, part) {
              const media = this.mediaBuffer ? this.mediaBuffer : this.media;
              this.log(`Buffered ${frag.type} sn: ${frag.sn}${part ? ' part: ' + part.index : ''} of ${this.logPrefix === '[stream-controller]' ? 'level' : 'track'} ${frag.level} ${media ? _utils_time_ranges__WEBPACK_IMPORTED_MODULE_13__["default"].toString(_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.getBuffered(media)) : '(detached)'}`);
              this.state = State.IDLE;
              if (!media) {
                return;
              }
              if (!this.loadedmetadata && frag.type == _types_loader__WEBPACK_IMPORTED_MODULE_14__.PlaylistLevelType.MAIN && media.buffered.length && this.fragCurrent?.sn === this.fragPrevious?.sn) {
                this.loadedmetadata = true;
                this.seekToStartPos();
              }
              this.tick();
            }
            seekToStartPos() { }
            _handleFragmentLoadComplete(fragLoadedEndData) {
              const {
                transmuxer
              } = this;
              if (!transmuxer) {
                return;
              }
              const {
                frag,
                part,
                partsLoaded
              } = fragLoadedEndData;
              // If we did not load parts, or loaded all parts, we have complete (not partial) fragment data
              const complete = !partsLoaded || partsLoaded.length === 0 || partsLoaded.some(fragLoaded => !fragLoaded);
              const chunkMeta = new _types_transmuxer__WEBPACK_IMPORTED_MODULE_6__.ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount + 1, 0, part ? part.index : -1, !complete);
              transmuxer.flush(chunkMeta);
            }

            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            _handleFragmentLoadProgress(frag) { }
            _doFragLoad(frag, details, targetBufferTime = null, progressCallback) {
              if (!this.levels) {
                throw new Error('frag load aborted, missing levels');
              }
              let keyLoadingPromise = null;
              if (frag.encrypted && !frag.decryptdata?.key) {
                this.log(`Loading key for ${frag.sn} of [${details.startSN}-${details.endSN}], ${this.logPrefix === '[stream-controller]' ? 'level' : 'track'} ${frag.level}`);
                this.state = State.KEY_LOADING;
                this.fragCurrent = frag;
                keyLoadingPromise = this.keyLoader.load(frag).then(keyLoadedData => {
                  if (!this.fragContextChanged(keyLoadedData.frag)) {
                    this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.KEY_LOADED, keyLoadedData);
                    return keyLoadedData;
                  }
                });
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.KEY_LOADING, {
                  frag
                });
                this.throwIfFragContextChanged('KEY_LOADING');
              } else if (!frag.encrypted && details.encryptedFragments.length) {
                this.keyLoader.loadClear(frag, details.encryptedFragments);
              }
              targetBufferTime = Math.max(frag.start, targetBufferTime || 0);
              if (this.config.lowLatencyMode && details) {
                const partList = details.partList;
                if (partList && progressCallback) {
                  if (targetBufferTime > frag.end && details.fragmentHint) {
                    frag = details.fragmentHint;
                  }
                  const partIndex = this.getNextPart(partList, frag, targetBufferTime);
                  if (partIndex > -1) {
                    const part = partList[partIndex];
                    this.log(`Loading part sn: ${frag.sn} p: ${part.index} cc: ${frag.cc} of playlist [${details.startSN}-${details.endSN}] parts [0-${partIndex}-${partList.length - 1}] ${this.logPrefix === '[stream-controller]' ? 'level' : 'track'}: ${frag.level}, target: ${parseFloat(targetBufferTime.toFixed(3))}`);
                    this.nextLoadPosition = part.start + part.duration;
                    this.state = State.FRAG_LOADING;
                    this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_LOADING, {
                      frag,
                      part: partList[partIndex],
                      targetBufferTime
                    });
                    this.throwIfFragContextChanged('FRAG_LOADING parts');
                    if (keyLoadingPromise) {
                      return keyLoadingPromise.then(keyLoadedData => {
                        if (!keyLoadedData || this.fragContextChanged(keyLoadedData.frag)) {
                          return null;
                        }
                        return this.doFragPartsLoad(frag, partList, partIndex, progressCallback);
                      }).catch(error => this.handleFragLoadError(error));
                    }
                    return this.doFragPartsLoad(frag, partList, partIndex, progressCallback).catch(error => this.handleFragLoadError(error));
                  } else if (!frag.url || this.loadedEndOfParts(partList, targetBufferTime)) {
                    // Fragment hint has no parts
                    return Promise.resolve(null);
                  }
                }
              }
              this.log(`Loading fragment ${frag.sn} cc: ${frag.cc} ${details ? 'of [' + details.startSN + '-' + details.endSN + '] ' : ''}${this.logPrefix === '[stream-controller]' ? 'level' : 'track'}: ${frag.level}, target: ${parseFloat(targetBufferTime.toFixed(3))}`);
              // Don't update nextLoadPosition for fragments which are not buffered
              if (Number.isFinite(frag.sn) && !this.bitrateTest) {
                this.nextLoadPosition = frag.start + frag.duration;
              }
              this.state = State.FRAG_LOADING;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_LOADING, {
                frag,
                targetBufferTime
              });
              this.throwIfFragContextChanged('FRAG_LOADING');

              // Load key before streaming fragment data
              const dataOnProgress = this.config.progressive;
              if (dataOnProgress && keyLoadingPromise) {
                return keyLoadingPromise.then(keyLoadedData => {
                  if (!keyLoadedData || this.fragContextChanged(keyLoadedData?.frag)) {
                    return null;
                  }
                  return this.fragmentLoader.load(frag, progressCallback);
                }).catch(error => this.handleFragLoadError(error));
              }

              // load unencrypted fragment data with progress event,
              // or handle fragment result after key and fragment are finished loading
              return Promise.all([this.fragmentLoader.load(frag, dataOnProgress ? progressCallback : undefined), keyLoadingPromise]).then(([fragLoadedData]) => {
                if (!dataOnProgress && fragLoadedData && progressCallback) {
                  progressCallback(fragLoadedData);
                }
                return fragLoadedData;
              }).catch(error => this.handleFragLoadError(error));
            }
            throwIfFragContextChanged(context) {
              // exit if context changed during event loop
              if (this.fragCurrent === null) {
                throw new Error(`frag load aborted, context changed in ${context}`);
              }
            }
            doFragPartsLoad(frag, partList, partIndex, progressCallback) {
              return new Promise((resolve, reject) => {
                const partsLoaded = [];
                const loadPartIndex = index => {
                  const part = partList[index];
                  this.fragmentLoader.loadPart(frag, part, progressCallback).then(partLoadedData => {
                    partsLoaded[part.index] = partLoadedData;
                    const loadedPart = partLoadedData.part;
                    this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_LOADED, partLoadedData);
                    const nextPart = partList[index + 1];
                    if (nextPart && nextPart.fragment === frag) {
                      loadPartIndex(index + 1);
                    } else {
                      return resolve({
                        frag,
                        part: loadedPart,
                        partsLoaded
                      });
                    }
                  }).catch(reject);
                };
                loadPartIndex(partIndex);
              });
            }
            handleFragLoadError(error) {
              if ('data' in error) {
                const data = error.data;
                if (error.data && data.details === _errors__WEBPACK_IMPORTED_MODULE_5__.ErrorDetails.INTERNAL_ABORTED) {
                  this.handleFragLoadAborted(data.frag, data.part);
                } else {
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.ERROR, data);
                }
              } else {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_5__.ErrorTypes.OTHER_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_5__.ErrorDetails.INTERNAL_EXCEPTION,
                  err: error,
                  fatal: true
                });
              }
              return null;
            }
            _handleTransmuxerFlush(chunkMeta) {
              const context = this.getCurrentContext(chunkMeta);
              if (!context || this.state !== State.PARSING) {
                if (!this.fragCurrent && this.state !== State.STOPPED && this.state !== State.ERROR) {
                  this.state = State.IDLE;
                }
                return;
              }
              const {
                frag,
                part,
                level
              } = context;
              const now = self.performance.now();
              frag.stats.parsing.end = now;
              if (part) {
                part.stats.parsing.end = now;
              }
              this.updateLevelTiming(frag, part, level, chunkMeta.partial);
            }
            getCurrentContext(chunkMeta) {
              const {
                levels
              } = this;
              const {
                level: levelIndex,
                sn,
                part: partIndex
              } = chunkMeta;
              if (!levels || !levels[levelIndex]) {
                this.warn(`Levels object was unset while buffering fragment ${sn} of level ${levelIndex}. The current chunk will not be buffered.`);
                return null;
              }
              const level = levels[levelIndex];
              const part = partIndex > -1 ? (0, _level_helper__WEBPACK_IMPORTED_MODULE_10__.getPartWith)(level, sn, partIndex) : null;
              const frag = part ? part.fragment : (0, _level_helper__WEBPACK_IMPORTED_MODULE_10__.getFragmentWithSN)(level, sn, this.fragCurrent);
              if (!frag) {
                return null;
              }
              return {
                frag,
                part,
                level
              };
            }
            bufferFragmentData(data, frag, part, chunkMeta) {
              if (!data || this.state !== State.PARSING) {
                return;
              }
              const {
                data1,
                data2
              } = data;
              let buffer = data1;
              if (data1 && data2) {
                // Combine the moof + mdat so that we buffer with a single append
                buffer = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_7__.appendUint8Array)(data1, data2);
              }
              if (!buffer || !buffer.length) {
                return;
              }
              const segment = {
                type: data.type,
                frag,
                part,
                chunkMeta,
                parent: frag.type,
                data: buffer
              };
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.BUFFER_APPENDING, segment);
              if (data.dropped && data.independent && !part) {
                // Clear buffer so that we reload previous segments sequentially if required
                this.flushBufferGap(frag);
              }
            }
            flushBufferGap(frag) {
              const media = this.media;
              if (!media) {
                return;
              }
              // If currentTime is not buffered, clear the back buffer so that we can backtrack as much as needed
              if (!_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.isBuffered(media, media.currentTime)) {
                this.flushMainBuffer(0, frag.start);
                return;
              }
              // Remove back-buffer without interrupting playback to allow back tracking
              const currentTime = media.currentTime;
              const bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.bufferInfo(media, currentTime, 0);
              const fragDuration = frag.duration;
              const segmentFraction = Math.min(this.config.maxFragLookUpTolerance * 2, fragDuration * 0.25);
              const start = Math.max(Math.min(frag.start - segmentFraction, bufferInfo.end - segmentFraction), currentTime + segmentFraction);
              if (frag.start - start > segmentFraction) {
                this.flushMainBuffer(start, frag.start);
              }
            }
            getFwdBufferInfo(bufferable, type) {
              const {
                config
              } = this;
              const pos = this.getLoadPosition();
              if (!Number.isFinite(pos)) {
                return null;
              }
              const bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.bufferInfo(bufferable, pos, config.maxBufferHole);
              // Workaround flaw in getting forward buffer when maxBufferHole is smaller than gap at current pos
              if (bufferInfo.len === 0 && bufferInfo.nextStart !== undefined) {
                const bufferedFragAtPos = this.fragmentTracker.getBufferedFrag(pos, type);
                if (bufferedFragAtPos && bufferInfo.nextStart < bufferedFragAtPos.end) {
                  return _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.bufferInfo(bufferable, pos, Math.max(bufferInfo.nextStart, config.maxBufferHole));
                }
              }
              return bufferInfo;
            }
            getMaxBufferLength(levelBitrate) {
              const {
                config
              } = this;
              let maxBufLen;
              if (levelBitrate) {
                maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);
              } else {
                maxBufLen = config.maxBufferLength;
              }
              return Math.min(maxBufLen, config.maxMaxBufferLength);
            }
            reduceMaxBufferLength(threshold) {
              const config = this.config;
              const minLength = threshold || config.maxBufferLength;
              if (config.maxMaxBufferLength >= minLength) {
                // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...
                config.maxMaxBufferLength /= 2;
                this.warn(`Reduce max buffer length to ${config.maxMaxBufferLength}s`);
                return true;
              }
              return false;
            }
            getNextFragment(pos, levelDetails) {
              const fragments = levelDetails.fragments;
              const fragLen = fragments.length;
              if (!fragLen) {
                return null;
              }

              // find fragment index, contiguous with end of buffer position
              const {
                config
              } = this;
              const start = fragments[0].start;
              let frag;
              if (levelDetails.live) {
                const initialLiveManifestSize = config.initialLiveManifestSize;
                if (fragLen < initialLiveManifestSize) {
                  this.warn(`Not enough fragments to start playback (have: ${fragLen}, need: ${initialLiveManifestSize})`);
                  return null;
                }
                // The real fragment start times for a live stream are only known after the PTS range for that level is known.
                // In order to discover the range, we load the best matching fragment for that level and demux it.
                // Do not load using live logic if the starting frag is requested - we want to use getFragmentAtPosition() so that
                // we get the fragment matching that start time
                if (!levelDetails.PTSKnown && !this.startFragRequested && this.startPosition === -1) {
                  frag = this.getInitialLiveFragment(levelDetails, fragments);
                  this.startPosition = frag ? this.hls.liveSyncPosition || frag.start : pos;
                }
              } else if (pos <= start) {
                // VoD playlist: if loadPosition before start of playlist, load first fragment
                frag = fragments[0];
              }

              // If we haven't run into any special cases already, just load the fragment most closely matching the requested position
              if (!frag) {
                const end = config.lowLatencyMode ? levelDetails.partEnd : levelDetails.fragmentEnd;
                frag = this.getFragmentAtPosition(pos, end, levelDetails);
              }
              return this.mapToInitFragWhenRequired(frag);
            }
            mapToInitFragWhenRequired(frag) {
              // If an initSegment is present, it must be buffered first
              if (frag?.initSegment && !frag?.initSegment.data && !this.bitrateTest) {
                return frag.initSegment;
              }
              return frag;
            }
            getNextPart(partList, frag, targetBufferTime) {
              let nextPart = -1;
              let contiguous = false;
              let independentAttrOmitted = true;
              for (let i = 0, len = partList.length; i < len; i++) {
                const part = partList[i];
                independentAttrOmitted = independentAttrOmitted && !part.independent;
                if (nextPart > -1 && targetBufferTime < part.start) {
                  break;
                }
                const loaded = part.loaded;
                if (loaded) {
                  nextPart = -1;
                } else if ((contiguous || part.independent || independentAttrOmitted) && part.fragment === frag) {
                  nextPart = i;
                }
                contiguous = loaded;
              }
              return nextPart;
            }
            loadedEndOfParts(partList, targetBufferTime) {
              const lastPart = partList[partList.length - 1];
              return lastPart && targetBufferTime > lastPart.start && lastPart.loaded;
            }

            /*
             This method is used find the best matching first fragment for a live playlist. This fragment is used to calculate the
             "sliding" of the playlist, which is its offset from the start of playback. After sliding we can compute the real
             start and end times for each fragment in the playlist (after which this method will not need to be called).
            */
            getInitialLiveFragment(levelDetails, fragments) {
              const fragPrevious = this.fragPrevious;
              let frag = null;
              if (fragPrevious) {
                if (levelDetails.hasProgramDateTime) {
                  // Prefer using PDT, because it can be accurate enough to choose the correct fragment without knowing the level sliding
                  this.log(`Live playlist, switching playlist, load frag with same PDT: ${fragPrevious.programDateTime}`);
                  frag = (0, _fragment_finders__WEBPACK_IMPORTED_MODULE_9__.findFragmentByPDT)(fragments, fragPrevious.endProgramDateTime, this.config.maxFragLookUpTolerance);
                }
                if (!frag) {
                  // SN does not need to be accurate between renditions, but depending on the packaging it may be so.
                  const targetSN = fragPrevious.sn + 1;
                  if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {
                    const fragNext = fragments[targetSN - levelDetails.startSN];
                    // Ensure that we're staying within the continuity range, since PTS resets upon a new range
                    if (fragPrevious.cc === fragNext.cc) {
                      frag = fragNext;
                      this.log(`Live playlist, switching playlist, load frag with next SN: ${frag.sn}`);
                    }
                  }
                  // It's important to stay within the continuity range if available; otherwise the fragments in the playlist
                  // will have the wrong start times
                  if (!frag) {
                    frag = (0, _fragment_finders__WEBPACK_IMPORTED_MODULE_9__.findFragWithCC)(fragments, fragPrevious.cc);
                    if (frag) {
                      this.log(`Live playlist, switching playlist, load frag with same CC: ${frag.sn}`);
                    }
                  }
                }
              } else {
                // Find a new start fragment when fragPrevious is null
                const liveStart = this.hls.liveSyncPosition;
                if (liveStart !== null) {
                  frag = this.getFragmentAtPosition(liveStart, this.bitrateTest ? levelDetails.fragmentEnd : levelDetails.edge, levelDetails);
                }
              }
              return frag;
            }

            /*
            This method finds the best matching fragment given the provided position.
             */
            getFragmentAtPosition(bufferEnd, end, levelDetails) {
              const {
                config
              } = this;
              let {
                fragPrevious
              } = this;
              let {
                fragments,
                endSN
              } = levelDetails;
              const {
                fragmentHint
              } = levelDetails;
              const tolerance = config.maxFragLookUpTolerance;
              const loadingParts = !!(config.lowLatencyMode && levelDetails.partList && fragmentHint);
              if (loadingParts && fragmentHint && !this.bitrateTest) {
                // Include incomplete fragment with parts at end
                fragments = fragments.concat(fragmentHint);
                endSN = fragmentHint.sn;
              }
              let frag;
              if (bufferEnd < end) {
                const lookupTolerance = bufferEnd > end - tolerance ? 0 : tolerance;
                // Remove the tolerance if it would put the bufferEnd past the actual end of stream
                // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)
                frag = (0, _fragment_finders__WEBPACK_IMPORTED_MODULE_9__.findFragmentByPTS)(fragPrevious, fragments, bufferEnd, lookupTolerance);
              } else {
                // reach end of playlist
                frag = fragments[fragments.length - 1];
              }
              if (frag) {
                const curSNIdx = frag.sn - levelDetails.startSN;
                // Move fragPrevious forward to support forcing the next fragment to load
                // when the buffer catches up to a previously buffered range.
                if (this.fragmentTracker.getState(frag) === _fragment_tracker__WEBPACK_IMPORTED_MODULE_1__.FragmentState.OK) {
                  fragPrevious = frag;
                }
                if (fragPrevious && frag.sn === fragPrevious.sn && !loadingParts) {
                  // Force the next fragment to load if the previous one was already selected. This can occasionally happen with
                  // non-uniform fragment durations
                  const sameLevel = fragPrevious && frag.level === fragPrevious.level;
                  if (sameLevel) {
                    const nextFrag = fragments[curSNIdx + 1];
                    if (frag.sn < endSN && this.fragmentTracker.getState(nextFrag) !== _fragment_tracker__WEBPACK_IMPORTED_MODULE_1__.FragmentState.OK) {
                      this.log(`SN ${frag.sn} just loaded, load next one: ${nextFrag.sn}`);
                      frag = nextFrag;
                    } else {
                      frag = null;
                    }
                  }
                }
              }
              return frag;
            }
            synchronizeToLiveEdge(levelDetails) {
              const {
                config,
                media
              } = this;
              if (!media) {
                return;
              }
              const liveSyncPosition = this.hls.liveSyncPosition;
              const currentTime = media.currentTime;
              const start = levelDetails.fragments[0].start;
              const end = levelDetails.edge;
              const withinSlidingWindow = currentTime >= start - config.maxFragLookUpTolerance && currentTime <= end;
              // Continue if we can seek forward to sync position or if current time is outside of sliding window
              if (liveSyncPosition !== null && media.duration > liveSyncPosition && (currentTime < liveSyncPosition || !withinSlidingWindow)) {
                // Continue if buffer is starving or if current time is behind max latency
                const maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;
                if (!withinSlidingWindow && media.readyState < 4 || currentTime < end - maxLatency) {
                  if (!this.loadedmetadata) {
                    this.nextLoadPosition = liveSyncPosition;
                  }
                  // Only seek if ready and there is not a significant forward buffer available for playback
                  if (media.readyState) {
                    this.warn(`Playback: ${currentTime.toFixed(3)} is located too far from the end of live sliding playlist: ${end}, reset currentTime to : ${liveSyncPosition.toFixed(3)}`);
                    media.currentTime = liveSyncPosition;
                  }
                }
              }
            }
            alignPlaylists(details, previousDetails) {
              const {
                levels,
                levelLastLoaded,
                fragPrevious
              } = this;
              const lastLevel = levelLastLoaded !== null ? levels[levelLastLoaded] : null;

              // FIXME: If not for `shouldAlignOnDiscontinuities` requiring fragPrevious.cc,
              //  this could all go in level-helper mergeDetails()
              const length = details.fragments.length;
              if (!length) {
                this.warn(`No fragments in live playlist`);
                return 0;
              }
              const slidingStart = details.fragments[0].start;
              const firstLevelLoad = !previousDetails;
              const aligned = details.alignedSliding && Number.isFinite(slidingStart);
              if (firstLevelLoad || !aligned && !slidingStart) {
                (0, _utils_discontinuities__WEBPACK_IMPORTED_MODULE_8__.alignStream)(fragPrevious, lastLevel, details);
                const alignedSlidingStart = details.fragments[0].start;
                this.log(`Live playlist sliding: ${alignedSlidingStart.toFixed(2)} start-sn: ${previousDetails ? previousDetails.startSN : 'na'}->${details.startSN} prev-sn: ${fragPrevious ? fragPrevious.sn : 'na'} fragments: ${length}`);
                return alignedSlidingStart;
              }
              return slidingStart;
            }
            waitForCdnTuneIn(details) {
              // Wait for Low-Latency CDN Tune-in to get an updated playlist
              const advancePartLimit = 3;
              return details.live && details.canBlockReload && details.partTarget && details.tuneInGoal > Math.max(details.partHoldBack, details.partTarget * advancePartLimit);
            }
            setStartPosition(details, sliding) {
              // compute start position if set to -1. use it straight away if value is defined
              let startPosition = this.startPosition;
              if (startPosition < sliding) {
                startPosition = -1;
              }
              if (startPosition === -1 || this.lastCurrentTime === -1) {
                // first, check if start time offset has been set in playlist, if yes, use this value
                const startTimeOffset = details.startTimeOffset;
                if (Number.isFinite(startTimeOffset)) {
                  startPosition = sliding + startTimeOffset;
                  if (startTimeOffset < 0) {
                    startPosition += details.totalduration;
                  }
                  startPosition = Math.min(Math.max(sliding, startPosition), sliding + details.totalduration);
                  this.log(`Start time offset ${startTimeOffset} found in playlist, adjust startPosition to ${startPosition}`);
                  this.startPosition = startPosition;
                } else if (details.live) {
                  // Leave this.startPosition at -1, so that we can use `getInitialLiveFragment` logic when startPosition has
                  // not been specified via the config or an as an argument to startLoad (#3736).
                  startPosition = this.hls.liveSyncPosition || sliding;
                } else {
                  this.startPosition = startPosition = 0;
                }
                this.lastCurrentTime = startPosition;
              }
              this.nextLoadPosition = startPosition;
            }
            getLoadPosition() {
              const {
                media
              } = this;
              // if we have not yet loaded any fragment, start loading from start position
              let pos = 0;
              if (this.loadedmetadata && media) {
                pos = media.currentTime;
              } else if (this.nextLoadPosition) {
                pos = this.nextLoadPosition;
              }
              return pos;
            }
            handleFragLoadAborted(frag, part) {
              if (this.transmuxer && frag.sn !== 'initSegment' && frag.stats.aborted) {
                this.warn(`Fragment ${frag.sn}${part ? ' part' + part.index : ''} of level ${frag.level} was aborted`);
                this.resetFragmentLoading(frag);
              }
            }
            resetFragmentLoading(frag) {
              if (!this.fragCurrent || !this.fragContextChanged(frag) && this.state !== State.FRAG_LOADING_WAITING_RETRY) {
                this.state = State.IDLE;
              }
            }
            onFragmentOrKeyLoadError(filterType, data) {
              if (data.fatal) {
                this.stopLoad();
                this.state = State.ERROR;
                return;
              }
              const config = this.config;
              if (data.chunkMeta) {
                // Parsing Error: no retries
                const context = this.getCurrentContext(data.chunkMeta);
                if (context) {
                  data.frag = context.frag;
                  data.levelRetry = true;
                  this.fragLoadError = config.fragLoadingMaxRetry;
                }
              }
              const frag = data.frag;
              // Handle frag error related to caller's filterType
              if (!frag || frag.type !== filterType) {
                return;
              }
              const fragCurrent = this.fragCurrent;
              console.assert(fragCurrent && frag.sn === fragCurrent.sn && frag.level === fragCurrent.level && frag.urlId === fragCurrent.urlId, 'Frag load error must match current frag to retry');
              // keep retrying until the limit will be reached
              if (this.fragLoadError + 1 <= config.fragLoadingMaxRetry) {
                if (!this.loadedmetadata) {
                  this.startFragRequested = false;
                  this.nextLoadPosition = this.startPosition;
                }
                // exponential backoff capped to config.fragLoadingMaxRetryTimeout
                const delay = Math.min(Math.pow(2, this.fragLoadError) * config.fragLoadingRetryDelay, config.fragLoadingMaxRetryTimeout);
                this.warn(`Fragment ${frag.sn} of ${filterType} ${frag.level} failed to load, retrying in ${delay}ms`);
                this.retryDate = self.performance.now() + delay;
                this.fragLoadError++;
                this.state = State.FRAG_LOADING_WAITING_RETRY;
              } else if (data.levelRetry) {
                if (filterType === _types_loader__WEBPACK_IMPORTED_MODULE_14__.PlaylistLevelType.AUDIO) {
                  // Reset current fragment since audio track audio is essential and may not have a fail-over track
                  this.fragCurrent = null;
                }
                // Fragment errors that result in a level switch or redundant fail-over
                // should reset the stream controller state to idle
                this.fragLoadError = 0;
                this.state = State.IDLE;
              } else {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.error(`${data.details} reaches max retry, redispatch as fatal ...`);
                // switch error to fatal
                data.fatal = true;
                this.hls.stopLoad();
                this.state = State.ERROR;
              }
            }
            afterBufferFlushed(media, bufferType, playlistType) {
              if (!media) {
                return;
              }
              // After successful buffer flushing, filter flushed fragments from bufferedFrags use mediaBuffered instead of media
              // (so that we will check against video.buffered ranges in case of alt audio track)
              const bufferedTimeRanges = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.getBuffered(media);
              this.fragmentTracker.detectEvictedFragments(bufferType, bufferedTimeRanges, playlistType);
              if (this.state === State.ENDED) {
                this.resetLoadingState();
              }
            }
            resetLoadingState() {
              this.log('Reset loading state');
              this.fragCurrent = null;
              this.fragPrevious = null;
              this.state = State.IDLE;
            }
            resetStartWhenNotLoaded(level) {
              // if loadedmetadata is not set, it means that first frag request failed
              // in that case, reset startFragRequested flag
              if (!this.loadedmetadata) {
                this.startFragRequested = false;
                const details = this.levels ? this.levels[level].details : null;
                if (details?.live) {
                  // Update the start position and return to IDLE to recover live start
                  this.startPosition = -1;
                  this.setStartPosition(details, 0);
                  this.resetLoadingState();
                } else {
                  this.nextLoadPosition = this.startPosition;
                }
              }
            }
            updateLevelTiming(frag, part, level, partial) {
              const details = level.details;
              console.assert(!!details, 'level.details must be defined');
              const parsed = Object.keys(frag.elementaryStreams).reduce((result, type) => {
                const info = frag.elementaryStreams[type];
                if (info) {
                  const parsedDuration = info.endPTS - info.startPTS;
                  if (parsedDuration <= 0) {
                    // Destroy the transmuxer after it's next time offset failed to advance because duration was <= 0.
                    // The new transmuxer will be configured with a time offset matching the next fragment start,
                    // preventing the timeline from shifting.
                    this.warn(`Could not parse fragment ${frag.sn} ${type} duration reliably (${parsedDuration})`);
                    return result || false;
                  }
                  const drift = partial ? 0 : (0, _level_helper__WEBPACK_IMPORTED_MODULE_10__.updateFragPTSDTS)(details, frag, info.startPTS, info.endPTS, info.startDTS, info.endDTS);
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.LEVEL_PTS_UPDATED, {
                    details,
                    level,
                    drift,
                    type,
                    frag,
                    start: info.startPTS,
                    end: info.endPTS
                  });
                  return true;
                }
                return result;
              }, false);
              if (!parsed) {
                this.warn(`Found no media in fragment ${frag.sn} of level ${level.id} resetting transmuxer to fallback to playlist timing`);
                this.resetTransmuxer();
              }
              this.state = State.PARSED;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_4__.Events.FRAG_PARSED, {
                frag,
                part
              });
            }
            resetTransmuxer() {
              if (this.transmuxer) {
                this.transmuxer.destroy();
                this.transmuxer = null;
              }
            }
            set state(nextState) {
              const previousState = this._state;
              if (previousState !== nextState) {
                this._state = nextState;
                this.log(`${previousState}->${nextState}`);
              }
            }
            get state() {
              return this._state;
            }
          }

          /***/
        }),

/***/ "./src/controller/buffer-controller.ts":
/*!*********************************************!*\
  !*** ./src/controller/buffer-controller.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BufferController)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/mediasource-helper */ "./src/utils/mediasource-helper.ts");
/* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
/* harmony import */ var _buffer_operation_queue__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./buffer-operation-queue */ "./src/controller/buffer-operation-queue.ts");







          const MediaSource = (0, _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_4__.getMediaSource)();
          const VIDEO_CODEC_PROFILE_REPACE = /([ha]vc.)(?:\.[^.,]+)+/;
          class BufferController {
            // The level details used to determine duration, target-duration and live
            details = null;
            // cache the self generated object url to detect hijack of video tag
            _objectUrl = null;
            // A queue of buffer operations which require the SourceBuffer to not be updating upon execution

            // The number of BUFFER_CODEC events received before any sourceBuffers are created
            bufferCodecEventsExpected = 0;

            // The total number of BUFFER_CODEC events received
            _bufferCodecEventsTotal = 0;

            // A reference to the attached media element
            media = null;

            // A reference to the active media source
            mediaSource = null;

            // Last MP3 audio chunk appended
            lastMpegAudioChunk = null;

            // counters
            appendError = 0;
            tracks = {};
            pendingTracks = {};
            constructor(hls) {
              this.hls = hls;
              this._initSourceBuffer();
              this.registerListeners();
            }
            hasSourceTypes() {
              return this.getSourceBufferTypes().length > 0 || Object.keys(this.pendingTracks).length > 0;
            }
            destroy() {
              this.unregisterListeners();
              this.details = null;
              this.lastMpegAudioChunk = null;
            }
            registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_RESET, this.onBufferReset, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_APPENDING, this.onBufferAppending, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CODECS, this.onBufferCodecs, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_EOS, this.onBufferEos, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_UPDATED, this.onLevelUpdated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_PARSED, this.onFragParsed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_CHANGED, this.onFragChanged, this);
            }
            unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_RESET, this.onBufferReset, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_APPENDING, this.onBufferAppending, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CODECS, this.onBufferCodecs, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_EOS, this.onBufferEos, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_UPDATED, this.onLevelUpdated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_PARSED, this.onFragParsed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_CHANGED, this.onFragChanged, this);
            }
            _initSourceBuffer() {
              this.sourceBuffer = {};
              this.operationQueue = new _buffer_operation_queue__WEBPACK_IMPORTED_MODULE_6__["default"](this.sourceBuffer);
              this.listeners = {
                audio: [],
                video: [],
                audiovideo: []
              };
              this.lastMpegAudioChunk = null;
            }
            onManifestParsed(event, data) {
              // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller
              // sourcebuffers will be created all at once when the expected nb of tracks will be reached
              // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller
              // it will contain the expected nb of source buffers, no need to compute it
              let codecEvents = 2;
              if (data.audio && !data.video || !data.altAudio) {
                codecEvents = 1;
              }
              this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = codecEvents;
              this.details = null;
              _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`${this.bufferCodecEventsExpected} bufferCodec event(s) expected`);
            }
            onMediaAttaching(event, data) {
              const media = this.media = data.media;
              if (media && MediaSource) {
                const ms = this.mediaSource = new MediaSource();
                // MediaSource listeners are arrow functions with a lexical scope, and do not need to be bound
                ms.addEventListener('sourceopen', this._onMediaSourceOpen);
                ms.addEventListener('sourceended', this._onMediaSourceEnded);
                ms.addEventListener('sourceclose', this._onMediaSourceClose);
                // link video and media Source
                media.src = self.URL.createObjectURL(ms);
                // cache the locally generated object url
                this._objectUrl = media.src;
              }
            }
            onMediaDetaching() {
              const {
                media,
                mediaSource,
                _objectUrl
              } = this;
              if (mediaSource) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log('[buffer-controller]: media source detaching');
                if (mediaSource.readyState === 'open') {
                  try {
                    // endOfStream could trigger exception if any sourcebuffer is in updating state
                    // we don't really care about checking sourcebuffer state here,
                    // as we are anyway detaching the MediaSource
                    // let's just avoid this exception to propagate
                    mediaSource.endOfStream();
                  } catch (err) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`[buffer-controller]: onMediaDetaching: ${err.message} while calling endOfStream`);
                  }
                }
                // Clean up the SourceBuffers by invoking onBufferReset
                this.onBufferReset();
                mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);
                mediaSource.removeEventListener('sourceended', this._onMediaSourceEnded);
                mediaSource.removeEventListener('sourceclose', this._onMediaSourceClose);

                // Detach properly the MediaSource from the HTMLMediaElement as
                // suggested in https://github.com/w3c/media-source/issues/53.
                if (media) {
                  if (_objectUrl) {
                    self.URL.revokeObjectURL(_objectUrl);
                  }

                  // clean up video tag src only if it's our own url. some external libraries might
                  // hijack the video tag and change its 'src' without destroying the Hls instance first
                  if (media.src === _objectUrl) {
                    media.removeAttribute('src');
                    media.load();
                  } else {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn('[buffer-controller]: media.src was changed by a third party - skip cleanup');
                  }
                }
                this.mediaSource = null;
                this.media = null;
                this._objectUrl = null;
                this.bufferCodecEventsExpected = this._bufferCodecEventsTotal;
                this.pendingTracks = {};
                this.tracks = {};
              }
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHED, undefined);
            }
            onBufferReset() {
              this.getSourceBufferTypes().forEach(type => {
                const sb = this.sourceBuffer[type];
                try {
                  if (sb) {
                    this.removeBufferListeners(type);
                    if (this.mediaSource) {
                      this.mediaSource.removeSourceBuffer(sb);
                    }
                    // Synchronously remove the SB from the map before the next call in order to prevent an async function from
                    // accessing it
                    this.sourceBuffer[type] = undefined;
                  }
                } catch (err) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`[buffer-controller]: Failed to reset the ${type} buffer`, err);
                }
              });
              this._initSourceBuffer();
            }
            onBufferCodecs(event, data) {
              const sourceBufferCount = this.getSourceBufferTypes().length;
              Object.keys(data).forEach(trackName => {
                if (sourceBufferCount) {
                  // check if SourceBuffer codec needs to change
                  const track = this.tracks[trackName];
                  if (track && typeof track.buffer.changeType === 'function') {
                    const {
                      id,
                      codec,
                      levelCodec,
                      container,
                      metadata
                    } = data[trackName];
                    const currentCodec = (track.levelCodec || track.codec).replace(VIDEO_CODEC_PROFILE_REPACE, '$1');
                    const nextCodec = (levelCodec || codec).replace(VIDEO_CODEC_PROFILE_REPACE, '$1');
                    if (currentCodec !== nextCodec) {
                      const mimeType = `${container};codecs=${levelCodec || codec}`;
                      this.appendChangeType(trackName, mimeType);
                      _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: switching codec ${currentCodec} to ${nextCodec}`);
                      this.tracks[trackName] = {
                        buffer: track.buffer,
                        codec,
                        container,
                        levelCodec,
                        metadata,
                        id
                      };
                    }
                  }
                } else {
                  // if source buffer(s) not created yet, appended buffer tracks in this.pendingTracks
                  this.pendingTracks[trackName] = data[trackName];
                }
              });

              // if sourcebuffers already created, do nothing ...
              if (sourceBufferCount) {
                return;
              }
              this.bufferCodecEventsExpected = Math.max(this.bufferCodecEventsExpected - 1, 0);
              if (this.mediaSource && this.mediaSource.readyState === 'open') {
                this.checkPendingTracks();
              }
            }
            appendChangeType(type, mimeType) {
              const {
                operationQueue
              } = this;
              const operation = {
                execute: () => {
                  const sb = this.sourceBuffer[type];
                  if (sb) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: changing ${type} sourceBuffer type to ${mimeType}`);
                    sb.changeType(mimeType);
                  }
                  operationQueue.shiftAndExecuteNext(type);
                },
                onStart: () => { },
                onComplete: () => { },
                onError: e => {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`[buffer-controller]: Failed to change ${type} SourceBuffer type`, e);
                }
              };
              operationQueue.append(operation, type);
            }
            onBufferAppending(event, eventData) {
              const {
                hls,
                operationQueue,
                tracks
              } = this;
              const {
                data,
                type,
                frag,
                part,
                chunkMeta
              } = eventData;
              const chunkStats = chunkMeta.buffering[type];
              const bufferAppendingStart = self.performance.now();
              chunkStats.start = bufferAppendingStart;
              const fragBuffering = frag.stats.buffering;
              const partBuffering = part ? part.stats.buffering : null;
              if (fragBuffering.start === 0) {
                fragBuffering.start = bufferAppendingStart;
              }
              if (partBuffering && partBuffering.start === 0) {
                partBuffering.start = bufferAppendingStart;
              }

              // TODO: Only update timestampOffset when audio/mpeg fragment or part is not contiguous with previously appended
              // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)
              // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`
              // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos).
              // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486
              const audioTrack = tracks.audio;
              let checkTimestampOffset = false;
              if (type === 'audio' && audioTrack?.container === 'audio/mpeg') {
                checkTimestampOffset = !this.lastMpegAudioChunk || chunkMeta.id === 1 || this.lastMpegAudioChunk.sn !== chunkMeta.sn;
                this.lastMpegAudioChunk = chunkMeta;
              }
              const fragStart = frag.start;
              const operation = {
                execute: () => {
                  chunkStats.executeStart = self.performance.now();
                  if (checkTimestampOffset) {
                    const sb = this.sourceBuffer[type];
                    if (sb) {
                      const delta = fragStart - sb.timestampOffset;
                      if (Math.abs(delta) >= 0.1) {
                        _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: Updating audio SourceBuffer timestampOffset to ${fragStart} (delta: ${delta}) sn: ${frag.sn})`);
                        sb.timestampOffset = fragStart;
                      }
                    }
                  }
                  this.appendExecutor(data, type);
                },
                onStart: () => {
                  // logger.debug(`[buffer-controller]: ${type} SourceBuffer updatestart`);
                },
                onComplete: () => {
                  // logger.debug(`[buffer-controller]: ${type} SourceBuffer updateend`);
                  const end = self.performance.now();
                  chunkStats.executeEnd = chunkStats.end = end;
                  if (fragBuffering.first === 0) {
                    fragBuffering.first = end;
                  }
                  if (partBuffering && partBuffering.first === 0) {
                    partBuffering.first = end;
                  }
                  const {
                    sourceBuffer
                  } = this;
                  const timeRanges = {};
                  for (const type in sourceBuffer) {
                    timeRanges[type] = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__.BufferHelper.getBuffered(sourceBuffer[type]);
                  }
                  this.appendError = 0;
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_APPENDED, {
                    type,
                    frag,
                    part,
                    chunkMeta,
                    parent: frag.type,
                    timeRanges
                  });
                },
                onError: err => {
                  // in case any error occured while appending, put back segment in segments table
                  _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.error(`[buffer-controller]: Error encountered while trying to append to the ${type} SourceBuffer`, err);
                  const event = {
                    type: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.MEDIA_ERROR,
                    parent: frag.type,
                    details: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.BUFFER_APPEND_ERROR,
                    err,
                    fatal: false
                  };
                  if (err.code === DOMException.QUOTA_EXCEEDED_ERR) {
                    // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror
                    // let's stop appending any segments, and report BUFFER_FULL_ERROR error
                    event.details = _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.BUFFER_FULL_ERROR;
                  } else {
                    this.appendError++;
                    event.details = _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.BUFFER_APPEND_ERROR;
                    /* with UHD content, we could get loop of quota exceeded error until
                      browser is able to evict some data from sourcebuffer. Retrying can help recover.
                    */
                    if (this.appendError > hls.config.appendErrorMaxRetry) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.error(`[buffer-controller]: Failed ${hls.config.appendErrorMaxRetry} times to append segment in sourceBuffer`);
                      event.fatal = true;
                      hls.stopLoad();
                    }
                  }
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, event);
                }
              };
              operationQueue.append(operation, type);
            }
            onBufferFlushing(event, data) {
              const {
                operationQueue
              } = this;
              const flushOperation = type => ({
                execute: this.removeExecutor.bind(this, type, data.startOffset, data.endOffset),
                onStart: () => {
                  // logger.debug(`[buffer-controller]: Started flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);
                },
                onComplete: () => {
                  // logger.debug(`[buffer-controller]: Finished flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHED, {
                    type
                  });
                },
                onError: e => {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`[buffer-controller]: Failed to remove from ${type} SourceBuffer`, e);
                }
              });
              if (data.type) {
                operationQueue.append(flushOperation(data.type), data.type);
              } else {
                this.getSourceBufferTypes().forEach(type => {
                  operationQueue.append(flushOperation(type), type);
                });
              }
            }
            onFragParsed(event, data) {
              const {
                frag,
                part
              } = data;
              const buffersAppendedTo = [];
              const elementaryStreams = part ? part.elementaryStreams : frag.elementaryStreams;
              if (elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_5__.ElementaryStreamTypes.AUDIOVIDEO]) {
                buffersAppendedTo.push('audiovideo');
              } else {
                if (elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_5__.ElementaryStreamTypes.AUDIO]) {
                  buffersAppendedTo.push('audio');
                }
                if (elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_5__.ElementaryStreamTypes.VIDEO]) {
                  buffersAppendedTo.push('video');
                }
              }
              const onUnblocked = () => {
                const now = self.performance.now();
                frag.stats.buffering.end = now;
                if (part) {
                  part.stats.buffering.end = now;
                }
                const stats = part ? part.stats : frag.stats;
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_BUFFERED, {
                  frag,
                  part,
                  stats,
                  id: frag.type
                });
              };
              if (buffersAppendedTo.length === 0) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`Fragments must have at least one ElementaryStreamType set. type: ${frag.type} level: ${frag.level} sn: ${frag.sn}`);
              }
              this.blockBuffers(onUnblocked, buffersAppendedTo);
            }
            onFragChanged(event, data) {
              this.flushBackBuffer();
            }

            // on BUFFER_EOS mark matching sourcebuffer(s) as ended and trigger checkEos()
            // an undefined data.type will mark all buffers as EOS.
            onBufferEos(event, data) {
              const ended = this.getSourceBufferTypes().reduce((acc, type) => {
                const sb = this.sourceBuffer[type];
                if (sb && (!data.type || data.type === type)) {
                  sb.ending = true;
                  if (!sb.ended) {
                    sb.ended = true;
                    _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: ${type} sourceBuffer now EOS`);
                  }
                }
                return acc && !!(!sb || sb.ended);
              }, true);
              if (ended) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: Queueing mediaSource.endOfStream()`);
                this.blockBuffers(() => {
                  this.getSourceBufferTypes().forEach(type => {
                    const sb = this.sourceBuffer[type];
                    if (sb) {
                      sb.ending = false;
                    }
                  });
                  const {
                    mediaSource
                  } = this;
                  if (!mediaSource || mediaSource.readyState !== 'open') {
                    if (mediaSource) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.info(`[buffer-controller]: Could not call mediaSource.endOfStream(). mediaSource.readyState: ${mediaSource.readyState}`);
                    }
                    return;
                  }
                  _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: Calling mediaSource.endOfStream()`);
                  // Allow this to throw and be caught by the enqueueing function
                  mediaSource.endOfStream();
                });
              }
            }
            onLevelUpdated(event, {
              details
            }) {
              if (!details.fragments.length) {
                return;
              }
              this.details = details;
              if (this.getSourceBufferTypes().length) {
                this.blockBuffers(this.updateMediaElementDuration.bind(this));
              } else {
                this.updateMediaElementDuration();
              }
            }
            flushBackBuffer() {
              const {
                hls,
                details,
                media,
                sourceBuffer
              } = this;
              if (!media || details === null) {
                return;
              }
              const sourceBufferTypes = this.getSourceBufferTypes();
              if (!sourceBufferTypes.length) {
                return;
              }

              // Support for deprecated liveBackBufferLength
              const backBufferLength = details.live && hls.config.liveBackBufferLength !== null ? hls.config.liveBackBufferLength : hls.config.backBufferLength;
              if (!Number.isFinite(backBufferLength) || backBufferLength < 0) {
                return;
              }
              const currentTime = media.currentTime;
              const targetDuration = details.levelTargetDuration;
              const maxBackBufferLength = Math.max(backBufferLength, targetDuration);
              const targetBackBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration - maxBackBufferLength;
              sourceBufferTypes.forEach(type => {
                const sb = sourceBuffer[type];
                if (sb) {
                  const buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__.BufferHelper.getBuffered(sb);
                  // when target buffer start exceeds actual buffer start
                  if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {
                    hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BACK_BUFFER_REACHED, {
                      bufferEnd: targetBackBufferPosition
                    });

                    // Support for deprecated event:
                    if (details.live) {
                      hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LIVE_BACK_BUFFER_REACHED, {
                        bufferEnd: targetBackBufferPosition
                      });
                    } else if (sb.ended && buffered.end(buffered.length - 1) - currentTime < targetDuration * 2) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.info(`[buffer-controller]: Cannot flush ${type} back buffer while SourceBuffer is in ended state`);
                      return;
                    }
                    hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, {
                      startOffset: 0,
                      endOffset: targetBackBufferPosition,
                      type
                    });
                  }
                }
              });
            }

            /**
             * Update Media Source duration to current level duration or override to Infinity if configuration parameter
             * 'liveDurationInfinity` is set to `true`
             * More details: https://github.com/video-dev/hls.js/issues/355
             */
            updateMediaElementDuration() {
              if (!this.details || !this.media || !this.mediaSource || this.mediaSource.readyState !== 'open') {
                return;
              }
              const {
                details,
                hls,
                media,
                mediaSource
              } = this;
              const levelDuration = details.fragments[0].start + details.totalduration;
              const mediaDuration = media.duration;
              const msDuration = Number.isFinite(mediaSource.duration) ? mediaSource.duration : 0;
              if (details.live && hls.config.liveDurationInfinity) {
                // Override duration to Infinity
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log('[buffer-controller]: Media Source duration is set to Infinity');
                mediaSource.duration = Infinity;
                this.updateSeekableRange(details);
              } else if (levelDuration > msDuration && levelDuration > mediaDuration || !Number.isFinite(mediaDuration)) {
                // levelDuration was the last value we set.
                // not using mediaSource.duration as the browser may tweak this value
                // only update Media Source duration if its value increase, this is to avoid
                // flushing already buffered portion when switching between quality level
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: Updating Media Source duration to ${levelDuration.toFixed(3)}`);
                mediaSource.duration = levelDuration;
              }
            }
            updateSeekableRange(levelDetails) {
              const mediaSource = this.mediaSource;
              const fragments = levelDetails.fragments;
              const len = fragments.length;
              if (len && levelDetails.live && mediaSource?.setLiveSeekableRange) {
                const start = Math.max(0, fragments[0].start);
                const end = Math.max(start, start + levelDetails.totalduration);
                mediaSource.setLiveSeekableRange(start, end);
              }
            }
            checkPendingTracks() {
              const {
                bufferCodecEventsExpected,
                operationQueue,
                pendingTracks
              } = this;

              // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.
              // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after
              // data has been appended to existing ones.
              // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.
              const pendingTracksCount = Object.keys(pendingTracks).length;
              if (pendingTracksCount && !bufferCodecEventsExpected || pendingTracksCount === 2) {
                // ok, let's create them now !
                this.createSourceBuffers(pendingTracks);
                this.pendingTracks = {};
                // append any pending segments now !
                const buffers = this.getSourceBufferTypes();
                if (buffers.length === 0) {
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                    type: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.MEDIA_ERROR,
                    details: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.BUFFER_INCOMPATIBLE_CODECS_ERROR,
                    fatal: true,
                    reason: 'could not create source buffer for media codec(s)'
                  });
                  return;
                }
                buffers.forEach(type => {
                  operationQueue.executeNext(type);
                });
              }
            }
            createSourceBuffers(tracks) {
              const {
                sourceBuffer,
                mediaSource
              } = this;
              if (!mediaSource) {
                throw Error('createSourceBuffers called when mediaSource was null');
              }
              let tracksCreated = 0;
              for (const trackName in tracks) {
                if (!sourceBuffer[trackName]) {
                  const track = tracks[trackName];
                  if (!track) {
                    throw Error(`source buffer exists for track ${trackName}, however track does not`);
                  }
                  // use levelCodec as first priority
                  const codec = track.levelCodec || track.codec;
                  const mimeType = `${track.container};codecs=${codec}`;
                  _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: creating sourceBuffer(${mimeType})`);
                  try {
                    const sb = sourceBuffer[trackName] = mediaSource.addSourceBuffer(mimeType);
                    const sbName = trackName;
                    this.addBufferListener(sbName, 'updatestart', this._onSBUpdateStart);
                    this.addBufferListener(sbName, 'updateend', this._onSBUpdateEnd);
                    this.addBufferListener(sbName, 'error', this._onSBUpdateError);
                    this.tracks[trackName] = {
                      buffer: sb,
                      codec: codec,
                      container: track.container,
                      levelCodec: track.levelCodec,
                      metadata: track.metadata,
                      id: track.id
                    };
                    tracksCreated++;
                  } catch (err) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.error(`[buffer-controller]: error while trying to add sourceBuffer: ${err.message}`);
                    this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                      type: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.MEDIA_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.BUFFER_ADD_CODEC_ERROR,
                      fatal: false,
                      error: err,
                      mimeType: mimeType
                    });
                  }
                }
              }
              if (tracksCreated) {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CREATED, {
                  tracks: this.tracks
                });
              }
            }

            // Keep as arrow functions so that we can directly reference these functions directly as event listeners
            _onMediaSourceOpen = () => {
              const {
                hls,
                media,
                mediaSource
              } = this;
              _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log('[buffer-controller]: Media source opened');
              if (media) {
                this.updateMediaElementDuration();
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, {
                  media
                });
              }
              if (mediaSource) {
                // once received, don't listen anymore to sourceopen event
                mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);
              }
              this.checkPendingTracks();
            };
            _onMediaSourceClose = () => {
              _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log('[buffer-controller]: Media source closed');
            };
            _onMediaSourceEnded = () => {
              _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log('[buffer-controller]: Media source ended');
            };
            _onSBUpdateStart(type) {
              const {
                operationQueue
              } = this;
              const operation = operationQueue.current(type);
              operation.onStart();
            }
            _onSBUpdateEnd(type) {
              const {
                operationQueue
              } = this;
              const operation = operationQueue.current(type);
              operation.onComplete();
              operationQueue.shiftAndExecuteNext(type);
            }
            _onSBUpdateError(type, event) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.error(`[buffer-controller]: ${type} SourceBuffer error`, event);
              // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error
              // SourceBuffer errors are not necessarily fatal; if so, the HTMLMediaElement will fire an error event
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.MEDIA_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.BUFFER_APPENDING_ERROR,
                fatal: false
              });
              // updateend is always fired after error, so we'll allow that to shift the current operation off of the queue
              const operation = this.operationQueue.current(type);
              if (operation) {
                operation.onError(event);
              }
            }

            // This method must result in an updateend event; if remove is not called, _onSBUpdateEnd must be called manually
            removeExecutor(type, startOffset, endOffset) {
              const {
                media,
                mediaSource,
                operationQueue,
                sourceBuffer
              } = this;
              const sb = sourceBuffer[type];
              if (!media || !mediaSource || !sb) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`[buffer-controller]: Attempting to remove from the ${type} SourceBuffer, but it does not exist`);
                operationQueue.shiftAndExecuteNext(type);
                return;
              }
              const mediaDuration = Number.isFinite(media.duration) ? media.duration : Infinity;
              const msDuration = Number.isFinite(mediaSource.duration) ? mediaSource.duration : Infinity;
              const removeStart = Math.max(0, startOffset);
              const removeEnd = Math.min(endOffset, mediaDuration, msDuration);
              if (removeEnd > removeStart && !sb.ending) {
                sb.ended = false;
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log(`[buffer-controller]: Removing [${removeStart},${removeEnd}] from the ${type} SourceBuffer`);
                console.assert(!sb.updating, `${type} sourceBuffer must not be updating`);
                sb.remove(removeStart, removeEnd);
              } else {
                // Cycle the queue
                operationQueue.shiftAndExecuteNext(type);
              }
            }

            // This method must result in an updateend event; if append is not called, _onSBUpdateEnd must be called manually
            appendExecutor(data, type) {
              const {
                operationQueue,
                sourceBuffer
              } = this;
              const sb = sourceBuffer[type];
              if (!sb) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`[buffer-controller]: Attempting to append to the ${type} SourceBuffer, but it does not exist`);
                operationQueue.shiftAndExecuteNext(type);
                return;
              }
              sb.ended = false;
              console.assert(!sb.updating, `${type} sourceBuffer must not be updating`);
              sb.appendBuffer(data);
            }

            // Enqueues an operation to each SourceBuffer queue which, upon execution, resolves a promise. When all promises
            // resolve, the onUnblocked function is executed. Functions calling this method do not need to unblock the queue
            // upon completion, since we already do it here
            blockBuffers(onUnblocked, buffers = this.getSourceBufferTypes()) {
              if (!buffers.length) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.log('[buffer-controller]: Blocking operation requested, but no SourceBuffers exist');
                Promise.resolve().then(onUnblocked);
                return;
              }
              const {
                operationQueue
              } = this;

              // logger.debug(`[buffer-controller]: Blocking ${buffers} SourceBuffer`);
              const blockingOperations = buffers.map(type => operationQueue.appendBlocker(type));
              Promise.all(blockingOperations).then(() => {
                // logger.debug(`[buffer-controller]: Blocking operation resolved; unblocking ${buffers} SourceBuffer`);
                onUnblocked();
                buffers.forEach(type => {
                  const sb = this.sourceBuffer[type];
                  // Only cycle the queue if the SB is not updating. There's a bug in Chrome which sets the SB updating flag to
                  // true when changing the MediaSource duration (https://bugs.chromium.org/p/chromium/issues/detail?id=959359&can=2&q=mediasource%20duration)
                  // While this is a workaround, it's probably useful to have around
                  if (!sb || !sb.updating) {
                    operationQueue.shiftAndExecuteNext(type);
                  }
                });
              });
            }
            getSourceBufferTypes() {
              return Object.keys(this.sourceBuffer);
            }
            addBufferListener(type, event, fn) {
              const buffer = this.sourceBuffer[type];
              if (!buffer) {
                return;
              }
              const listener = fn.bind(this, type);
              this.listeners[type].push({
                event,
                listener
              });
              buffer.addEventListener(event, listener);
            }
            removeBufferListeners(type) {
              const buffer = this.sourceBuffer[type];
              if (!buffer) {
                return;
              }
              this.listeners[type].forEach(l => {
                buffer.removeEventListener(l.event, l.listener);
              });
            }
          }

          /***/
        }),

/***/ "./src/controller/buffer-operation-queue.ts":
/*!**************************************************!*\
  !*** ./src/controller/buffer-operation-queue.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ BufferOperationQueue)
            /* harmony export */
          });
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");

          class BufferOperationQueue {
            queues = {
              video: [],
              audio: [],
              audiovideo: []
            };
            constructor(sourceBufferReference) {
              this.buffers = sourceBufferReference;
            }
            append(operation, type) {
              const queue = this.queues[type];
              queue.push(operation);
              if (queue.length === 1 && this.buffers[type]) {
                this.executeNext(type);
              }
            }
            insertAbort(operation, type) {
              const queue = this.queues[type];
              queue.unshift(operation);
              this.executeNext(type);
            }
            appendBlocker(type) {
              let execute;
              const promise = new Promise(resolve => {
                execute = resolve;
              });
              const operation = {
                execute,
                onStart: () => { },
                onComplete: () => { },
                onError: () => { }
              };
              this.append(operation, type);
              return promise;
            }
            executeNext(type) {
              const {
                buffers,
                queues
              } = this;
              const sb = buffers[type];
              const queue = queues[type];
              if (queue.length) {
                const operation = queue[0];
                try {
                  // Operations are expected to result in an 'updateend' event being fired. If not, the queue will lock. Operations
                  // which do not end with this event must call _onSBUpdateEnd manually
                  operation.execute();
                } catch (e) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn('[buffer-operation-queue]: Unhandled exception executing the current operation');
                  operation.onError(e);

                  // Only shift the current operation off, otherwise the updateend handler will do this for us
                  if (!sb || !sb.updating) {
                    queue.shift();
                    this.executeNext(type);
                  }
                }
              }
            }
            shiftAndExecuteNext(type) {
              this.queues[type].shift();
              this.executeNext(type);
            }
            current(type) {
              return this.queues[type][0];
            }
          }

          /***/
        }),

/***/ "./src/controller/cap-level-controller.ts":
/*!************************************************!*\
  !*** ./src/controller/cap-level-controller.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
          /*
           * cap stream level to media size dimension controller
           */


          class CapLevelController {
            constructor(hls) {
              this.hls = hls;
              this.autoLevelCapping = Number.POSITIVE_INFINITY;
              this.firstLevel = -1;
              this.media = null;
              this.restrictedLevels = [];
              this.timer = undefined;
              this.clientRect = null;
              this.registerListeners();
            }
            setStreamController(streamController) {
              this.streamController = streamController;
            }
            destroy() {
              this.unregisterListener();
              if (this.hls.config.capLevelToPlayerSize) {
                this.stopCapping();
              }
              this.media = null;
              this.clientRect = null;
              // @ts-ignore
              this.hls = this.streamController = null;
            }
            registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CODECS, this.onBufferCodecs, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
            }
            unregisterListener() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CODECS, this.onBufferCodecs, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
            }
            onFpsDropLevelCapping(event, data) {
              // Don't add a restricted level more than once
              if (CapLevelController.isLevelAllowed(data.droppedLevel, this.restrictedLevels)) {
                this.restrictedLevels.push(data.droppedLevel);
              }
            }
            onMediaAttaching(event, data) {
              this.media = data.media instanceof HTMLVideoElement ? data.media : null;
              this.clientRect = null;
            }
            onManifestParsed(event, data) {
              const hls = this.hls;
              this.restrictedLevels = [];
              this.firstLevel = data.firstLevel;
              if (hls.config.capLevelToPlayerSize && data.video) {
                // Start capping immediately if the manifest has signaled video codecs
                this.startCapping();
              }
            }

            // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted
            // to the first level
            onBufferCodecs(event, data) {
              const hls = this.hls;
              if (hls.config.capLevelToPlayerSize && data.video) {
                // If the manifest did not signal a video codec capping has been deferred until we're certain video is present
                this.startCapping();
              }
            }
            onMediaDetaching() {
              this.stopCapping();
            }
            detectPlayerSize() {
              if (this.media && this.mediaHeight > 0 && this.mediaWidth > 0) {
                const levels = this.hls.levels;
                if (levels.length) {
                  const hls = this.hls;
                  hls.autoLevelCapping = this.getMaxLevel(levels.length - 1);
                  if (hls.autoLevelCapping > this.autoLevelCapping && this.streamController) {
                    // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch
                    // usually happen when the user go to the fullscreen mode.
                    this.streamController.nextLevelSwitch();
                  }
                  this.autoLevelCapping = hls.autoLevelCapping;
                }
              }
            }

            /*
             * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)
             */
            getMaxLevel(capLevelIndex) {
              const levels = this.hls.levels;
              if (!levels.length) {
                return -1;
              }
              const validLevels = levels.filter((level, index) => CapLevelController.isLevelAllowed(index, this.restrictedLevels) && index <= capLevelIndex);
              this.clientRect = null;
              return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);
            }
            startCapping() {
              if (this.timer) {
                // Don't reset capping if started twice; this can happen if the manifest signals a video codec
                return;
              }
              this.autoLevelCapping = Number.POSITIVE_INFINITY;
              this.hls.firstLevel = this.getMaxLevel(this.firstLevel);
              self.clearInterval(this.timer);
              this.timer = self.setInterval(this.detectPlayerSize.bind(this), 1000);
              this.detectPlayerSize();
            }
            stopCapping() {
              this.restrictedLevels = [];
              this.firstLevel = -1;
              this.autoLevelCapping = Number.POSITIVE_INFINITY;
              if (this.timer) {
                self.clearInterval(this.timer);
                this.timer = undefined;
              }
            }
            getDimensions() {
              if (this.clientRect) {
                return this.clientRect;
              }
              const media = this.media;
              const boundsRect = {
                width: 0,
                height: 0
              };
              if (media) {
                const clientRect = media.getBoundingClientRect();
                boundsRect.width = clientRect.width;
                boundsRect.height = clientRect.height;
                if (!boundsRect.width && !boundsRect.height) {
                  // When the media element has no width or height (equivalent to not being in the DOM),
                  // then use its width and height attributes (media.width, media.height)
                  boundsRect.width = clientRect.right - clientRect.left || media.width || 0;
                  boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;
                }
              }
              this.clientRect = boundsRect;
              return boundsRect;
            }
            get mediaWidth() {
              return this.getDimensions().width * this.contentScaleFactor;
            }
            get mediaHeight() {
              return this.getDimensions().height * this.contentScaleFactor;
            }
            get contentScaleFactor() {
              let pixelRatio = 1;
              if (!this.hls.config.ignoreDevicePixelRatio) {
                try {
                  pixelRatio = self.devicePixelRatio;
                } catch (e) {
                  /* no-op */
                }
              }
              return pixelRatio;
            }
            static isLevelAllowed(level, restrictedLevels = []) {
              return restrictedLevels.indexOf(level) === -1;
            }
            static getMaxLevelByMediaSize(levels, width, height) {
              if (!levels || !levels.length) {
                return -1;
              }

              // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next
              // to determine whether we've chosen the greatest bandwidth for the media's dimensions
              const atGreatestBandwidth = (curLevel, nextLevel) => {
                if (!nextLevel) {
                  return true;
                }
                return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;
              };

              // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to
              // the max level
              let maxLevelIndex = levels.length - 1;
              for (let i = 0; i < levels.length; i += 1) {
                const level = levels[i];
                if ((level.width >= width || level.height >= height) && atGreatestBandwidth(level, levels[i + 1])) {
                  maxLevelIndex = i;
                  break;
                }
              }
              return maxLevelIndex;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CapLevelController);

          /***/
        }),

/***/ "./src/controller/cmcd-controller.ts":
/*!*******************************************!*\
  !*** ./src/controller/cmcd-controller.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ CMCDController)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _types_cmcd__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../types/cmcd */ "./src/types/cmcd.ts");
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");





          /**
           * Controller to deal with Common Media Client Data (CMCD)
           * @see https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf
           */
          class CMCDController {
            useHeaders = false;
            initialized = false;
            starved = false;
            buffering = true;
            // eslint-disable-line no-restricted-globals

            constructor(hls) {
              this.hls = hls;
              const config = this.config = hls.config;
              const {
                cmcd
              } = config;
              if (cmcd != null) {
                config.pLoader = this.createPlaylistLoader();
                config.fLoader = this.createFragmentLoader();
                this.sid = cmcd.sessionId || CMCDController.uuid();
                this.cid = cmcd.contentId;
                this.useHeaders = cmcd.useHeaders === true;
                this.registerListeners();
              }
            }
            registerListeners() {
              const hls = this.hls;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHED, this.onMediaDetached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CREATED, this.onBufferCreated, this);
            }
            unregisterListeners() {
              const hls = this.hls;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHED, this.onMediaDetached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_CREATED, this.onBufferCreated, this);
              this.onMediaDetached();
            }
            destroy() {
              this.unregisterListeners();

              // @ts-ignore
              this.hls = this.config = this.audioBuffer = this.videoBuffer = null;
            }
            onMediaAttached(event, data) {
              this.media = data.media;
              this.media.addEventListener('waiting', this.onWaiting);
              this.media.addEventListener('playing', this.onPlaying);
            }
            onMediaDetached() {
              if (!this.media) {
                return;
              }
              this.media.removeEventListener('waiting', this.onWaiting);
              this.media.removeEventListener('playing', this.onPlaying);

              // @ts-ignore
              this.media = null;
            }
            onBufferCreated(event, data) {
              this.audioBuffer = data.tracks.audio?.buffer;
              this.videoBuffer = data.tracks.video?.buffer;
            }
            onWaiting = () => {
              if (this.initialized) {
                this.starved = true;
              }
              this.buffering = true;
            };
            onPlaying = () => {
              if (!this.initialized) {
                this.initialized = true;
              }
              this.buffering = false;
            };

            /**
             * Create baseline CMCD data
             */
            createData() {
              return {
                v: _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDVersion,
                sf: _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDStreamingFormat.HLS,
                sid: this.sid,
                cid: this.cid,
                pr: this.media?.playbackRate,
                mtp: this.hls.bandwidthEstimate / 1000
              };
            }

            /**
             * Apply CMCD data to a request.
             */
            apply(context, data = {}) {
              // apply baseline data
              Object.assign(data, this.createData());
              const isVideo = data.ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.INIT || data.ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.VIDEO || data.ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.MUXED;
              if (this.starved && isVideo) {
                data.bs = true;
                data.su = true;
                this.starved = false;
              }
              if (data.su == null) {
                data.su = this.buffering;
              }

              // TODO: Implement rtp, nrr, nor, dl

              if (this.useHeaders) {
                const headers = CMCDController.toHeaders(data);
                if (!Object.keys(headers).length) {
                  return;
                }
                if (!context.headers) {
                  context.headers = {};
                }
                Object.assign(context.headers, headers);
              } else {
                const query = CMCDController.toQuery(data);
                if (!query) {
                  return;
                }
                context.url = CMCDController.appendQueryToUri(context.url, query);
              }
            }

            /**
             * Apply CMCD data to a manifest request.
             */
            applyPlaylistData = context => {
              try {
                this.apply(context, {
                  ot: _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.MANIFEST,
                  su: !this.initialized
                });
              } catch (error) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('Could not generate manifest CMCD data.', error);
              }
            };

            /**
             * Apply CMCD data to a segment request
             */
            applyFragmentData = context => {
              try {
                const fragment = context.frag;
                const level = this.hls.levels[fragment.level];
                const ot = this.getObjectType(fragment);
                const data = {
                  d: fragment.duration * 1000,
                  ot
                };
                if (ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.VIDEO || ot === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.AUDIO || ot == _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.MUXED) {
                  data.br = level.bitrate / 1000;
                  data.tb = this.getTopBandwidth(ot) / 1000;
                  data.bl = this.getBufferLength(ot);
                }
                this.apply(context, data);
              } catch (error) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('Could not generate segment CMCD data.', error);
              }
            };

            /**
             * The CMCD object type.
             */
            getObjectType(fragment) {
              const {
                type
              } = fragment;
              if (type === 'subtitle') {
                return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.TIMED_TEXT;
              }
              if (fragment.sn === 'initSegment') {
                return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.INIT;
              }
              if (type === 'audio') {
                return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.AUDIO;
              }
              if (type === 'main') {
                if (!this.hls.audioTracks.length) {
                  return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.MUXED;
                }
                return _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.VIDEO;
              }
              return undefined;
            }

            /**
             * Get the highest bitrate.
             */
            getTopBandwidth(type) {
              let bitrate = 0;
              let levels;
              const hls = this.hls;
              if (type === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.AUDIO) {
                levels = hls.audioTracks;
              } else {
                const max = hls.maxAutoLevel;
                const len = max > -1 ? max + 1 : hls.levels.length;
                levels = hls.levels.slice(0, len);
              }
              for (const level of levels) {
                if (level.bitrate > bitrate) {
                  bitrate = level.bitrate;
                }
              }
              return bitrate > 0 ? bitrate : NaN;
            }

            /**
             * Get the buffer length for a media type in milliseconds
             */
            getBufferLength(type) {
              const media = this.hls.media;
              const buffer = type === _types_cmcd__WEBPACK_IMPORTED_MODULE_1__.CMCDObjectType.AUDIO ? this.audioBuffer : this.videoBuffer;
              if (!buffer || !media) {
                return NaN;
              }
              const info = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_2__.BufferHelper.bufferInfo(buffer, media.currentTime, this.config.maxBufferHole);
              return info.len * 1000;
            }

            /**
             * Create a playlist loader
             */
            createPlaylistLoader() {
              const {
                pLoader
              } = this.config;
              const apply = this.applyPlaylistData;
              const Ctor = pLoader || this.config.loader;
              return class CmcdPlaylistLoader {
                constructor(config) {
                  this.loader = new Ctor(config);
                }
                get stats() {
                  return this.loader.stats;
                }
                get context() {
                  return this.loader.context;
                }
                destroy() {
                  this.loader.destroy();
                }
                abort() {
                  this.loader.abort();
                }
                load(context, config, callbacks) {
                  apply(context);
                  this.loader.load(context, config, callbacks);
                }
              };
            }

            /**
             * Create a playlist loader
             */
            createFragmentLoader() {
              const {
                fLoader
              } = this.config;
              const apply = this.applyFragmentData;
              const Ctor = fLoader || this.config.loader;
              return class CmcdFragmentLoader {
                constructor(config) {
                  this.loader = new Ctor(config);
                }
                get stats() {
                  return this.loader.stats;
                }
                get context() {
                  return this.loader.context;
                }
                destroy() {
                  this.loader.destroy();
                }
                abort() {
                  this.loader.abort();
                }
                load(context, config, callbacks) {
                  apply(context);
                  this.loader.load(context, config, callbacks);
                }
              };
            }

            /**
             * Generate a random v4 UUI
             *
             * @returns {string}
             */
            static uuid() {
              const url = URL.createObjectURL(new Blob());
              const uuid = url.toString();
              URL.revokeObjectURL(url);
              return uuid.slice(uuid.lastIndexOf('/') + 1);
            }

            /**
             * Serialize a CMCD data object according to the rules defined in the
             * section 3.2 of
             * [CTA-5004](https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf).
             */
            static serialize(data) {
              const results = [];
              const isValid = value => !Number.isNaN(value) && value != null && value !== '' && value !== false;
              const toRounded = value => Math.round(value);
              const toHundred = value => toRounded(value / 100) * 100;
              const toUrlSafe = value => encodeURIComponent(value);
              const formatters = {
                br: toRounded,
                d: toRounded,
                bl: toHundred,
                dl: toHundred,
                mtp: toHundred,
                nor: toUrlSafe,
                rtp: toHundred,
                tb: toRounded
              };
              const keys = Object.keys(data || {}).sort();
              for (const key of keys) {
                let value = data[key];

                // ignore invalid values
                if (!isValid(value)) {
                  continue;
                }

                // Version should only be reported if not equal to 1.
                if (key === 'v' && value === 1) {
                  continue;
                }

                // Playback rate should only be sent if not equal to 1.
                if (key == 'pr' && value === 1) {
                  continue;
                }

                // Certain values require special formatting
                const formatter = formatters[key];
                if (formatter) {
                  value = formatter(value);
                }

                // Serialize the key/value pair
                const type = typeof value;
                let result;
                if (key === 'ot' || key === 'sf' || key === 'st') {
                  result = `${key}=${value}`;
                } else if (type === 'boolean') {
                  result = key;
                } else if (type === 'number') {
                  result = `${key}=${value}`;
                } else {
                  result = `${key}=${JSON.stringify(value)}`;
                }
                results.push(result);
              }
              return results.join(',');
            }

            /**
             * Convert a CMCD data object to request headers according to the rules
             * defined in the section 2.1 and 3.2 of
             * [CTA-5004](https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf).
             */
            static toHeaders(data) {
              const keys = Object.keys(data);
              const headers = {};
              const headerNames = ['Object', 'Request', 'Session', 'Status'];
              const headerGroups = [{}, {}, {}, {}];
              const headerMap = {
                br: 0,
                d: 0,
                ot: 0,
                tb: 0,
                bl: 1,
                dl: 1,
                mtp: 1,
                nor: 1,
                nrr: 1,
                su: 1,
                cid: 2,
                pr: 2,
                sf: 2,
                sid: 2,
                st: 2,
                v: 2,
                bs: 3,
                rtp: 3
              };
              for (const key of keys) {
                // Unmapped fields are mapped to the Request header
                const index = headerMap[key] != null ? headerMap[key] : 1;
                headerGroups[index][key] = data[key];
              }
              for (let i = 0; i < headerGroups.length; i++) {
                const value = CMCDController.serialize(headerGroups[i]);
                if (value) {
                  headers[`CMCD-${headerNames[i]}`] = value;
                }
              }
              return headers;
            }

            /**
             * Convert a CMCD data object to query args according to the rules
             * defined in the section 2.2 and 3.2 of
             * [CTA-5004](https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf).
             */
            static toQuery(data) {
              return `CMCD=${encodeURIComponent(CMCDController.serialize(data))}`;
            }

            /**
             * Append query args to a uri.
             */
            static appendQueryToUri(uri, query) {
              if (!query) {
                return uri;
              }
              const separator = uri.includes('?') ? '&' : '?';
              return `${uri}${separator}${query}`;
            }
          }

          /***/
        }),

/***/ "./src/controller/eme-controller.ts":
/*!******************************************!*\
  !*** ./src/controller/eme-controller.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/mediakeys-helper */ "./src/utils/mediakeys-helper.ts");
/* harmony import */ var _utils_keysystem_util__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/keysystem-util */ "./src/utils/keysystem-util.ts");
/* harmony import */ var _utils_numeric_encoding_utils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/numeric-encoding-utils */ "./src/utils/numeric-encoding-utils.ts");
/* harmony import */ var _loader_level_key__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../loader/level-key */ "./src/loader/level-key.ts");
/* harmony import */ var _utils_hex__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/hex */ "./src/utils/hex.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(eventemitter3__WEBPACK_IMPORTED_MODULE_9__);
          /**
           * @author Stephan Hesse <disparat@gmail.com> | <tchakabam@gmail.com>
           *
           * DRM support for Hls.js
           */











          const MAX_LICENSE_REQUEST_FAILURES = 3;
          const LOGGER_PREFIX = '[eme]';
          /**
           * Controller to deal with encrypted media extensions (EME)
           * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API
           *
           * @class
           * @constructor
           */
          class EMEController {
            media = null;
            keyFormatPromise = null;
            keySystemAccessPromises = {};
            _requestLicenseFailureCount = 0;
            mediaKeySessions = [];
            keyIdToKeySessionPromise = {};
            setMediaKeysQueue = EMEController.CDMCleanupPromise ? [EMEController.CDMCleanupPromise] : [];
            onMediaEncrypted = this._onMediaEncrypted.bind(this);
            onWaitingForKey = this._onWaitingForKey.bind(this);
            debug = _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.debug.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger, LOGGER_PREFIX);
            log = _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.log.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger, LOGGER_PREFIX);
            warn = _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.warn.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger, LOGGER_PREFIX);
            error = _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.error.bind(_utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger, LOGGER_PREFIX);
            constructor(hls) {
              this.hls = hls;
              this.config = hls.config;
              this.registerListeners();
            }
            destroy() {
              this.unregisterListeners();
              this.onMediaDetached();
              // @ts-ignore
              this.hls = this.onMediaEncrypted = this.onWaitingForKey = this.keyIdToKeySessionPromise = null;
            }
            registerListeners() {
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHED, this.onMediaDetached, this);
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADED, this.onManifestLoaded, this);
            }
            unregisterListeners() {
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHED, this.onMediaDetached, this);
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADED, this.onManifestLoaded, this);
            }
            getLicenseServerUrl(keySystem) {
              const {
                drmSystems,
                widevineLicenseUrl
              } = this.config;
              const keySystemConfiguration = drmSystems[keySystem];
              if (keySystemConfiguration) {
                return keySystemConfiguration.licenseUrl;
              }

              // For backward compatibility
              if (keySystem === _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.KeySystems.WIDEVINE && widevineLicenseUrl) {
                return widevineLicenseUrl;
              }
              throw new Error(`no license server URL configured for key-system "${keySystem}"`);
            }
            getServerCertificateUrl(keySystem) {
              const {
                drmSystems
              } = this.config;
              const keySystemConfiguration = drmSystems[keySystem];
              if (keySystemConfiguration) {
                return keySystemConfiguration.serverCertificateUrl;
              } else {
                this.log(`No Server Certificate in config.drmSystems["${keySystem}"]`);
              }
            }
            attemptKeySystemAccess(keySystemsToAttempt) {
              const levels = this.hls.levels;
              const uniqueCodec = (value, i, a) => !!value && a.indexOf(value) === i;
              const audioCodecs = levels.map(level => level.audioCodec).filter(uniqueCodec);
              const videoCodecs = levels.map(level => level.videoCodec).filter(uniqueCodec);
              if (audioCodecs.length + videoCodecs.length === 0) {
                videoCodecs.push('avc1.42e01e');
              }
              return new Promise((resolve, reject) => {
                const attempt = keySystems => {
                  const keySystem = keySystems.shift();
                  this.getMediaKeysPromise(keySystem, audioCodecs, videoCodecs).then(mediaKeys => resolve({
                    keySystem,
                    mediaKeys
                  })).catch(error => {
                    if (keySystems.length) {
                      attempt(keySystems);
                    } else if (error instanceof EMEKeyError) {
                      reject(error);
                    } else {
                      reject(new EMEKeyError({
                        type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                        details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_NO_ACCESS,
                        error,
                        fatal: true
                      }, error.message));
                    }
                  });
                };
                attempt(keySystemsToAttempt);
              });
            }
            requestMediaKeySystemAccess(keySystem, supportedConfigurations) {
              const {
                requestMediaKeySystemAccessFunc
              } = this.config;
              if (!(typeof requestMediaKeySystemAccessFunc === 'function')) {
                let errMessage = `Configured requestMediaKeySystemAccess is not a function ${requestMediaKeySystemAccessFunc}`;
                if (_utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.requestMediaKeySystemAccess === null && self.location.protocol === 'http:') {
                  errMessage = `navigator.requestMediaKeySystemAccess is not available over insecure protocol ${location.protocol}`;
                }
                return Promise.reject(new Error(errMessage));
              }
              return requestMediaKeySystemAccessFunc(keySystem, supportedConfigurations);
            }
            getMediaKeysPromise(keySystem, audioCodecs, videoCodecs) {
              // This can throw, but is caught in event handler callpath
              const mediaKeySystemConfigs = (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.getSupportedMediaKeySystemConfigurations)(keySystem, audioCodecs, videoCodecs, this.config.drmSystemOptions);
              const keySystemAccessPromises = this.keySystemAccessPromises[keySystem];
              let keySystemAccess = keySystemAccessPromises?.keySystemAccess;
              if (!keySystemAccess) {
                this.log(`Requesting encrypted media "${keySystem}" key-system access with config: ${JSON.stringify(mediaKeySystemConfigs)}`);
                keySystemAccess = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);
                const keySystemAccessPromises = this.keySystemAccessPromises[keySystem] = {
                  keySystemAccess
                };
                keySystemAccess.catch(error => {
                  this.log(`Failed to obtain access to key-system "${keySystem}": ${error}`);
                });
                return keySystemAccess.then(mediaKeySystemAccess => {
                  this.log(`Access for key-system "${mediaKeySystemAccess.keySystem}" obtained`);
                  const certificateRequest = this.fetchServerCertificate(keySystem);
                  this.log(`Create media-keys for "${keySystem}"`);
                  keySystemAccessPromises.mediaKeys = mediaKeySystemAccess.createMediaKeys().then(mediaKeys => {
                    this.log(`Media-keys created for "${keySystem}"`);
                    return certificateRequest.then(certificate => {
                      if (certificate) {
                        return this.setMediaKeysServerCertificate(mediaKeys, keySystem, certificate);
                      }
                      return mediaKeys;
                    });
                  });
                  keySystemAccessPromises.mediaKeys.catch(error => {
                    this.error(`Failed to create media-keys for "${keySystem}"}: ${error}`);
                  });
                  return keySystemAccessPromises.mediaKeys;
                });
              }
              return keySystemAccess.then(() => keySystemAccessPromises.mediaKeys);
            }
            createMediaKeySessionContext({
              decryptdata,
              keySystem,
              mediaKeys
            }) {
              console.assert(!!mediaKeys, 'mediaKeys is defined');
              this.log(`Creating key-system session "${keySystem}" keyId: ${_utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump(decryptdata.keyId || [])}`);
              const mediaKeysSession = mediaKeys.createSession();
              const mediaKeySessionContext = {
                decryptdata,
                keySystem,
                mediaKeys,
                mediaKeysSession,
                keyStatus: 'status-pending'
              };
              this.mediaKeySessions.push(mediaKeySessionContext);
              return mediaKeySessionContext;
            }
            renewKeySession(mediaKeySessionContext) {
              const decryptdata = mediaKeySessionContext.decryptdata;
              if (decryptdata.pssh) {
                const keySessionContext = this.createMediaKeySessionContext(mediaKeySessionContext);
                const keyId = this.getKeyIdString(decryptdata);
                const scheme = 'cenc';
                this.keyIdToKeySessionPromise[keyId] = this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh, 'expired');
              } else {
                this.warn(`Could not renew expired session. Missing pssh initData.`);
              }
              this.removeSession(mediaKeySessionContext);
            }
            getKeyIdString(decryptdata) {
              if (!decryptdata) {
                throw new Error('Could not read keyId of undefined decryptdata');
              }
              if (decryptdata.keyId === null) {
                throw new Error('keyId is null');
              }
              return _utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump(decryptdata.keyId);
            }
            updateKeySession(mediaKeySessionContext, data) {
              const keySession = mediaKeySessionContext.mediaKeysSession;
              this.log(`Updating key-session "${keySession.sessionId}" for keyID ${_utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump(mediaKeySessionContext.decryptdata?.keyId || [])}
      } (data length: ${data ? data.byteLength : data})`);
              return keySession.update(data);
            }
            selectKeySystemFormat(frag) {
              const keyFormats = Object.keys(frag.levelkeys || {});
              if (!this.keyFormatPromise) {
                this.log(`Selecting key-system from fragment (sn: ${frag.sn} ${frag.type}: ${frag.level}) key formats ${keyFormats.join(', ')}`);
                this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);
              }
              return this.keyFormatPromise;
            }
            getKeyFormatPromise(keyFormats) {
              return new Promise((resolve, reject) => {
                const keySystemsInConfig = (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.getKeySystemsForConfig)(this.config);
                const keySystemsToAttempt = keyFormats.map(_utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.keySystemFormatToKeySystemDomain).filter(value => !!value && keySystemsInConfig.indexOf(value) !== -1);
                return this.getKeySystemSelectionPromise(keySystemsToAttempt).then(({
                  keySystem
                }) => {
                  const keySystemFormat = (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.keySystemDomainToKeySystemFormat)(keySystem);
                  if (keySystemFormat) {
                    resolve(keySystemFormat);
                  } else {
                    reject(new Error(`Unable to find format for key-system "${keySystem}"`));
                  }
                }).catch(reject);
              });
            }
            loadKey(data) {
              const decryptdata = data.keyInfo.decryptdata;
              const keyId = this.getKeyIdString(decryptdata);
              const keyDetails = `(keyId: ${keyId} format: "${decryptdata.keyFormat}" method: ${decryptdata.method} uri: ${decryptdata.uri})`;
              this.log(`Starting session for key ${keyDetails}`);
              let keySessionContextPromise = this.keyIdToKeySessionPromise[keyId];
              if (!keySessionContextPromise) {
                keySessionContextPromise = this.keyIdToKeySessionPromise[keyId] = this.getKeySystemForKeyPromise(decryptdata).then(({
                  keySystem,
                  mediaKeys
                }) => {
                  this.throwIfDestroyed();
                  this.log(`Handle encrypted media sn: ${data.frag.sn} ${data.frag.type}: ${data.frag.level} using key ${keyDetails}`);
                  return this.attemptSetMediaKeys(keySystem, mediaKeys).then(() => {
                    this.throwIfDestroyed();
                    const keySessionContext = this.createMediaKeySessionContext({
                      keySystem,
                      mediaKeys,
                      decryptdata
                    });
                    const scheme = 'cenc';
                    return this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh, 'playlist-key');
                  });
                });
                keySessionContextPromise.catch(error => this.handleError(error));
              }
              return keySessionContextPromise;
            }
            throwIfDestroyed(message = 'Invalid state') {
              if (!this.hls) {
                throw new Error('invalid state');
              }
            }
            handleError(error) {
              if (!this.hls) {
                return;
              }
              this.error(error.message);
              if (error instanceof EMEKeyError) {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, error.data);
              } else {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_NO_KEYS,
                  error,
                  fatal: true
                });
              }
            }
            getKeySystemForKeyPromise(decryptdata) {
              const keyId = this.getKeyIdString(decryptdata);
              const mediaKeySessionContext = this.keyIdToKeySessionPromise[keyId];
              if (!mediaKeySessionContext) {
                const keySystem = (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.keySystemFormatToKeySystemDomain)(decryptdata.keyFormat);
                const keySystemsToAttempt = keySystem ? [keySystem] : (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.getKeySystemsForConfig)(this.config);
                return this.attemptKeySystemAccess(keySystemsToAttempt);
              }
              return mediaKeySessionContext;
            }
            getKeySystemSelectionPromise(keySystemsToAttempt) {
              if (!keySystemsToAttempt.length) {
                keySystemsToAttempt = (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.getKeySystemsForConfig)(this.config);
              }
              if (keySystemsToAttempt.length === 0) {
                throw new EMEKeyError({
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_NO_CONFIGURED_LICENSE,
                  fatal: true
                }, `Missing key-system license configuration options ${JSON.stringify({
                  drmSystems: this.config.drmSystems
                })}`);
              }
              return this.attemptKeySystemAccess(keySystemsToAttempt);
            }
            _onMediaEncrypted(event) {
              const {
                initDataType,
                initData
              } = event;
              this.debug(`"${event.type}" event: init data type: "${initDataType}"`);

              // Ignore event when initData is null
              if (initData === null) {
                return;
              }
              let keyId;
              let keySystemDomain;
              if (initDataType === 'sinf' && this.config.drmSystems[_utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.KeySystems.FAIRPLAY]) {
                // Match sinf keyId to playlist skd://keyId=
                const json = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_8__.bin2str)(new Uint8Array(initData));
                try {
                  const sinf = (0, _utils_numeric_encoding_utils__WEBPACK_IMPORTED_MODULE_5__.base64Decode)(JSON.parse(json).sinf);
                  const tenc = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_8__.parseSinf)(new Uint8Array(sinf));
                  if (!tenc) {
                    return;
                  }
                  keyId = tenc.subarray(8, 24);
                  keySystemDomain = _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.KeySystems.FAIRPLAY;
                } catch (error) {
                  this.warn('Failed to parse sinf "encrypted" event message initData');
                  return;
                }
              } else {
                // Support clear-lead key-session creation (otherwise depend on playlist keys)
                const psshInfo = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_8__.parsePssh)(initData);
                if (psshInfo === null) {
                  return;
                }
                if (psshInfo.version === 0 && psshInfo.systemId === _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.KeySystemIds.WIDEVINE && psshInfo.data) {
                  keyId = psshInfo.data.subarray(8, 24);
                }
                keySystemDomain = (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.keySystemIdToKeySystemDomain)(psshInfo.systemId);
              }
              if (!keySystemDomain || !keyId) {
                return;
              }
              const keyIdHex = _utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump(keyId);
              const {
                keyIdToKeySessionPromise,
                mediaKeySessions
              } = this;
              let keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex];
              for (let i = 0; i < mediaKeySessions.length; i++) {
                // Match playlist key
                const keyContext = mediaKeySessions[i];
                const decryptdata = keyContext.decryptdata;
                if (decryptdata.pssh || !decryptdata.keyId) {
                  continue;
                }
                const oldKeyIdHex = _utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump(decryptdata.keyId);
                if (keyIdHex === oldKeyIdHex || decryptdata.uri.replace(/-/g, '').indexOf(keyIdHex) !== -1) {
                  keySessionContextPromise = keyIdToKeySessionPromise[oldKeyIdHex];
                  delete keyIdToKeySessionPromise[oldKeyIdHex];
                  decryptdata.pssh = new Uint8Array(initData);
                  decryptdata.keyId = keyId;
                  keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = keySessionContextPromise.then(() => {
                    return this.generateRequestWithPreferredKeySession(keyContext, initDataType, initData, 'encrypted-event-key-match');
                  });
                  break;
                }
              }
              if (!keySessionContextPromise) {
                // Clear-lead key (not encountered in playlist)
                keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = this.getKeySystemSelectionPromise([keySystemDomain]).then(({
                  keySystem,
                  mediaKeys
                }) => {
                  this.throwIfDestroyed();
                  const decryptdata = new _loader_level_key__WEBPACK_IMPORTED_MODULE_6__.LevelKey('ISO-23001-7', keyIdHex, (0, _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.keySystemDomainToKeySystemFormat)(keySystem) ?? '');
                  decryptdata.pssh = new Uint8Array(initData);
                  decryptdata.keyId = keyId;
                  return this.attemptSetMediaKeys(keySystem, mediaKeys).then(() => {
                    this.throwIfDestroyed();
                    const keySessionContext = this.createMediaKeySessionContext({
                      decryptdata,
                      keySystem,
                      mediaKeys
                    });
                    return this.generateRequestWithPreferredKeySession(keySessionContext, initDataType, initData, 'encrypted-event-no-match');
                  });
                });
              }
              keySessionContextPromise.catch(error => this.handleError(error));
            }
            _onWaitingForKey(event) {
              this.log(`"${event.type}" event`);
            }
            attemptSetMediaKeys(keySystem, mediaKeys) {
              const queue = this.setMediaKeysQueue.slice();
              this.log(`Setting media-keys for "${keySystem}"`);
              // Only one setMediaKeys() can run at one time, and multiple setMediaKeys() operations
              // can be queued for execution for multiple key sessions.
              const setMediaKeysPromise = Promise.all(queue).then(() => {
                if (!this.media) {
                  throw new Error('Attempted to set mediaKeys without media element attached');
                }
                return this.media.setMediaKeys(mediaKeys);
              });
              this.setMediaKeysQueue.push(setMediaKeysPromise);
              return setMediaKeysPromise.then(() => {
                this.log(`Media-keys set for "${keySystem}"`);
                queue.push(setMediaKeysPromise);
                this.setMediaKeysQueue = this.setMediaKeysQueue.filter(p => queue.indexOf(p) === -1);
              });
            }
            generateRequestWithPreferredKeySession(context, initDataType, initData, reason) {
              const generateRequestFilter = this.config.drmSystems?.[context.keySystem]?.generateRequest;
              if (generateRequestFilter) {
                try {
                  const mappedInitData = generateRequestFilter.call(this.hls, initDataType, initData, context);
                  if (!mappedInitData) {
                    throw new Error('Invalid response from configured generateRequest filter');
                  }
                  initDataType = mappedInitData.initDataType;
                  initData = context.decryptdata.pssh = mappedInitData.initData ? new Uint8Array(mappedInitData.initData) : null;
                } catch (error) {
                  this.warn(error.message);
                  if (this.hls?.config.debug) {
                    throw error;
                  }
                }
              }
              if (initData === null) {
                this.log(`Skipping key-session request for "${reason}" (no initData)`);
                return Promise.resolve(context);
              }
              const keyId = this.getKeyIdString(context.decryptdata);
              this.log(`Generating key-session request for "${reason}": ${keyId} (init data type: ${initDataType} length: ${initData ? initData.byteLength : null})`);
              const licenseStatus = new (eventemitter3__WEBPACK_IMPORTED_MODULE_9___default())();
              context.mediaKeysSession.onmessage = event => {
                const keySession = context.mediaKeysSession;
                if (!keySession) {
                  licenseStatus.emit('error', new Error('invalid state'));
                  return;
                }
                const {
                  messageType,
                  message
                } = event;
                this.log(`"${messageType}" message event for session "${keySession.sessionId}" message size: ${message.byteLength}`);
                if (messageType === 'license-request' || messageType === 'license-renewal') {
                  this.renewLicense(context, message).catch(error => {
                    this.handleError(error);
                    licenseStatus.emit('error', error);
                  });
                } else if (messageType === 'license-release') {
                  if (context.keySystem === _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_3__.KeySystems.FAIRPLAY) {
                    this.updateKeySession(context, (0, _utils_keysystem_util__WEBPACK_IMPORTED_MODULE_4__.strToUtf8array)('acknowledged'));
                    this.removeSession(context);
                  }
                } else {
                  this.warn(`unhandled media key message type "${messageType}"`);
                }
              };
              context.mediaKeysSession.onkeystatuseschange = event => {
                const keySession = context.mediaKeysSession;
                if (!keySession) {
                  licenseStatus.emit('error', new Error('invalid state'));
                  return;
                }
                this.onKeyStatusChange(context);
                const keyStatus = context.keyStatus;
                licenseStatus.emit('keyStatus', keyStatus);
                if (keyStatus === 'expired') {
                  this.warn(`${context.keySystem} expired for key ${keyId}`);
                  this.renewKeySession(context);
                }
              };
              const keyUsablePromise = new Promise((resolve, reject) => {
                licenseStatus.on('error', reject);
                licenseStatus.on('keyStatus', keyStatus => {
                  if (keyStatus.startsWith('usable')) {
                    resolve();
                  } else if (keyStatus === 'output-restricted') {
                    reject(new EMEKeyError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED,
                      fatal: false
                    }, 'HDCP level output restricted'));
                  } else if (keyStatus === 'internal-error') {
                    reject(new EMEKeyError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR,
                      fatal: true
                    }, `key status changed to "${keyStatus}"`));
                  } else if (keyStatus === 'expired') {
                    reject(new Error('key expired while generating request'));
                  } else {
                    this.warn(`unhandled key status change "${keyStatus}"`);
                  }
                });
              });
              return context.mediaKeysSession.generateRequest(initDataType, initData).then(() => {
                this.log(`Request generated for key-session "${context.mediaKeysSession?.sessionId}" keyId: ${keyId}`);
              }).catch(error => {
                throw new EMEKeyError({
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_NO_SESSION,
                  error,
                  fatal: false
                }, `Error generating key-session request: ${error}`);
              }).then(() => keyUsablePromise).catch(error => {
                licenseStatus.removeAllListeners();
                this.removeSession(context);
                throw error;
              }).then(() => {
                licenseStatus.removeAllListeners();
                return context;
              });
            }
            onKeyStatusChange(mediaKeySessionContext) {
              mediaKeySessionContext.mediaKeysSession.keyStatuses.forEach((status, keyId) => {
                this.log(`key status change "${status}" for keyStatuses keyId: ${_utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump('buffer' in keyId ? new Uint8Array(keyId.buffer, keyId.byteOffset, keyId.byteLength) : new Uint8Array(keyId))} session keyId: ${_utils_hex__WEBPACK_IMPORTED_MODULE_7__["default"].hexDump(new Uint8Array(mediaKeySessionContext.decryptdata.keyId || []))} uri: ${mediaKeySessionContext.decryptdata.uri}`);
                mediaKeySessionContext.keyStatus = status;
              });
            }
            fetchServerCertificate(keySystem) {
              return new Promise((resolve, reject) => {
                const url = this.getServerCertificateUrl(keySystem);
                if (!url) {
                  return resolve();
                }
                this.log(`Fetching serverCertificate for "${keySystem}"`);
                const xhr = new XMLHttpRequest();
                xhr.open('GET', url, true);
                xhr.responseType = 'arraybuffer';
                xhr.onreadystatechange = () => {
                  if (xhr.readyState === XMLHttpRequest.DONE) {
                    if (xhr.status === 200) {
                      resolve(xhr.response);
                    } else {
                      reject(new EMEKeyError({
                        type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                        details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,
                        fatal: true,
                        networkDetails: xhr
                      }, `"${keySystem}" certificate request XHR failed (${url}). Status: ${xhr.status} (${xhr.statusText})`));
                    }
                  }
                };
                xhr.send();
              });
            }
            setMediaKeysServerCertificate(mediaKeys, keySystem, cert) {
              return new Promise((resolve, reject) => {
                mediaKeys.setServerCertificate(cert).then(success => {
                  this.log(`setServerCertificate ${success ? 'success' : 'not supported by CDM'} (${cert?.byteLength}) on "${keySystem}"`);
                  resolve(mediaKeys);
                }).catch(error => {
                  reject(new EMEKeyError({
                    type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                    details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED,
                    error,
                    fatal: true
                  }, error.message));
                });
              });
            }
            renewLicense(context, keyMessage) {
              return this.requestLicense(context, new Uint8Array(keyMessage)).then(data => {
                return this.updateKeySession(context, new Uint8Array(data)).catch(error => {
                  throw new EMEKeyError({
                    type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                    details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED,
                    error,
                    fatal: true
                  }, error.message);
                });
              });
            }
            setupLicenseXHR(xhr, url, keysListItem, licenseChallenge) {
              const licenseXhrSetup = this.config.licenseXhrSetup;
              if (!licenseXhrSetup) {
                xhr.open('POST', url, true);
                return Promise.resolve({
                  xhr,
                  licenseChallenge
                });
              }
              return Promise.resolve().then(() => {
                if (!keysListItem.decryptdata) {
                  throw new Error('Key removed');
                }
                return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);
              }).catch(error => {
                if (!keysListItem.decryptdata) {
                  // Key session removed. Cancel license request.
                  throw error;
                }
                // let's try to open before running setup
                xhr.open('POST', url, true);
                return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);
              }).then(licenseXhrSetupResult => {
                // if licenseXhrSetup did not yet call open, let's do it now
                if (!xhr.readyState) {
                  xhr.open('POST', url, true);
                }
                const finalLicenseChallenge = licenseXhrSetupResult ? licenseXhrSetupResult : licenseChallenge;
                return {
                  xhr,
                  licenseChallenge: finalLicenseChallenge
                };
              });
            }
            requestLicense(keySessionContext, licenseChallenge) {
              return new Promise((resolve, reject) => {
                const url = this.getLicenseServerUrl(keySessionContext.keySystem);
                this.log(`Sending license request to URL: ${url}`);
                const xhr = new XMLHttpRequest();
                xhr.responseType = 'arraybuffer';
                xhr.onreadystatechange = () => {
                  if (!this.hls || !keySessionContext.mediaKeysSession) {
                    return reject(new Error('invalid state'));
                  }
                  if (xhr.readyState === 4) {
                    if (xhr.status === 200) {
                      this._requestLicenseFailureCount = 0;
                      let data = xhr.response;
                      this.log(`License received ${data instanceof ArrayBuffer ? data.byteLength : data}`);
                      const licenseResponseCallback = this.config.licenseResponseCallback;
                      if (licenseResponseCallback) {
                        try {
                          data = licenseResponseCallback.call(this.hls, xhr, url, keySessionContext);
                        } catch (error) {
                          this.error(error);
                        }
                      }
                      resolve(data);
                    } else {
                      this._requestLicenseFailureCount++;
                      if (this._requestLicenseFailureCount > MAX_LICENSE_REQUEST_FAILURES || xhr.status >= 400 && xhr.status < 500) {
                        reject(new EMEKeyError({
                          type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.KEY_SYSTEM_ERROR,
                          details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.KEY_SYSTEM_LICENSE_REQUEST_FAILED,
                          fatal: true,
                          networkDetails: xhr
                        }, `License Request XHR failed (${url}). Status: ${xhr.status} (${xhr.statusText})`));
                      } else {
                        const attemptsLeft = MAX_LICENSE_REQUEST_FAILURES - this._requestLicenseFailureCount + 1;
                        this.warn(`Retrying license request, ${attemptsLeft} attempts left`);
                        this.requestLicense(keySessionContext, licenseChallenge).then(resolve, reject);
                      }
                    }
                  }
                };
                if (keySessionContext.licenseXhr && keySessionContext.licenseXhr.readyState !== XMLHttpRequest.DONE) {
                  keySessionContext.licenseXhr.abort();
                }
                keySessionContext.licenseXhr = xhr;
                this.setupLicenseXHR(xhr, url, keySessionContext, licenseChallenge).then(({
                  xhr,
                  licenseChallenge
                }) => {
                  xhr.send(licenseChallenge);
                });
              });
            }
            onMediaAttached(event, data) {
              if (!this.config.emeEnabled) {
                return;
              }
              const media = data.media;

              // keep reference of media
              this.media = media;
              media.addEventListener('encrypted', this.onMediaEncrypted);
              media.addEventListener('waitingforkey', this.onWaitingForKey);
            }
            onMediaDetached() {
              const media = this.media;
              const mediaKeysList = this.mediaKeySessions;
              if (media) {
                media.removeEventListener('encrypted', this.onMediaEncrypted);
                media.removeEventListener('waitingforkey', this.onWaitingForKey);
                this.media = null;
              }
              this._requestLicenseFailureCount = 0;
              this.setMediaKeysQueue = [];
              this.mediaKeySessions = [];
              this.keyIdToKeySessionPromise = {};
              _loader_level_key__WEBPACK_IMPORTED_MODULE_6__.LevelKey.clearKeyUriToKeyIdMap();

              // Close all sessions and remove media keys from the video element.
              const keySessionCount = mediaKeysList.length;
              EMEController.CDMCleanupPromise = Promise.all(mediaKeysList.map(mediaKeySessionContext => this.removeSession(mediaKeySessionContext)).concat(media?.setMediaKeys(null).catch(error => {
                this.log(`Could not clear media keys: ${error}. media.src: ${media?.src}`);
              }))).then(() => {
                if (keySessionCount) {
                  this.log('finished closing key sessions and clearing media keys');
                  mediaKeysList.length = 0;
                }
              }).catch(error => {
                this.log(`Could not close sessions and clear media keys: ${error}. media.src: ${media?.src}`);
              });
            }
            onManifestLoaded(event, {
              sessionKeys
            }) {
              if (!sessionKeys || !this.config.emeEnabled) {
                return;
              }
              if (!this.keyFormatPromise) {
                const keyFormats = sessionKeys.reduce((formats, sessionKey) => {
                  if (formats.indexOf(sessionKey.keyFormat) === -1) {
                    formats.push(sessionKey.keyFormat);
                  }
                  return formats;
                }, []);
                this.log(`Selecting key-system from session-keys ${keyFormats.join(', ')}`);
                this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);
              }
            }
            removeSession(mediaKeySessionContext) {
              const {
                mediaKeysSession,
                licenseXhr
              } = mediaKeySessionContext;
              if (mediaKeysSession) {
                this.log(`Remove licenses and keys and close session ${mediaKeysSession.sessionId}`);
                mediaKeysSession.onmessage = null;
                mediaKeysSession.onkeystatuseschange = null;
                if (licenseXhr && licenseXhr.readyState !== XMLHttpRequest.DONE) {
                  licenseXhr.abort();
                }
                mediaKeySessionContext.mediaKeysSession = mediaKeySessionContext.decryptdata = mediaKeySessionContext.licenseXhr = undefined;
                const index = this.mediaKeySessions.indexOf(mediaKeySessionContext);
                if (index > -1) {
                  this.mediaKeySessions.splice(index, 1);
                }
                return mediaKeysSession.remove().catch(error => {
                  this.log(`Could not remove session: ${error}`);
                }).then(() => {
                  return mediaKeysSession.close();
                }).catch(error => {
                  this.log(`Could not close session: ${error}`);
                });
              }
            }
          }
          class EMEKeyError extends Error {
            constructor(data, message) {
              super(message);
              this.data = data;
              data.err = data.error;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (EMEController);

          /***/
        }),

/***/ "./src/controller/fps-controller.ts":
/*!******************************************!*\
  !*** ./src/controller/fps-controller.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");


          class FPSController {
            isVideoPlaybackQualityAvailable = false;
            media = null;
            lastDroppedFrames = 0;
            lastDecodedFrames = 0;
            // stream controller must be provided as a dependency!

            constructor(hls) {
              this.hls = hls;
              this.registerListeners();
            }
            setStreamController(streamController) {
              this.streamController = streamController;
            }
            registerListeners() {
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
            }
            unregisterListeners() {
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching);
            }
            destroy() {
              if (this.timer) {
                clearInterval(this.timer);
              }
              this.unregisterListeners();
              this.isVideoPlaybackQualityAvailable = false;
              this.media = null;
            }
            onMediaAttaching(event, data) {
              const config = this.hls.config;
              if (config.capLevelOnFPSDrop) {
                const media = data.media instanceof self.HTMLVideoElement ? data.media : null;
                this.media = media;
                if (media && typeof media.getVideoPlaybackQuality === 'function') {
                  this.isVideoPlaybackQualityAvailable = true;
                }
                self.clearInterval(this.timer);
                this.timer = self.setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);
              }
            }
            checkFPS(video, decodedFrames, droppedFrames) {
              const currentTime = performance.now();
              if (decodedFrames) {
                if (this.lastTime) {
                  const currentPeriod = currentTime - this.lastTime;
                  const currentDropped = droppedFrames - this.lastDroppedFrames;
                  const currentDecoded = decodedFrames - this.lastDecodedFrames;
                  const droppedFPS = 1000 * currentDropped / currentPeriod;
                  const hls = this.hls;
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FPS_DROP, {
                    currentDropped: currentDropped,
                    currentDecoded: currentDecoded,
                    totalDroppedFrames: droppedFrames
                  });
                  if (droppedFPS > 0) {
                    // logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));
                    if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {
                      let currentLevel = hls.currentLevel;
                      _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);
                      if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {
                        currentLevel = currentLevel - 1;
                        hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FPS_DROP_LEVEL_CAPPING, {
                          level: currentLevel,
                          droppedLevel: hls.currentLevel
                        });
                        hls.autoLevelCapping = currentLevel;
                        this.streamController.nextLevelSwitch();
                      }
                    }
                  }
                }
                this.lastTime = currentTime;
                this.lastDroppedFrames = droppedFrames;
                this.lastDecodedFrames = decodedFrames;
              }
            }
            checkFPSInterval() {
              const video = this.media;
              if (video) {
                if (this.isVideoPlaybackQualityAvailable) {
                  const videoPlaybackQuality = video.getVideoPlaybackQuality();
                  this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);
                } else {
                  // HTMLVideoElement doesn't include the webkit types
                  this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);
                }
              }
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FPSController);

          /***/
        }),

/***/ "./src/controller/fragment-finders.ts":
/*!********************************************!*\
  !*** ./src/controller/fragment-finders.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "findFragWithCC": () => (/* binding */ findFragWithCC),
/* harmony export */   "findFragmentByPDT": () => (/* binding */ findFragmentByPDT),
/* harmony export */   "findFragmentByPTS": () => (/* binding */ findFragmentByPTS),
/* harmony export */   "fragmentWithinToleranceTest": () => (/* binding */ fragmentWithinToleranceTest),
/* harmony export */   "pdtWithinToleranceTest": () => (/* binding */ pdtWithinToleranceTest)
            /* harmony export */
          });
/* harmony import */ var _utils_binary_search__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/binary-search */ "./src/utils/binary-search.ts");

          /**
           * Returns first fragment whose endPdt value exceeds the given PDT.
           * @param {Array<Fragment>} fragments - The array of candidate fragments
           * @param {number|null} [PDTValue = null] - The PDT value which must be exceeded
           * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start/end can be within in order to be considered contiguous
           * @returns {*|null} fragment - The best matching fragment
           */
          function findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {
            if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !Number.isFinite(PDTValue)) {
              return null;
            }

            // if less than start
            const startPDT = fragments[0].programDateTime;
            if (PDTValue < (startPDT || 0)) {
              return null;
            }
            const endPDT = fragments[fragments.length - 1].endProgramDateTime;
            if (PDTValue >= (endPDT || 0)) {
              return null;
            }
            maxFragLookUpTolerance = maxFragLookUpTolerance || 0;
            for (let seg = 0; seg < fragments.length; ++seg) {
              const frag = fragments[seg];
              if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {
                return frag;
              }
            }
            return null;
          }

          /**
           * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.
           * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus
           * breaking any traps which would cause the same fragment to be continuously selected within a small range.
           * @param {*} fragPrevious - The last frag successfully appended
           * @param {Array} fragments - The array of candidate fragments
           * @param {number} [bufferEnd = 0] - The end of the contiguous buffered range the playhead is currently within
           * @param {number} maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous
           * @returns {*} foundFrag - The best matching fragment
           */
          function findFragmentByPTS(fragPrevious, fragments, bufferEnd = 0, maxFragLookUpTolerance = 0) {
            let fragNext = null;
            if (fragPrevious) {
              fragNext = fragments[fragPrevious.sn - fragments[0].sn + 1] || null;
            } else if (bufferEnd === 0 && fragments[0].start === 0) {
              fragNext = fragments[0];
            }
            // Prefer the next fragment if it's within tolerance
            if (fragNext && fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0) {
              return fragNext;
            }
            // We might be seeking past the tolerance so find the best match
            const foundFragment = _utils_binary_search__WEBPACK_IMPORTED_MODULE_0__["default"].search(fragments, fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));
            if (foundFragment && (foundFragment !== fragPrevious || !fragNext)) {
              return foundFragment;
            }
            // If no match was found return the next fragment after fragPrevious, or null
            return fragNext;
          }

          /**
           * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.
           * @param {*} candidate - The fragment to test
           * @param {number} [bufferEnd = 0] - The end of the current buffered range the playhead is currently within
           * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start can be within in order to be considered contiguous
           * @returns {number} - 0 if it matches, 1 if too low, -1 if too high
           */
          function fragmentWithinToleranceTest(bufferEnd = 0, maxFragLookUpTolerance = 0, candidate) {
            // eagerly accept an accurate match (no tolerance)
            if (candidate.start <= bufferEnd && candidate.start + candidate.duration > bufferEnd) {
              return 0;
            }
            // offset should be within fragment boundary - config.maxFragLookUpTolerance
            // this is to cope with situations like
            // bufferEnd = 9.991
            // frag[Ø] : [0,10]
            // frag[1] : [10,20]
            // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here
            //              frag start               frag start+duration
            //                  |-----------------------------|
            //              <--->                         <--->
            //  ...--------><-----------------------------><---------....
            // previous frag         matching fragment         next frag
            //  return -1             return 0                 return 1
            // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);
            // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments
            const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));
            if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {
              return 1;
            } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {
              // if maxFragLookUpTolerance will have negative value then don't return -1 for first element
              return -1;
            }
            return 0;
          }

          /**
           * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.
           * This function tests the candidate's program date time values, as represented in Unix time
           * @param {*} candidate - The fragment to test
           * @param {number} [pdtBufferEnd = 0] - The Unix time representing the end of the current buffered range
           * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start can be within in order to be considered contiguous
           * @returns {boolean} True if contiguous, false otherwise
           */
          function pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {
            const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000;

            // endProgramDateTime can be null, default to zero
            const endProgramDateTime = candidate.endProgramDateTime || 0;
            return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;
          }
          function findFragWithCC(fragments, cc) {
            return _utils_binary_search__WEBPACK_IMPORTED_MODULE_0__["default"].search(fragments, candidate => {
              if (candidate.cc < cc) {
                return 1;
              } else if (candidate.cc > cc) {
                return -1;
              } else {
                return 0;
              }
            });
          }

          /***/
        }),

/***/ "./src/controller/fragment-tracker.ts":
/*!********************************************!*\
  !*** ./src/controller/fragment-tracker.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "FragmentState": () => (/* binding */ FragmentState),
/* harmony export */   "FragmentTracker": () => (/* binding */ FragmentTracker)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");


          let FragmentState;
          (function (FragmentState) {
            FragmentState["NOT_LOADED"] = "NOT_LOADED";
            FragmentState["APPENDING"] = "APPENDING";
            FragmentState["PARTIAL"] = "PARTIAL";
            FragmentState["OK"] = "OK";
          })(FragmentState || (FragmentState = {}));
          class FragmentTracker {
            activeFragment = null;
            activeParts = null;
            endListFragments = Object.create(null);
            fragments = Object.create(null);
            timeRanges = Object.create(null);
            bufferPadding = 0.2;
            constructor(hls) {
              this.hls = hls;
              this._registerListeners();
            }
            _registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_APPENDED, this.onBufferAppended, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADED, this.onFragLoaded, this);
            }
            _unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_APPENDED, this.onBufferAppended, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADED, this.onFragLoaded, this);
            }
            destroy() {
              this._unregisterListeners();
              // @ts-ignore
              this.fragments =
                // @ts-ignore
                this.endListFragments = this.timeRanges = this.activeFragment = this.activeParts = null;
            }

            /**
             * Return a Fragment with an appended range that matches the position and levelType.
             * If not found any Fragment, return null
             */
            getAppendedFrag(position, levelType) {
              if (levelType === _types_loader__WEBPACK_IMPORTED_MODULE_1__.PlaylistLevelType.MAIN) {
                const {
                  activeFragment,
                  activeParts
                } = this;
                if (!activeFragment) {
                  return null;
                }
                if (activeParts) {
                  for (let i = activeParts.length; i--;) {
                    const activePart = activeParts[i];
                    const appendedPTS = activePart ? activePart.end : activeFragment.appendedPTS;
                    if (activePart.start <= position && appendedPTS !== undefined && position <= appendedPTS) {
                      // 9 is a magic number. remove parts from lookup after a match but keep some short seeks back.
                      if (i > 9) {
                        this.activeParts = activeParts.slice(i - 9);
                      }
                      return activePart;
                    }
                  }
                } else if (activeFragment.start <= position && activeFragment.appendedPTS !== undefined && position <= activeFragment.appendedPTS) {
                  return activeFragment;
                }
              }
              return this.getBufferedFrag(position, levelType);
            }

            /**
             * Return a buffered Fragment that matches the position and levelType.
             * A buffered Fragment is one whose loading, parsing and appending is done (completed or "partial" meaning aborted).
             * If not found any Fragment, return null
             */
            getBufferedFrag(position, levelType) {
              const {
                fragments
              } = this;
              const keys = Object.keys(fragments);
              for (let i = keys.length; i--;) {
                const fragmentEntity = fragments[keys[i]];
                if (fragmentEntity?.body.type === levelType && fragmentEntity.buffered) {
                  const frag = fragmentEntity.body;
                  if (frag.start <= position && position <= frag.end) {
                    return frag;
                  }
                }
              }
              return null;
            }

            /**
             * Partial fragments effected by coded frame eviction will be removed
             * The browser will unload parts of the buffer to free up memory for new buffer data
             * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)
             */
            detectEvictedFragments(elementaryStream, timeRange, playlistType) {
              if (this.timeRanges) {
                this.timeRanges[elementaryStream] = timeRange;
              }
              // Check if any flagged fragments have been unloaded
              Object.keys(this.fragments).forEach(key => {
                const fragmentEntity = this.fragments[key];
                if (!fragmentEntity) {
                  return;
                }
                if (!fragmentEntity.buffered && !fragmentEntity.loaded) {
                  if (fragmentEntity.body.type === playlistType) {
                    this.removeFragment(fragmentEntity.body);
                  }
                  return;
                }
                const esData = fragmentEntity.range[elementaryStream];
                if (!esData) {
                  return;
                }
                esData.time.some(time => {
                  const isNotBuffered = !this.isTimeBuffered(time.startPTS, time.endPTS, timeRange);
                  if (isNotBuffered) {
                    // Unregister partial fragment as it needs to load again to be reused
                    this.removeFragment(fragmentEntity.body);
                  }
                  return isNotBuffered;
                });
              });
            }

            /**
             * Checks if the fragment passed in is loaded in the buffer properly
             * Partially loaded fragments will be registered as a partial fragment
             */
            detectPartialFragments(data) {
              const timeRanges = this.timeRanges;
              const {
                frag,
                part
              } = data;
              if (!timeRanges || frag.sn === 'initSegment') {
                return;
              }
              const fragKey = getFragmentKey(frag);
              const fragmentEntity = this.fragments[fragKey];
              if (!fragmentEntity) {
                return;
              }
              Object.keys(timeRanges).forEach(elementaryStream => {
                const streamInfo = frag.elementaryStreams[elementaryStream];
                if (!streamInfo) {
                  return;
                }
                const timeRange = timeRanges[elementaryStream];
                const partial = part !== null || streamInfo.partial === true;
                fragmentEntity.range[elementaryStream] = this.getBufferedTimes(frag, part, partial, timeRange);
              });
              fragmentEntity.loaded = null;
              if (Object.keys(fragmentEntity.range).length) {
                fragmentEntity.buffered = true;
                if (fragmentEntity.body.endList) {
                  this.endListFragments[fragmentEntity.body.type] = fragmentEntity;
                }
              } else {
                // remove fragment if nothing was appended
                this.removeFragment(fragmentEntity.body);
              }
            }
            fragBuffered(frag) {
              const fragKey = getFragmentKey(frag);
              const fragmentEntity = this.fragments[fragKey];
              if (fragmentEntity) {
                fragmentEntity.loaded = null;
                fragmentEntity.buffered = true;
              }
            }
            getBufferedTimes(fragment, part, partial, timeRange) {
              const buffered = {
                time: [],
                partial
              };
              const startPTS = part ? part.start : fragment.start;
              const endPTS = part ? part.end : fragment.end;
              const minEndPTS = fragment.minEndPTS || endPTS;
              const maxStartPTS = fragment.maxStartPTS || startPTS;
              for (let i = 0; i < timeRange.length; i++) {
                const startTime = timeRange.start(i) - this.bufferPadding;
                const endTime = timeRange.end(i) + this.bufferPadding;
                if (maxStartPTS >= startTime && minEndPTS <= endTime) {
                  // Fragment is entirely contained in buffer
                  // No need to check the other timeRange times since it's completely playable
                  buffered.time.push({
                    startPTS: Math.max(startPTS, timeRange.start(i)),
                    endPTS: Math.min(endPTS, timeRange.end(i))
                  });
                  break;
                } else if (startPTS < endTime && endPTS > startTime) {
                  buffered.partial = true;
                  // Check for intersection with buffer
                  // Get playable sections of the fragment
                  buffered.time.push({
                    startPTS: Math.max(startPTS, timeRange.start(i)),
                    endPTS: Math.min(endPTS, timeRange.end(i))
                  });
                } else if (endPTS <= startTime) {
                  // No need to check the rest of the timeRange as it is in order
                  break;
                }
              }
              return buffered;
            }

            /**
             * Gets the partial fragment for a certain time
             */
            getPartialFragment(time) {
              let bestFragment = null;
              let timePadding;
              let startTime;
              let endTime;
              let bestOverlap = 0;
              const {
                bufferPadding,
                fragments
              } = this;
              Object.keys(fragments).forEach(key => {
                const fragmentEntity = fragments[key];
                if (!fragmentEntity) {
                  return;
                }
                if (isPartial(fragmentEntity)) {
                  startTime = fragmentEntity.body.start - bufferPadding;
                  endTime = fragmentEntity.body.end + bufferPadding;
                  if (time >= startTime && time <= endTime) {
                    // Use the fragment that has the most padding from start and end time
                    timePadding = Math.min(time - startTime, endTime - time);
                    if (bestOverlap <= timePadding) {
                      bestFragment = fragmentEntity.body;
                      bestOverlap = timePadding;
                    }
                  }
                }
              });
              return bestFragment;
            }
            isEndListAppended(type) {
              const lastFragmentEntity = this.endListFragments[type];
              return lastFragmentEntity !== undefined && (lastFragmentEntity.buffered || isPartial(lastFragmentEntity));
            }
            getState(fragment) {
              const fragKey = getFragmentKey(fragment);
              const fragmentEntity = this.fragments[fragKey];
              if (fragmentEntity) {
                if (!fragmentEntity.buffered) {
                  return FragmentState.APPENDING;
                } else if (isPartial(fragmentEntity)) {
                  return FragmentState.PARTIAL;
                } else {
                  return FragmentState.OK;
                }
              }
              return FragmentState.NOT_LOADED;
            }
            isTimeBuffered(startPTS, endPTS, timeRange) {
              let startTime;
              let endTime;
              for (let i = 0; i < timeRange.length; i++) {
                startTime = timeRange.start(i) - this.bufferPadding;
                endTime = timeRange.end(i) + this.bufferPadding;
                if (startPTS >= startTime && endPTS <= endTime) {
                  return true;
                }
                if (endPTS <= startTime) {
                  // No need to check the rest of the timeRange as it is in order
                  return false;
                }
              }
              return false;
            }
            onFragLoaded(event, data) {
              const {
                frag,
                part
              } = data;
              // don't track initsegment (for which sn is not a number)
              // don't track frags used for bitrateTest, they're irrelevant.
              // don't track parts for memory efficiency
              if (frag.sn === 'initSegment' || frag.bitrateTest || part) {
                return;
              }
              const fragKey = getFragmentKey(frag);
              this.fragments[fragKey] = {
                body: frag,
                loaded: data,
                buffered: false,
                range: Object.create(null)
              };
            }
            onBufferAppended(event, data) {
              const {
                frag,
                part,
                timeRanges
              } = data;
              if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_1__.PlaylistLevelType.MAIN) {
                if (this.activeFragment !== frag) {
                  this.activeFragment = frag;
                  frag.appendedPTS = undefined;
                }
                if (part) {
                  let activeParts = this.activeParts;
                  if (!activeParts) {
                    this.activeParts = activeParts = [];
                  }
                  activeParts.push(part);
                } else {
                  this.activeParts = null;
                }
              }
              // Store the latest timeRanges loaded in the buffer
              this.timeRanges = timeRanges;
              Object.keys(timeRanges).forEach(elementaryStream => {
                const timeRange = timeRanges[elementaryStream];
                this.detectEvictedFragments(elementaryStream, timeRange);
                if (!part && frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_1__.PlaylistLevelType.MAIN) {
                  const streamInfo = frag.elementaryStreams[elementaryStream];
                  if (!streamInfo) {
                    return;
                  }
                  for (let i = 0; i < timeRange.length; i++) {
                    const rangeEnd = timeRange.end(i);
                    if (rangeEnd <= streamInfo.endPTS && rangeEnd > streamInfo.startPTS) {
                      frag.appendedPTS = Math.max(rangeEnd, frag.appendedPTS || 0);
                    } else {
                      frag.appendedPTS = streamInfo.endPTS;
                    }
                  }
                }
              });
            }
            onFragBuffered(event, data) {
              this.detectPartialFragments(data);
            }
            hasFragment(fragment) {
              const fragKey = getFragmentKey(fragment);
              return !!this.fragments[fragKey];
            }
            removeFragmentsInRange(start, end, playlistType) {
              Object.keys(this.fragments).forEach(key => {
                const fragmentEntity = this.fragments[key];
                if (!fragmentEntity) {
                  return;
                }
                if (fragmentEntity.buffered) {
                  const frag = fragmentEntity.body;
                  if (frag.type === playlistType && frag.start < end && frag.end > start) {
                    this.removeFragment(frag);
                  }
                }
              });
            }
            removeFragment(fragment) {
              const fragKey = getFragmentKey(fragment);
              fragment.stats.loaded = 0;
              fragment.clearElementaryStreamInfo();
              fragment.appendedPTS = undefined;
              delete this.fragments[fragKey];
              if (fragment.endList) {
                delete this.endListFragments[fragment.type];
              }
            }
            removeAllFragments() {
              this.fragments = Object.create(null);
              this.endListFragments = Object.create(null);
              this.activeFragment = null;
              this.activeParts = null;
            }
          }
          function isPartial(fragmentEntity) {
            return fragmentEntity.buffered && (fragmentEntity.range.video?.partial || fragmentEntity.range.audio?.partial);
          }
          function getFragmentKey(fragment) {
            return `${fragment.type}_${fragment.level}_${fragment.urlId}_${fragment.sn}`;
          }

          /***/
        }),

/***/ "./src/controller/gap-controller.ts":
/*!******************************************!*\
  !*** ./src/controller/gap-controller.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "MAX_START_GAP_JUMP": () => (/* binding */ MAX_START_GAP_JUMP),
/* harmony export */   "SKIP_BUFFER_HOLE_STEP_SECONDS": () => (/* binding */ SKIP_BUFFER_HOLE_STEP_SECONDS),
/* harmony export */   "SKIP_BUFFER_RANGE_START": () => (/* binding */ SKIP_BUFFER_RANGE_START),
/* harmony export */   "STALL_MINIMUM_DURATION_MS": () => (/* binding */ STALL_MINIMUM_DURATION_MS),
/* harmony export */   "default": () => (/* binding */ GapController)
            /* harmony export */
          });
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");




          const STALL_MINIMUM_DURATION_MS = 250;
          const MAX_START_GAP_JUMP = 2.0;
          const SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;
          const SKIP_BUFFER_RANGE_START = 0.05;
          class GapController {
            media = null;
            nudgeRetry = 0;
            stallReported = false;
            stalled = null;
            moved = false;
            seeking = false;
            constructor(config, media, fragmentTracker, hls) {
              this.config = config;
              this.media = media;
              this.fragmentTracker = fragmentTracker;
              this.hls = hls;
            }
            destroy() {
              this.media = null;
              // @ts-ignore
              this.hls = this.fragmentTracker = null;
            }

            /**
             * Checks if the playhead is stuck within a gap, and if so, attempts to free it.
             * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).
             *
             * @param {number} lastCurrentTime Previously read playhead position
             */
            poll(lastCurrentTime, activeFrag) {
              const {
                config,
                media,
                stalled
              } = this;
              if (media === null) {
                return;
              }
              const {
                currentTime,
                seeking
              } = media;
              const seeked = this.seeking && !seeking;
              const beginSeek = !this.seeking && seeking;
              this.seeking = seeking;

              // The playhead is moving, no-op
              if (currentTime !== lastCurrentTime) {
                this.moved = true;
                if (stalled !== null) {
                  // The playhead is now moving, but was previously stalled
                  if (this.stallReported) {
                    const stalledDuration = self.performance.now() - stalled;
                    _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn(`playback not stuck anymore @${currentTime}, after ${Math.round(stalledDuration)}ms`);
                    this.stallReported = false;
                  }
                  this.stalled = null;
                  this.nudgeRetry = 0;
                }
                return;
              }

              // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek
              if (beginSeek || seeked) {
                this.stalled = null;
              }

              // The playhead should not be moving
              if (media.paused && !seeking || media.ended || media.playbackRate === 0 || !_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__.BufferHelper.getBuffered(media).length) {
                return;
              }
              const bufferInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__.BufferHelper.bufferInfo(media, currentTime, 0);
              const isBuffered = bufferInfo.len > 0;
              const nextStart = bufferInfo.nextStart || 0;

              // There is no playable buffer (seeked, waiting for buffer)
              if (!isBuffered && !nextStart) {
                return;
              }
              if (seeking) {
                // Waiting for seeking in a buffered range to complete
                const hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP;
                // Next buffered range is too far ahead to jump to while still seeking
                const noBufferGap = !nextStart || activeFrag && activeFrag.start <= currentTime || nextStart - currentTime > MAX_START_GAP_JUMP && !this.fragmentTracker.getPartialFragment(currentTime);
                if (hasEnoughBuffer || noBufferGap) {
                  return;
                }
                // Reset moved state when seeking to a point in or before a gap
                this.moved = false;
              }

              // Skip start gaps if we haven't played, but the last poll detected the start of a stall
              // The addition poll gives the browser a chance to jump the gap for us
              if (!this.moved && this.stalled !== null) {
                // Jump start gaps within jump threshold
                const startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime;

                // When joining a live stream with audio tracks, account for live playlist window sliding by allowing
                // a larger jump over start gaps caused by the audio-stream-controller buffering a start fragment
                // that begins over 1 target duration after the video start position.
                const level = this.hls.levels ? this.hls.levels[this.hls.currentLevel] : null;
                const isLive = level?.details?.live;
                const maxStartGapJump = isLive ? level.details.targetduration * 2 : MAX_START_GAP_JUMP;
                if (startJump > 0 && startJump <= maxStartGapJump) {
                  this._trySkipBufferHole(null);
                  return;
                }
              }

              // Start tracking stall time
              const tnow = self.performance.now();
              if (stalled === null) {
                this.stalled = tnow;
                return;
              }
              const stalledDuration = tnow - stalled;
              if (!seeking && stalledDuration >= STALL_MINIMUM_DURATION_MS) {
                // Report stalling after trying to fix
                this._reportStall(bufferInfo);
                if (!this.media) {
                  return;
                }
              }
              const bufferedWithHoles = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__.BufferHelper.bufferInfo(media, currentTime, config.maxBufferHole);
              this._tryFixBufferStall(bufferedWithHoles, stalledDuration);
            }

            /**
             * Detects and attempts to fix known buffer stalling issues.
             * @param bufferInfo - The properties of the current buffer.
             * @param stalledDurationMs - The amount of time Hls.js has been stalling for.
             * @private
             */
            _tryFixBufferStall(bufferInfo, stalledDurationMs) {
              const {
                config,
                fragmentTracker,
                media
              } = this;
              if (media === null) {
                return;
              }
              const currentTime = media.currentTime;
              const partial = fragmentTracker.getPartialFragment(currentTime);
              if (partial) {
                // Try to skip over the buffer hole caused by a partial fragment
                // This method isn't limited by the size of the gap between buffered ranges
                const targetTime = this._trySkipBufferHole(partial);
                // we return here in this case, meaning
                // the branch below only executes when we don't handle a partial fragment
                if (targetTime || !this.media) {
                  return;
                }
              }

              // if we haven't had to skip over a buffer hole of a partial fragment
              // we may just have to "nudge" the playlist as the browser decoding/rendering engine
              // needs to cross some sort of threshold covering all source-buffers content
              // to start playing properly.
              if (bufferInfo.len > config.maxBufferHole && stalledDurationMs > config.highBufferWatchdogPeriod * 1000) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('Trying to nudge playhead over buffer-hole');
                // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds
                // We only try to jump the hole if it's under the configured size
                // Reset stalled so to rearm watchdog timer
                this.stalled = null;
                this._tryNudgeBuffer();
              }
            }

            /**
             * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.
             * @param bufferLen - The playhead distance from the end of the current buffer segment.
             * @private
             */
            _reportStall(bufferInfo) {
              const {
                hls,
                media,
                stallReported
              } = this;
              if (!stallReported && media) {
                // Report stalled error once
                this.stallReported = true;
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn(`Playback stalling at @${media.currentTime} due to low buffer (${JSON.stringify(bufferInfo)})`);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.BUFFER_STALLED_ERROR,
                  fatal: false,
                  buffer: bufferInfo.len
                });
              }
            }

            /**
             * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments
             * @param partial - The partial fragment found at the current time (where playback is stalling).
             * @private
             */
            _trySkipBufferHole(partial) {
              const {
                config,
                hls,
                media
              } = this;
              if (media === null) {
                return 0;
              }
              const currentTime = media.currentTime;
              let lastEndTime = 0;
              // Check if currentTime is between unbuffered regions of partial fragments
              const buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_0__.BufferHelper.getBuffered(media);
              for (let i = 0; i < buffered.length; i++) {
                const startTime = buffered.start(i);
                if (currentTime + config.maxBufferHole >= lastEndTime && currentTime < startTime) {
                  const targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, media.currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);
                  _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn(`skipping hole, adjusting currentTime from ${currentTime} to ${targetTime}`);
                  this.moved = true;
                  this.stalled = null;
                  media.currentTime = targetTime;
                  if (partial) {
                    hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                      type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.BUFFER_SEEK_OVER_HOLE,
                      fatal: false,
                      reason: `fragment loaded with buffer holes, seeking from ${currentTime} to ${targetTime}`,
                      frag: partial
                    });
                  }
                  return targetTime;
                }
                lastEndTime = buffered.end(i);
              }
              return 0;
            }

            /**
             * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.
             * @private
             */
            _tryNudgeBuffer() {
              const {
                config,
                hls,
                media,
                nudgeRetry
              } = this;
              if (media === null) {
                return;
              }
              const currentTime = media.currentTime;
              this.nudgeRetry++;
              if (nudgeRetry < config.nudgeMaxRetry) {
                const targetTime = currentTime + (nudgeRetry + 1) * config.nudgeOffset;
                // playback stalled in buffered area ... let's nudge currentTime to try to overcome this
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn(`Nudging 'currentTime' from ${currentTime} to ${targetTime}`);
                media.currentTime = targetTime;
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.BUFFER_NUDGE_ON_STALL,
                  fatal: false
                });
              } else {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.error(`Playhead still not moving while enough data buffered @${currentTime} after ${config.nudgeMaxRetry} nudges`);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.BUFFER_STALLED_ERROR,
                  fatal: true
                });
              }
            }
          }

          /***/
        }),

/***/ "./src/controller/id3-track-controller.ts":
/*!************************************************!*\
  !*** ./src/controller/id3-track-controller.ts ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/texttrack-utils */ "./src/utils/texttrack-utils.ts");
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
/* harmony import */ var _loader_date_range__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../loader/date-range */ "./src/loader/date-range.ts");
/* harmony import */ var _types_demuxer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../types/demuxer */ "./src/types/demuxer.ts");





          const MIN_CUE_DURATION = 0.25;
          function getCueClass() {
            // Attempt to recreate Safari functionality by creating
            // WebKitDataCue objects when available and store the decoded
            // ID3 data in the value property of the cue
            return self.WebKitDataCue || self.VTTCue || self.TextTrackCue;
          }

          // VTTCue latest draft allows an infinite duration, fallback
          // to MAX_VALUE if necessary
          const MAX_CUE_ENDTIME = (() => {
            const Cue = getCueClass();
            try {
              new Cue(0, Number.POSITIVE_INFINITY, '');
            } catch (e) {
              return Number.MAX_VALUE;
            }
            return Number.POSITIVE_INFINITY;
          })();
          function dateRangeDateToTimelineSeconds(date, offset) {
            return date.getTime() / 1000 - offset;
          }
          function hexToArrayBuffer(str) {
            return Uint8Array.from(str.replace(/^0x/, '').replace(/([\da-fA-F]{2}) ?/g, '0x$1 ').replace(/ +$/, '').split(' ')).buffer;
          }
          class ID3TrackController {
            id3Track = null;
            media = null;
            dateRangeCuesAppended = {};
            constructor(hls) {
              this.hls = hls;
              this._registerListeners();
            }
            destroy() {
              this._unregisterListeners();
              this.id3Track = null;
              this.media = null;
              this.dateRangeCuesAppended = {};
              // @ts-ignore
              this.hls = null;
            }
            _registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_UPDATED, this.onLevelUpdated, this);
            }
            _unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_UPDATED, this.onLevelUpdated, this);
            }

            // Add ID3 metatadata text track.
            onMediaAttached(event, data) {
              this.media = data.media;
            }
            onMediaDetaching() {
              if (!this.id3Track) {
                return;
              }
              (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__.clearCurrentCues)(this.id3Track);
              this.id3Track = null;
              this.media = null;
              this.dateRangeCuesAppended = {};
            }
            onManifestLoading() {
              this.dateRangeCuesAppended = {};
            }
            createTrack(media) {
              const track = this.getID3Track(media.textTracks);
              track.mode = 'hidden';
              return track;
            }
            getID3Track(textTracks) {
              if (!this.media) {
                return;
              }
              for (let i = 0; i < textTracks.length; i++) {
                const textTrack = textTracks[i];
                if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {
                  // send 'addtrack' when reusing the textTrack for metadata,
                  // same as what we do for captions
                  (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__.sendAddTrackEvent)(textTrack, this.media);
                  return textTrack;
                }
              }
              return this.media.addTextTrack('metadata', 'id3');
            }
            onFragParsingMetadata(event, data) {
              if (!this.media) {
                return;
              }
              const {
                hls: {
                  config: {
                    enableEmsgMetadataCues,
                    enableID3MetadataCues
                  }
                }
              } = this;
              if (!enableEmsgMetadataCues && !enableID3MetadataCues) {
                return;
              }
              const {
                samples
              } = data;

              // create track dynamically
              if (!this.id3Track) {
                this.id3Track = this.createTrack(this.media);
              }
              const Cue = getCueClass();
              for (let i = 0; i < samples.length; i++) {
                const type = samples[i].type;
                if (type === _types_demuxer__WEBPACK_IMPORTED_MODULE_4__.MetadataSchema.emsg && !enableEmsgMetadataCues || !enableID3MetadataCues) {
                  continue;
                }
                const frames = _demux_id3__WEBPACK_IMPORTED_MODULE_2__.getID3Frames(samples[i].data);
                if (frames) {
                  const startTime = samples[i].pts;
                  let endTime = startTime + samples[i].duration;
                  if (endTime > MAX_CUE_ENDTIME) {
                    endTime = MAX_CUE_ENDTIME;
                  }
                  const timeDiff = endTime - startTime;
                  if (timeDiff <= 0) {
                    endTime = startTime + MIN_CUE_DURATION;
                  }
                  for (let j = 0; j < frames.length; j++) {
                    const frame = frames[j];
                    // Safari doesn't put the timestamp frame in the TextTrack
                    if (!_demux_id3__WEBPACK_IMPORTED_MODULE_2__.isTimeStampFrame(frame)) {
                      // add a bounds to any unbounded cues
                      this.updateId3CueEnds(startTime);
                      const cue = new Cue(startTime, endTime, '');
                      cue.value = frame;
                      if (type) {
                        cue.type = type;
                      }
                      this.id3Track.addCue(cue);
                    }
                  }
                }
              }
            }
            updateId3CueEnds(startTime) {
              const cues = this.id3Track?.cues;
              if (cues) {
                for (let i = cues.length; i--;) {
                  const cue = cues[i];
                  if (cue.startTime < startTime && cue.endTime === MAX_CUE_ENDTIME) {
                    cue.endTime = startTime;
                  }
                }
              }
            }
            onBufferFlushing(event, {
              startOffset,
              endOffset,
              type
            }) {
              const {
                id3Track,
                hls
              } = this;
              if (!hls) {
                return;
              }
              const {
                config: {
                  enableEmsgMetadataCues,
                  enableID3MetadataCues
                }
              } = hls;
              if (id3Track && (enableEmsgMetadataCues || enableID3MetadataCues)) {
                let predicate;
                if (type === 'audio') {
                  predicate = cue => cue.type === _types_demuxer__WEBPACK_IMPORTED_MODULE_4__.MetadataSchema.audioId3 && enableID3MetadataCues;
                } else if (type === 'video') {
                  predicate = cue => cue.type === _types_demuxer__WEBPACK_IMPORTED_MODULE_4__.MetadataSchema.emsg && enableEmsgMetadataCues;
                } else {
                  predicate = cue => cue.type === _types_demuxer__WEBPACK_IMPORTED_MODULE_4__.MetadataSchema.audioId3 && enableID3MetadataCues || cue.type === _types_demuxer__WEBPACK_IMPORTED_MODULE_4__.MetadataSchema.emsg && enableEmsgMetadataCues;
                }
                (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__.removeCuesInRange)(id3Track, startOffset, endOffset, predicate);
              }
            }
            onLevelUpdated(event, {
              details
            }) {
              if (!this.media || !details.hasProgramDateTime || !this.hls.config.enableDateRangeMetadataCues) {
                return;
              }
              const {
                dateRangeCuesAppended,
                id3Track
              } = this;
              const {
                dateRanges
              } = details;
              const ids = Object.keys(dateRanges);
              // Remove cues from track not found in details.dateRanges
              if (id3Track) {
                const idsToRemove = Object.keys(dateRangeCuesAppended).filter(id => !ids.includes(id));
                for (let i = idsToRemove.length; i--;) {
                  const id = idsToRemove[i];
                  Object.keys(dateRangeCuesAppended[id].cues).forEach(key => {
                    id3Track.removeCue(dateRangeCuesAppended[id].cues[key]);
                  });
                  delete dateRangeCuesAppended[id];
                }
              }
              // Exit if the playlist does not have Date Ranges or does not have Program Date Time
              const lastFragment = details.fragments[details.fragments.length - 1];
              if (ids.length === 0 || !Number.isFinite(lastFragment?.programDateTime)) {
                return;
              }
              if (!this.id3Track) {
                this.id3Track = this.createTrack(this.media);
              }
              const dateTimeOffset = lastFragment.programDateTime / 1000 - lastFragment.start;
              const Cue = getCueClass();
              for (let i = 0; i < ids.length; i++) {
                const id = ids[i];
                const dateRange = dateRanges[id];
                const appendedDateRangeCues = dateRangeCuesAppended[id];
                const cues = appendedDateRangeCues?.cues || {};
                let durationKnown = appendedDateRangeCues?.durationKnown || false;
                const startTime = dateRangeDateToTimelineSeconds(dateRange.startDate, dateTimeOffset);
                let endTime = MAX_CUE_ENDTIME;
                const endDate = dateRange.endDate;
                if (endDate) {
                  endTime = dateRangeDateToTimelineSeconds(endDate, dateTimeOffset);
                  durationKnown = true;
                } else if (dateRange.endOnNext && !durationKnown) {
                  const nextDateRangeWithSameClass = ids.reduce((filterMapArray, id) => {
                    const candidate = dateRanges[id];
                    if (candidate.class === dateRange.class && candidate.id !== id && candidate.startDate > dateRange.startDate) {
                      filterMapArray.push(candidate);
                    }
                    return filterMapArray;
                  }, []).sort((a, b) => a.startDate.getTime() - b.startDate.getTime())[0];
                  if (nextDateRangeWithSameClass) {
                    endTime = dateRangeDateToTimelineSeconds(nextDateRangeWithSameClass.startDate, dateTimeOffset);
                    durationKnown = true;
                  }
                }
                const attributes = Object.keys(dateRange.attr);
                for (let j = 0; j < attributes.length; j++) {
                  const key = attributes[j];
                  if (key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.ID || key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.CLASS || key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.START_DATE || key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.DURATION || key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.END_DATE || key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.END_ON_NEXT) {
                    continue;
                  }
                  let cue = cues[key];
                  if (cue) {
                    if (durationKnown && !appendedDateRangeCues.durationKnown) {
                      cue.endTime = endTime;
                    }
                  } else {
                    let data = dateRange.attr[key];
                    cue = new Cue(startTime, endTime, '');
                    if (key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.SCTE35_OUT || key === _loader_date_range__WEBPACK_IMPORTED_MODULE_3__.DateRangeAttribute.SCTE35_IN) {
                      data = hexToArrayBuffer(data);
                    }
                    cue.value = {
                      key,
                      data
                    };
                    cue.type = _types_demuxer__WEBPACK_IMPORTED_MODULE_4__.MetadataSchema.dateRange;
                    this.id3Track.addCue(cue);
                    cues[key] = cue;
                  }
                }
                dateRangeCuesAppended[id] = {
                  cues,
                  dateRange,
                  durationKnown
                };
              }
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ID3TrackController);

          /***/
        }),

/***/ "./src/controller/latency-controller.ts":
/*!**********************************************!*\
  !*** ./src/controller/latency-controller.ts ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ LatencyController)
            /* harmony export */
          });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");



          class LatencyController {
            media = null;
            levelDetails = null;
            currentTime = 0;
            stallCount = 0;
            _latency = null;
            timeupdateHandler = () => this.timeupdate();
            constructor(hls) {
              this.hls = hls;
              this.config = hls.config;
              this.registerListeners();
            }
            get latency() {
              return this._latency || 0;
            }
            get maxLatency() {
              const {
                config,
                levelDetails
              } = this;
              if (config.liveMaxLatencyDuration !== undefined) {
                return config.liveMaxLatencyDuration;
              }
              return levelDetails ? config.liveMaxLatencyDurationCount * levelDetails.targetduration : 0;
            }
            get targetLatency() {
              const {
                levelDetails
              } = this;
              if (levelDetails === null) {
                return null;
              }
              const {
                holdBack,
                partHoldBack,
                targetduration
              } = levelDetails;
              const {
                liveSyncDuration,
                liveSyncDurationCount,
                lowLatencyMode
              } = this.config;
              const userConfig = this.hls.userConfig;
              let targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;
              if (userConfig.liveSyncDuration || userConfig.liveSyncDurationCount || targetLatency === 0) {
                targetLatency = liveSyncDuration !== undefined ? liveSyncDuration : liveSyncDurationCount * targetduration;
              }
              const maxLiveSyncOnStallIncrease = targetduration;
              const liveSyncOnStallIncrease = 1.0;
              return targetLatency + Math.min(this.stallCount * liveSyncOnStallIncrease, maxLiveSyncOnStallIncrease);
            }
            get liveSyncPosition() {
              const liveEdge = this.estimateLiveEdge();
              const targetLatency = this.targetLatency;
              const levelDetails = this.levelDetails;
              if (liveEdge === null || targetLatency === null || levelDetails === null) {
                return null;
              }
              const edge = levelDetails.edge;
              const syncPosition = liveEdge - targetLatency - this.edgeStalled;
              const min = edge - levelDetails.totalduration;
              const max = edge - (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration);
              return Math.min(Math.max(min, syncPosition), max);
            }
            get drift() {
              const {
                levelDetails
              } = this;
              if (levelDetails === null) {
                return 1;
              }
              return levelDetails.drift;
            }
            get edgeStalled() {
              const {
                levelDetails
              } = this;
              if (levelDetails === null) {
                return 0;
              }
              const maxLevelUpdateAge = (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration) * 3;
              return Math.max(levelDetails.age - maxLevelUpdateAge, 0);
            }
            get forwardBufferLength() {
              const {
                media,
                levelDetails
              } = this;
              if (!media || !levelDetails) {
                return 0;
              }
              const bufferedRanges = media.buffered.length;
              return (bufferedRanges ? media.buffered.end(bufferedRanges - 1) : levelDetails.edge) - this.currentTime;
            }
            destroy() {
              this.unregisterListeners();
              this.onMediaDetaching();
              this.levelDetails = null;
              // @ts-ignore
              this.hls = this.timeupdateHandler = null;
            }
            registerListeners() {
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_UPDATED, this.onLevelUpdated, this);
              this.hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
            }
            unregisterListeners() {
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_ATTACHED, this.onMediaAttached);
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MEDIA_DETACHING, this.onMediaDetaching);
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_LOADING, this.onManifestLoading);
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_UPDATED, this.onLevelUpdated);
              this.hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError);
            }
            onMediaAttached(event, data) {
              this.media = data.media;
              this.media.addEventListener('timeupdate', this.timeupdateHandler);
            }
            onMediaDetaching() {
              if (this.media) {
                this.media.removeEventListener('timeupdate', this.timeupdateHandler);
                this.media = null;
              }
            }
            onManifestLoading() {
              this.levelDetails = null;
              this._latency = null;
              this.stallCount = 0;
            }
            onLevelUpdated(event, {
              details
            }) {
              this.levelDetails = details;
              if (details.advanced) {
                this.timeupdate();
              }
              if (!details.live && this.media) {
                this.media.removeEventListener('timeupdate', this.timeupdateHandler);
              }
            }
            onError(event, data) {
              if (data.details !== _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.BUFFER_STALLED_ERROR) {
                return;
              }
              this.stallCount++;
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.warn('[playback-rate-controller]: Stall detected, adjusting target latency');
            }
            timeupdate() {
              const {
                media,
                levelDetails
              } = this;
              if (!media || !levelDetails) {
                return;
              }
              this.currentTime = media.currentTime;
              const latency = this.computeLatency();
              if (latency === null) {
                return;
              }
              this._latency = latency;

              // Adapt playbackRate to meet target latency in low-latency mode
              const {
                lowLatencyMode,
                maxLiveSyncPlaybackRate
              } = this.config;
              if (!lowLatencyMode || maxLiveSyncPlaybackRate === 1) {
                return;
              }
              const targetLatency = this.targetLatency;
              if (targetLatency === null) {
                return;
              }
              const distanceFromTarget = latency - targetLatency;
              // Only adjust playbackRate when within one target duration of targetLatency
              // and more than one second from under-buffering.
              // Playback further than one target duration from target can be considered DVR playback.
              const liveMinLatencyDuration = Math.min(this.maxLatency, targetLatency + levelDetails.targetduration);
              const inLiveRange = distanceFromTarget < liveMinLatencyDuration;
              if (levelDetails.live && inLiveRange && distanceFromTarget > 0.05 && this.forwardBufferLength > 1) {
                const max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));
                const rate = Math.round(2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled)) * 20) / 20;
                media.playbackRate = Math.min(max, Math.max(1, rate));
              } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {
                media.playbackRate = 1;
              }
            }
            estimateLiveEdge() {
              const {
                levelDetails
              } = this;
              if (levelDetails === null) {
                return null;
              }
              return levelDetails.edge + levelDetails.age;
            }
            computeLatency() {
              const liveEdge = this.estimateLiveEdge();
              if (liveEdge === null) {
                return null;
              }
              return liveEdge - this.currentTime;
            }
          }

          /***/
        }),

/***/ "./src/controller/level-controller.ts":
/*!********************************************!*\
  !*** ./src/controller/level-controller.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ LevelController)
            /* harmony export */
          });
/* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _utils_codecs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/codecs */ "./src/utils/codecs.ts");
/* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
/* harmony import */ var _base_playlist_controller__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./base-playlist-controller */ "./src/controller/base-playlist-controller.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
          /*
           * Level Controller
           */








          const chromeOrFirefox = /chrome|firefox/.test(navigator.userAgent.toLowerCase());
          class LevelController extends _base_playlist_controller__WEBPACK_IMPORTED_MODULE_5__["default"] {
            _levels = [];
            _firstLevel = -1;
            currentLevelIndex = -1;
            manualLevelIndex = -1;
            constructor(hls) {
              super(hls, '[level-controller]');
              this._registerListeners();
            }
            _registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_LOADED, this.onManifestLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOADED, this.onFragLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
            }
            _unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_LOADED, this.onManifestLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_LOADED, this.onFragLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, this.onError, this);
            }
            destroy() {
              this._unregisterListeners();
              this.manualLevelIndex = -1;
              this._levels.length = 0;
              super.destroy();
            }
            startLoad() {
              const levels = this._levels;

              // clean up live level details to force reload them, and reset load errors
              levels.forEach(level => {
                level.loadError = 0;
              });
              super.startLoad();
            }
            onManifestLoaded(event, data) {
              let levels = [];
              let audioTracks = [];
              let subtitleTracks = [];
              let bitrateStart;
              const levelSet = {};
              let levelFromSet;
              let resolutionFound = false;
              let videoCodecFound = false;
              let audioCodecFound = false;

              // regroup redundant levels together
              data.levels.forEach(levelParsed => {
                const attributes = levelParsed.attrs;
                resolutionFound = resolutionFound || !!(levelParsed.width && levelParsed.height);
                videoCodecFound = videoCodecFound || !!levelParsed.videoCodec;
                audioCodecFound = audioCodecFound || !!levelParsed.audioCodec;

                // erase audio codec info if browser does not support mp4a.40.34.
                // demuxer will autodetect codec and fallback to mpeg/audio
                if (chromeOrFirefox && levelParsed.audioCodec && levelParsed.audioCodec.indexOf('mp4a.40.34') !== -1) {
                  levelParsed.audioCodec = undefined;
                }
                const levelKey = `${levelParsed.bitrate}-${levelParsed.attrs.RESOLUTION}-${levelParsed.attrs.CODECS}`;
                levelFromSet = levelSet[levelKey];
                if (!levelFromSet) {
                  levelFromSet = new _types_level__WEBPACK_IMPORTED_MODULE_0__.Level(levelParsed);
                  levelSet[levelKey] = levelFromSet;
                  levels.push(levelFromSet);
                } else {
                  levelFromSet.url.push(levelParsed.url);
                }
                if (attributes) {
                  if (attributes.AUDIO) {
                    (0, _level_helper__WEBPACK_IMPORTED_MODULE_4__.addGroupId)(levelFromSet, 'audio', attributes.AUDIO);
                  }
                  if (attributes.SUBTITLES) {
                    (0, _level_helper__WEBPACK_IMPORTED_MODULE_4__.addGroupId)(levelFromSet, 'text', attributes.SUBTITLES);
                  }
                }
              });

              // remove audio-only level if we also have levels with video codecs or RESOLUTION signalled
              if ((resolutionFound || videoCodecFound) && audioCodecFound) {
                levels = levels.filter(({
                  videoCodec,
                  width,
                  height
                }) => !!videoCodec || !!(width && height));
              }

              // only keep levels with supported audio/video codecs
              levels = levels.filter(({
                audioCodec,
                videoCodec
              }) => {
                return (!audioCodec || (0, _utils_codecs__WEBPACK_IMPORTED_MODULE_3__.isCodecSupportedInMp4)(audioCodec, 'audio')) && (!videoCodec || (0, _utils_codecs__WEBPACK_IMPORTED_MODULE_3__.isCodecSupportedInMp4)(videoCodec, 'video'));
              });
              if (data.audioTracks) {
                audioTracks = data.audioTracks.filter(track => !track.audioCodec || (0, _utils_codecs__WEBPACK_IMPORTED_MODULE_3__.isCodecSupportedInMp4)(track.audioCodec, 'audio'));
                // Assign ids after filtering as array indices by group-id
                (0, _level_helper__WEBPACK_IMPORTED_MODULE_4__.assignTrackIdsByGroup)(audioTracks);
              }
              if (data.subtitles) {
                subtitleTracks = data.subtitles;
                (0, _level_helper__WEBPACK_IMPORTED_MODULE_4__.assignTrackIdsByGroup)(subtitleTracks);
              }
              if (levels.length > 0) {
                // start bitrate is the first bitrate of the manifest
                bitrateStart = levels[0].bitrate;
                // sort level on bitrate
                levels.sort((a, b) => a.bitrate - b.bitrate);
                this._levels = levels;
                // find index of first level in sorted levels
                for (let i = 0; i < levels.length; i++) {
                  if (levels[i].bitrate === bitrateStart) {
                    this._firstLevel = i;
                    this.log(`manifest loaded, ${levels.length} level(s) found, first bitrate: ${bitrateStart}`);
                    break;
                  }
                }

                // Audio is only alternate if manifest include a URI along with the audio group tag,
                // and this is not an audio-only stream where levels contain audio-only
                const audioOnly = audioCodecFound && !videoCodecFound;
                const edata = {
                  levels,
                  audioTracks,
                  subtitleTracks,
                  sessionData: data.sessionData,
                  sessionKeys: data.sessionKeys,
                  firstLevel: this._firstLevel,
                  stats: data.stats,
                  audio: audioCodecFound,
                  video: videoCodecFound,
                  altAudio: !audioOnly && audioTracks.some(t => !!t.url)
                };
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.MANIFEST_PARSED, edata);

                // Initiate loading after all controllers have received MANIFEST_PARSED
                if (this.hls.config.autoStartLoad || this.hls.forceStartLoad) {
                  this.hls.startLoad(this.hls.config.startPosition);
                }
              } else {
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.MANIFEST_INCOMPATIBLE_CODECS_ERROR,
                  fatal: true,
                  url: data.url,
                  reason: 'no level with compatible codecs found in manifest'
                });
              }
            }
            get levels() {
              if (this._levels.length === 0) {
                return null;
              }
              return this._levels;
            }
            get level() {
              return this.currentLevelIndex;
            }
            set level(newLevel) {
              const levels = this._levels;
              if (levels.length === 0) {
                return;
              }
              if (this.currentLevelIndex === newLevel && levels[newLevel]?.details) {
                return;
              }
              // check if level idx is valid
              if (newLevel < 0 || newLevel >= levels.length) {
                // invalid level id given, trigger error
                const fatal = newLevel < 0;
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorTypes.OTHER_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.LEVEL_SWITCH_ERROR,
                  level: newLevel,
                  fatal,
                  reason: 'invalid level idx'
                });
                if (fatal) {
                  return;
                }
                newLevel = Math.min(newLevel, levels.length - 1);
              }

              // stopping live reloading timer if any
              this.clearTimer();
              const lastLevelIndex = this.currentLevelIndex;
              const lastLevel = levels[lastLevelIndex];
              const level = levels[newLevel];
              this.log(`switching to level ${newLevel} from ${lastLevelIndex}`);
              this.currentLevelIndex = newLevel;
              const levelSwitchingData = Object.assign({}, level, {
                level: newLevel,
                maxBitrate: level.maxBitrate,
                uri: level.uri,
                urlId: level.urlId
              });
              // @ts-ignore
              delete levelSwitchingData._urlId;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_SWITCHING, levelSwitchingData);
              // check if we need to load playlist for this level
              const levelDetails = level.details;
              if (!levelDetails || levelDetails.live) {
                // level not retrieved yet, or live playlist we need to (re)load it
                const hlsUrlParameters = this.switchParams(level.uri, lastLevel?.details);
                this.loadPlaylist(hlsUrlParameters);
              }
            }
            get manualLevel() {
              return this.manualLevelIndex;
            }
            set manualLevel(newLevel) {
              this.manualLevelIndex = newLevel;
              if (this._startLevel === undefined) {
                this._startLevel = newLevel;
              }
              if (newLevel !== -1) {
                this.level = newLevel;
              }
            }
            get firstLevel() {
              return this._firstLevel;
            }
            set firstLevel(newLevel) {
              this._firstLevel = newLevel;
            }
            get startLevel() {
              // hls.startLevel takes precedence over config.startLevel
              // if none of these values are defined, fallback on this._firstLevel (first quality level appearing in variant manifest)
              if (this._startLevel === undefined) {
                const configStartLevel = this.hls.config.startLevel;
                if (configStartLevel !== undefined) {
                  return configStartLevel;
                } else {
                  return this._firstLevel;
                }
              } else {
                return this._startLevel;
              }
            }
            set startLevel(newLevel) {
              this._startLevel = newLevel;
            }
            onError(event, data) {
              super.onError(event, data);
              if (data.fatal) {
                return;
              }

              // Switch to redundant level when track fails to load
              const context = data.context;
              const level = this._levels[this.currentLevelIndex];
              if (context && (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__.PlaylistContextType.AUDIO_TRACK && level.audioGroupIds && context.groupId === level.audioGroupIds[level.urlId] || context.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__.PlaylistContextType.SUBTITLE_TRACK && level.textGroupIds && context.groupId === level.textGroupIds[level.urlId])) {
                this.redundantFailover(this.currentLevelIndex);
                return;
              }
              let levelError = false;
              let levelSwitch = true;
              let levelIndex;

              // try to recover not fatal errors
              switch (data.details) {
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.FRAG_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.FRAG_LOAD_TIMEOUT:
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.KEY_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.KEY_LOAD_TIMEOUT:
                  if (data.frag) {
                    // Share fragment error count accross media options (main, audio, subs)
                    // This allows for level based rendition switching when media option assets fail
                    const variantLevelIndex = data.frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__.PlaylistLevelType.MAIN ? data.frag.level : this.currentLevelIndex;
                    const level = this._levels[variantLevelIndex];
                    // Set levelIndex when we're out of fragment retries
                    if (level) {
                      level.fragmentError++;
                      if (level.fragmentError > this.hls.config.fragLoadingMaxRetry) {
                        levelIndex = variantLevelIndex;
                      }
                    } else {
                      levelIndex = variantLevelIndex;
                    }
                  }
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.FRAG_PARSING_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.KEY_SYSTEM_NO_SESSION:
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED:
                  levelIndex = data.frag?.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__.PlaylistLevelType.MAIN ? data.frag.level : this.currentLevelIndex;
                  // Do not retry level. Escalate to fatal if switching levels fails.
                  data.levelRetry = false;
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.LEVEL_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.LEVEL_LOAD_TIMEOUT:
                  // Do not perform level switch if an error occurred using delivery directives
                  // Attempt to reload level without directives first
                  if (context) {
                    if (context.deliveryDirectives) {
                      levelSwitch = false;
                    }
                    levelIndex = context.level;
                  }
                  levelError = true;
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_2__.ErrorDetails.REMUX_ALLOC_ERROR:
                  levelIndex = data.level ?? this.currentLevelIndex;
                  levelError = true;
                  break;
              }
              if (levelIndex !== undefined) {
                this.recoverLevel(data, levelIndex, levelError, levelSwitch);
              }
            }

            /**
             * Switch to a redundant stream if any available.
             * If redundant stream is not available, emergency switch down if ABR mode is enabled.
             */
            recoverLevel(errorEvent, levelIndex, levelError, levelSwitch) {
              const {
                details: errorDetails
              } = errorEvent;
              const level = this._levels[levelIndex];
              level.loadError++;
              if (levelError) {
                const retrying = this.retryLoadingOrFail(errorEvent);
                if (retrying) {
                  // boolean used to inform stream controller not to switch back to IDLE on non fatal error
                  errorEvent.levelRetry = true;
                } else {
                  this.currentLevelIndex = -1;
                  return;
                }
              }
              if (levelSwitch) {
                const redundantLevels = level.url.length;
                // Try redundant fail-over until level.loadError reaches redundantLevels
                if (redundantLevels > 1 && level.loadError < redundantLevels) {
                  errorEvent.levelRetry = true;
                  this.redundantFailover(levelIndex);
                } else if (this.manualLevelIndex === -1) {
                  // Search for next level to retry
                  let nextLevel = -1;
                  const levels = this._levels;
                  for (let i = levels.length; i--;) {
                    const candidate = (i + this.currentLevelIndex) % levels.length;
                    if (candidate !== this.currentLevelIndex && levels[candidate].loadError === 0) {
                      nextLevel = candidate;
                      break;
                    }
                  }
                  if (nextLevel > -1 && this.currentLevelIndex !== nextLevel) {
                    this.warn(`${errorDetails}: switch to ${nextLevel}`);
                    errorEvent.levelRetry = true;
                    this.hls.nextAutoLevel = nextLevel;
                  } else if (errorEvent.levelRetry === false) {
                    // No levels to switch to and no more retries
                    errorEvent.fatal = true;
                  }
                }
              }
            }
            redundantFailover(levelIndex) {
              const level = this._levels[levelIndex];
              const redundantLevels = level.url.length;
              if (redundantLevels > 1) {
                // Update the url id of all levels so that we stay on the same set of variants when level switching
                const newUrlId = (level.urlId + 1) % redundantLevels;
                this.warn(`Switching to redundant URL-id ${newUrlId}`);
                this._levels.forEach(level => {
                  level.urlId = newUrlId;
                });
                this.level = levelIndex;
              }
            }

            // reset errors on the successful load of a fragment
            onFragLoaded(event, {
              frag
            }) {
              if (frag !== undefined && frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_6__.PlaylistLevelType.MAIN) {
                const level = this._levels[frag.level];
                if (level !== undefined) {
                  level.fragmentError = 0;
                  level.loadError = 0;
                }
              }
            }
            onLevelLoaded(event, data) {
              const {
                level,
                details
              } = data;
              const curLevel = this._levels[level];
              if (!curLevel) {
                this.warn(`Invalid level index ${level}`);
                if (data.deliveryDirectives?.skip) {
                  details.deltaUpdateFailed = true;
                }
                return;
              }

              // only process level loaded events matching with expected level
              if (level === this.currentLevelIndex) {
                // reset level load error counter on successful level loaded only if there is no issues with fragments
                if (curLevel.fragmentError === 0) {
                  curLevel.loadError = 0;
                  this.retryCount = 0;
                }
                this.playlistLoaded(level, data, curLevel.details);
              } else if (data.deliveryDirectives?.skip) {
                // received a delta playlist update that cannot be merged
                details.deltaUpdateFailed = true;
              }
            }
            onAudioTrackSwitched(event, data) {
              const currentLevel = this.hls.levels[this.currentLevelIndex];
              if (!currentLevel) {
                return;
              }
              if (currentLevel.audioGroupIds) {
                let urlId = -1;
                const audioGroupId = this.hls.audioTracks[data.id].groupId;
                for (let i = 0; i < currentLevel.audioGroupIds.length; i++) {
                  if (currentLevel.audioGroupIds[i] === audioGroupId) {
                    urlId = i;
                    break;
                  }
                }
                if (urlId !== currentLevel.urlId) {
                  currentLevel.urlId = urlId;
                  this.startLoad();
                }
              }
            }
            loadPlaylist(hlsUrlParameters) {
              super.loadPlaylist();
              const level = this.currentLevelIndex;
              const currentLevel = this._levels[level];
              if (this.canLoad && currentLevel && currentLevel.url.length > 0) {
                const id = currentLevel.urlId;
                let url = currentLevel.url[id];
                if (hlsUrlParameters) {
                  try {
                    url = hlsUrlParameters.addDirectives(url);
                  } catch (error) {
                    this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);
                  }
                }
                this.log(`Attempt loading level index ${level}${hlsUrlParameters ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''} with URL-id ${id} ${url}`);

                // console.log('Current audio track group ID:', this.hls.audioTracks[this.hls.audioTrack].groupId);
                // console.log('New video quality level audio group id:', levelObject.attrs.AUDIO, level);
                this.clearTimer();
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVEL_LOADING, {
                  url,
                  level,
                  id,
                  deliveryDirectives: hlsUrlParameters || null
                });
              }
            }
            get nextLoadLevel() {
              if (this.manualLevelIndex !== -1) {
                return this.manualLevelIndex;
              } else {
                return this.hls.nextAutoLevel;
              }
            }
            set nextLoadLevel(nextLevel) {
              this.level = nextLevel;
              if (this.manualLevelIndex === -1) {
                this.hls.nextAutoLevel = nextLevel;
              }
            }
            removeLevel(levelIndex, urlId) {
              const filterLevelAndGroupByIdIndex = (url, id) => id !== urlId;
              const levels = this._levels.filter((level, index) => {
                if (index !== levelIndex) {
                  return true;
                }
                if (level.url.length > 1 && urlId !== undefined) {
                  level.url = level.url.filter(filterLevelAndGroupByIdIndex);
                  if (level.audioGroupIds) {
                    level.audioGroupIds = level.audioGroupIds.filter(filterLevelAndGroupByIdIndex);
                  }
                  if (level.textGroupIds) {
                    level.textGroupIds = level.textGroupIds.filter(filterLevelAndGroupByIdIndex);
                  }
                  level.urlId = 0;
                  return true;
                }
                return false;
              }).map((level, index) => {
                const {
                  details
                } = level;
                if (details?.fragments) {
                  details.fragments.forEach(fragment => {
                    fragment.level = index;
                  });
                }
                return level;
              });
              this._levels = levels;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.LEVELS_UPDATED, {
                levels
              });
            }
          }

          /***/
        }),

/***/ "./src/controller/level-helper.ts":
/*!****************************************!*\
  !*** ./src/controller/level-helper.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "addGroupId": () => (/* binding */ addGroupId),
/* harmony export */   "addSliding": () => (/* binding */ addSliding),
/* harmony export */   "adjustSliding": () => (/* binding */ adjustSliding),
/* harmony export */   "assignTrackIdsByGroup": () => (/* binding */ assignTrackIdsByGroup),
/* harmony export */   "computeReloadInterval": () => (/* binding */ computeReloadInterval),
/* harmony export */   "getFragmentWithSN": () => (/* binding */ getFragmentWithSN),
/* harmony export */   "getPartWith": () => (/* binding */ getPartWith),
/* harmony export */   "mapFragmentIntersection": () => (/* binding */ mapFragmentIntersection),
/* harmony export */   "mapPartIntersection": () => (/* binding */ mapPartIntersection),
/* harmony export */   "mergeDetails": () => (/* binding */ mergeDetails),
/* harmony export */   "updateFragPTSDTS": () => (/* binding */ updateFragPTSDTS),
/* harmony export */   "updatePTS": () => (/* binding */ updatePTS)
            /* harmony export */
          });
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _loader_date_range__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader/date-range */ "./src/loader/date-range.ts");
          /**
           * @module LevelHelper
           * Providing methods dealing with playlist sliding and drift
           * */



          function addGroupId(level, type, id) {
            switch (type) {
              case 'audio':
                if (!level.audioGroupIds) {
                  level.audioGroupIds = [];
                }
                level.audioGroupIds.push(id);
                break;
              case 'text':
                if (!level.textGroupIds) {
                  level.textGroupIds = [];
                }
                level.textGroupIds.push(id);
                break;
            }
          }
          function assignTrackIdsByGroup(tracks) {
            const groups = {};
            tracks.forEach(track => {
              const groupId = track.groupId || '';
              track.id = groups[groupId] = groups[groupId] || 0;
              groups[groupId]++;
            });
          }
          function updatePTS(fragments, fromIdx, toIdx) {
            const fragFrom = fragments[fromIdx];
            const fragTo = fragments[toIdx];
            updateFromToPTS(fragFrom, fragTo);
          }
          function updateFromToPTS(fragFrom, fragTo) {
            const fragToPTS = fragTo.startPTS;
            // if we know startPTS[toIdx]
            if (Number.isFinite(fragToPTS)) {
              // update fragment duration.
              // it helps to fix drifts between playlist reported duration and fragment real duration
              let duration = 0;
              let frag;
              if (fragTo.sn > fragFrom.sn) {
                duration = fragToPTS - fragFrom.start;
                frag = fragFrom;
              } else {
                duration = fragFrom.start - fragToPTS;
                frag = fragTo;
              }
              // TODO? Drift can go either way, or the playlist could be completely accurate
              // console.assert(duration > 0,
              //   `duration of ${duration} computed for frag ${frag.sn}, level ${frag.level}, there should be some duration drift between playlist and fragment!`);
              if (frag.duration !== duration) {
                frag.duration = duration;
              }
              // we dont know startPTS[toIdx]
            } else if (fragTo.sn > fragFrom.sn) {
              const contiguous = fragFrom.cc === fragTo.cc;
              // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS
              if (contiguous && fragFrom.minEndPTS) {
                fragTo.start = fragFrom.start + (fragFrom.minEndPTS - fragFrom.start);
              } else {
                fragTo.start = fragFrom.start + fragFrom.duration;
              }
            } else {
              fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);
            }
          }
          function updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS) {
            const parsedMediaDuration = endPTS - startPTS;
            if (parsedMediaDuration <= 0) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn('Fragment should have a positive duration', frag);
              endPTS = startPTS + frag.duration;
              endDTS = startDTS + frag.duration;
            }
            let maxStartPTS = startPTS;
            let minEndPTS = endPTS;
            const fragStartPts = frag.startPTS;
            const fragEndPts = frag.endPTS;
            if (Number.isFinite(fragStartPts)) {
              // delta PTS between audio and video
              const deltaPTS = Math.abs(fragStartPts - startPTS);
              if (!Number.isFinite(frag.deltaPTS)) {
                frag.deltaPTS = deltaPTS;
              } else {
                frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);
              }
              maxStartPTS = Math.max(startPTS, fragStartPts);
              startPTS = Math.min(startPTS, fragStartPts);
              startDTS = Math.min(startDTS, frag.startDTS);
              minEndPTS = Math.min(endPTS, fragEndPts);
              endPTS = Math.max(endPTS, fragEndPts);
              endDTS = Math.max(endDTS, frag.endDTS);
            }
            frag.duration = endPTS - startPTS;
            const drift = startPTS - frag.start;
            frag.start = frag.startPTS = startPTS;
            frag.maxStartPTS = maxStartPTS;
            frag.startDTS = startDTS;
            frag.endPTS = endPTS;
            frag.minEndPTS = minEndPTS;
            frag.endDTS = endDTS;
            const sn = frag.sn; // 'initSegment'
            // exit if sn out of range
            if (!details || sn < details.startSN || sn > details.endSN) {
              return 0;
            }
            let i;
            const fragIdx = sn - details.startSN;
            const fragments = details.fragments;
            // update frag reference in fragments array
            // rationale is that fragments array might not contain this frag object.
            // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()
            // if we don't update frag, we won't be able to propagate PTS info on the playlist
            // resulting in invalid sliding computation
            fragments[fragIdx] = frag;
            // adjust fragment PTS/duration from seqnum-1 to frag 0
            for (i = fragIdx; i > 0; i--) {
              updateFromToPTS(fragments[i], fragments[i - 1]);
            }

            // adjust fragment PTS/duration from seqnum to last frag
            for (i = fragIdx; i < fragments.length - 1; i++) {
              updateFromToPTS(fragments[i], fragments[i + 1]);
            }
            if (details.fragmentHint) {
              updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);
            }
            details.PTSKnown = details.alignedSliding = true;
            return drift;
          }
          function mergeDetails(oldDetails, newDetails) {
            // Track the last initSegment processed. Initialize it to the last one on the timeline.
            let currentInitSegment = null;
            const oldFragments = oldDetails.fragments;
            for (let i = oldFragments.length - 1; i >= 0; i--) {
              const oldInit = oldFragments[i].initSegment;
              if (oldInit) {
                currentInitSegment = oldInit;
                break;
              }
            }
            if (oldDetails.fragmentHint) {
              // prevent PTS and duration from being adjusted on the next hint
              delete oldDetails.fragmentHint.endPTS;
            }
            // check if old/new playlists have fragments in common
            // loop through overlapping SN and update startPTS , cc, and duration if any found
            let ccOffset = 0;
            let PTSFrag;
            mapFragmentIntersection(oldDetails, newDetails, (oldFrag, newFrag) => {
              if (oldFrag.relurl) {
                // Do not compare CC if the old fragment has no url. This is a level.fragmentHint used by LL-HLS parts.
                // It maybe be off by 1 if it was created before any parts or discontinuity tags were appended to the end
                // of the playlist.
                ccOffset = oldFrag.cc - newFrag.cc;
              }
              if (Number.isFinite(oldFrag.startPTS) && Number.isFinite(oldFrag.endPTS)) {
                newFrag.start = newFrag.startPTS = oldFrag.startPTS;
                newFrag.startDTS = oldFrag.startDTS;
                newFrag.appendedPTS = oldFrag.appendedPTS;
                newFrag.maxStartPTS = oldFrag.maxStartPTS;
                newFrag.endPTS = oldFrag.endPTS;
                newFrag.endDTS = oldFrag.endDTS;
                newFrag.minEndPTS = oldFrag.minEndPTS;
                newFrag.duration = oldFrag.endPTS - oldFrag.startPTS;
                if (newFrag.duration) {
                  PTSFrag = newFrag;
                }

                // PTS is known when any segment has startPTS and endPTS
                newDetails.PTSKnown = newDetails.alignedSliding = true;
              }
              newFrag.elementaryStreams = oldFrag.elementaryStreams;
              newFrag.loader = oldFrag.loader;
              newFrag.stats = oldFrag.stats;
              newFrag.urlId = oldFrag.urlId;
              if (oldFrag.initSegment) {
                newFrag.initSegment = oldFrag.initSegment;
                currentInitSegment = oldFrag.initSegment;
              }
            });
            if (currentInitSegment) {
              const fragmentsToCheck = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;
              fragmentsToCheck.forEach(frag => {
                if (!frag.initSegment || frag.initSegment.relurl === currentInitSegment?.relurl) {
                  frag.initSegment = currentInitSegment;
                }
              });
            }
            if (newDetails.skippedSegments) {
              newDetails.deltaUpdateFailed = newDetails.fragments.some(frag => !frag);
              if (newDetails.deltaUpdateFailed) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn('[level-helper] Previous playlist missing segments skipped in delta playlist');
                for (let i = newDetails.skippedSegments; i--;) {
                  newDetails.fragments.shift();
                }
                newDetails.startSN = newDetails.fragments[0].sn;
                newDetails.startCC = newDetails.fragments[0].cc;
              } else if (newDetails.canSkipDateRanges) {
                newDetails.dateRanges = mergeDateRanges(oldDetails.dateRanges, newDetails.dateRanges, newDetails.recentlyRemovedDateranges);
              }
            }
            const newFragments = newDetails.fragments;
            if (ccOffset) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn('discontinuity sliding from playlist, take drift into account');
              for (let i = 0; i < newFragments.length; i++) {
                newFragments[i].cc += ccOffset;
              }
            }
            if (newDetails.skippedSegments) {
              newDetails.startCC = newDetails.fragments[0].cc;
            }

            // Merge parts
            mapPartIntersection(oldDetails.partList, newDetails.partList, (oldPart, newPart) => {
              newPart.elementaryStreams = oldPart.elementaryStreams;
              newPart.stats = oldPart.stats;
            });

            // if at least one fragment contains PTS info, recompute PTS information for all fragments
            if (PTSFrag) {
              updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS);
            } else {
              // ensure that delta is within oldFragments range
              // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])
              // in that case we also need to adjust start offset of all fragments
              adjustSliding(oldDetails, newDetails);
            }
            if (newFragments.length) {
              newDetails.totalduration = newDetails.edge - newFragments[0].start;
            }
            newDetails.driftStartTime = oldDetails.driftStartTime;
            newDetails.driftStart = oldDetails.driftStart;
            const advancedDateTime = newDetails.advancedDateTime;
            if (newDetails.advanced && advancedDateTime) {
              const edge = newDetails.edge;
              if (!newDetails.driftStart) {
                newDetails.driftStartTime = advancedDateTime;
                newDetails.driftStart = edge;
              }
              newDetails.driftEndTime = advancedDateTime;
              newDetails.driftEnd = edge;
            } else {
              newDetails.driftEndTime = oldDetails.driftEndTime;
              newDetails.driftEnd = oldDetails.driftEnd;
              newDetails.advancedDateTime = oldDetails.advancedDateTime;
            }
          }
          function mergeDateRanges(oldDateRanges, deltaDateRanges, recentlyRemovedDateranges) {
            const dateRanges = Object.assign({}, oldDateRanges);
            if (recentlyRemovedDateranges) {
              recentlyRemovedDateranges.forEach(id => {
                delete dateRanges[id];
              });
            }
            Object.keys(deltaDateRanges).forEach(id => {
              const dateRange = new _loader_date_range__WEBPACK_IMPORTED_MODULE_1__.DateRange(deltaDateRanges[id].attr, dateRanges[id]);
              if (dateRange.isValid) {
                dateRanges[id] = dateRange;
              } else {
                _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn(`Ignoring invalid Playlist Delta Update DATERANGE tag: "${JSON.stringify(deltaDateRanges[id].attr)}"`);
              }
            });
            return dateRanges;
          }
          function mapPartIntersection(oldParts, newParts, intersectionFn) {
            if (oldParts && newParts) {
              let delta = 0;
              for (let i = 0, len = oldParts.length; i <= len; i++) {
                const oldPart = oldParts[i];
                const newPart = newParts[i + delta];
                if (oldPart && newPart && oldPart.index === newPart.index && oldPart.fragment.sn === newPart.fragment.sn) {
                  intersectionFn(oldPart, newPart);
                } else {
                  delta--;
                }
              }
            }
          }
          function mapFragmentIntersection(oldDetails, newDetails, intersectionFn) {
            const skippedSegments = newDetails.skippedSegments;
            const start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;
            const end = (oldDetails.fragmentHint ? 1 : 0) + (skippedSegments ? newDetails.endSN : Math.min(oldDetails.endSN, newDetails.endSN)) - newDetails.startSN;
            const delta = newDetails.startSN - oldDetails.startSN;
            const newFrags = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;
            const oldFrags = oldDetails.fragmentHint ? oldDetails.fragments.concat(oldDetails.fragmentHint) : oldDetails.fragments;
            for (let i = start; i <= end; i++) {
              const oldFrag = oldFrags[delta + i];
              let newFrag = newFrags[i];
              if (skippedSegments && !newFrag && i < skippedSegments) {
                // Fill in skipped segments in delta playlist
                newFrag = newDetails.fragments[i] = oldFrag;
              }
              if (oldFrag && newFrag) {
                intersectionFn(oldFrag, newFrag);
              }
            }
          }
          function adjustSliding(oldDetails, newDetails) {
            const delta = newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;
            const oldFragments = oldDetails.fragments;
            if (delta < 0 || delta >= oldFragments.length) {
              return;
            }
            addSliding(newDetails, oldFragments[delta].start);
          }
          function addSliding(details, start) {
            if (start) {
              const fragments = details.fragments;
              for (let i = details.skippedSegments; i < fragments.length; i++) {
                fragments[i].start += start;
              }
              if (details.fragmentHint) {
                details.fragmentHint.start += start;
              }
            }
          }
          function computeReloadInterval(newDetails, distanceToLiveEdgeMs = Infinity) {
            let reloadInterval = 1000 * newDetails.targetduration;
            if (newDetails.updated) {
              // Use last segment duration when shorter than target duration and near live edge
              const fragments = newDetails.fragments;
              const liveEdgeMaxTargetDurations = 4;
              if (fragments.length && reloadInterval * liveEdgeMaxTargetDurations > distanceToLiveEdgeMs) {
                const lastSegmentDuration = fragments[fragments.length - 1].duration * 1000;
                if (lastSegmentDuration < reloadInterval) {
                  reloadInterval = lastSegmentDuration;
                }
              }
            } else {
              // estimate = 'miss half average';
              // follow HLS Spec, If the client reloads a Playlist file and finds that it has not
              // changed then it MUST wait for a period of one-half the target
              // duration before retrying.
              reloadInterval /= 2;
            }
            return Math.round(reloadInterval);
          }
          function getFragmentWithSN(level, sn, fragCurrent) {
            if (!level || !level.details) {
              return null;
            }
            const levelDetails = level.details;
            let fragment = levelDetails.fragments[sn - levelDetails.startSN];
            if (fragment) {
              return fragment;
            }
            fragment = levelDetails.fragmentHint;
            if (fragment && fragment.sn === sn) {
              return fragment;
            }
            if (sn < levelDetails.startSN && fragCurrent && fragCurrent.sn === sn) {
              return fragCurrent;
            }
            return null;
          }
          function getPartWith(level, sn, partIndex) {
            if (!level || !level.details) {
              return null;
            }
            const partList = level.details.partList;
            if (partList) {
              for (let i = partList.length; i--;) {
                const part = partList[i];
                if (part.index === partIndex && part.fragment.sn === sn) {
                  return part;
                }
              }
            }
            return null;
          }

          /***/
        }),

/***/ "./src/controller/stream-controller.ts":
/*!*********************************************!*\
  !*** ./src/controller/stream-controller.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ StreamController)
            /* harmony export */
          });
/* harmony import */ var _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base-stream-controller */ "./src/controller/base-stream-controller.ts");
/* harmony import */ var _is_supported__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../is-supported */ "./src/is-supported.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
/* harmony import */ var _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../demux/transmuxer-interface */ "./src/demux/transmuxer-interface.ts");
/* harmony import */ var _types_transmuxer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../types/transmuxer */ "./src/types/transmuxer.ts");
/* harmony import */ var _gap_controller__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./gap-controller */ "./src/controller/gap-controller.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");











          const TICK_INTERVAL = 100; // how often to tick in ms

          class StreamController extends _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__["default"] {
            audioCodecSwap = false;
            gapController = null;
            level = -1;
            _forceStartLoad = false;
            altAudio = false;
            audioOnly = false;
            fragPlaying = null;
            onvplaying = null;
            onvseeked = null;
            fragLastKbps = 0;
            couldBacktrack = false;
            backtrackFragment = null;
            audioCodecSwitch = false;
            videoBuffer = null;
            constructor(hls, fragmentTracker, keyLoader) {
              super(hls, fragmentTracker, keyLoader, '[stream-controller]');
              this._registerListeners();
            }
            _registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, this.onError, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_CREATED, this.onBufferCreated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
            }
            _unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, this.onError, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_CREATED, this.onBufferCreated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_FLUSHED, this.onBufferFlushed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVELS_UPDATED, this.onLevelsUpdated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
            }
            onHandlerDestroying() {
              this._unregisterListeners();
              this.onMediaDetaching();
            }
            startLoad(startPosition) {
              if (this.levels) {
                const {
                  lastCurrentTime,
                  hls
                } = this;
                this.stopLoad();
                this.setInterval(TICK_INTERVAL);
                this.level = -1;
                this.fragLoadError = 0;
                if (!this.startFragRequested) {
                  // determine load level
                  let startLevel = hls.startLevel;
                  if (startLevel === -1) {
                    if (hls.config.testBandwidth && this.levels.length > 1) {
                      // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level
                      startLevel = 0;
                      this.bitrateTest = true;
                    } else {
                      startLevel = hls.nextAutoLevel;
                    }
                  }
                  // set new level to playlist loader : this will trigger start level load
                  // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded
                  this.level = hls.nextLoadLevel = startLevel;
                  this.loadedmetadata = false;
                }
                // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime
                if (lastCurrentTime > 0 && startPosition === -1) {
                  this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);
                  startPosition = lastCurrentTime;
                }
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;
                this.tick();
              } else {
                this._forceStartLoad = true;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.STOPPED;
              }
            }
            stopLoad() {
              this._forceStartLoad = false;
              super.stopLoad();
            }
            doTick() {
              switch (this.state) {
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE:
                  this.doTickIdle();
                  break;
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_LEVEL:
                  {
                    const {
                      levels,
                      level
                    } = this;
                    const details = levels?.[level]?.details;
                    if (details && (!details.live || this.levelLastLoaded === this.level)) {
                      if (this.waitForCdnTuneIn(details)) {
                        break;
                      }
                      this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                      break;
                    }
                    break;
                  }
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING_WAITING_RETRY:
                  {
                    const now = self.performance.now();
                    const retryDate = this.retryDate;
                    // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading
                    if (!retryDate || now >= retryDate || this.media?.seeking) {
                      this.log('retryDate reached, switch back to IDLE state');
                      this.resetStartWhenNotLoaded(this.level);
                      this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                    }
                  }
                  break;
                default:
                  break;
              }
              // check buffer
              // check/update current fragment
              this.onTickEnd();
            }
            onTickEnd() {
              super.onTickEnd();
              this.checkBuffer();
              this.checkFragmentChanged();
            }
            doTickIdle() {
              const {
                hls,
                levelLastLoaded,
                levels,
                media
              } = this;
              const {
                config,
                nextLoadLevel: level
              } = hls;

              // if start level not parsed yet OR
              // if video not attached AND start fragment already requested OR start frag prefetch not enabled
              // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment
              if (levelLastLoaded === null || !media && (this.startFragRequested || !config.startFragPrefetch)) {
                return;
              }

              // If the "main" level is audio-only but we are loading an alternate track in the same group, do not load anything
              if (this.altAudio && this.audioOnly) {
                return;
              }
              if (!levels || !levels[level]) {
                return;
              }
              const levelInfo = levels[level];

              // if buffer length is less than maxBufLen try to load a new fragment

              const bufferInfo = this.getMainFwdBufferInfo();
              if (bufferInfo === null) {
                return;
              }
              const lastDetails = this.getLevelDetails();
              if (lastDetails && this._streamEnded(bufferInfo, lastDetails)) {
                const data = {};
                if (this.altAudio) {
                  data.type = 'video';
                }
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_EOS, data);
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ENDED;
                return;
              }

              // set next load level : this will trigger a playlist load if needed
              this.level = hls.nextLoadLevel = level;
              const levelDetails = levelInfo.details;
              // if level info not retrieved yet, switch state and wait for level retrieval
              // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load
              // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)
              if (!levelDetails || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_LEVEL || levelDetails.live && this.levelLastLoaded !== level) {
                this.level = level;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_LEVEL;
                return;
              }
              const bufferLen = bufferInfo.len;

              // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s
              const maxBufLen = this.getMaxBufferLength(levelInfo.maxBitrate);

              // Stay idle if we are still with buffer margins
              if (bufferLen >= maxBufLen) {
                return;
              }
              if (this.backtrackFragment && this.backtrackFragment.start > bufferInfo.end) {
                this.backtrackFragment = null;
              }
              const targetBufferTime = this.backtrackFragment ? this.backtrackFragment.start : bufferInfo.end;
              let frag = this.getNextFragment(targetBufferTime, levelDetails);
              // Avoid backtracking by loading an earlier segment in streams with segments that do not start with a key frame (flagged by `couldBacktrack`)
              if (this.couldBacktrack && !this.fragPrevious && frag && frag.sn !== 'initSegment' && this.fragmentTracker.getState(frag) !== _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__.FragmentState.OK) {
                const backtrackSn = (this.backtrackFragment ?? frag).sn;
                const fragIdx = backtrackSn - levelDetails.startSN;
                const backtrackFrag = levelDetails.fragments[fragIdx - 1];
                if (backtrackFrag && frag.cc === backtrackFrag.cc) {
                  frag = backtrackFrag;
                  this.fragmentTracker.removeFragment(backtrackFrag);
                }
              } else if (this.backtrackFragment && bufferInfo.len) {
                this.backtrackFragment = null;
              }
              // Avoid loop loading by using nextLoadPosition set for backtracking
              if (frag && this.fragmentTracker.getState(frag) === _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__.FragmentState.OK && this.nextLoadPosition > targetBufferTime) {
                // Cleanup the fragment tracker before trying to find the next unbuffered fragment
                const type = this.audioOnly && !this.altAudio ? _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO : _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.VIDEO;
                const mediaBuffer = (type === _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;
                if (mediaBuffer) {
                  this.afterBufferFlushed(mediaBuffer, type, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
                }
                frag = this.getNextFragment(this.nextLoadPosition, levelDetails);
              }
              if (!frag) {
                return;
              }
              if (frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {
                frag = frag.initSegment;
              }
              this.loadFragment(frag, levelDetails, targetBufferTime);
            }
            loadFragment(frag, levelDetails, targetBufferTime) {
              // Check if fragment is not loaded
              const fragState = this.fragmentTracker.getState(frag);
              this.fragCurrent = frag;
              if (fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__.FragmentState.NOT_LOADED) {
                if (frag.sn === 'initSegment') {
                  this._loadInitSegment(frag, levelDetails);
                } else if (this.bitrateTest) {
                  this.log(`Fragment ${frag.sn} of level ${frag.level} is being downloaded to test bitrate and will not be buffered`);
                  this._loadBitrateTestFrag(frag, levelDetails);
                } else {
                  this.startFragRequested = true;
                  super.loadFragment(frag, levelDetails, targetBufferTime);
                }
              } else if (fragState === _fragment_tracker__WEBPACK_IMPORTED_MODULE_4__.FragmentState.APPENDING) {
                // Lower the buffer size and try again
                if (this.reduceMaxBufferLength(frag.duration)) {
                  this.fragmentTracker.removeFragment(frag);
                }
              } else if (this.media?.buffered.length === 0) {
                // Stop gap for bad tracker / buffer flush behavior
                this.fragmentTracker.removeAllFragments();
              }
            }
            getAppendedFrag(position) {
              const fragOrPart = this.fragmentTracker.getAppendedFrag(position, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
              if (fragOrPart && 'fragment' in fragOrPart) {
                return fragOrPart.fragment;
              }
              return fragOrPart;
            }
            getBufferedFrag(position) {
              return this.fragmentTracker.getBufferedFrag(position, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
            }
            followingBufferedFrag(frag) {
              if (frag) {
                // try to get range of next fragment (500ms after this range)
                return this.getBufferedFrag(frag.end + 0.5);
              }
              return null;
            }

            /*
              on immediate level switch :
               - pause playback if playing
               - cancel any pending load request
               - and trigger a buffer flush
            */
            immediateLevelSwitch() {
              this.abortCurrentFrag();
              this.flushMainBuffer(0, Number.POSITIVE_INFINITY);
            }

            /**
             * try to switch ASAP without breaking video playback:
             * in order to ensure smooth but quick level switching,
             * we need to find the next flushable buffer range
             * we should take into account new segment fetch time
             */
            nextLevelSwitch() {
              const {
                levels,
                media
              } = this;
              // ensure that media is defined and that metadata are available (to retrieve currentTime)
              if (media?.readyState) {
                let fetchdelay;
                const fragPlayingCurrent = this.getAppendedFrag(media.currentTime);
                if (fragPlayingCurrent && fragPlayingCurrent.start > 1) {
                  // flush buffer preceding current fragment (flush until current fragment start offset)
                  // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...
                  this.flushMainBuffer(0, fragPlayingCurrent.start - 1);
                }
                if (!media.paused && levels) {
                  // add a safety delay of 1s
                  const nextLevelId = this.hls.nextLoadLevel;
                  const nextLevel = levels[nextLevelId];
                  const fragLastKbps = this.fragLastKbps;
                  if (fragLastKbps && this.fragCurrent) {
                    fetchdelay = this.fragCurrent.duration * nextLevel.maxBitrate / (1000 * fragLastKbps) + 1;
                  } else {
                    fetchdelay = 0;
                  }
                } else {
                  fetchdelay = 0;
                }
                // this.log('fetchdelay:'+fetchdelay);
                // find buffer range that will be reached once new fragment will be fetched
                const bufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);
                if (bufferedFrag) {
                  // we can flush buffer range following this one without stalling playback
                  const nextBufferedFrag = this.followingBufferedFrag(bufferedFrag);
                  if (nextBufferedFrag) {
                    // if we are here, we can also cancel any loading/demuxing in progress, as they are useless
                    this.abortCurrentFrag();
                    // start flush position is in next buffered frag. Leave some padding for non-independent segments and smoother playback.
                    const maxStart = nextBufferedFrag.maxStartPTS ? nextBufferedFrag.maxStartPTS : nextBufferedFrag.start;
                    const fragDuration = nextBufferedFrag.duration;
                    const startPts = Math.max(bufferedFrag.end, maxStart + Math.min(Math.max(fragDuration - this.config.maxFragLookUpTolerance, fragDuration * 0.5), fragDuration * 0.75));
                    this.flushMainBuffer(startPts, Number.POSITIVE_INFINITY);
                  }
                }
              }
            }
            abortCurrentFrag() {
              const fragCurrent = this.fragCurrent;
              this.fragCurrent = null;
              this.backtrackFragment = null;
              if (fragCurrent) {
                fragCurrent.abortRequests();
              }
              switch (this.state) {
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.KEY_LOADING:
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING:
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING_WAITING_RETRY:
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING:
                case _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSED:
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                  break;
              }
              this.nextLoadPosition = this.getLoadPosition();
            }
            flushMainBuffer(startOffset, endOffset) {
              super.flushMainBuffer(startOffset, endOffset, this.altAudio ? 'video' : null);
            }
            onMediaAttached(event, data) {
              super.onMediaAttached(event, data);
              const media = data.media;
              this.onvplaying = this.onMediaPlaying.bind(this);
              this.onvseeked = this.onMediaSeeked.bind(this);
              media.addEventListener('playing', this.onvplaying);
              media.addEventListener('seeked', this.onvseeked);
              this.gapController = new _gap_controller__WEBPACK_IMPORTED_MODULE_9__["default"](this.config, media, this.fragmentTracker, this.hls);
            }
            onMediaDetaching() {
              const {
                media
              } = this;
              if (media && this.onvplaying && this.onvseeked) {
                media.removeEventListener('playing', this.onvplaying);
                media.removeEventListener('seeked', this.onvseeked);
                this.onvplaying = this.onvseeked = null;
                this.videoBuffer = null;
              }
              this.fragPlaying = null;
              if (this.gapController) {
                this.gapController.destroy();
                this.gapController = null;
              }
              super.onMediaDetaching();
            }
            onMediaPlaying() {
              // tick to speed up FRAG_CHANGED triggering
              this.tick();
            }
            onMediaSeeked() {
              const media = this.media;
              const currentTime = media ? media.currentTime : null;
              if (Number.isFinite(currentTime)) {
                this.log(`Media seeked to ${currentTime.toFixed(3)}`);
              }

              // tick to speed up FRAG_CHANGED triggering
              this.tick();
            }
            onManifestLoading() {
              // reset buffer on manifest loading
              this.log('Trigger BUFFER_RESET');
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_RESET, undefined);
              this.fragmentTracker.removeAllFragments();
              this.couldBacktrack = false;
              this.startPosition = this.lastCurrentTime = 0;
              this.fragPlaying = null;
              this.backtrackFragment = null;
            }
            onManifestParsed(event, data) {
              let aac = false;
              let heaac = false;
              let codec;
              data.levels.forEach(level => {
                // detect if we have different kind of audio codecs used amongst playlists
                codec = level.audioCodec;
                if (codec) {
                  if (codec.indexOf('mp4a.40.2') !== -1) {
                    aac = true;
                  }
                  if (codec.indexOf('mp4a.40.5') !== -1) {
                    heaac = true;
                  }
                }
              });
              this.audioCodecSwitch = aac && heaac && !(0, _is_supported__WEBPACK_IMPORTED_MODULE_1__.changeTypeSupported)();
              if (this.audioCodecSwitch) {
                this.log('Both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');
              }
              this.levels = data.levels;
              this.startFragRequested = false;
            }
            onLevelLoading(event, data) {
              const {
                levels
              } = this;
              if (!levels || this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE) {
                return;
              }
              const level = levels[data.level];
              if (!level.details || level.details.live && this.levelLastLoaded !== data.level || this.waitForCdnTuneIn(level.details)) {
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_LEVEL;
              }
            }
            onLevelLoaded(event, data) {
              const {
                levels
              } = this;
              const newLevelId = data.level;
              const newDetails = data.details;
              const duration = newDetails.totalduration;
              if (!levels) {
                this.warn(`Levels were reset while loading level ${newLevelId}`);
                return;
              }
              this.log(`Level ${newLevelId} loaded [${newDetails.startSN},${newDetails.endSN}], cc [${newDetails.startCC}, ${newDetails.endCC}] duration:${duration}`);
              const fragCurrent = this.fragCurrent;
              if (fragCurrent && (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.FRAG_LOADING_WAITING_RETRY)) {
                if (fragCurrent.level !== data.level && fragCurrent.loader) {
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                  this.backtrackFragment = null;
                  fragCurrent.abortRequests();
                }
              }
              const curLevel = levels[newLevelId];
              let sliding = 0;
              if (newDetails.live || curLevel.details?.live) {
                if (!newDetails.fragments[0]) {
                  newDetails.deltaUpdateFailed = true;
                }
                if (newDetails.deltaUpdateFailed) {
                  return;
                }
                sliding = this.alignPlaylists(newDetails, curLevel.details);
              }
              // override level info
              curLevel.details = newDetails;
              this.levelLastLoaded = newLevelId;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVEL_UPDATED, {
                details: newDetails,
                level: newLevelId
              });

              // only switch back to IDLE state if we were waiting for level to start downloading a new fragment
              if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_LEVEL) {
                if (this.waitForCdnTuneIn(newDetails)) {
                  // Wait for Low-Latency CDN Tune-in
                  return;
                }
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
              }
              if (!this.startFragRequested) {
                this.setStartPosition(newDetails, sliding);
              } else if (newDetails.live) {
                this.synchronizeToLiveEdge(newDetails);
              }

              // trigger handler right now
              this.tick();
            }
            _handleFragmentLoadProgress(data) {
              const {
                frag,
                part,
                payload
              } = data;
              const {
                levels
              } = this;
              if (!levels) {
                this.warn(`Levels were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);
                return;
              }
              const currentLevel = levels[frag.level];
              const details = currentLevel.details;
              if (!details) {
                this.warn(`Dropping fragment ${frag.sn} of level ${frag.level} after level details were reset`);
                return;
              }
              const videoCodec = currentLevel.videoCodec;

              // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)
              const accurateTimeOffset = details.PTSKnown || !details.live;
              const initSegmentData = frag.initSegment?.data;
              const audioCodec = this._getAudioCodec(currentLevel);

              // transmux the MPEG-TS data to ISO-BMFF segments
              // this.log(`Transmuxing ${frag.sn} of [${details.startSN} ,${details.endSN}],level ${frag.level}, cc ${frag.cc}`);
              const transmuxer = this.transmuxer = this.transmuxer || new _demux_transmuxer_interface__WEBPACK_IMPORTED_MODULE_7__["default"](this.hls, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));
              const partIndex = part ? part.index : -1;
              const partial = partIndex !== -1;
              const chunkMeta = new _types_transmuxer__WEBPACK_IMPORTED_MODULE_8__.ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);
              const initPTS = this.initPTS[frag.cc];
              transmuxer.push(payload, initSegmentData, audioCodec, videoCodec, frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);
            }
            onAudioTrackSwitching(event, data) {
              // if any URL found on new audio track, it is an alternate audio track
              const fromAltAudio = this.altAudio;
              const altAudio = !!data.url;
              const trackId = data.id;
              // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered
              // don't do anything if we switch to alt audio: audio stream controller is handling it.
              // we will just have to change buffer scheduling on audioTrackSwitched
              if (!altAudio) {
                if (this.mediaBuffer !== this.media) {
                  this.log('Switching on main audio, use media.buffered to schedule main fragment loading');
                  this.mediaBuffer = this.media;
                  const fragCurrent = this.fragCurrent;
                  // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch
                  if (fragCurrent) {
                    this.log('Switching to main audio track, cancel main fragment load');
                    fragCurrent.abortRequests();
                  }
                  // destroy transmuxer to force init segment generation (following audio switch)
                  this.resetTransmuxer();
                  // switch to IDLE state to load new fragment
                  this.resetLoadingState();
                } else if (this.audioOnly) {
                  // Reset audio transmuxer so when switching back to main audio we're not still appending where we left off
                  this.resetTransmuxer();
                }
                const hls = this.hls;
                // If switching from alt to main audio, flush all audio and trigger track switched
                if (fromAltAudio) {
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_FLUSHING, {
                    startOffset: 0,
                    endOffset: Number.POSITIVE_INFINITY,
                    type: 'audio'
                  });
                }
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.AUDIO_TRACK_SWITCHED, {
                  id: trackId
                });
              }
            }
            onAudioTrackSwitched(event, data) {
              const trackId = data.id;
              const altAudio = !!this.hls.audioTracks[trackId].url;
              if (altAudio) {
                const videoBuffer = this.videoBuffer;
                // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered
                if (videoBuffer && this.mediaBuffer !== videoBuffer) {
                  this.log('Switching on alternate audio, use video.buffered to schedule main fragment loading');
                  this.mediaBuffer = videoBuffer;
                }
              }
              this.altAudio = altAudio;
              this.tick();
            }
            onBufferCreated(event, data) {
              const tracks = data.tracks;
              let mediaTrack;
              let name;
              let alternate = false;
              for (const type in tracks) {
                const track = tracks[type];
                if (track.id === 'main') {
                  name = type;
                  mediaTrack = track;
                  // keep video source buffer reference
                  if (type === 'video') {
                    const videoTrack = tracks[type];
                    if (videoTrack) {
                      this.videoBuffer = videoTrack.buffer;
                    }
                  }
                } else {
                  alternate = true;
                }
              }
              if (alternate && mediaTrack) {
                this.log(`Alternate track found, use ${name}.buffered to schedule main fragment loading`);
                this.mediaBuffer = mediaTrack.buffer;
              } else {
                this.mediaBuffer = this.media;
              }
            }
            onFragBuffered(event, data) {
              const {
                frag,
                part
              } = data;
              if (frag && frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN) {
                return;
              }
              if (this.fragContextChanged(frag)) {
                // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion
                // Avoid setting state back to IDLE, since that will interfere with a level switch
                this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}`);
                if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSED) {
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                }
                return;
              }
              const stats = part ? part.stats : frag.stats;
              this.fragLastKbps = Math.round(8 * stats.total / (stats.buffering.end - stats.loading.first));
              if (frag.sn !== 'initSegment') {
                this.fragPrevious = frag;
              }
              this.fragBufferedComplete(frag, part);
            }
            onError(event, data) {
              if (data.type === _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorTypes.KEY_SYSTEM_ERROR) {
                this.onFragmentOrKeyLoadError(_types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN, data);
                return;
              }
              switch (data.details) {
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.FRAG_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.FRAG_LOAD_TIMEOUT:
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.FRAG_PARSING_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.KEY_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.KEY_LOAD_TIMEOUT:
                  this.onFragmentOrKeyLoadError(_types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN, data);
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.LEVEL_LOAD_ERROR:
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.LEVEL_LOAD_TIMEOUT:
                  if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ERROR) {
                    if (data.fatal) {
                      // if fatal error, stop processing
                      this.warn(`${data.details}`);
                      this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.ERROR;
                    } else {
                      // in case of non fatal error while loading level, if level controller is not retrying to load level , switch back to IDLE
                      if (!data.levelRetry && this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.WAITING_LEVEL) {
                        this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                      }
                    }
                  }
                  break;
                case _errors__WEBPACK_IMPORTED_MODULE_10__.ErrorDetails.BUFFER_FULL_ERROR:
                  // if in appending state
                  if (data.parent === 'main' && (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING || this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSED)) {
                    let flushBuffer = true;
                    const bufferedInfo = this.getFwdBufferInfo(this.media, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
                    // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end
                    // reduce max buf len if current position is buffered
                    if (bufferedInfo && bufferedInfo.len > 0.5) {
                      flushBuffer = !this.reduceMaxBufferLength(bufferedInfo.len);
                    }
                    if (flushBuffer) {
                      // current position is not buffered, but browser is still complaining about buffer full error
                      // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708
                      // in that case flush the whole buffer to recover
                      this.warn('buffer full error also media.currentTime is not buffered, flush main');
                      // flush main buffer
                      this.immediateLevelSwitch();
                    }
                    this.resetLoadingState();
                  }
                  break;
                default:
                  break;
              }
            }

            // Checks the health of the buffer and attempts to resolve playback stalls.
            checkBuffer() {
              const {
                media,
                gapController
              } = this;
              if (!media || !gapController || !media.readyState) {
                // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)
                return;
              }
              if (this.loadedmetadata || !_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__.BufferHelper.getBuffered(media).length) {
                // Resolve gaps using the main buffer, whose ranges are the intersections of the A/V sourcebuffers
                const activeFrag = this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE ? this.fragCurrent : null;
                gapController.poll(this.lastCurrentTime, activeFrag);
              }
              this.lastCurrentTime = media.currentTime;
            }
            onFragLoadEmergencyAborted() {
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
              // if loadedmetadata is not set, it means that we are emergency switch down on first frag
              // in that case, reset startFragRequested flag
              if (!this.loadedmetadata) {
                this.startFragRequested = false;
                this.nextLoadPosition = this.startPosition;
              }
              this.tickImmediate();
            }
            onBufferFlushed(event, {
              type
            }) {
              if (type !== _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO || this.audioOnly && !this.altAudio) {
                const mediaBuffer = (type === _loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;
                this.afterBufferFlushed(mediaBuffer, type, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
              }
            }
            onLevelsUpdated(event, data) {
              this.levels = data.levels;
            }
            swapAudioCodec() {
              this.audioCodecSwap = !this.audioCodecSwap;
            }

            /**
             * Seeks to the set startPosition if not equal to the mediaElement's current time.
             */
            seekToStartPos() {
              const {
                media
              } = this;
              if (!media) {
                return;
              }
              const currentTime = media.currentTime;
              let startPosition = this.startPosition;
              // only adjust currentTime if different from startPosition or if startPosition not buffered
              // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered
              if (startPosition >= 0 && currentTime < startPosition) {
                if (media.seeking) {
                  this.log(`could not seek to ${startPosition}, already seeking at ${currentTime}`);
                  return;
                }
                const buffered = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__.BufferHelper.getBuffered(media);
                const bufferStart = buffered.length ? buffered.start(0) : 0;
                const delta = bufferStart - startPosition;
                if (delta > 0 && (delta < this.config.maxBufferHole || delta < this.config.maxFragLookUpTolerance)) {
                  this.log(`adjusting start position by ${delta} to match buffer start`);
                  startPosition += delta;
                  this.startPosition = startPosition;
                }
                this.log(`seek to target start position ${startPosition} from current time ${currentTime}`);
                media.currentTime = startPosition;
              }
            }
            _getAudioCodec(currentLevel) {
              let audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;
              if (this.audioCodecSwap && audioCodec) {
                this.log('Swapping audio codec');
                if (audioCodec.indexOf('mp4a.40.5') !== -1) {
                  audioCodec = 'mp4a.40.2';
                } else {
                  audioCodec = 'mp4a.40.5';
                }
              }
              return audioCodec;
            }
            _loadBitrateTestFrag(frag, levelDetails) {
              frag.bitrateTest = true;
              this._doFragLoad(frag, levelDetails).then(data => {
                const {
                  hls
                } = this;
                if (!data || hls.nextLoadLevel || this.fragContextChanged(frag)) {
                  return;
                }
                this.fragLoadError = 0;
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
                this.startFragRequested = false;
                this.bitrateTest = false;
                const stats = frag.stats;
                // Bitrate tests fragments are neither parsed nor buffered
                stats.parsing.start = stats.parsing.end = stats.buffering.start = stats.buffering.end = self.performance.now();
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_LOADED, data);
                frag.bitrateTest = false;
              });
            }
            _handleTransmuxComplete(transmuxResult) {
              const id = 'main';
              const {
                hls
              } = this;
              const {
                remuxResult,
                chunkMeta
              } = transmuxResult;
              const context = this.getCurrentContext(chunkMeta);
              if (!context) {
                this.warn(`The loading context changed while buffering fragment ${chunkMeta.sn} of level ${chunkMeta.level}. This chunk will not be buffered.`);
                this.resetStartWhenNotLoaded(chunkMeta.level);
                return;
              }
              const {
                frag,
                part,
                level
              } = context;
              const {
                video,
                text,
                id3,
                initSegment
              } = remuxResult;
              const {
                details
              } = level;
              // The audio-stream-controller handles audio buffering if Hls.js is playing an alternate audio track
              const audio = this.altAudio ? undefined : remuxResult.audio;

              // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.
              // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.
              if (this.fragContextChanged(frag)) {
                return;
              }
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING;
              if (initSegment) {
                if (initSegment.tracks) {
                  this._bufferInitSegment(level, initSegment.tracks, frag, chunkMeta);
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_PARSING_INIT_SEGMENT, {
                    frag,
                    id,
                    tracks: initSegment.tracks
                  });
                }

                // This would be nice if Number.isFinite acted as a typeguard, but it doesn't. See: https://github.com/Microsoft/TypeScript/issues/10038
                const initPTS = initSegment.initPTS;
                const timescale = initSegment.timescale;
                if (Number.isFinite(initPTS)) {
                  this.initPTS[frag.cc] = initPTS;
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.INIT_PTS_FOUND, {
                    frag,
                    id,
                    initPTS,
                    timescale
                  });
                }
              }

              // Avoid buffering if backtracking this fragment
              if (video && remuxResult.independent !== false) {
                if (details) {
                  const {
                    startPTS,
                    endPTS,
                    startDTS,
                    endDTS
                  } = video;
                  if (part) {
                    part.elementaryStreams[video.type] = {
                      startPTS,
                      endPTS,
                      startDTS,
                      endDTS
                    };
                  } else {
                    if (video.firstKeyFrame && video.independent && chunkMeta.id === 1) {
                      this.couldBacktrack = true;
                    }
                    if (video.dropped && video.independent) {
                      // Backtrack if dropped frames create a gap after currentTime

                      const bufferInfo = this.getMainFwdBufferInfo();
                      const targetBufferTime = (bufferInfo ? bufferInfo.end : this.getLoadPosition()) + this.config.maxBufferHole;
                      const startTime = video.firstKeyFramePTS ? video.firstKeyFramePTS : startPTS;
                      if (targetBufferTime < startTime - this.config.maxBufferHole) {
                        this.backtrack(frag);
                        return;
                      }
                      // Set video stream start to fragment start so that truncated samples do not distort the timeline, and mark it partial
                      frag.setElementaryStreamInfo(video.type, frag.start, endPTS, frag.start, endDTS, true);
                    }
                  }
                  frag.setElementaryStreamInfo(video.type, startPTS, endPTS, startDTS, endDTS);
                  if (this.backtrackFragment) {
                    this.backtrackFragment = frag;
                  }
                  this.bufferFragmentData(video, frag, part, chunkMeta);
                }
              } else if (remuxResult.independent === false) {
                this.backtrack(frag);
                return;
              }
              if (audio) {
                const {
                  startPTS,
                  endPTS,
                  startDTS,
                  endDTS
                } = audio;
                if (part) {
                  part.elementaryStreams[_loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO] = {
                    startPTS,
                    endPTS,
                    startDTS,
                    endDTS
                  };
                }
                frag.setElementaryStreamInfo(_loader_fragment__WEBPACK_IMPORTED_MODULE_6__.ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);
                this.bufferFragmentData(audio, frag, part, chunkMeta);
              }
              if (details && id3?.samples?.length) {
                const emittedID3 = {
                  id,
                  frag,
                  details,
                  samples: id3.samples
                };
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_PARSING_METADATA, emittedID3);
              }
              if (details && text) {
                const emittedText = {
                  id,
                  frag,
                  details,
                  samples: text.samples
                };
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_PARSING_USERDATA, emittedText);
              }
            }
            _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {
              if (this.state !== _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.PARSING) {
                return;
              }
              this.audioOnly = !!tracks.audio && !tracks.video;

              // if audio track is expected to come from audio stream controller, discard any coming from main
              if (this.altAudio && !this.audioOnly) {
                delete tracks.audio;
              }
              // include levelCodec in audio and video tracks
              const {
                audio,
                video,
                audiovideo
              } = tracks;
              if (audio) {
                let audioCodec = currentLevel.audioCodec;
                const ua = navigator.userAgent.toLowerCase();
                if (this.audioCodecSwitch) {
                  if (audioCodec) {
                    if (audioCodec.indexOf('mp4a.40.5') !== -1) {
                      audioCodec = 'mp4a.40.2';
                    } else {
                      audioCodec = 'mp4a.40.5';
                    }
                  }
                  // In the case that AAC and HE-AAC audio codecs are signalled in manifest,
                  // force HE-AAC, as it seems that most browsers prefers it.
                  // don't force HE-AAC if mono stream, or in Firefox
                  if (audio.metadata.channelCount !== 1 && ua.indexOf('firefox') === -1) {
                    audioCodec = 'mp4a.40.5';
                  }
                }
                // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise
                if (ua.indexOf('android') !== -1 && audio.container !== 'audio/mpeg') {
                  // Exclude mpeg audio
                  audioCodec = 'mp4a.40.2';
                  this.log(`Android: force audio codec to ${audioCodec}`);
                }
                if (currentLevel.audioCodec && currentLevel.audioCodec !== audioCodec) {
                  this.log(`Swapping manifest audio codec "${currentLevel.audioCodec}" for "${audioCodec}"`);
                }
                audio.levelCodec = audioCodec;
                audio.id = 'main';
                this.log(`Init audio buffer, container:${audio.container}, codecs[selected/level/parsed]=[${audioCodec || ''}/${currentLevel.audioCodec || ''}/${audio.codec}]`);
              }
              if (video) {
                video.levelCodec = currentLevel.videoCodec;
                video.id = 'main';
                this.log(`Init video buffer, container:${video.container}, codecs[level/parsed]=[${currentLevel.videoCodec || ''}/${video.codec}]`);
              }
              if (audiovideo) {
                this.log(`Init audiovideo buffer, container:${audiovideo.container}, codecs[level/parsed]=[${currentLevel.attrs.CODECS || ''}/${audiovideo.codec}]`);
              }
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_CODECS, tracks);
              // loop through tracks that are going to be provided to bufferController
              Object.keys(tracks).forEach(trackName => {
                const track = tracks[trackName];
                const initSegment = track.initSegment;
                if (initSegment?.byteLength) {
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.BUFFER_APPENDING, {
                    type: trackName,
                    data: initSegment,
                    frag,
                    part: null,
                    chunkMeta,
                    parent: frag.type
                  });
                }
              });
              // trigger handler right now
              this.tick();
            }
            getMainFwdBufferInfo() {
              return this.getFwdBufferInfo(this.mediaBuffer ? this.mediaBuffer : this.media, _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.MAIN);
            }
            backtrack(frag) {
              this.couldBacktrack = true;
              // Causes findFragments to backtrack through fragments to find the keyframe
              this.backtrackFragment = frag;
              this.resetTransmuxer();
              this.flushBufferGap(frag);
              this.fragmentTracker.removeFragment(frag);
              this.fragPrevious = null;
              this.nextLoadPosition = frag.start;
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_0__.State.IDLE;
            }
            checkFragmentChanged() {
              const video = this.media;
              let fragPlayingCurrent = null;
              if (video && video.readyState > 1 && video.seeking === false) {
                const currentTime = video.currentTime;
                /* if video element is in seeked state, currentTime can only increase.
                  (assuming that playback rate is positive ...)
                  As sometimes currentTime jumps back to zero after a
                  media decode error, check this, to avoid seeking back to
                  wrong position after a media decode error
                */

                if (_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__.BufferHelper.isBuffered(video, currentTime)) {
                  fragPlayingCurrent = this.getAppendedFrag(currentTime);
                } else if (_utils_buffer_helper__WEBPACK_IMPORTED_MODULE_3__.BufferHelper.isBuffered(video, currentTime + 0.1)) {
                  /* ensure that FRAG_CHANGED event is triggered at startup,
                    when first video frame is displayed and playback is paused.
                    add a tolerance of 100ms, in case current position is not buffered,
                    check if current pos+100ms is buffered and use that buffer range
                    for FRAG_CHANGED event reporting */
                  fragPlayingCurrent = this.getAppendedFrag(currentTime + 0.1);
                }
                if (fragPlayingCurrent) {
                  this.backtrackFragment = null;
                  const fragPlaying = this.fragPlaying;
                  const fragCurrentLevel = fragPlayingCurrent.level;
                  if (!fragPlaying || fragPlayingCurrent.sn !== fragPlaying.sn || fragPlaying.level !== fragCurrentLevel || fragPlayingCurrent.urlId !== fragPlaying.urlId) {
                    this.fragPlaying = fragPlayingCurrent;
                    this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.FRAG_CHANGED, {
                      frag: fragPlayingCurrent
                    });
                    if (!fragPlaying || fragPlaying.level !== fragCurrentLevel) {
                      this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.LEVEL_SWITCHED, {
                        level: fragCurrentLevel
                      });
                    }
                  }
                }
              }
            }
            get nextLevel() {
              const frag = this.nextBufferedFrag;
              if (frag) {
                return frag.level;
              }
              return -1;
            }
            get currentFrag() {
              const media = this.media;
              if (media) {
                return this.fragPlaying || this.getAppendedFrag(media.currentTime);
              }
              return null;
            }
            get currentProgramDateTime() {
              const media = this.media;
              if (media) {
                const currentTime = media.currentTime;
                const frag = this.currentFrag;
                if (frag && Number.isFinite(currentTime) && Number.isFinite(frag.programDateTime)) {
                  const epocMs = frag.programDateTime + (currentTime - frag.start) * 1000;
                  return new Date(epocMs);
                }
              }
              return null;
            }
            get currentLevel() {
              const frag = this.currentFrag;
              if (frag) {
                return frag.level;
              }
              return -1;
            }
            get nextBufferedFrag() {
              const frag = this.currentFrag;
              if (frag) {
                return this.followingBufferedFrag(frag);
              }
              return null;
            }
            get forceStartLoad() {
              return this._forceStartLoad;
            }
          }

          /***/
        }),

/***/ "./src/controller/subtitle-stream-controller.ts":
/*!******************************************************!*\
  !*** ./src/controller/subtitle-stream-controller.ts ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "SubtitleStreamController": () => (/* binding */ SubtitleStreamController)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/buffer-helper */ "./src/utils/buffer-helper.ts");
/* harmony import */ var _fragment_finders__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fragment-finders */ "./src/controller/fragment-finders.ts");
/* harmony import */ var _utils_discontinuities__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/discontinuities */ "./src/utils/discontinuities.ts");
/* harmony import */ var _level_helper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./level-helper */ "./src/controller/level-helper.ts");
/* harmony import */ var _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fragment-tracker */ "./src/controller/fragment-tracker.ts");
/* harmony import */ var _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./base-stream-controller */ "./src/controller/base-stream-controller.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _types_level__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../types/level */ "./src/types/level.ts");









          const TICK_INTERVAL = 500; // how often to tick in ms

          class SubtitleStreamController extends _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__["default"] {
            levels = [];
            currentTrackId = -1;
            tracksBuffered = [];
            mainDetails = null;
            constructor(hls, fragmentTracker, keyLoader) {
              super(hls, fragmentTracker, keyLoader, '[subtitle-stream-controller]');
              this._registerListeners();
            }
            onHandlerDestroying() {
              this._unregisterListeners();
              this.mainDetails = null;
            }
            _registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, this.onError, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
            }
            _unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADED, this.onLevelLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, this.onError, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_BUFFERED, this.onFragBuffered, this);
            }
            startLoad(startPosition) {
              this.stopLoad();
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE;
              this.setInterval(TICK_INTERVAL);
              this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;
              this.tick();
            }
            onManifestLoading() {
              this.mainDetails = null;
              this.fragmentTracker.removeAllFragments();
            }
            onLevelLoaded(event, data) {
              this.mainDetails = data.details;
            }
            onSubtitleFragProcessed(event, data) {
              const {
                frag,
                success
              } = data;
              this.fragPrevious = frag;
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE;
              if (!success) {
                return;
              }
              const buffered = this.tracksBuffered[this.currentTrackId];
              if (!buffered) {
                return;
              }

              // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo
              // so we can re-use the logic used to detect how much has been buffered
              let timeRange;
              const fragStart = frag.start;
              for (let i = 0; i < buffered.length; i++) {
                if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {
                  timeRange = buffered[i];
                  break;
                }
              }
              const fragEnd = frag.start + frag.duration;
              if (timeRange) {
                timeRange.end = fragEnd;
              } else {
                timeRange = {
                  start: fragStart,
                  end: fragEnd
                };
                buffered.push(timeRange);
              }
              this.fragmentTracker.fragBuffered(frag);
            }
            onBufferFlushing(event, data) {
              const {
                startOffset,
                endOffset
              } = data;
              if (startOffset === 0 && endOffset !== Number.POSITIVE_INFINITY) {
                const {
                  currentTrackId,
                  levels
                } = this;
                if (!levels.length || !levels[currentTrackId] || !levels[currentTrackId].details) {
                  return;
                }
                const trackDetails = levels[currentTrackId].details;
                const targetDuration = trackDetails.targetduration;
                const endOffsetSubtitles = endOffset - targetDuration;
                if (endOffsetSubtitles <= 0) {
                  return;
                }
                data.endOffsetSubtitles = Math.max(0, endOffsetSubtitles);
                this.tracksBuffered.forEach(buffered => {
                  for (let i = 0; i < buffered.length;) {
                    if (buffered[i].end <= endOffsetSubtitles) {
                      buffered.shift();
                      continue;
                    } else if (buffered[i].start < endOffsetSubtitles) {
                      buffered[i].start = endOffsetSubtitles;
                    } else {
                      break;
                    }
                    i++;
                  }
                });
                this.fragmentTracker.removeFragmentsInRange(startOffset, endOffsetSubtitles, _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.SUBTITLE);
              }
            }
            onFragBuffered(event, data) {
              if (!this.loadedmetadata && data.frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.MAIN) {
                if (this.media?.buffered.length) {
                  this.loadedmetadata = true;
                }
              }
            }

            // If something goes wrong, proceed to next frag, if we were processing one.
            onError(event, data) {
              const frag = data.frag;
              // don't handle error not related to subtitle fragment
              if (!frag || frag.type !== _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.SUBTITLE) {
                return;
              }
              if (this.fragCurrent) {
                this.fragCurrent.abortRequests();
              }
              this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE;
            }

            // Got all new subtitle levels.
            onSubtitleTracksUpdated(event, {
              subtitleTracks
            }) {
              this.tracksBuffered = [];
              this.levels = subtitleTracks.map(mediaPlaylist => new _types_level__WEBPACK_IMPORTED_MODULE_8__.Level(mediaPlaylist));
              this.fragmentTracker.removeAllFragments();
              this.fragPrevious = null;
              this.levels.forEach(level => {
                this.tracksBuffered[level.id] = [];
              });
              this.mediaBuffer = null;
            }
            onSubtitleTrackSwitch(event, data) {
              this.currentTrackId = data.id;
              if (!this.levels.length || this.currentTrackId === -1) {
                this.clearInterval();
                return;
              }

              // Check if track has the necessary details to load fragments
              const currentTrack = this.levels[this.currentTrackId];
              if (currentTrack?.details) {
                this.mediaBuffer = this.mediaBufferTimeRanges;
              } else {
                this.mediaBuffer = null;
              }
              if (currentTrack) {
                this.setInterval(TICK_INTERVAL);
              }
            }

            // Got a new set of subtitle fragments.
            onSubtitleTrackLoaded(event, data) {
              const {
                details: newDetails,
                id: trackId
              } = data;
              const {
                currentTrackId,
                levels
              } = this;
              if (!levels.length) {
                return;
              }
              const track = levels[currentTrackId];
              if (trackId >= levels.length || trackId !== currentTrackId || !track) {
                return;
              }
              this.mediaBuffer = this.mediaBufferTimeRanges;
              let sliding = 0;
              if (newDetails.live || track.details?.live) {
                const mainDetails = this.mainDetails;
                if (newDetails.deltaUpdateFailed || !mainDetails) {
                  return;
                }
                const mainSlidingStartFragment = mainDetails.fragments[0];
                if (!track.details) {
                  if (newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {
                    (0, _utils_discontinuities__WEBPACK_IMPORTED_MODULE_3__.alignMediaPlaylistByPDT)(newDetails, mainDetails);
                    sliding = newDetails.fragments[0].start;
                  } else if (mainSlidingStartFragment) {
                    // line up live playlist with main so that fragments in range are loaded
                    sliding = mainSlidingStartFragment.start;
                    (0, _level_helper__WEBPACK_IMPORTED_MODULE_4__.addSliding)(newDetails, sliding);
                  }
                } else {
                  sliding = this.alignPlaylists(newDetails, track.details);
                  if (sliding === 0 && mainSlidingStartFragment) {
                    // realign with main when there is no overlap with last refresh
                    sliding = mainSlidingStartFragment.start;
                    (0, _level_helper__WEBPACK_IMPORTED_MODULE_4__.addSliding)(newDetails, sliding);
                  }
                }
              }
              track.details = newDetails;
              this.levelLastLoaded = trackId;
              if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {
                this.setStartPosition(track.details, sliding);
              }

              // trigger handler right now
              this.tick();

              // If playlist is misaligned because of bad PDT or drift, delete details to resync with main on reload
              if (newDetails.live && !this.fragCurrent && this.media && this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE) {
                const foundFrag = (0, _fragment_finders__WEBPACK_IMPORTED_MODULE_2__.findFragmentByPTS)(null, newDetails.fragments, this.media.currentTime, 0);
                if (!foundFrag) {
                  this.warn('Subtitle playlist not aligned with playback');
                  track.details = undefined;
                }
              }
            }
            _handleFragmentLoadComplete(fragLoadedData) {
              const {
                frag,
                payload
              } = fragLoadedData;
              const decryptData = frag.decryptdata;
              const hls = this.hls;
              if (this.fragContextChanged(frag)) {
                return;
              }
              // check to see if the payload needs to be decrypted
              if (payload && payload.byteLength > 0 && decryptData && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {
                const startTime = performance.now();
                // decrypt the subtitles
                this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).then(decryptedData => {
                  const endTime = performance.now();
                  hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_DECRYPTED, {
                    frag,
                    payload: decryptedData,
                    stats: {
                      tstart: startTime,
                      tdecrypt: endTime
                    }
                  });
                }).catch(err => {
                  this.warn(`${err.name}: ${err.message}`);
                  this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE;
                });
              }
            }
            doTick() {
              if (!this.media) {
                this.state = _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE;
                return;
              }
              if (this.state === _base_stream_controller__WEBPACK_IMPORTED_MODULE_6__.State.IDLE) {
                const {
                  currentTrackId,
                  levels
                } = this;
                if (!levels.length || !levels[currentTrackId] || !levels[currentTrackId].details) {
                  return;
                }

                // Expand range of subs loaded by one target-duration in either direction to make up for misaligned playlists
                const trackDetails = levels[currentTrackId].details;
                const targetDuration = trackDetails.targetduration;
                const {
                  config
                } = this;
                const currentTime = this.getLoadPosition();
                const bufferedInfo = _utils_buffer_helper__WEBPACK_IMPORTED_MODULE_1__.BufferHelper.bufferedInfo(this.tracksBuffered[this.currentTrackId] || [], currentTime - targetDuration, config.maxBufferHole);
                const {
                  end: targetBufferTime,
                  len: bufferLen
                } = bufferedInfo;
                const mainBufferInfo = this.getFwdBufferInfo(this.media, _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.MAIN);
                const maxBufLen = this.getMaxBufferLength(mainBufferInfo?.len) + targetDuration;
                if (bufferLen > maxBufLen) {
                  return;
                }
                console.assert(trackDetails, 'Subtitle track details are defined on idle subtitle stream controller tick');
                const fragments = trackDetails.fragments;
                const fragLen = fragments.length;
                const end = trackDetails.edge;
                let foundFrag = null;
                const fragPrevious = this.fragPrevious;
                if (targetBufferTime < end) {
                  const {
                    maxFragLookUpTolerance
                  } = config;
                  foundFrag = (0, _fragment_finders__WEBPACK_IMPORTED_MODULE_2__.findFragmentByPTS)(fragPrevious, fragments, Math.max(fragments[0].start, targetBufferTime), maxFragLookUpTolerance);
                  if (!foundFrag && fragPrevious && fragPrevious.start < fragments[0].start) {
                    foundFrag = fragments[0];
                  }
                } else {
                  foundFrag = fragments[fragLen - 1];
                }
                if (!foundFrag) {
                  return;
                }
                foundFrag = this.mapToInitFragWhenRequired(foundFrag);
                if (this.fragmentTracker.getState(foundFrag) === _fragment_tracker__WEBPACK_IMPORTED_MODULE_5__.FragmentState.NOT_LOADED) {
                  // only load if fragment is not loaded
                  this.loadFragment(foundFrag, trackDetails, targetBufferTime);
                }
              }
            }
            getMaxBufferLength(mainBufferLength) {
              const maxConfigBuffer = super.getMaxBufferLength();
              if (!mainBufferLength) {
                return maxConfigBuffer;
              }
              return Math.max(maxConfigBuffer, mainBufferLength);
            }
            loadFragment(frag, levelDetails, targetBufferTime) {
              this.fragCurrent = frag;
              if (frag.sn === 'initSegment') {
                this._loadInitSegment(frag, levelDetails);
              } else {
                this.startFragRequested = true;
                super.loadFragment(frag, levelDetails, targetBufferTime);
              }
            }
            get mediaBufferTimeRanges() {
              return new BufferableInstance(this.tracksBuffered[this.currentTrackId] || []);
            }
          }
          class BufferableInstance {
            constructor(timeranges) {
              const getRange = (name, index, length) => {
                index = index >>> 0;
                if (index > length - 1) {
                  throw new DOMException(`Failed to execute '${name}' on 'TimeRanges': The index provided (${index}) is greater than the maximum bound (${length})`);
                }
                return timeranges[index][name];
              };
              this.buffered = {
                get length() {
                  return timeranges.length;
                },
                end(index) {
                  return getRange('end', index, timeranges.length);
                },
                start(index) {
                  return getRange('start', index, timeranges.length);
                }
              };
            }
          }

          /***/
        }),

/***/ "./src/controller/subtitle-track-controller.ts":
/*!*****************************************************!*\
  !*** ./src/controller/subtitle-track-controller.ts ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/texttrack-utils */ "./src/utils/texttrack-utils.ts");
/* harmony import */ var _base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./base-playlist-controller */ "./src/controller/base-playlist-controller.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");




          class SubtitleTrackController extends _base_playlist_controller__WEBPACK_IMPORTED_MODULE_2__["default"] {
            media = null;
            tracks = [];
            groupId = null;
            tracksInGroup = [];
            trackId = -1;
            selectDefaultTrack = true;
            queuedDefaultTrack = -1;
            trackChangeListener = () => this.onTextTracksChanged();
            asyncPollTrackChange = () => this.pollTrackChange(0);
            useTextTrackPolling = false;
            subtitlePollingInterval = -1;
            _subtitleDisplay = true;
            constructor(hls) {
              super(hls, '[subtitle-track-controller]');
              this.registerListeners();
            }
            destroy() {
              this.unregisterListeners();
              this.tracks.length = 0;
              this.tracksInGroup.length = 0;
              this.trackChangeListener = this.asyncPollTrackChange = null;
              super.destroy();
            }
            get subtitleDisplay() {
              return this._subtitleDisplay;
            }
            set subtitleDisplay(value) {
              this._subtitleDisplay = value;
              if (this.trackId > -1) {
                this.toggleTrackModes(this.trackId);
              }
            }
            registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, this.onError, this);
            }
            unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHED, this.onMediaAttached, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_PARSED, this.onManifestParsed, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_SWITCHING, this.onLevelSwitching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, this.onError, this);
            }

            // Listen for subtitle track change, then extract the current track ID.
            onMediaAttached(event, data) {
              this.media = data.media;
              if (!this.media) {
                return;
              }
              if (this.queuedDefaultTrack > -1) {
                this.subtitleTrack = this.queuedDefaultTrack;
                this.queuedDefaultTrack = -1;
              }
              this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);
              if (this.useTextTrackPolling) {
                this.pollTrackChange(500);
              } else {
                this.media.textTracks.addEventListener('change', this.asyncPollTrackChange);
              }
            }
            pollTrackChange(timeout) {
              self.clearInterval(this.subtitlePollingInterval);
              this.subtitlePollingInterval = self.setInterval(this.trackChangeListener, timeout);
            }
            onMediaDetaching() {
              if (!this.media) {
                return;
              }
              self.clearInterval(this.subtitlePollingInterval);
              if (!this.useTextTrackPolling) {
                this.media.textTracks.removeEventListener('change', this.asyncPollTrackChange);
              }
              if (this.trackId > -1) {
                this.queuedDefaultTrack = this.trackId;
              }
              const textTracks = filterSubtitleTracks(this.media.textTracks);
              // Clear loaded cues on media detachment from tracks
              textTracks.forEach(track => {
                (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_1__.clearCurrentCues)(track);
              });
              // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.
              this.subtitleTrack = -1;
              this.media = null;
            }
            onManifestLoading() {
              this.tracks = [];
              this.groupId = null;
              this.tracksInGroup = [];
              this.trackId = -1;
              this.selectDefaultTrack = true;
            }

            // Fired whenever a new manifest is loaded.
            onManifestParsed(event, data) {
              this.tracks = data.subtitleTracks;
            }
            onSubtitleTrackLoaded(event, data) {
              const {
                id,
                details
              } = data;
              const {
                trackId
              } = this;
              const currentTrack = this.tracksInGroup[trackId];
              if (!currentTrack) {
                this.warn(`Invalid subtitle track id ${id}`);
                return;
              }
              const curDetails = currentTrack.details;
              currentTrack.details = data.details;
              this.log(`subtitle track ${id} loaded [${details.startSN}-${details.endSN}]`);
              if (id === this.trackId) {
                this.retryCount = 0;
                this.playlistLoaded(id, data, curDetails);
              }
            }
            onLevelLoading(event, data) {
              this.switchLevel(data.level);
            }
            onLevelSwitching(event, data) {
              this.switchLevel(data.level);
            }
            switchLevel(levelIndex) {
              const levelInfo = this.hls.levels[levelIndex];
              if (!levelInfo?.textGroupIds) {
                return;
              }
              const textGroupId = levelInfo.textGroupIds[levelInfo.urlId];
              if (this.groupId !== textGroupId) {
                const lastTrack = this.tracksInGroup ? this.tracksInGroup[this.trackId] : undefined;
                const subtitleTracks = this.tracks.filter(track => !textGroupId || track.groupId === textGroupId);
                this.tracksInGroup = subtitleTracks;
                const initialTrackId = this.findTrackId(lastTrack?.name) || this.findTrackId();
                this.groupId = textGroupId;
                const subtitleTracksUpdated = {
                  subtitleTracks
                };
                this.log(`Updating subtitle tracks, ${subtitleTracks.length} track(s) found in "${textGroupId}" group-id`);
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_UPDATED, subtitleTracksUpdated);
                if (initialTrackId !== -1) {
                  this.setSubtitleTrack(initialTrackId, lastTrack);
                }
              }
            }
            findTrackId(name) {
              const textTracks = this.tracksInGroup;
              for (let i = 0; i < textTracks.length; i++) {
                const track = textTracks[i];
                if (!this.selectDefaultTrack || track.default) {
                  if (!name || name === track.name) {
                    return track.id;
                  }
                }
              }
              return -1;
            }
            onError(event, data) {
              super.onError(event, data);
              if (data.fatal || !data.context) {
                return;
              }
              if (data.context.type === _types_loader__WEBPACK_IMPORTED_MODULE_3__.PlaylistContextType.SUBTITLE_TRACK && data.context.id === this.trackId && data.context.groupId === this.groupId) {
                this.retryLoadingOrFail(data);
              }
            }

            /** get alternate subtitle tracks list from playlist **/
            get subtitleTracks() {
              return this.tracksInGroup;
            }

            /** get/set index of the selected subtitle track (based on index in subtitle track lists) **/
            get subtitleTrack() {
              return this.trackId;
            }
            set subtitleTrack(newId) {
              this.selectDefaultTrack = false;
              const lastTrack = this.tracksInGroup ? this.tracksInGroup[this.trackId] : undefined;
              this.setSubtitleTrack(newId, lastTrack);
            }
            loadPlaylist(hlsUrlParameters) {
              super.loadPlaylist();
              const currentTrack = this.tracksInGroup[this.trackId];
              if (this.shouldLoadTrack(currentTrack)) {
                const id = currentTrack.id;
                const groupId = currentTrack.groupId;
                let url = currentTrack.url;
                if (hlsUrlParameters) {
                  try {
                    url = hlsUrlParameters.addDirectives(url);
                  } catch (error) {
                    this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);
                  }
                }
                this.log(`Loading subtitle playlist for id ${id}`);
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADING, {
                  url,
                  id,
                  groupId,
                  deliveryDirectives: hlsUrlParameters || null
                });
              }
            }

            /**
             * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.
             * This operates on the DOM textTracks.
             * A value of -1 will disable all subtitle tracks.
             */
            toggleTrackModes(newId) {
              const {
                media,
                trackId
              } = this;
              if (!media) {
                return;
              }
              const textTracks = filterSubtitleTracks(media.textTracks);
              const groupTracks = textTracks.filter(track => track.groupId === this.groupId);
              if (newId === -1) {
                [].slice.call(textTracks).forEach(track => {
                  track.mode = 'disabled';
                });
              } else {
                const oldTrack = groupTracks[trackId];
                if (oldTrack) {
                  oldTrack.mode = 'disabled';
                }
              }
              const nextTrack = groupTracks[newId];
              if (nextTrack) {
                nextTrack.mode = this.subtitleDisplay ? 'showing' : 'hidden';
              }
            }

            /**
             * This method is responsible for validating the subtitle index and periodically reloading if live.
             * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.
             */
            setSubtitleTrack(newId, lastTrack) {
              const tracks = this.tracksInGroup;

              // setting this.subtitleTrack will trigger internal logic
              // if media has not been attached yet, it will fail
              // we keep a reference to the default track id
              // and we'll set subtitleTrack when onMediaAttached is triggered
              if (!this.media) {
                this.queuedDefaultTrack = newId;
                return;
              }
              if (this.trackId !== newId) {
                this.toggleTrackModes(newId);
              }

              // exit if track id as already set or invalid
              if (this.trackId === newId && (newId === -1 || tracks[newId]?.details) || newId < -1 || newId >= tracks.length) {
                return;
              }

              // stopping live reloading timer if any
              this.clearTimer();
              const track = tracks[newId];
              this.log(`Switching to subtitle track ${newId}`);
              this.trackId = newId;
              if (track) {
                const {
                  id,
                  groupId = '',
                  name,
                  type,
                  url
                } = track;
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_SWITCH, {
                  id,
                  groupId,
                  name,
                  type,
                  url
                });
                const hlsUrlParameters = this.switchParams(track.url, lastTrack?.details);
                this.loadPlaylist(hlsUrlParameters);
              } else {
                // switch to -1
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_SWITCH, {
                  id: newId
                });
              }
            }
            onTextTracksChanged() {
              if (!this.useTextTrackPolling) {
                self.clearInterval(this.subtitlePollingInterval);
              }
              // Media is undefined when switching streams via loadSource()
              if (!this.media || !this.hls.config.renderTextTracksNatively) {
                return;
              }
              let trackId = -1;
              const tracks = filterSubtitleTracks(this.media.textTracks);
              for (let id = 0; id < tracks.length; id++) {
                if (tracks[id].mode === 'hidden') {
                  // Do not break in case there is a following track with showing.
                  trackId = id;
                } else if (tracks[id].mode === 'showing') {
                  trackId = id;
                  break;
                }
              }

              // Setting current subtitleTrack will invoke code.
              if (this.subtitleTrack !== trackId) {
                this.subtitleTrack = trackId;
              }
            }
          }
          function filterSubtitleTracks(textTrackList) {
            const tracks = [];
            for (let i = 0; i < textTrackList.length; i++) {
              const track = textTrackList[i];
              // Edge adds a track without a label; we don't want to use it
              if (track.kind === 'subtitles' && track.label) {
                tracks.push(textTrackList[i]);
              }
            }
            return tracks;
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SubtitleTrackController);

          /***/
        }),

/***/ "./src/controller/timeline-controller.ts":
/*!***********************************************!*\
  !*** ./src/controller/timeline-controller.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "TimelineController": () => (/* binding */ TimelineController)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_cea_608_parser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/cea-608-parser */ "./src/utils/cea-608-parser.ts");
/* harmony import */ var _utils_output_filter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/output-filter */ "./src/utils/output-filter.ts");
/* harmony import */ var _utils_webvtt_parser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/webvtt-parser */ "./src/utils/webvtt-parser.ts");
/* harmony import */ var _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/texttrack-utils */ "./src/utils/texttrack-utils.ts");
/* harmony import */ var _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/imsc1-ttml-parser */ "./src/utils/imsc1-ttml-parser.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");









          class TimelineController {
            media = null;
            enabled = true;
            textTracks = [];
            tracks = [];
            initPTS = [];
            timescale = [];
            unparsedVttFrags = [];
            captionsTracks = {};
            nonNativeCaptionsTracks = {};
            lastSn = -1;
            lastPartIndex = -1;
            prevCC = -1;
            vttCCs = newVTTCCs();
            constructor(hls) {
              this.hls = hls;
              this.config = hls.config;
              this.Cues = hls.config.cueHandler;
              this.captionsProperties = {
                textTrack1: {
                  label: this.config.captionsTextTrack1Label,
                  languageCode: this.config.captionsTextTrack1LanguageCode
                },
                textTrack2: {
                  label: this.config.captionsTextTrack2Label,
                  languageCode: this.config.captionsTextTrack2LanguageCode
                },
                textTrack3: {
                  label: this.config.captionsTextTrack3Label,
                  languageCode: this.config.captionsTextTrack3LanguageCode
                },
                textTrack4: {
                  label: this.config.captionsTextTrack4Label,
                  languageCode: this.config.captionsTextTrack4LanguageCode
                }
              };
              if (this.config.enableCEA708Captions) {
                const channel1 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_2__["default"](this, 'textTrack1');
                const channel2 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_2__["default"](this, 'textTrack2');
                const channel3 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_2__["default"](this, 'textTrack3');
                const channel4 = new _utils_output_filter__WEBPACK_IMPORTED_MODULE_2__["default"](this, 'textTrack4');
                this.cea608Parser1 = new _utils_cea_608_parser__WEBPACK_IMPORTED_MODULE_1__["default"](1, channel1, channel2);
                this.cea608Parser2 = new _utils_cea_608_parser__WEBPACK_IMPORTED_MODULE_1__["default"](3, channel3, channel4);
              }
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADED, this.onManifestLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADING, this.onFragLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADED, this.onFragLoaded, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_DECRYPTED, this.onFragDecrypted, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
            }
            destroy() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_ATTACHING, this.onMediaAttaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MEDIA_DETACHING, this.onMediaDetaching, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADED, this.onManifestLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADING, this.onFragLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADED, this.onFragLoaded, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_DECRYPTED, this.onFragDecrypted, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.INIT_PTS_FOUND, this.onInitPtsFound, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.BUFFER_FLUSHING, this.onBufferFlushing, this);
              // @ts-ignore
              this.hls = this.config = this.cea608Parser1 = this.cea608Parser2 = null;
            }
            addCues(trackName, startTime, endTime, screen, cueRanges) {
              // skip cues which overlap more than 50% with previously parsed time ranges
              let merged = false;
              for (let i = cueRanges.length; i--;) {
                const cueRange = cueRanges[i];
                const overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);
                if (overlap >= 0) {
                  cueRange[0] = Math.min(cueRange[0], startTime);
                  cueRange[1] = Math.max(cueRange[1], endTime);
                  merged = true;
                  if (overlap / (endTime - startTime) > 0.5) {
                    return;
                  }
                }
              }
              if (!merged) {
                cueRanges.push([startTime, endTime]);
              }
              if (this.config.renderTextTracksNatively) {
                const track = this.captionsTracks[trackName];
                this.Cues.newCue(track, startTime, endTime, screen);
              } else {
                const cues = this.Cues.newCue(null, startTime, endTime, screen);
                this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.CUES_PARSED, {
                  type: 'captions',
                  cues,
                  track: trackName
                });
              }
            }

            // Triggered when an initial PTS is found; used for synchronisation of WebVTT.
            onInitPtsFound(event, {
              frag,
              id,
              initPTS,
              timescale
            }) {
              const {
                unparsedVttFrags
              } = this;
              if (id === 'main') {
                this.initPTS[frag.cc] = initPTS;
                this.timescale[frag.cc] = timescale;
              }

              // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.
              // Parse any unparsed fragments upon receiving the initial PTS.
              if (unparsedVttFrags.length) {
                this.unparsedVttFrags = [];
                unparsedVttFrags.forEach(frag => {
                  this.onFragLoaded(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADED, frag);
                });
              }
            }
            getExistingTrack(trackName) {
              const {
                media
              } = this;
              if (media) {
                for (let i = 0; i < media.textTracks.length; i++) {
                  const textTrack = media.textTracks[i];
                  if (textTrack[trackName]) {
                    return textTrack;
                  }
                }
              }
              return null;
            }
            createCaptionsTrack(trackName) {
              if (this.config.renderTextTracksNatively) {
                this.createNativeTrack(trackName);
              } else {
                this.createNonNativeTrack(trackName);
              }
            }
            createNativeTrack(trackName) {
              if (this.captionsTracks[trackName]) {
                return;
              }
              const {
                captionsProperties,
                captionsTracks,
                media
              } = this;
              const {
                label,
                languageCode
              } = captionsProperties[trackName];
              // Enable reuse of existing text track.
              const existingTrack = this.getExistingTrack(trackName);
              if (!existingTrack) {
                const textTrack = this.createTextTrack('captions', label, languageCode);
                if (textTrack) {
                  // Set a special property on the track so we know it's managed by Hls.js
                  textTrack[trackName] = true;
                  captionsTracks[trackName] = textTrack;
                }
              } else {
                captionsTracks[trackName] = existingTrack;
                (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.clearCurrentCues)(captionsTracks[trackName]);
                (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.sendAddTrackEvent)(captionsTracks[trackName], media);
              }
            }
            createNonNativeTrack(trackName) {
              if (this.nonNativeCaptionsTracks[trackName]) {
                return;
              }
              // Create a list of a single track for the provider to consume
              const trackProperties = this.captionsProperties[trackName];
              if (!trackProperties) {
                return;
              }
              const label = trackProperties.label;
              const track = {
                _id: trackName,
                label,
                kind: 'captions',
                default: trackProperties.media ? !!trackProperties.media.default : false,
                closedCaptions: trackProperties.media
              };
              this.nonNativeCaptionsTracks[trackName] = track;
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.NON_NATIVE_TEXT_TRACKS_FOUND, {
                tracks: [track]
              });
            }
            createTextTrack(kind, label, lang) {
              const media = this.media;
              if (!media) {
                return;
              }
              return media.addTextTrack(kind, label, lang);
            }
            onMediaAttaching(event, data) {
              this.media = data.media;
              this._cleanTracks();
            }
            onMediaDetaching() {
              const {
                captionsTracks
              } = this;
              Object.keys(captionsTracks).forEach(trackName => {
                (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.clearCurrentCues)(captionsTracks[trackName]);
                delete captionsTracks[trackName];
              });
              this.nonNativeCaptionsTracks = {};
            }
            onManifestLoading() {
              this.lastSn = -1; // Detect discontinuity in fragment parsing
              this.lastPartIndex = -1;
              this.prevCC = -1;
              this.vttCCs = newVTTCCs(); // Detect discontinuity in subtitle manifests
              this._cleanTracks();
              this.tracks = [];
              this.captionsTracks = {};
              this.nonNativeCaptionsTracks = {};
              this.textTracks = [];
              this.unparsedVttFrags = this.unparsedVttFrags || [];
              this.initPTS = [];
              this.timescale = [];
              if (this.cea608Parser1 && this.cea608Parser2) {
                this.cea608Parser1.reset();
                this.cea608Parser2.reset();
              }
            }
            _cleanTracks() {
              // clear outdated subtitles
              const {
                media
              } = this;
              if (!media) {
                return;
              }
              const textTracks = media.textTracks;
              if (textTracks) {
                for (let i = 0; i < textTracks.length; i++) {
                  (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.clearCurrentCues)(textTracks[i]);
                }
              }
            }
            onSubtitleTracksUpdated(event, data) {
              this.textTracks = [];
              const tracks = data.subtitleTracks || [];
              const hasIMSC1 = tracks.some(track => track.textCodec === _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_5__.IMSC1_CODEC);
              if (this.config.enableWebVTT || hasIMSC1 && this.config.enableIMSC1) {
                const sameTracks = this.tracks && tracks && this.tracks.length === tracks.length;
                this.tracks = tracks || [];
                if (this.config.renderTextTracksNatively) {
                  const inUseTracks = this.media ? this.media.textTracks : [];
                  this.tracks.forEach((track, index) => {
                    let textTrack;
                    if (index < inUseTracks.length) {
                      let inUseTrack = null;
                      for (let i = 0; i < inUseTracks.length; i++) {
                        if (canReuseVttTextTrack(inUseTracks[i], track)) {
                          inUseTrack = inUseTracks[i];
                          break;
                        }
                      }

                      // Reuse tracks with the same label, but do not reuse 608/708 tracks
                      if (inUseTrack) {
                        textTrack = inUseTrack;
                      }
                    }
                    if (textTrack) {
                      (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.clearCurrentCues)(textTrack);
                    } else {
                      const textTrackKind = this._captionsOrSubtitlesFromCharacteristics(track);
                      textTrack = this.createTextTrack(textTrackKind, track.name, track.lang);
                      if (textTrack) {
                        textTrack.mode = 'disabled';
                      }
                    }
                    if (textTrack) {
                      textTrack.groupId = track.groupId;
                      this.textTracks.push(textTrack);
                    }
                  });
                } else if (!sameTracks && this.tracks && this.tracks.length) {
                  // Create a list of tracks for the provider to consume
                  const tracksList = this.tracks.map(track => {
                    return {
                      label: track.name,
                      kind: track.type.toLowerCase(),
                      default: track.default,
                      subtitleTrack: track
                    };
                  });
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.NON_NATIVE_TEXT_TRACKS_FOUND, {
                    tracks: tracksList
                  });
                }
              }
            }
            _captionsOrSubtitlesFromCharacteristics(track) {
              if (track.attrs?.CHARACTERISTICS) {
                const transcribesSpokenDialog = /transcribes-spoken-dialog/gi.test(track.attrs.CHARACTERISTICS);
                const describesMusicAndSound = /describes-music-and-sound/gi.test(track.attrs.CHARACTERISTICS);
                if (transcribesSpokenDialog && describesMusicAndSound) {
                  return 'captions';
                }
              }
              return 'subtitles';
            }
            onManifestLoaded(event, data) {
              if (this.config.enableCEA708Captions && data.captions) {
                data.captions.forEach(captionsTrack => {
                  const instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);
                  if (!instreamIdMatch) {
                    return;
                  }
                  const trackName = `textTrack${instreamIdMatch[1]}`;
                  const trackProperties = this.captionsProperties[trackName];
                  if (!trackProperties) {
                    return;
                  }
                  trackProperties.label = captionsTrack.name;
                  if (captionsTrack.lang) {
                    // optional attribute
                    trackProperties.languageCode = captionsTrack.lang;
                  }
                  trackProperties.media = captionsTrack;
                });
              }
            }
            closedCaptionsForLevel(frag) {
              const level = this.hls.levels[frag.level];
              return level?.attrs['CLOSED-CAPTIONS'];
            }
            onFragLoading(event, data) {
              const {
                cea608Parser1,
                cea608Parser2,
                lastSn,
                lastPartIndex
              } = this;
              if (!this.enabled || !(cea608Parser1 && cea608Parser2)) {
                return;
              }
              // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack
              if (data.frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.MAIN) {
                const sn = data.frag.sn;
                const partIndex = data?.part?.index ?? -1;
                if (!(sn === lastSn + 1 || sn === lastSn && partIndex === lastPartIndex + 1)) {
                  cea608Parser1.reset();
                  cea608Parser2.reset();
                }
                this.lastSn = sn;
                this.lastPartIndex = partIndex;
              }
            }
            onFragLoaded(event, data) {
              const {
                frag,
                payload
              } = data;
              const {
                initPTS,
                unparsedVttFrags
              } = this;
              if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.SUBTITLE) {
                // If fragment is subtitle type, parse as WebVTT.
                if (payload.byteLength) {
                  // We need an initial synchronisation PTS. Store fragments as long as none has arrived.
                  if (!Number.isFinite(initPTS[frag.cc])) {
                    unparsedVttFrags.push(data);
                    if (initPTS.length) {
                      // finish unsuccessfully, otherwise the subtitle-stream-controller could be blocked from loading new frags.
                      this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, {
                        success: false,
                        frag,
                        error: new Error('Missing initial subtitle PTS')
                      });
                    }
                    return;
                  }
                  const decryptData = frag.decryptdata;
                  // fragment after decryption has a stats object
                  const decrypted = ('stats' in data);
                  // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.
                  if (decryptData == null || !decryptData.encrypted || decrypted) {
                    const trackPlaylistMedia = this.tracks[frag.level];
                    const vttCCs = this.vttCCs;
                    if (!vttCCs[frag.cc]) {
                      vttCCs[frag.cc] = {
                        start: frag.start,
                        prevCC: this.prevCC,
                        new: true
                      };
                      this.prevCC = frag.cc;
                    }
                    if (trackPlaylistMedia && trackPlaylistMedia.textCodec === _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_5__.IMSC1_CODEC) {
                      this._parseIMSC1(frag, payload);
                    } else {
                      this._parseVTTs(frag, payload, vttCCs);
                    }
                  }
                } else {
                  // In case there is no payload, finish unsuccessfully.
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, {
                    success: false,
                    frag,
                    error: new Error('Empty subtitle payload')
                  });
                }
              }
            }
            _parseIMSC1(frag, payload) {
              const hls = this.hls;
              (0, _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_5__.parseIMSC1)(payload, this.initPTS[frag.cc], this.timescale[frag.cc], cues => {
                this._appendCues(cues, frag.level);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, {
                  success: true,
                  frag: frag
                });
              }, error => {
                _utils_logger__WEBPACK_IMPORTED_MODULE_8__.logger.log(`Failed to parse IMSC1: ${error}`);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, {
                  success: false,
                  frag: frag,
                  error
                });
              });
            }
            _parseVTTs(frag, payload, vttCCs) {
              const hls = this.hls;
              // Parse the WebVTT file contents.
              const payloadWebVTT = frag.initSegment?.data ? (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_6__.appendUint8Array)(frag.initSegment.data, new Uint8Array(payload)) : payload;
              (0, _utils_webvtt_parser__WEBPACK_IMPORTED_MODULE_3__.parseWebVTT)(payloadWebVTT, this.initPTS[frag.cc], this.timescale[frag.cc], vttCCs, frag.cc, frag.start, cues => {
                this._appendCues(cues, frag.level);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, {
                  success: true,
                  frag: frag
                });
              }, error => {
                this._fallbackToIMSC1(frag, payload);
                // Something went wrong while parsing. Trigger event with success false.
                _utils_logger__WEBPACK_IMPORTED_MODULE_8__.logger.log(`Failed to parse VTT cue: ${error}`);
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_FRAG_PROCESSED, {
                  success: false,
                  frag: frag,
                  error
                });
              });
            }
            _fallbackToIMSC1(frag, payload) {
              // If textCodec is unknown, try parsing as IMSC1. Set textCodec based on the result
              const trackPlaylistMedia = this.tracks[frag.level];
              if (!trackPlaylistMedia.textCodec) {
                (0, _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_5__.parseIMSC1)(payload, this.initPTS[frag.cc], this.timescale[frag.cc], () => {
                  trackPlaylistMedia.textCodec = _utils_imsc1_ttml_parser__WEBPACK_IMPORTED_MODULE_5__.IMSC1_CODEC;
                  this._parseIMSC1(frag, payload);
                }, () => {
                  trackPlaylistMedia.textCodec = 'wvtt';
                });
              }
            }
            _appendCues(cues, fragLevel) {
              const hls = this.hls;
              if (this.config.renderTextTracksNatively) {
                const textTrack = this.textTracks[fragLevel];
                // WebVTTParser.parse is an async method and if the currently selected text track mode is set to "disabled"
                // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null
                // and trying to access getCueById method of cues will throw an exception
                // Because we check if the mode is disabled, we can force check `cues` below. They can't be null.
                if (!textTrack || textTrack.mode === 'disabled') {
                  return;
                }
                cues.forEach(cue => (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.addCueToTrack)(textTrack, cue));
              } else {
                const currentTrack = this.tracks[fragLevel];
                if (!currentTrack) {
                  return;
                }
                const track = currentTrack.default ? 'default' : 'subtitles' + fragLevel;
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.CUES_PARSED, {
                  type: 'subtitles',
                  cues,
                  track
                });
              }
            }
            onFragDecrypted(event, data) {
              const {
                frag
              } = data;
              if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.SUBTITLE) {
                if (!Number.isFinite(this.initPTS[frag.cc])) {
                  this.unparsedVttFrags.push(data);
                  return;
                }
                this.onFragLoaded(_events__WEBPACK_IMPORTED_MODULE_0__.Events.FRAG_LOADED, data);
              }
            }
            onSubtitleTracksCleared() {
              this.tracks = [];
              this.captionsTracks = {};
            }
            onFragParsingUserdata(event, data) {
              const {
                cea608Parser1,
                cea608Parser2
              } = this;
              if (!this.enabled || !(cea608Parser1 && cea608Parser2)) {
                return;
              }
              const {
                frag,
                samples
              } = data;
              if (frag.type === _types_loader__WEBPACK_IMPORTED_MODULE_7__.PlaylistLevelType.MAIN && this.closedCaptionsForLevel(frag) === 'NONE') {
                return;
              }
              // If the event contains captions (found in the bytes property), push all bytes into the parser immediately
              // It will create the proper timestamps based on the PTS value
              for (let i = 0; i < samples.length; i++) {
                const ccBytes = samples[i].bytes;
                if (ccBytes) {
                  const ccdatas = this.extractCea608Data(ccBytes);
                  cea608Parser1.addData(samples[i].pts, ccdatas[0]);
                  cea608Parser2.addData(samples[i].pts, ccdatas[1]);
                }
              }
            }
            onBufferFlushing(event, {
              startOffset,
              endOffset,
              endOffsetSubtitles,
              type
            }) {
              const {
                media
              } = this;
              if (!media || media.currentTime < endOffset) {
                return;
              }
              // Clear 608 caption cues from the captions TextTracks when the video back buffer is flushed
              // Forward cues are never removed because we can loose streamed 608 content from recent fragments
              if (!type || type === 'video') {
                const {
                  captionsTracks
                } = this;
                Object.keys(captionsTracks).forEach(trackName => (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.removeCuesInRange)(captionsTracks[trackName], startOffset, endOffset));
              }
              if (this.config.renderTextTracksNatively) {
                // Clear VTT/IMSC1 subtitle cues from the subtitle TextTracks when the back buffer is flushed
                if (startOffset === 0 && endOffsetSubtitles !== undefined) {
                  const {
                    textTracks
                  } = this;
                  Object.keys(textTracks).forEach(trackName => (0, _utils_texttrack_utils__WEBPACK_IMPORTED_MODULE_4__.removeCuesInRange)(textTracks[trackName], startOffset, endOffsetSubtitles));
                }
              }
            }
            extractCea608Data(byteArray) {
              const actualCCBytes = [[], []];
              const count = byteArray[0] & 0x1f;
              let position = 2;
              for (let j = 0; j < count; j++) {
                const tmpByte = byteArray[position++];
                const ccbyte1 = 0x7f & byteArray[position++];
                const ccbyte2 = 0x7f & byteArray[position++];
                if (ccbyte1 === 0 && ccbyte2 === 0) {
                  continue;
                }
                const ccValid = (0x04 & tmpByte) !== 0; // Support all four channels
                if (ccValid) {
                  const ccType = 0x03 & tmpByte;
                  if (0x00 /* CEA608 field1*/ === ccType || 0x01 /* CEA608 field2*/ === ccType) {
                    // Exclude CEA708 CC data.
                    actualCCBytes[ccType].push(ccbyte1);
                    actualCCBytes[ccType].push(ccbyte2);
                  }
                }
              }
              return actualCCBytes;
            }
          }
          function canReuseVttTextTrack(inUseTrack, manifestTrack) {
            return inUseTrack && inUseTrack.label === manifestTrack.name && !(inUseTrack.textTrack1 || inUseTrack.textTrack2);
          }
          function intersection(x1, x2, y1, y2) {
            return Math.min(x2, y2) - Math.max(x1, y1);
          }
          function newVTTCCs() {
            return {
              ccOffset: 0,
              presentationOffset: 0,
              0: {
                start: 0,
                prevCC: -1,
                new: true
              }
            };
          }

          /***/
        }),

/***/ "./src/crypt/aes-crypto.ts":
/*!*********************************!*\
  !*** ./src/crypt/aes-crypto.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AESCrypto)
            /* harmony export */
          });
          class AESCrypto {
            constructor(subtle, iv) {
              this.subtle = subtle;
              this.aesIV = iv;
            }
            decrypt(data, key) {
              return this.subtle.decrypt({
                name: 'AES-CBC',
                iv: this.aesIV
              }, key, data);
            }
          }

          /***/
        }),

/***/ "./src/crypt/aes-decryptor.ts":
/*!************************************!*\
  !*** ./src/crypt/aes-decryptor.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ AESDecryptor),
/* harmony export */   "removePadding": () => (/* binding */ removePadding)
            /* harmony export */
          });
/* harmony import */ var _utils_typed_array__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/typed-array */ "./src/utils/typed-array.ts");


          // PKCS7
          function removePadding(array) {
            const outputBytes = array.byteLength;
            const paddingBytes = outputBytes && new DataView(array.buffer).getUint8(outputBytes - 1);
            if (paddingBytes) {
              return (0, _utils_typed_array__WEBPACK_IMPORTED_MODULE_0__.sliceUint8)(array, 0, outputBytes - paddingBytes);
            }
            return array;
          }
          class AESDecryptor {
            rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];
            subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];
            invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];
            sBox = new Uint32Array(256);
            invSBox = new Uint32Array(256);
            key = new Uint32Array(0);
            ksRows = 0;
            keySize = 0;
            constructor() {
              this.initTable();
            }

            // Using view.getUint32() also swaps the byte order.
            uint8ArrayToUint32Array_(arrayBuffer) {
              const view = new DataView(arrayBuffer);
              const newArray = new Uint32Array(4);
              for (let i = 0; i < 4; i++) {
                newArray[i] = view.getUint32(i * 4);
              }
              return newArray;
            }
            initTable() {
              const sBox = this.sBox;
              const invSBox = this.invSBox;
              const subMix = this.subMix;
              const subMix0 = subMix[0];
              const subMix1 = subMix[1];
              const subMix2 = subMix[2];
              const subMix3 = subMix[3];
              const invSubMix = this.invSubMix;
              const invSubMix0 = invSubMix[0];
              const invSubMix1 = invSubMix[1];
              const invSubMix2 = invSubMix[2];
              const invSubMix3 = invSubMix[3];
              const d = new Uint32Array(256);
              let x = 0;
              let xi = 0;
              let i = 0;
              for (i = 0; i < 256; i++) {
                if (i < 128) {
                  d[i] = i << 1;
                } else {
                  d[i] = i << 1 ^ 0x11b;
                }
              }
              for (i = 0; i < 256; i++) {
                let sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;
                sx = sx >>> 8 ^ sx & 0xff ^ 0x63;
                sBox[x] = sx;
                invSBox[sx] = x;

                // Compute multiplication
                const x2 = d[x];
                const x4 = d[x2];
                const x8 = d[x4];

                // Compute sub/invSub bytes, mix columns tables
                let t = d[sx] * 0x101 ^ sx * 0x1010100;
                subMix0[x] = t << 24 | t >>> 8;
                subMix1[x] = t << 16 | t >>> 16;
                subMix2[x] = t << 8 | t >>> 24;
                subMix3[x] = t;

                // Compute inv sub bytes, inv mix columns tables
                t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;
                invSubMix0[sx] = t << 24 | t >>> 8;
                invSubMix1[sx] = t << 16 | t >>> 16;
                invSubMix2[sx] = t << 8 | t >>> 24;
                invSubMix3[sx] = t;

                // Compute next counter
                if (!x) {
                  x = xi = 1;
                } else {
                  x = x2 ^ d[d[d[x8 ^ x2]]];
                  xi ^= d[d[xi]];
                }
              }
            }
            expandKey(keyBuffer) {
              // convert keyBuffer to Uint32Array
              const key = this.uint8ArrayToUint32Array_(keyBuffer);
              let sameKey = true;
              let offset = 0;
              while (offset < key.length && sameKey) {
                sameKey = key[offset] === this.key[offset];
                offset++;
              }
              if (sameKey) {
                return;
              }
              this.key = key;
              const keySize = this.keySize = key.length;
              if (keySize !== 4 && keySize !== 6 && keySize !== 8) {
                throw new Error('Invalid aes key size=' + keySize);
              }
              const ksRows = this.ksRows = (keySize + 6 + 1) * 4;
              let ksRow;
              let invKsRow;
              const keySchedule = this.keySchedule = new Uint32Array(ksRows);
              const invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);
              const sbox = this.sBox;
              const rcon = this.rcon;
              const invSubMix = this.invSubMix;
              const invSubMix0 = invSubMix[0];
              const invSubMix1 = invSubMix[1];
              const invSubMix2 = invSubMix[2];
              const invSubMix3 = invSubMix[3];
              let prev;
              let t;
              for (ksRow = 0; ksRow < ksRows; ksRow++) {
                if (ksRow < keySize) {
                  prev = keySchedule[ksRow] = key[ksRow];
                  continue;
                }
                t = prev;
                if (ksRow % keySize === 0) {
                  // Rot word
                  t = t << 8 | t >>> 24;

                  // Sub word
                  t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];

                  // Mix Rcon
                  t ^= rcon[ksRow / keySize | 0] << 24;
                } else if (keySize > 6 && ksRow % keySize === 4) {
                  // Sub word
                  t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];
                }
                keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;
              }
              for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {
                ksRow = ksRows - invKsRow;
                if (invKsRow & 3) {
                  t = keySchedule[ksRow];
                } else {
                  t = keySchedule[ksRow - 4];
                }
                if (invKsRow < 4 || ksRow <= 4) {
                  invKeySchedule[invKsRow] = t;
                } else {
                  invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];
                }
                invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;
              }
            }

            // Adding this as a method greatly improves performance.
            networkToHostOrderSwap(word) {
              return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;
            }
            decrypt(inputArrayBuffer, offset, aesIV) {
              const nRounds = this.keySize + 6;
              const invKeySchedule = this.invKeySchedule;
              const invSBOX = this.invSBox;
              const invSubMix = this.invSubMix;
              const invSubMix0 = invSubMix[0];
              const invSubMix1 = invSubMix[1];
              const invSubMix2 = invSubMix[2];
              const invSubMix3 = invSubMix[3];
              const initVector = this.uint8ArrayToUint32Array_(aesIV);
              let initVector0 = initVector[0];
              let initVector1 = initVector[1];
              let initVector2 = initVector[2];
              let initVector3 = initVector[3];
              const inputInt32 = new Int32Array(inputArrayBuffer);
              const outputInt32 = new Int32Array(inputInt32.length);
              let t0, t1, t2, t3;
              let s0, s1, s2, s3;
              let inputWords0, inputWords1, inputWords2, inputWords3;
              let ksRow, i;
              const swapWord = this.networkToHostOrderSwap;
              while (offset < inputInt32.length) {
                inputWords0 = swapWord(inputInt32[offset]);
                inputWords1 = swapWord(inputInt32[offset + 1]);
                inputWords2 = swapWord(inputInt32[offset + 2]);
                inputWords3 = swapWord(inputInt32[offset + 3]);
                s0 = inputWords0 ^ invKeySchedule[0];
                s1 = inputWords3 ^ invKeySchedule[1];
                s2 = inputWords2 ^ invKeySchedule[2];
                s3 = inputWords1 ^ invKeySchedule[3];
                ksRow = 4;

                // Iterate through the rounds of decryption
                for (i = 1; i < nRounds; i++) {
                  t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];
                  t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];
                  t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];
                  t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3];
                  // Update state
                  s0 = t0;
                  s1 = t1;
                  s2 = t2;
                  s3 = t3;
                  ksRow = ksRow + 4;
                }

                // Shift rows, sub bytes, add round key
                t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];
                t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];
                t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];
                t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];

                // Write
                outputInt32[offset] = swapWord(t0 ^ initVector0);
                outputInt32[offset + 1] = swapWord(t3 ^ initVector1);
                outputInt32[offset + 2] = swapWord(t2 ^ initVector2);
                outputInt32[offset + 3] = swapWord(t1 ^ initVector3);

                // reset initVector to last 4 unsigned int
                initVector0 = inputWords0;
                initVector1 = inputWords1;
                initVector2 = inputWords2;
                initVector3 = inputWords3;
                offset = offset + 4;
              }
              return outputInt32.buffer;
            }
          }

          /***/
        }),

/***/ "./src/crypt/decrypter.ts":
/*!********************************!*\
  !*** ./src/crypt/decrypter.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Decrypter)
            /* harmony export */
          });
/* harmony import */ var _aes_crypto__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./aes-crypto */ "./src/crypt/aes-crypto.ts");
/* harmony import */ var _fast_aes_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fast-aes-key */ "./src/crypt/fast-aes-key.ts");
/* harmony import */ var _aes_decryptor__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./aes-decryptor */ "./src/crypt/aes-decryptor.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _utils_typed_array__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/typed-array */ "./src/utils/typed-array.ts");






          const CHUNK_SIZE = 16; // 16 bytes, 128 bits

          class Decrypter {
            logEnabled = true;
            subtle = null;
            softwareDecrypter = null;
            key = null;
            fastAesKey = null;
            remainderData = null;
            currentIV = null;
            currentResult = null;
            constructor(config, {
              removePKCS7Padding = true
            } = {}) {
              this.useSoftware = config.enableSoftwareAES;
              this.removePKCS7Padding = removePKCS7Padding;
              // built in decryptor expects PKCS7 padding
              if (removePKCS7Padding) {
                try {
                  const browserCrypto = self.crypto;
                  if (browserCrypto) {
                    this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;
                  }
                } catch (e) {
                  /* no-op */
                }
              }
              if (this.subtle === null) {
                this.useSoftware = true;
              }
            }
            destroy() {
              this.subtle = null;
              this.softwareDecrypter = null;
              this.key = null;
              this.fastAesKey = null;
              this.remainderData = null;
              this.currentIV = null;
              this.currentResult = null;
            }
            isSync() {
              return this.useSoftware;
            }
            flush() {
              const {
                currentResult,
                remainderData
              } = this;
              if (!currentResult || remainderData) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.error(`[softwareDecrypt] ${remainderData ? 'overflow bytes: ' + remainderData.byteLength : 'no result'}`);
                this.reset();
                return null;
              }
              const data = new Uint8Array(currentResult);
              this.reset();
              if (this.removePKCS7Padding) {
                return (0, _aes_decryptor__WEBPACK_IMPORTED_MODULE_2__.removePadding)(data);
              }
              return data;
            }
            reset() {
              this.currentResult = null;
              this.currentIV = null;
              this.remainderData = null;
              if (this.softwareDecrypter) {
                this.softwareDecrypter = null;
              }
            }
            decrypt(data, key, iv) {
              if (this.useSoftware) {
                return new Promise((resolve, reject) => {
                  this.softwareDecrypt(new Uint8Array(data), key, iv);
                  const decryptResult = this.flush();
                  if (decryptResult) {
                    resolve(decryptResult.buffer);
                  } else {
                    reject(new Error('[softwareDecrypt] Failed to decrypt data'));
                  }
                });
              }
              return this.webCryptoDecrypt(new Uint8Array(data), key, iv);
            }

            // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached
            // data is handled in the flush() call
            softwareDecrypt(data, key, iv) {
              const {
                currentIV,
                currentResult,
                remainderData
              } = this;
              this.logOnce('JS AES decrypt');
              // The output is staggered during progressive parsing - the current result is cached, and emitted on the next call
              // This is done in order to strip PKCS7 padding, which is found at the end of each segment. We only know we've reached
              // the end on flush(), but by that time we have already received all bytes for the segment.
              // Progressive decryption does not work with WebCrypto

              if (remainderData) {
                data = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_4__.appendUint8Array)(remainderData, data);
                this.remainderData = null;
              }

              // Byte length must be a multiple of 16 (AES-128 = 128 bit blocks = 16 bytes)
              const currentChunk = this.getValidChunk(data);
              if (!currentChunk.length) {
                return null;
              }
              if (currentIV) {
                iv = currentIV;
              }
              let softwareDecrypter = this.softwareDecrypter;
              if (!softwareDecrypter) {
                softwareDecrypter = this.softwareDecrypter = new _aes_decryptor__WEBPACK_IMPORTED_MODULE_2__["default"]();
              }
              softwareDecrypter.expandKey(key);
              const result = currentResult;
              this.currentResult = softwareDecrypter.decrypt(currentChunk.buffer, 0, iv);
              this.currentIV = (0, _utils_typed_array__WEBPACK_IMPORTED_MODULE_5__.sliceUint8)(currentChunk, -16).buffer;
              if (!result) {
                return null;
              }
              return result;
            }
            webCryptoDecrypt(data, key, iv) {
              const subtle = this.subtle;
              if (this.key !== key || !this.fastAesKey) {
                this.key = key;
                this.fastAesKey = new _fast_aes_key__WEBPACK_IMPORTED_MODULE_1__["default"](subtle, key);
              }
              return this.fastAesKey.expandKey().then(aesKey => {
                // decrypt using web crypto
                if (!subtle) {
                  return Promise.reject(new Error('web crypto not initialized'));
                }
                this.logOnce('WebCrypto AES decrypt');
                const crypto = new _aes_crypto__WEBPACK_IMPORTED_MODULE_0__["default"](subtle, new Uint8Array(iv));
                return crypto.decrypt(data.buffer, aesKey);
              }).catch(err => {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn(`[decrypter]: WebCrypto Error, disable WebCrypto API, ${err.name}: ${err.message}`);
                return this.onWebCryptoError(data, key, iv);
              });
            }
            onWebCryptoError(data, key, iv) {
              this.useSoftware = true;
              this.logEnabled = true;
              this.softwareDecrypt(data, key, iv);
              const decryptResult = this.flush();
              if (decryptResult) {
                return decryptResult.buffer;
              }
              throw new Error('WebCrypto and softwareDecrypt: failed to decrypt data');
            }
            getValidChunk(data) {
              let currentChunk = data;
              const splitPoint = data.length - data.length % CHUNK_SIZE;
              if (splitPoint !== data.length) {
                currentChunk = (0, _utils_typed_array__WEBPACK_IMPORTED_MODULE_5__.sliceUint8)(data, 0, splitPoint);
                this.remainderData = (0, _utils_typed_array__WEBPACK_IMPORTED_MODULE_5__.sliceUint8)(data, splitPoint);
              }
              return currentChunk;
            }
            logOnce(msg) {
              if (!this.logEnabled) {
                return;
              }
              _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.log(`[decrypter]: ${msg}`);
              this.logEnabled = false;
            }
          }

          /***/
        }),

/***/ "./src/crypt/fast-aes-key.ts":
/*!***********************************!*\
  !*** ./src/crypt/fast-aes-key.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ FastAESKey)
            /* harmony export */
          });
          class FastAESKey {
            constructor(subtle, key) {
              this.subtle = subtle;
              this.key = key;
            }
            expandKey() {
              return this.subtle.importKey('raw', this.key, {
                name: 'AES-CBC'
              }, false, ['encrypt', 'decrypt']);
            }
          }

          /***/
        }),

/***/ "./src/demux/aacdemuxer.ts":
/*!*********************************!*\
  !*** ./src/demux/aacdemuxer.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base-audio-demuxer */ "./src/demux/base-audio-demuxer.ts");
/* harmony import */ var _adts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./adts */ "./src/demux/adts.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
          /**
           * AAC demuxer
           */




          class AACDemuxer extends _base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__["default"] {
            constructor(observer, config) {
              super();
              this.observer = observer;
              this.config = config;
            }
            resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
              super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);
              this._audioTrack = {
                container: 'audio/adts',
                type: 'audio',
                id: 2,
                pid: -1,
                sequenceNumber: 0,
                segmentCodec: 'aac',
                samples: [],
                manifestCodec: audioCodec,
                duration: trackDuration,
                inputTimeScale: 90000,
                dropped: 0
              };
            }

            // Source for probe info - https://wiki.multimedia.cx/index.php?title=ADTS
            static probe(data) {
              if (!data) {
                return false;
              }

              // Check for the ADTS sync word
              // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1
              // Layer bits (position 14 and 15) in header should be always 0 for ADTS
              // More info https://wiki.multimedia.cx/index.php?title=ADTS
              const id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_3__.getID3Data(data, 0) || [];
              let offset = id3Data.length;
              for (let length = data.length; offset < length; offset++) {
                if (_adts__WEBPACK_IMPORTED_MODULE_1__.probe(data, offset)) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.log('ADTS sync word found !');
                  return true;
                }
              }
              return false;
            }
            canParse(data, offset) {
              return _adts__WEBPACK_IMPORTED_MODULE_1__.canParse(data, offset);
            }
            appendFrame(track, data, offset) {
              _adts__WEBPACK_IMPORTED_MODULE_1__.initTrackConfig(track, this.observer, data, offset, track.manifestCodec);
              const frame = _adts__WEBPACK_IMPORTED_MODULE_1__.appendFrame(track, data, offset, this.basePTS, this.frameIndex);
              if (frame && frame.missing === 0) {
                return frame;
              }
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AACDemuxer);

          /***/
        }),

/***/ "./src/demux/adts.ts":
/*!***************************!*\
  !*** ./src/demux/adts.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "appendFrame": () => (/* binding */ appendFrame),
/* harmony export */   "canGetFrameLength": () => (/* binding */ canGetFrameLength),
/* harmony export */   "canParse": () => (/* binding */ canParse),
/* harmony export */   "getAudioConfig": () => (/* binding */ getAudioConfig),
/* harmony export */   "getFrameDuration": () => (/* binding */ getFrameDuration),
/* harmony export */   "getFullFrameLength": () => (/* binding */ getFullFrameLength),
/* harmony export */   "getHeaderLength": () => (/* binding */ getHeaderLength),
/* harmony export */   "initTrackConfig": () => (/* binding */ initTrackConfig),
/* harmony export */   "isHeader": () => (/* binding */ isHeader),
/* harmony export */   "isHeaderPattern": () => (/* binding */ isHeaderPattern),
/* harmony export */   "parseFrameHeader": () => (/* binding */ parseFrameHeader),
/* harmony export */   "probe": () => (/* binding */ probe)
            /* harmony export */
          });
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
          /**
           * ADTS parser helper
           * @link https://wiki.multimedia.cx/index.php?title=ADTS
           */



          function getAudioConfig(observer, data, offset, audioCodec) {
            let adtsObjectType;
            let adtsExtensionSamplingIndex;
            let adtsChannelConfig;
            let config;
            const userAgent = navigator.userAgent.toLowerCase();
            const manifestCodec = audioCodec;
            const adtsSamplingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];
            // byte 2
            adtsObjectType = ((data[offset + 2] & 0xc0) >>> 6) + 1;
            const adtsSamplingIndex = (data[offset + 2] & 0x3c) >>> 2;
            if (adtsSamplingIndex > adtsSamplingRates.length - 1) {
              observer.trigger(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.FRAG_PARSING_ERROR,
                fatal: true,
                reason: `invalid ADTS sampling index:${adtsSamplingIndex}`
              });
              return;
            }
            adtsChannelConfig = (data[offset + 2] & 0x01) << 2;
            // byte 3
            adtsChannelConfig |= (data[offset + 3] & 0xc0) >>> 6;
            _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.log(`manifest codec:${audioCodec}, ADTS type:${adtsObjectType}, samplingIndex:${adtsSamplingIndex}`);
            // firefox: freq less than 24kHz = AAC SBR (HE-AAC)
            if (/firefox/i.test(userAgent)) {
              if (adtsSamplingIndex >= 6) {
                adtsObjectType = 5;
                config = new Array(4);
                // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies
                // there is a factor 2 between frame sample rate and output sample rate
                // multiply frequency by 2 (see table below, equivalent to substract 3)
                adtsExtensionSamplingIndex = adtsSamplingIndex - 3;
              } else {
                adtsObjectType = 2;
                config = new Array(2);
                adtsExtensionSamplingIndex = adtsSamplingIndex;
              }
              // Android : always use AAC
            } else if (userAgent.indexOf('android') !== -1) {
              adtsObjectType = 2;
              config = new Array(2);
              adtsExtensionSamplingIndex = adtsSamplingIndex;
            } else {
              /*  for other browsers (Chrome/Vivaldi/Opera ...)
                  always force audio type to be HE-AAC SBR, as some browsers do not support audio codec switch properly (like Chrome ...)
              */
              adtsObjectType = 5;
              config = new Array(4);
              // if (manifest codec is HE-AAC or HE-AACv2) OR (manifest codec not specified AND frequency less than 24kHz)
              if (audioCodec && (audioCodec.indexOf('mp4a.40.29') !== -1 || audioCodec.indexOf('mp4a.40.5') !== -1) || !audioCodec && adtsSamplingIndex >= 6) {
                // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies
                // there is a factor 2 between frame sample rate and output sample rate
                // multiply frequency by 2 (see table below, equivalent to substract 3)
                adtsExtensionSamplingIndex = adtsSamplingIndex - 3;
              } else {
                // if (manifest codec is AAC) AND (frequency less than 24kHz AND nb channel is 1) OR (manifest codec not specified and mono audio)
                // Chrome fails to play back with low frequency AAC LC mono when initialized with HE-AAC.  This is not a problem with stereo.
                if (audioCodec && audioCodec.indexOf('mp4a.40.2') !== -1 && (adtsSamplingIndex >= 6 && adtsChannelConfig === 1 || /vivaldi/i.test(userAgent)) || !audioCodec && adtsChannelConfig === 1) {
                  adtsObjectType = 2;
                  config = new Array(2);
                }
                adtsExtensionSamplingIndex = adtsSamplingIndex;
              }
            }
            /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config
                ISO 14496-3 (AAC).pdf - Table 1.13 — Syntax of AudioSpecificConfig()
              Audio Profile / Audio Object Type
              0: Null
              1: AAC Main
              2: AAC LC (Low Complexity)
              3: AAC SSR (Scalable Sample Rate)
              4: AAC LTP (Long Term Prediction)
              5: SBR (Spectral Band Replication)
              6: AAC Scalable
             sampling freq
              0: 96000 Hz
              1: 88200 Hz
              2: 64000 Hz
              3: 48000 Hz
              4: 44100 Hz
              5: 32000 Hz
              6: 24000 Hz
              7: 22050 Hz
              8: 16000 Hz
              9: 12000 Hz
              10: 11025 Hz
              11: 8000 Hz
              12: 7350 Hz
              13: Reserved
              14: Reserved
              15: frequency is written explictly
              Channel Configurations
              These are the channel configurations:
              0: Defined in AOT Specifc Config
              1: 1 channel: front-center
              2: 2 channels: front-left, front-right
            */
            // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1
            config[0] = adtsObjectType << 3;
            // samplingFrequencyIndex
            config[0] |= (adtsSamplingIndex & 0x0e) >> 1;
            config[1] |= (adtsSamplingIndex & 0x01) << 7;
            // channelConfiguration
            config[1] |= adtsChannelConfig << 3;
            if (adtsObjectType === 5) {
              // adtsExtensionSamplingIndex
              config[1] |= (adtsExtensionSamplingIndex & 0x0e) >> 1;
              config[2] = (adtsExtensionSamplingIndex & 0x01) << 7;
              // adtsObjectType (force to 2, chrome is checking that object type is less than 5 ???
              //    https://chromium.googlesource.com/chromium/src.git/+/master/media/formats/mp4/aac.cc
              config[2] |= 2 << 2;
              config[3] = 0;
            }
            return {
              config,
              samplerate: adtsSamplingRates[adtsSamplingIndex],
              channelCount: adtsChannelConfig,
              codec: 'mp4a.40.' + adtsObjectType,
              manifestCodec
            };
          }
          function isHeaderPattern(data, offset) {
            return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;
          }
          function getHeaderLength(data, offset) {
            return data[offset + 1] & 0x01 ? 7 : 9;
          }
          function getFullFrameLength(data, offset) {
            return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xe0) >>> 5;
          }
          function canGetFrameLength(data, offset) {
            return offset + 5 < data.length;
          }
          function isHeader(data, offset) {
            // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1
            // Layer bits (position 14 and 15) in header should be always 0 for ADTS
            // More info https://wiki.multimedia.cx/index.php?title=ADTS
            return offset + 1 < data.length && isHeaderPattern(data, offset);
          }
          function canParse(data, offset) {
            return canGetFrameLength(data, offset) && isHeaderPattern(data, offset) && getFullFrameLength(data, offset) <= data.length - offset;
          }
          function probe(data, offset) {
            // same as isHeader but we also check that ADTS frame follows last ADTS frame
            // or end of data is reached
            if (isHeader(data, offset)) {
              // ADTS header Length
              const headerLength = getHeaderLength(data, offset);
              if (offset + headerLength >= data.length) {
                return false;
              }
              // ADTS frame Length
              const frameLength = getFullFrameLength(data, offset);
              if (frameLength <= headerLength) {
                return false;
              }
              const newOffset = offset + frameLength;
              return newOffset === data.length || isHeader(data, newOffset);
            }
            return false;
          }
          function initTrackConfig(track, observer, data, offset, audioCodec) {
            if (!track.samplerate) {
              const config = getAudioConfig(observer, data, offset, audioCodec);
              if (!config) {
                return;
              }
              track.config = config.config;
              track.samplerate = config.samplerate;
              track.channelCount = config.channelCount;
              track.codec = config.codec;
              track.manifestCodec = config.manifestCodec;
              _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.log(`parsed codec:${track.codec}, rate:${config.samplerate}, channels:${config.channelCount}`);
            }
          }
          function getFrameDuration(samplerate) {
            return 1024 * 90000 / samplerate;
          }
          function parseFrameHeader(data, offset) {
            // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header
            const headerLength = getHeaderLength(data, offset);
            if (offset + headerLength <= data.length) {
              // retrieve frame size
              const frameLength = getFullFrameLength(data, offset) - headerLength;
              if (frameLength > 0) {
                // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}`);
                return {
                  headerLength,
                  frameLength
                };
              }
            }
          }
          function appendFrame(track, data, offset, pts, frameIndex) {
            const frameDuration = getFrameDuration(track.samplerate);
            const stamp = pts + frameIndex * frameDuration;
            const header = parseFrameHeader(data, offset);
            let unit;
            if (header) {
              const {
                frameLength,
                headerLength
              } = header;
              const length = headerLength + frameLength;
              const missing = Math.max(0, offset + length - data.length);
              // logger.log(`AAC frame ${frameIndex}, pts:${stamp} length@offset/total: ${frameLength}@${offset+headerLength}/${data.byteLength} missing: ${missing}`);
              if (missing) {
                unit = new Uint8Array(length - headerLength);
                unit.set(data.subarray(offset + headerLength, data.length), 0);
              } else {
                unit = data.subarray(offset + headerLength, offset + length);
              }
              const sample = {
                unit,
                pts: stamp
              };
              if (!missing) {
                track.samples.push(sample);
              }
              return {
                sample,
                length,
                missing
              };
            }
            // overflow incomplete header
            const length = data.length - offset;
            unit = new Uint8Array(length);
            unit.set(data.subarray(offset, data.length), 0);
            const sample = {
              unit,
              pts: stamp
            };
            return {
              sample,
              length,
              missing: -1
            };
          }

          /***/
        }),

/***/ "./src/demux/base-audio-demuxer.ts":
/*!*****************************************!*\
  !*** ./src/demux/base-audio-demuxer.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   "initPTSFn": () => (/* binding */ initPTSFn)
            /* harmony export */
          });
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
/* harmony import */ var _types_demuxer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../types/demuxer */ "./src/types/demuxer.ts");
/* harmony import */ var _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./dummy-demuxed-track */ "./src/demux/dummy-demuxed-track.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _utils_typed_array__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/typed-array */ "./src/utils/typed-array.ts");





          class BaseAudioDemuxer {
            frameIndex = 0;
            cachedData = null;
            basePTS = null;
            initPTS = null;
            lastPTS = null;
            resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
              this._id3Track = {
                type: 'id3',
                id: 3,
                pid: -1,
                inputTimeScale: 90000,
                sequenceNumber: 0,
                samples: [],
                dropped: 0
              };
            }
            resetTimeStamp(deaultTimestamp) {
              this.initPTS = deaultTimestamp;
              this.resetContiguity();
            }
            resetContiguity() {
              this.basePTS = null;
              this.lastPTS = null;
              this.frameIndex = 0;
            }
            canParse(data, offset) {
              return false;
            }
            appendFrame(track, data, offset) { }

            // feed incoming data to the front of the parsing pipeline
            demux(data, timeOffset) {
              if (this.cachedData) {
                data = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_3__.appendUint8Array)(this.cachedData, data);
                this.cachedData = null;
              }
              let id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_0__.getID3Data(data, 0);
              let offset = id3Data ? id3Data.length : 0;
              let lastDataIndex;
              const track = this._audioTrack;
              const id3Track = this._id3Track;
              const timestamp = id3Data ? _demux_id3__WEBPACK_IMPORTED_MODULE_0__.getTimeStamp(id3Data) : undefined;
              const length = data.length;
              if (this.basePTS === null || this.frameIndex === 0 && Number.isFinite(timestamp)) {
                this.basePTS = initPTSFn(timestamp, timeOffset, this.initPTS);
                this.lastPTS = this.basePTS;
              }
              if (this.lastPTS === null) {
                this.lastPTS = this.basePTS;
              }

              // more expressive than alternative: id3Data?.length
              if (id3Data && id3Data.length > 0) {
                id3Track.samples.push({
                  pts: this.lastPTS,
                  dts: this.lastPTS,
                  data: id3Data,
                  type: _types_demuxer__WEBPACK_IMPORTED_MODULE_1__.MetadataSchema.audioId3,
                  duration: Number.POSITIVE_INFINITY
                });
              }
              while (offset < length) {
                if (this.canParse(data, offset)) {
                  const frame = this.appendFrame(track, data, offset);
                  if (frame) {
                    this.frameIndex++;
                    this.lastPTS = frame.sample.pts;
                    offset += frame.length;
                    lastDataIndex = offset;
                  } else {
                    offset = length;
                  }
                } else if (_demux_id3__WEBPACK_IMPORTED_MODULE_0__.canParse(data, offset)) {
                  // after a ID3.canParse, a call to ID3.getID3Data *should* always returns some data
                  id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_0__.getID3Data(data, offset);
                  id3Track.samples.push({
                    pts: this.lastPTS,
                    dts: this.lastPTS,
                    data: id3Data,
                    type: _types_demuxer__WEBPACK_IMPORTED_MODULE_1__.MetadataSchema.audioId3,
                    duration: Number.POSITIVE_INFINITY
                  });
                  offset += id3Data.length;
                  lastDataIndex = offset;
                } else {
                  offset++;
                }
                if (offset === length && lastDataIndex !== length) {
                  const partialData = (0, _utils_typed_array__WEBPACK_IMPORTED_MODULE_4__.sliceUint8)(data, lastDataIndex);
                  if (this.cachedData) {
                    this.cachedData = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_3__.appendUint8Array)(this.cachedData, partialData);
                  } else {
                    this.cachedData = partialData;
                  }
                }
              }
              return {
                audioTrack: track,
                videoTrack: (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)(),
                id3Track,
                textTrack: (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)()
              };
            }
            demuxSampleAes(data, keyData, timeOffset) {
              return Promise.reject(new Error(`[${this}] This demuxer does not support Sample-AES decryption`));
            }
            flush(timeOffset) {
              // Parse cache in case of remaining frames.
              const cachedData = this.cachedData;
              if (cachedData) {
                this.cachedData = null;
                this.demux(cachedData, 0);
              }
              return {
                audioTrack: this._audioTrack,
                videoTrack: (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)(),
                id3Track: this._id3Track,
                textTrack: (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)()
              };
            }
            destroy() { }
          }

          /**
           * Initialize PTS
           * <p>
           *    use timestamp unless it is undefined, NaN or Infinity
           * </p>
           */
          const initPTSFn = (timestamp, timeOffset, initPTS) => {
            if (Number.isFinite(timestamp)) {
              return timestamp * 90;
            }
            return timeOffset * 90000 + (initPTS || 0);
          };
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (BaseAudioDemuxer);

          /***/
        }),

/***/ "./src/demux/chunk-cache.ts":
/*!**********************************!*\
  !*** ./src/demux/chunk-cache.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ ChunkCache)
            /* harmony export */
          });
          class ChunkCache {
            chunks = [];
            dataLength = 0;
            push(chunk) {
              this.chunks.push(chunk);
              this.dataLength += chunk.length;
            }
            flush() {
              const {
                chunks,
                dataLength
              } = this;
              let result;
              if (!chunks.length) {
                return new Uint8Array(0);
              } else if (chunks.length === 1) {
                result = chunks[0];
              } else {
                result = concatUint8Arrays(chunks, dataLength);
              }
              this.reset();
              return result;
            }
            reset() {
              this.chunks.length = 0;
              this.dataLength = 0;
            }
          }
          function concatUint8Arrays(chunks, dataLength) {
            const result = new Uint8Array(dataLength);
            let offset = 0;
            for (let i = 0; i < chunks.length; i++) {
              const chunk = chunks[i];
              result.set(chunk, offset);
              offset += chunk.length;
            }
            return result;
          }

          /***/
        }),

/***/ "./src/demux/dummy-demuxed-track.ts":
/*!******************************************!*\
  !*** ./src/demux/dummy-demuxed-track.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "dummyTrack": () => (/* binding */ dummyTrack)
            /* harmony export */
          });
          function dummyTrack(type = '', inputTimeScale = 90000) {
            return {
              type,
              id: -1,
              pid: -1,
              inputTimeScale,
              sequenceNumber: -1,
              samples: [],
              dropped: 0
            };
          }

          /***/
        }),

/***/ "./src/demux/exp-golomb.ts":
/*!*********************************!*\
  !*** ./src/demux/exp-golomb.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
          /**
           * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.
           */


          class ExpGolomb {
            constructor(data) {
              this.data = data;
              // the number of bytes left to examine in this.data
              this.bytesAvailable = data.byteLength;
              // the current word being examined
              this.word = 0; // :uint
              // the number of bits left to examine in the current word
              this.bitsAvailable = 0; // :uint
            }

            // ():void
            loadWord() {
              const data = this.data;
              const bytesAvailable = this.bytesAvailable;
              const position = data.byteLength - bytesAvailable;
              const workingBytes = new Uint8Array(4);
              const availableBytes = Math.min(4, bytesAvailable);
              if (availableBytes === 0) {
                throw new Error('no bytes available');
              }
              workingBytes.set(data.subarray(position, position + availableBytes));
              this.word = new DataView(workingBytes.buffer).getUint32(0);
              // track the amount of this.data that has been processed
              this.bitsAvailable = availableBytes * 8;
              this.bytesAvailable -= availableBytes;
            }

            // (count:int):void
            skipBits(count) {
              let skipBytes; // :int
              count = Math.min(count, this.bytesAvailable * 8 + this.bitsAvailable);
              if (this.bitsAvailable > count) {
                this.word <<= count;
                this.bitsAvailable -= count;
              } else {
                count -= this.bitsAvailable;
                skipBytes = count >> 3;
                count -= skipBytes << 3;
                this.bytesAvailable -= skipBytes;
                this.loadWord();
                this.word <<= count;
                this.bitsAvailable -= count;
              }
            }

            // (size:int):uint
            readBits(size) {
              let bits = Math.min(this.bitsAvailable, size); // :uint
              const valu = this.word >>> 32 - bits; // :uint
              if (size > 32) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.error('Cannot read more than 32 bits at a time');
              }
              this.bitsAvailable -= bits;
              if (this.bitsAvailable > 0) {
                this.word <<= bits;
              } else if (this.bytesAvailable > 0) {
                this.loadWord();
              } else {
                throw new Error('no bits available');
              }
              bits = size - bits;
              if (bits > 0 && this.bitsAvailable) {
                return valu << bits | this.readBits(bits);
              } else {
                return valu;
              }
            }

            // ():uint
            skipLZ() {
              let leadingZeroCount; // :uint
              for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {
                if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {
                  // the first bit of working word is 1
                  this.word <<= leadingZeroCount;
                  this.bitsAvailable -= leadingZeroCount;
                  return leadingZeroCount;
                }
              }
              // we exhausted word and still have not found a 1
              this.loadWord();
              return leadingZeroCount + this.skipLZ();
            }

            // ():void
            skipUEG() {
              this.skipBits(1 + this.skipLZ());
            }

            // ():void
            skipEG() {
              this.skipBits(1 + this.skipLZ());
            }

            // ():uint
            readUEG() {
              const clz = this.skipLZ(); // :uint
              return this.readBits(clz + 1) - 1;
            }

            // ():int
            readEG() {
              const valu = this.readUEG(); // :int
              if (0x01 & valu) {
                // the number is odd if the low order bit is set
                return 1 + valu >>> 1; // add 1 to make it even, and divide by 2
              } else {
                return -1 * (valu >>> 1); // divide by two then make it negative
              }
            }

            // Some convenience functions
            // :Boolean
            readBoolean() {
              return this.readBits(1) === 1;
            }

            // ():int
            readUByte() {
              return this.readBits(8);
            }

            // ():int
            readUShort() {
              return this.readBits(16);
            }

            // ():int
            readUInt() {
              return this.readBits(32);
            }

            /**
             * Advance the ExpGolomb decoder past a scaling list. The scaling
             * list is optionally transmitted as part of a sequence parameter
             * set and is not relevant to transmuxing.
             * @param count the number of entries in this scaling list
             * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1
             */
            skipScalingList(count) {
              let lastScale = 8;
              let nextScale = 8;
              let deltaScale;
              for (let j = 0; j < count; j++) {
                if (nextScale !== 0) {
                  deltaScale = this.readEG();
                  nextScale = (lastScale + deltaScale + 256) % 256;
                }
                lastScale = nextScale === 0 ? lastScale : nextScale;
              }
            }

            /**
             * Read a sequence parameter set and return some interesting video
             * properties. A sequence parameter set is the H264 metadata that
             * describes the properties of upcoming video frames.
             * @param data {Uint8Array} the bytes of a sequence parameter set
             * @return {object} an object with configuration parsed from the
             * sequence parameter set, including the dimensions of the
             * associated video frames.
             */
            readSPS() {
              let frameCropLeftOffset = 0;
              let frameCropRightOffset = 0;
              let frameCropTopOffset = 0;
              let frameCropBottomOffset = 0;
              let numRefFramesInPicOrderCntCycle;
              let scalingListCount;
              let i;
              const readUByte = this.readUByte.bind(this);
              const readBits = this.readBits.bind(this);
              const readUEG = this.readUEG.bind(this);
              const readBoolean = this.readBoolean.bind(this);
              const skipBits = this.skipBits.bind(this);
              const skipEG = this.skipEG.bind(this);
              const skipUEG = this.skipUEG.bind(this);
              const skipScalingList = this.skipScalingList.bind(this);
              readUByte();
              const profileIdc = readUByte(); // profile_idc
              readBits(5); // profileCompat constraint_set[0-4]_flag, u(5)
              skipBits(3); // reserved_zero_3bits u(3),
              readUByte(); // level_idc u(8)
              skipUEG(); // seq_parameter_set_id
              // some profiles have more optional data we don't need
              if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {
                const chromaFormatIdc = readUEG();
                if (chromaFormatIdc === 3) {
                  skipBits(1);
                } // separate_colour_plane_flag

                skipUEG(); // bit_depth_luma_minus8
                skipUEG(); // bit_depth_chroma_minus8
                skipBits(1); // qpprime_y_zero_transform_bypass_flag
                if (readBoolean()) {
                  // seq_scaling_matrix_present_flag
                  scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;
                  for (i = 0; i < scalingListCount; i++) {
                    if (readBoolean()) {
                      // seq_scaling_list_present_flag[ i ]
                      if (i < 6) {
                        skipScalingList(16);
                      } else {
                        skipScalingList(64);
                      }
                    }
                  }
                }
              }
              skipUEG(); // log2_max_frame_num_minus4
              const picOrderCntType = readUEG();
              if (picOrderCntType === 0) {
                readUEG(); // log2_max_pic_order_cnt_lsb_minus4
              } else if (picOrderCntType === 1) {
                skipBits(1); // delta_pic_order_always_zero_flag
                skipEG(); // offset_for_non_ref_pic
                skipEG(); // offset_for_top_to_bottom_field
                numRefFramesInPicOrderCntCycle = readUEG();
                for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {
                  skipEG();
                } // offset_for_ref_frame[ i ]
              }

              skipUEG(); // max_num_ref_frames
              skipBits(1); // gaps_in_frame_num_value_allowed_flag
              const picWidthInMbsMinus1 = readUEG();
              const picHeightInMapUnitsMinus1 = readUEG();
              const frameMbsOnlyFlag = readBits(1);
              if (frameMbsOnlyFlag === 0) {
                skipBits(1);
              } // mb_adaptive_frame_field_flag

              skipBits(1); // direct_8x8_inference_flag
              if (readBoolean()) {
                // frame_cropping_flag
                frameCropLeftOffset = readUEG();
                frameCropRightOffset = readUEG();
                frameCropTopOffset = readUEG();
                frameCropBottomOffset = readUEG();
              }
              let pixelRatio = [1, 1];
              if (readBoolean()) {
                // vui_parameters_present_flag
                if (readBoolean()) {
                  // aspect_ratio_info_present_flag
                  const aspectRatioIdc = readUByte();
                  switch (aspectRatioIdc) {
                    case 1:
                      pixelRatio = [1, 1];
                      break;
                    case 2:
                      pixelRatio = [12, 11];
                      break;
                    case 3:
                      pixelRatio = [10, 11];
                      break;
                    case 4:
                      pixelRatio = [16, 11];
                      break;
                    case 5:
                      pixelRatio = [40, 33];
                      break;
                    case 6:
                      pixelRatio = [24, 11];
                      break;
                    case 7:
                      pixelRatio = [20, 11];
                      break;
                    case 8:
                      pixelRatio = [32, 11];
                      break;
                    case 9:
                      pixelRatio = [80, 33];
                      break;
                    case 10:
                      pixelRatio = [18, 11];
                      break;
                    case 11:
                      pixelRatio = [15, 11];
                      break;
                    case 12:
                      pixelRatio = [64, 33];
                      break;
                    case 13:
                      pixelRatio = [160, 99];
                      break;
                    case 14:
                      pixelRatio = [4, 3];
                      break;
                    case 15:
                      pixelRatio = [3, 2];
                      break;
                    case 16:
                      pixelRatio = [2, 1];
                      break;
                    case 255:
                      {
                        pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];
                        break;
                      }
                  }
                }
              }
              return {
                width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),
                height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),
                pixelRatio: pixelRatio
              };
            }
            readSliceType() {
              // skip NALu type
              this.readUByte();
              // discard first_mb_in_slice
              this.readUEG();
              // return slice_type
              return this.readUEG();
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ExpGolomb);

          /***/
        }),

/***/ "./src/demux/id3.ts":
/*!**************************!*\
  !*** ./src/demux/id3.ts ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "canParse": () => (/* binding */ canParse),
/* harmony export */   "decodeFrame": () => (/* binding */ decodeFrame),
/* harmony export */   "getID3Data": () => (/* binding */ getID3Data),
/* harmony export */   "getID3Frames": () => (/* binding */ getID3Frames),
/* harmony export */   "getTimeStamp": () => (/* binding */ getTimeStamp),
/* harmony export */   "isFooter": () => (/* binding */ isFooter),
/* harmony export */   "isHeader": () => (/* binding */ isHeader),
/* harmony export */   "isTimeStampFrame": () => (/* binding */ isTimeStampFrame),
/* harmony export */   "testables": () => (/* binding */ testables),
/* harmony export */   "utf8ArrayToStr": () => (/* binding */ utf8ArrayToStr)
            /* harmony export */
          });
          // breaking up those two types in order to clarify what is happening in the decoding path.

          /**
           * Returns true if an ID3 header can be found at offset in data
           * @param {Uint8Array} data - The data to search in
           * @param {number} offset - The offset at which to start searching
           * @return {boolean} - True if an ID3 header is found
           */
          const isHeader = (data, offset) => {
            /*
             * http://id3.org/id3v2.3.0
             * [0]     = 'I'
             * [1]     = 'D'
             * [2]     = '3'
             * [3,4]   = {Version}
             * [5]     = {Flags}
             * [6-9]   = {ID3 Size}
             *
             * An ID3v2 tag can be detected with the following pattern:
             *  $49 44 33 yy yy xx zz zz zz zz
             * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80
             */
            if (offset + 10 <= data.length) {
              // look for 'ID3' identifier
              if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {
                // check version is within range
                if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {
                  // check size is within range
                  if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {
                    return true;
                  }
                }
              }
            }
            return false;
          };

          /**
           * Returns true if an ID3 footer can be found at offset in data
           * @param {Uint8Array} data - The data to search in
           * @param {number} offset - The offset at which to start searching
           * @return {boolean} - True if an ID3 footer is found
           */
          const isFooter = (data, offset) => {
            /*
             * The footer is a copy of the header, but with a different identifier
             */
            if (offset + 10 <= data.length) {
              // look for '3DI' identifier
              if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {
                // check version is within range
                if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {
                  // check size is within range
                  if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {
                    return true;
                  }
                }
              }
            }
            return false;
          };

          /**
           * Returns any adjacent ID3 tags found in data starting at offset, as one block of data
           * @param {Uint8Array} data - The data to search in
           * @param {number} offset - The offset at which to start searching
           * @return {Uint8Array | undefined} - The block of data containing any ID3 tags found
           * or *undefined* if no header is found at the starting offset
           */
          const getID3Data = (data, offset) => {
            const front = offset;
            let length = 0;
            while (isHeader(data, offset)) {
              // ID3 header is 10 bytes
              length += 10;
              const size = readSize(data, offset + 6);
              length += size;
              if (isFooter(data, offset + 10)) {
                // ID3 footer is 10 bytes
                length += 10;
              }
              offset += length;
            }
            if (length > 0) {
              return data.subarray(front, front + length);
            }
            return undefined;
          };
          const readSize = (data, offset) => {
            let size = 0;
            size = (data[offset] & 0x7f) << 21;
            size |= (data[offset + 1] & 0x7f) << 14;
            size |= (data[offset + 2] & 0x7f) << 7;
            size |= data[offset + 3] & 0x7f;
            return size;
          };
          const canParse = (data, offset) => {
            return isHeader(data, offset) && readSize(data, offset + 6) + 10 <= data.length - offset;
          };

          /**
           * Searches for the Elementary Stream timestamp found in the ID3 data chunk
           * @param {Uint8Array} data - Block of data containing one or more ID3 tags
           * @return {number | undefined} - The timestamp
           */
          const getTimeStamp = data => {
            const frames = getID3Frames(data);
            for (let i = 0; i < frames.length; i++) {
              const frame = frames[i];
              if (isTimeStampFrame(frame)) {
                return readTimeStamp(frame);
              }
            }
            return undefined;
          };

          /**
           * Returns true if the ID3 frame is an Elementary Stream timestamp frame
           * @param {ID3 frame} frame
           */
          const isTimeStampFrame = frame => {
            return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';
          };
          const getFrameData = data => {
            /*
            Frame ID       $xx xx xx xx (four characters)
            Size           $xx xx xx xx
            Flags          $xx xx
            */
            const type = String.fromCharCode(data[0], data[1], data[2], data[3]);
            const size = readSize(data, 4);

            // skip frame id, size, and flags
            const offset = 10;
            return {
              type,
              size,
              data: data.subarray(offset, offset + size)
            };
          };

          /**
           * Returns an array of ID3 frames found in all the ID3 tags in the id3Data
           * @param {Uint8Array} id3Data - The ID3 data containing one or more ID3 tags
           * @return {ID3.Frame[]} - Array of ID3 frame objects
           */
          const getID3Frames = id3Data => {
            let offset = 0;
            const frames = [];
            while (isHeader(id3Data, offset)) {
              const size = readSize(id3Data, offset + 6);
              // skip past ID3 header
              offset += 10;
              const end = offset + size;
              // loop through frames in the ID3 tag
              while (offset + 8 < end) {
                const frameData = getFrameData(id3Data.subarray(offset));
                const frame = decodeFrame(frameData);
                if (frame) {
                  frames.push(frame);
                }

                // skip frame header and frame data
                offset += frameData.size + 10;
              }
              if (isFooter(id3Data, offset)) {
                offset += 10;
              }
            }
            return frames;
          };
          const decodeFrame = frame => {
            if (frame.type === 'PRIV') {
              return decodePrivFrame(frame);
            } else if (frame.type[0] === 'W') {
              return decodeURLFrame(frame);
            }
            return decodeTextFrame(frame);
          };
          const decodePrivFrame = frame => {
            /*
            Format: <text string>\0<binary data>
            */
            if (frame.size < 2) {
              return undefined;
            }
            const owner = utf8ArrayToStr(frame.data, true);
            const privateData = new Uint8Array(frame.data.subarray(owner.length + 1));
            return {
              key: frame.type,
              info: owner,
              data: privateData.buffer
            };
          };
          const decodeTextFrame = frame => {
            if (frame.size < 2) {
              return undefined;
            }
            if (frame.type === 'TXXX') {
              /*
              Format:
              [0]   = {Text Encoding}
              [1-?] = {Description}\0{Value}
              */
              let index = 1;
              const description = utf8ArrayToStr(frame.data.subarray(index), true);
              index += description.length + 1;
              const value = utf8ArrayToStr(frame.data.subarray(index));
              return {
                key: frame.type,
                info: description,
                data: value
              };
            }
            /*
            Format:
            [0]   = {Text Encoding}
            [1-?] = {Value}
            */
            const text = utf8ArrayToStr(frame.data.subarray(1));
            return {
              key: frame.type,
              data: text
            };
          };
          const decodeURLFrame = frame => {
            if (frame.type === 'WXXX') {
              /*
              Format:
              [0]   = {Text Encoding}
              [1-?] = {Description}\0{URL}
              */
              if (frame.size < 2) {
                return undefined;
              }
              let index = 1;
              const description = utf8ArrayToStr(frame.data.subarray(index), true);
              index += description.length + 1;
              const value = utf8ArrayToStr(frame.data.subarray(index));
              return {
                key: frame.type,
                info: description,
                data: value
              };
            }
            /*
            Format:
            [0-?] = {URL}
            */
            const url = utf8ArrayToStr(frame.data);
            return {
              key: frame.type,
              data: url
            };
          };
          const readTimeStamp = timeStampFrame => {
            if (timeStampFrame.data.byteLength === 8) {
              const data = new Uint8Array(timeStampFrame.data);
              // timestamp is 33 bit expressed as a big-endian eight-octet number,
              // with the upper 31 bits set to zero.
              const pts33Bit = data[3] & 0x1;
              let timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];
              timestamp /= 45;
              if (pts33Bit) {
                timestamp += 47721858.84;
              } // 2^32 / 90

              return Math.round(timestamp);
            }
            return undefined;
          };

          // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197
          // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt
          /* utf.js - UTF-8 <=> UTF-16 convertion
           *
           * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>
           * Version: 1.0
           * LastModified: Dec 25 1999
           * This library is free.  You can redistribute it and/or modify it.
           */
          const utf8ArrayToStr = (array, exitOnNull = false) => {
            const decoder = getTextDecoder();
            if (decoder) {
              const decoded = decoder.decode(array);
              if (exitOnNull) {
                // grab up to the first null
                const idx = decoded.indexOf('\0');
                return idx !== -1 ? decoded.substring(0, idx) : decoded;
              }

              // remove any null characters
              return decoded.replace(/\0/g, '');
            }
            const len = array.length;
            let c;
            let char2;
            let char3;
            let out = '';
            let i = 0;
            while (i < len) {
              c = array[i++];
              if (c === 0x00 && exitOnNull) {
                return out;
              } else if (c === 0x00 || c === 0x03) {
                // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it
                continue;
              }
              switch (c >> 4) {
                case 0:
                case 1:
                case 2:
                case 3:
                case 4:
                case 5:
                case 6:
                case 7:
                  // 0xxxxxxx
                  out += String.fromCharCode(c);
                  break;
                case 12:
                case 13:
                  // 110x xxxx   10xx xxxx
                  char2 = array[i++];
                  out += String.fromCharCode((c & 0x1f) << 6 | char2 & 0x3f);
                  break;
                case 14:
                  // 1110 xxxx  10xx xxxx  10xx xxxx
                  char2 = array[i++];
                  char3 = array[i++];
                  out += String.fromCharCode((c & 0x0f) << 12 | (char2 & 0x3f) << 6 | (char3 & 0x3f) << 0);
                  break;
                default:
              }
            }
            return out;
          };
          const testables = {
            decodeTextFrame: decodeTextFrame
          };
          let decoder;
          function getTextDecoder() {
            if (!decoder && typeof self.TextDecoder !== 'undefined') {
              decoder = new self.TextDecoder('utf-8');
            }
            return decoder;
          }

          /***/
        }),

/***/ "./src/demux/mp3demuxer.ts":
/*!*********************************!*\
  !*** ./src/demux/mp3demuxer.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base-audio-demuxer */ "./src/demux/base-audio-demuxer.ts");
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _mpegaudio__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./mpegaudio */ "./src/demux/mpegaudio.ts");
          /**
           * MP3 demuxer
           */




          class MP3Demuxer extends _base_audio_demuxer__WEBPACK_IMPORTED_MODULE_0__["default"] {
            resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
              super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);
              this._audioTrack = {
                container: 'audio/mpeg',
                type: 'audio',
                id: 2,
                pid: -1,
                sequenceNumber: 0,
                segmentCodec: 'mp3',
                samples: [],
                manifestCodec: audioCodec,
                duration: trackDuration,
                inputTimeScale: 90000,
                dropped: 0
              };
            }
            static probe(data) {
              if (!data) {
                return false;
              }

              // check if data contains ID3 timestamp and MPEG sync word
              // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1
              // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)
              // More info http://www.mp3-tech.org/programmer/frame_header.html
              const id3Data = _demux_id3__WEBPACK_IMPORTED_MODULE_1__.getID3Data(data, 0) || [];
              let offset = id3Data.length;
              for (let length = data.length; offset < length; offset++) {
                if (_mpegaudio__WEBPACK_IMPORTED_MODULE_3__.probe(data, offset)) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.log('MPEG Audio sync word found !');
                  return true;
                }
              }
              return false;
            }
            canParse(data, offset) {
              return _mpegaudio__WEBPACK_IMPORTED_MODULE_3__.canParse(data, offset);
            }
            appendFrame(track, data, offset) {
              if (this.basePTS === null) {
                return;
              }
              return _mpegaudio__WEBPACK_IMPORTED_MODULE_3__.appendFrame(track, data, offset, this.basePTS, this.frameIndex);
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (MP3Demuxer);

          /***/
        }),

/***/ "./src/demux/mp4demuxer.ts":
/*!*********************************!*\
  !*** ./src/demux/mp4demuxer.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _types_demuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../types/demuxer */ "./src/types/demuxer.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./dummy-demuxed-track */ "./src/demux/dummy-demuxed-track.ts");
          /**
           * MP4 demuxer
           */



          const emsgSchemePattern = /\/emsg[-/]ID3/i;
          class MP4Demuxer {
            remainderData = null;
            timeOffset = 0;
            constructor(observer, config) {
              this.config = config;
            }
            resetTimeStamp() { }
            resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
              const videoTrack = this.videoTrack = (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)('video', 1);
              const audioTrack = this.audioTrack = (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)('audio', 1);
              const captionTrack = this.txtTrack = (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)('text', 1);
              this.id3Track = (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)('id3', 1);
              this.timeOffset = 0;
              if (!initSegment || !initSegment.byteLength) {
                return;
              }
              const initData = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.parseInitSegment)(initSegment);
              if (initData.video) {
                const {
                  id,
                  timescale,
                  codec
                } = initData.video;
                videoTrack.id = id;
                videoTrack.timescale = captionTrack.timescale = timescale;
                videoTrack.codec = codec;
              }
              if (initData.audio) {
                const {
                  id,
                  timescale,
                  codec
                } = initData.audio;
                audioTrack.id = id;
                audioTrack.timescale = timescale;
                audioTrack.codec = codec;
              }
              captionTrack.id = _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.RemuxerTrackIdConfig.text;
              videoTrack.sampleDuration = 0;
              videoTrack.duration = audioTrack.duration = trackDuration;
            }
            resetContiguity() { }
            static probe(data) {
              // ensure we find a moof box in the first 16 kB
              data = data.length > 16384 ? data.subarray(0, 16384) : data;
              return (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.findBox)(data, ['moof']).length > 0;
            }
            demux(data, timeOffset) {
              this.timeOffset = timeOffset;
              // Load all data into the avc track. The CMAF remuxer will look for the data in the samples object; the rest of the fields do not matter
              let videoSamples = data;
              const videoTrack = this.videoTrack;
              const textTrack = this.txtTrack;
              if (this.config.progressive) {
                // Split the bytestream into two ranges: one encompassing all data up until the start of the last moof, and everything else.
                // This is done to guarantee that we're sending valid data to MSE - when demuxing progressively, we have no guarantee
                // that the fetch loader gives us flush moof+mdat pairs. If we push jagged data to MSE, it will throw an exception.
                if (this.remainderData) {
                  videoSamples = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.appendUint8Array)(this.remainderData, data);
                }
                const segmentedData = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.segmentValidRange)(videoSamples);
                this.remainderData = segmentedData.remainder;
                videoTrack.samples = segmentedData.valid || new Uint8Array();
              } else {
                videoTrack.samples = videoSamples;
              }
              const id3Track = this.extractID3Track(videoTrack, timeOffset);
              textTrack.samples = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.parseSamples)(timeOffset, videoTrack);
              return {
                videoTrack,
                audioTrack: this.audioTrack,
                id3Track,
                textTrack: this.txtTrack
              };
            }
            flush() {
              const timeOffset = this.timeOffset;
              const videoTrack = this.videoTrack;
              const textTrack = this.txtTrack;
              videoTrack.samples = this.remainderData || new Uint8Array();
              this.remainderData = null;
              const id3Track = this.extractID3Track(videoTrack, this.timeOffset);
              textTrack.samples = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.parseSamples)(timeOffset, videoTrack);
              return {
                videoTrack,
                audioTrack: (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)(),
                id3Track,
                textTrack: (0, _dummy_demuxed_track__WEBPACK_IMPORTED_MODULE_2__.dummyTrack)()
              };
            }
            extractID3Track(videoTrack, timeOffset) {
              const id3Track = this.id3Track;
              if (videoTrack.samples.length) {
                const emsgs = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.findBox)(videoTrack.samples, ['emsg']);
                if (emsgs) {
                  emsgs.forEach(data => {
                    const emsgInfo = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.parseEmsg)(data);
                    if (emsgSchemePattern.test(emsgInfo.schemeIdUri)) {
                      const pts = Number.isFinite(emsgInfo.presentationTime) ? emsgInfo.presentationTime / emsgInfo.timeScale : timeOffset + emsgInfo.presentationTimeDelta / emsgInfo.timeScale;
                      let duration = emsgInfo.eventDuration === 0xffffffff ? Number.POSITIVE_INFINITY : emsgInfo.eventDuration / emsgInfo.timeScale;
                      // Safari takes anything <= 0.001 seconds and maps it to Infinity
                      if (duration <= 0.001) {
                        duration = Number.POSITIVE_INFINITY;
                      }
                      const payload = emsgInfo.payload;
                      id3Track.samples.push({
                        data: payload,
                        len: payload.byteLength,
                        dts: pts,
                        pts: pts,
                        type: _types_demuxer__WEBPACK_IMPORTED_MODULE_0__.MetadataSchema.emsg,
                        duration: duration
                      });
                    }
                  });
                }
              }
              return id3Track;
            }
            demuxSampleAes(data, keyData, timeOffset) {
              return Promise.reject(new Error('The MP4 demuxer does not support SAMPLE-AES decryption'));
            }
            destroy() { }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (MP4Demuxer);

          /***/
        }),

/***/ "./src/demux/mpegaudio.ts":
/*!********************************!*\
  !*** ./src/demux/mpegaudio.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "appendFrame": () => (/* binding */ appendFrame),
/* harmony export */   "canParse": () => (/* binding */ canParse),
/* harmony export */   "isHeader": () => (/* binding */ isHeader),
/* harmony export */   "isHeaderPattern": () => (/* binding */ isHeaderPattern),
/* harmony export */   "parseHeader": () => (/* binding */ parseHeader),
/* harmony export */   "probe": () => (/* binding */ probe)
            /* harmony export */
          });
          /**
           *  MPEG parser helper
           */

          let chromeVersion = null;
          const BitratesMap = [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160];
          const SamplingRateMap = [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000];
          const SamplesCoefficients = [
            // MPEG 2.5
            [0,
              // Reserved
              72,
              // Layer3
              144,
              // Layer2
              12 // Layer1
            ],
            // Reserved
            [0,
              // Reserved
              0,
              // Layer3
              0,
              // Layer2
              0 // Layer1
            ],
            // MPEG 2
            [0,
              // Reserved
              72,
              // Layer3
              144,
              // Layer2
              12 // Layer1
            ],
            // MPEG 1
            [0,
              // Reserved
              144,
              // Layer3
              144,
              // Layer2
              12 // Layer1
            ]];

          const BytesInSlot = [0,
            // Reserved
            1,
            // Layer3
            1,
            // Layer2
            4 // Layer1
          ];

          function appendFrame(track, data, offset, pts, frameIndex) {
            // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference
            if (offset + 24 > data.length) {
              return;
            }
            const header = parseHeader(data, offset);
            if (header && offset + header.frameLength <= data.length) {
              const frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;
              const stamp = pts + frameIndex * frameDuration;
              const sample = {
                unit: data.subarray(offset, offset + header.frameLength),
                pts: stamp,
                dts: stamp
              };
              track.config = [];
              track.channelCount = header.channelCount;
              track.samplerate = header.sampleRate;
              track.samples.push(sample);
              return {
                sample,
                length: header.frameLength,
                missing: 0
              };
            }
          }
          function parseHeader(data, offset) {
            const mpegVersion = data[offset + 1] >> 3 & 3;
            const mpegLayer = data[offset + 1] >> 1 & 3;
            const bitRateIndex = data[offset + 2] >> 4 & 15;
            const sampleRateIndex = data[offset + 2] >> 2 & 3;
            if (mpegVersion !== 1 && bitRateIndex !== 0 && bitRateIndex !== 15 && sampleRateIndex !== 3) {
              const paddingBit = data[offset + 2] >> 1 & 1;
              const channelMode = data[offset + 3] >> 6;
              const columnInBitrates = mpegVersion === 3 ? 3 - mpegLayer : mpegLayer === 3 ? 3 : 4;
              const bitRate = BitratesMap[columnInBitrates * 14 + bitRateIndex - 1] * 1000;
              const columnInSampleRates = mpegVersion === 3 ? 0 : mpegVersion === 2 ? 1 : 2;
              const sampleRate = SamplingRateMap[columnInSampleRates * 3 + sampleRateIndex];
              const channelCount = channelMode === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)
              const sampleCoefficient = SamplesCoefficients[mpegVersion][mpegLayer];
              const bytesInSlot = BytesInSlot[mpegLayer];
              const samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;
              const frameLength = Math.floor(sampleCoefficient * bitRate / sampleRate + paddingBit) * bytesInSlot;
              if (chromeVersion === null) {
                const userAgent = navigator.userAgent || '';
                const result = userAgent.match(/Chrome\/(\d+)/i);
                chromeVersion = result ? parseInt(result[1]) : 0;
              }
              const needChromeFix = !!chromeVersion && chromeVersion <= 87;
              if (needChromeFix && mpegLayer === 2 && bitRate >= 224000 && channelMode === 0) {
                // Work around bug in Chromium by setting channelMode to dual-channel (01) instead of stereo (00)
                data[offset + 3] = data[offset + 3] | 0x80;
              }
              return {
                sampleRate,
                channelCount,
                frameLength,
                samplesPerFrame
              };
            }
          }
          function isHeaderPattern(data, offset) {
            return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;
          }
          function isHeader(data, offset) {
            // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1
            // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)
            // More info http://www.mp3-tech.org/programmer/frame_header.html
            return offset + 1 < data.length && isHeaderPattern(data, offset);
          }
          function canParse(data, offset) {
            const headerSize = 4;
            return isHeaderPattern(data, offset) && headerSize <= data.length - offset;
          }
          function probe(data, offset) {
            // same as isHeader but we also check that MPEG frame follows last MPEG frame
            // or end of data is reached
            if (offset + 1 < data.length && isHeaderPattern(data, offset)) {
              // MPEG header Length
              const headerLength = 4;
              // MPEG frame Length
              const header = parseHeader(data, offset);
              let frameLength = headerLength;
              if (header?.frameLength) {
                frameLength = header.frameLength;
              }
              const newOffset = offset + frameLength;
              return newOffset === data.length || isHeader(data, newOffset);
            }
            return false;
          }

          /***/
        }),

/***/ "./src/demux/sample-aes.ts":
/*!*********************************!*\
  !*** ./src/demux/sample-aes.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _crypt_decrypter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../crypt/decrypter */ "./src/crypt/decrypter.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
          /**
           * SAMPLE-AES decrypter
           */



          class SampleAesDecrypter {
            constructor(observer, config, keyData) {
              this.keyData = keyData;
              this.decrypter = new _crypt_decrypter__WEBPACK_IMPORTED_MODULE_0__["default"](config, {
                removePKCS7Padding: false
              });
            }
            decryptBuffer(encryptedData) {
              return this.decrypter.decrypt(encryptedData, this.keyData.key.buffer, this.keyData.iv.buffer);
            }

            // AAC - encrypt all full 16 bytes blocks starting from offset 16
            decryptAacSample(samples, sampleIndex, callback) {
              const curUnit = samples[sampleIndex].unit;
              if (curUnit.length <= 16) {
                // No encrypted portion in this sample (first 16 bytes is not
                // encrypted, see https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/HLS_Sample_Encryption/Encryption/Encryption.html),
                return;
              }
              const encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);
              const encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);
              this.decryptBuffer(encryptedBuffer).then(decryptedBuffer => {
                const decryptedData = new Uint8Array(decryptedBuffer);
                curUnit.set(decryptedData, 16);
                if (!this.decrypter.isSync()) {
                  this.decryptAacSamples(samples, sampleIndex + 1, callback);
                }
              });
            }
            decryptAacSamples(samples, sampleIndex, callback) {
              for (; ; sampleIndex++) {
                if (sampleIndex >= samples.length) {
                  callback();
                  return;
                }
                if (samples[sampleIndex].unit.length < 32) {
                  continue;
                }
                this.decryptAacSample(samples, sampleIndex, callback);
                if (!this.decrypter.isSync()) {
                  return;
                }
              }
            }

            // AVC - encrypt one 16 bytes block out of ten, starting from offset 32
            getAvcEncryptedData(decodedData) {
              const encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;
              const encryptedData = new Int8Array(encryptedDataLen);
              let outputPos = 0;
              for (let inputPos = 32; inputPos < decodedData.length - 16; inputPos += 160, outputPos += 16) {
                encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);
              }
              return encryptedData;
            }
            getAvcDecryptedUnit(decodedData, decryptedData) {
              const uint8DecryptedData = new Uint8Array(decryptedData);
              let inputPos = 0;
              for (let outputPos = 32; outputPos < decodedData.length - 16; outputPos += 160, inputPos += 16) {
                decodedData.set(uint8DecryptedData.subarray(inputPos, inputPos + 16), outputPos);
              }
              return decodedData;
            }
            decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit) {
              const decodedData = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.discardEPB)(curUnit.data);
              const encryptedData = this.getAvcEncryptedData(decodedData);
              this.decryptBuffer(encryptedData.buffer).then(decryptedBuffer => {
                curUnit.data = this.getAvcDecryptedUnit(decodedData, decryptedBuffer);
                if (!this.decrypter.isSync()) {
                  this.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);
                }
              });
            }
            decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {
              if (samples instanceof Uint8Array) {
                throw new Error('Cannot decrypt samples of type Uint8Array');
              }
              for (; ; sampleIndex++, unitIndex = 0) {
                if (sampleIndex >= samples.length) {
                  callback();
                  return;
                }
                const curUnits = samples[sampleIndex].units;
                for (; ; unitIndex++) {
                  if (unitIndex >= curUnits.length) {
                    break;
                  }
                  const curUnit = curUnits[unitIndex];
                  if (curUnit.data.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) {
                    continue;
                  }
                  this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit);
                  if (!this.decrypter.isSync()) {
                    return;
                  }
                }
              }
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SampleAesDecrypter);

          /***/
        }),

/***/ "./src/demux/transmuxer-interface.ts":
/*!*******************************************!*\
  !*** ./src/demux/transmuxer-interface.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TransmuxerInterface)
            /* harmony export */
          });
/* harmony import */ var _webworkify_webpack__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./webworkify-webpack */ "./src/demux/webworkify-webpack.js");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/transmuxer */ "./src/demux/transmuxer.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/mediasource-helper */ "./src/utils/mediasource-helper.ts");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(eventemitter3__WEBPACK_IMPORTED_MODULE_6__);







          const MediaSource = (0, _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_5__.getMediaSource)() || {
            isTypeSupported: () => false
          };
          class TransmuxerInterface {
            frag = null;
            part = null;
            transmuxer = null;
            constructor(hls, id, onTransmuxComplete, onFlush) {
              const config = hls.config;
              this.hls = hls;
              this.id = id;
              this.useWorker = !!config.enableWorker;
              this.onTransmuxComplete = onTransmuxComplete;
              this.onFlush = onFlush;
              const forwardMessage = (ev, data) => {
                data = data || {};
                data.frag = this.frag;
                data.id = this.id;
                this.hls.trigger(ev, data);
              };

              // forward events to main thread
              this.observer = new eventemitter3__WEBPACK_IMPORTED_MODULE_6__.EventEmitter();
              this.observer.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_DECRYPTED, forwardMessage);
              this.observer.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, forwardMessage);
              const typeSupported = {
                mp4: MediaSource.isTypeSupported('video/mp4'),
                mpeg: MediaSource.isTypeSupported('audio/mpeg'),
                mp3: MediaSource.isTypeSupported('audio/mp4; codecs="mp3"')
              };
              // navigator.vendor is not always available in Web Worker
              // refer to https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope/navigator
              const vendor = navigator.vendor;
              if (this.useWorker && typeof Worker !== 'undefined') {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.log('demuxing in webworker');
                let worker;
                try {
                  worker = this.worker = (0, _webworkify_webpack__WEBPACK_IMPORTED_MODULE_0__["default"])(/*require.resolve*/(/*! ../demux/transmuxer-worker.ts */ "./src/demux/transmuxer-worker.ts"));
                  this.onwmsg = this.onWorkerMessage.bind(this);
                  worker.addEventListener('message', this.onwmsg);
                  worker.onerror = event => {
                    this.useWorker = false;
                    _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('Exception in webworker, fallback to inline');
                    this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, {
                      type: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorTypes.OTHER_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorDetails.INTERNAL_EXCEPTION,
                      fatal: false,
                      event: 'demuxerWorker',
                      error: new Error(`${event.message}  (${event.filename}:${event.lineno})`)
                    });
                  };
                  worker.postMessage({
                    cmd: 'init',
                    typeSupported: typeSupported,
                    vendor: vendor,
                    id: id,
                    config: JSON.stringify(config)
                  });
                } catch (err) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('Error in worker:', err);
                  _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.error('Error while initializing DemuxerWorker, fallback to inline');
                  if (worker) {
                    // revoke the Object URL that was used to create transmuxer worker, so as not to leak it
                    self.URL.revokeObjectURL(worker.objectURL);
                  }
                  this.transmuxer = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["default"](this.observer, typeSupported, config, vendor, id);
                  this.worker = null;
                }
              } else {
                this.transmuxer = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__["default"](this.observer, typeSupported, config, vendor, id);
              }
            }
            destroy() {
              const w = this.worker;
              if (w) {
                w.removeEventListener('message', this.onwmsg);
                w.terminate();
                this.worker = null;
                this.onwmsg = undefined;
              } else {
                const transmuxer = this.transmuxer;
                if (transmuxer) {
                  transmuxer.destroy();
                  this.transmuxer = null;
                }
              }
              const observer = this.observer;
              if (observer) {
                observer.removeAllListeners();
              }
              this.frag = null;
              // @ts-ignore
              this.observer = null;
              // @ts-ignore
              this.hls = null;
            }
            push(data, initSegmentData, audioCodec, videoCodec, frag, part, duration, accurateTimeOffset, chunkMeta, defaultInitPTS) {
              chunkMeta.transmuxing.start = self.performance.now();
              const {
                transmuxer,
                worker
              } = this;
              const timeOffset = part ? part.start : frag.start;
              // TODO: push "clear-lead" decrypt data for unencrypted fragments in streams with encrypted ones
              const decryptdata = frag.decryptdata;
              const lastFrag = this.frag;
              const discontinuity = !(lastFrag && frag.cc === lastFrag.cc);
              const trackSwitch = !(lastFrag && chunkMeta.level === lastFrag.level);
              const snDiff = lastFrag ? chunkMeta.sn - lastFrag.sn : -1;
              const partDiff = this.part ? chunkMeta.part - this.part.index : -1;
              const progressive = snDiff === 0 && chunkMeta.id > 1 && chunkMeta.id === lastFrag?.stats.chunkCount;
              const contiguous = !trackSwitch && (snDiff === 1 || snDiff === 0 && (partDiff === 1 || progressive && partDiff <= 0));
              const now = self.performance.now();
              if (trackSwitch || snDiff || frag.stats.parsing.start === 0) {
                frag.stats.parsing.start = now;
              }
              if (part && (partDiff || !contiguous)) {
                part.stats.parsing.start = now;
              }
              const initSegmentChange = !(lastFrag && frag.initSegment?.url === lastFrag.initSegment?.url);
              const state = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__.TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange);
              if (!contiguous || discontinuity || initSegmentChange) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.log(`[transmuxer-interface, ${frag.type}]: Starting new transmux session for sn: ${chunkMeta.sn} p: ${chunkMeta.part} level: ${chunkMeta.level} id: ${chunkMeta.id}
        discontinuity: ${discontinuity}
        trackSwitch: ${trackSwitch}
        contiguous: ${contiguous}
        accurateTimeOffset: ${accurateTimeOffset}
        timeOffset: ${timeOffset}
        initSegmentChange: ${initSegmentChange}`);
                const config = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__.TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPTS);
                this.configureTransmuxer(config);
              }
              this.frag = frag;
              this.part = part;

              // Frags with sn of 'initSegment' are not transmuxed
              if (worker) {
                // post fragment payload as transferable objects for ArrayBuffer (no copy)
                worker.postMessage({
                  cmd: 'demux',
                  data,
                  decryptdata,
                  chunkMeta,
                  state
                }, data instanceof ArrayBuffer ? [data] : []);
              } else if (transmuxer) {
                const transmuxResult = transmuxer.push(data, decryptdata, chunkMeta, state);
                if ((0, _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__.isPromise)(transmuxResult)) {
                  transmuxer.async = true;
                  transmuxResult.then(data => {
                    this.handleTransmuxComplete(data);
                  }).catch(error => {
                    this.transmuxerError(error, chunkMeta, 'transmuxer-interface push error');
                  });
                } else {
                  transmuxer.async = false;
                  this.handleTransmuxComplete(transmuxResult);
                }
              }
            }
            flush(chunkMeta) {
              chunkMeta.transmuxing.start = self.performance.now();
              const {
                transmuxer,
                worker
              } = this;
              if (worker) {
                1;
                worker.postMessage({
                  cmd: 'flush',
                  chunkMeta
                });
              } else if (transmuxer) {
                let transmuxResult = transmuxer.flush(chunkMeta);
                const asyncFlush = (0, _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__.isPromise)(transmuxResult);
                if (asyncFlush || transmuxer.async) {
                  if (!(0, _demux_transmuxer__WEBPACK_IMPORTED_MODULE_2__.isPromise)(transmuxResult)) {
                    transmuxResult = Promise.resolve(transmuxResult);
                  }
                  transmuxResult.then(data => {
                    this.handleFlushResult(data, chunkMeta);
                  }).catch(error => {
                    this.transmuxerError(error, chunkMeta, 'transmuxer-interface flush error');
                  });
                } else {
                  this.handleFlushResult(transmuxResult, chunkMeta);
                }
              }
            }
            transmuxerError(error, chunkMeta, reason) {
              if (!this.hls) {
                return;
              }
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorTypes.MEDIA_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorDetails.FRAG_PARSING_ERROR,
                chunkMeta,
                fatal: false,
                error,
                err: error,
                reason
              });
            }
            handleFlushResult(results, chunkMeta) {
              results.forEach(result => {
                this.handleTransmuxComplete(result);
              });
              this.onFlush(chunkMeta);
            }
            onWorkerMessage(ev) {
              const data = ev.data;
              const hls = this.hls;
              switch (data.event) {
                case 'init':
                  {
                    // revoke the Object URL that was used to create transmuxer worker, so as not to leak it
                    self.URL.revokeObjectURL(this.worker.objectURL);
                    break;
                  }
                case 'transmuxComplete':
                  {
                    this.handleTransmuxComplete(data.data);
                    break;
                  }
                case 'flush':
                  {
                    this.onFlush(data.data);
                    break;
                  }

                // pass logs from the worker thread to the main logger
                case 'workerLog':
                  if (_utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger[data.data.logType]) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger[data.data.logType](data.data.message);
                  }
                  break;
                default:
                  {
                    data.data = data.data || {};
                    data.data.frag = this.frag;
                    data.data.id = this.id;
                    hls.trigger(data.event, data.data);
                    break;
                  }
              }
            }
            configureTransmuxer(config) {
              const {
                worker,
                transmuxer
              } = this;
              if (worker) {
                worker.postMessage({
                  cmd: 'configure',
                  config
                });
              } else if (transmuxer) {
                transmuxer.configure(config);
              }
            }
            handleTransmuxComplete(result) {
              result.chunkMeta.transmuxing.end = self.performance.now();
              this.onTransmuxComplete(result);
            }
          }

          /***/
        }),

/***/ "./src/demux/transmuxer-worker.ts":
/*!****************************************!*\
  !*** ./src/demux/transmuxer-worker.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TransmuxerWorker)
            /* harmony export */
          });
/* harmony import */ var _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../demux/transmuxer */ "./src/demux/transmuxer.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(eventemitter3__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");





          function TransmuxerWorker(self) {
            const observer = new eventemitter3__WEBPACK_IMPORTED_MODULE_3__.EventEmitter();
            const forwardMessage = (ev, data) => {
              self.postMessage({
                event: ev,
                data: data
              });
            };

            // forward events to main thread
            observer.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.FRAG_DECRYPTED, forwardMessage);
            observer.on(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, forwardMessage);

            // forward logger events to main thread
            const forwardWorkerLogs = () => {
              for (const logFn in _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger) {
                const func = message => {
                  forwardMessage('workerLog', {
                    logType: logFn,
                    message
                  });
                };
                _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger[logFn] = func;
              }
            };
            self.addEventListener('message', ev => {
              const data = ev.data;
              switch (data.cmd) {
                case 'init':
                  {
                    const config = JSON.parse(data.config);
                    self.transmuxer = new _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__["default"](observer, data.typeSupported, config, data.vendor, data.id);
                    (0, _utils_logger__WEBPACK_IMPORTED_MODULE_2__.enableLogs)(config.debug, data.id);
                    forwardWorkerLogs();
                    forwardMessage('init', null);
                    break;
                  }
                case 'configure':
                  {
                    self.transmuxer.configure(data.config);
                    break;
                  }
                case 'demux':
                  {
                    const transmuxResult = self.transmuxer.push(data.data, data.decryptdata, data.chunkMeta, data.state);
                    if ((0, _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__.isPromise)(transmuxResult)) {
                      self.transmuxer.async = true;
                      transmuxResult.then(data => {
                        emitTransmuxComplete(self, data);
                      }).catch(error => {
                        forwardMessage(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, {
                          type: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorTypes.MEDIA_ERROR,
                          details: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorDetails.FRAG_PARSING_ERROR,
                          chunkMeta: data.chunkMeta,
                          fatal: false,
                          error,
                          err: error,
                          reason: `transmuxer-worker push error`
                        });
                      });
                    } else {
                      self.transmuxer.async = false;
                      emitTransmuxComplete(self, transmuxResult);
                    }
                    break;
                  }
                case 'flush':
                  {
                    const id = data.chunkMeta;
                    let transmuxResult = self.transmuxer.flush(id);
                    const asyncFlush = (0, _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__.isPromise)(transmuxResult);
                    if (asyncFlush || self.transmuxer.async) {
                      if (!(0, _demux_transmuxer__WEBPACK_IMPORTED_MODULE_0__.isPromise)(transmuxResult)) {
                        transmuxResult = Promise.resolve(transmuxResult);
                      }
                      transmuxResult.then(results => {
                        handleFlushResult(self, results, id);
                      }).catch(error => {
                        forwardMessage(_events__WEBPACK_IMPORTED_MODULE_1__.Events.ERROR, {
                          type: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorTypes.MEDIA_ERROR,
                          details: _errors__WEBPACK_IMPORTED_MODULE_4__.ErrorDetails.FRAG_PARSING_ERROR,
                          chunkMeta: data.chunkMeta,
                          fatal: false,
                          error,
                          err: error,
                          reason: `transmuxer-worker flush error`
                        });
                      });
                    } else {
                      handleFlushResult(self, transmuxResult, id);
                    }
                    break;
                  }
                default:
                  break;
              }
            });
          }
          function emitTransmuxComplete(self, transmuxResult) {
            if (isEmptyResult(transmuxResult.remuxResult)) {
              return false;
            }
            const transferable = [];
            const {
              audio,
              video
            } = transmuxResult.remuxResult;
            if (audio) {
              addToTransferable(transferable, audio);
            }
            if (video) {
              addToTransferable(transferable, video);
            }
            self.postMessage({
              event: 'transmuxComplete',
              data: transmuxResult
            }, transferable);
            return true;
          }

          // Converts data to a transferable object https://developers.google.com/web/updates/2011/12/Transferable-Objects-Lightning-Fast)
          // in order to minimize message passing overhead
          function addToTransferable(transferable, track) {
            if (track.data1) {
              transferable.push(track.data1.buffer);
            }
            if (track.data2) {
              transferable.push(track.data2.buffer);
            }
          }
          function handleFlushResult(self, results, chunkMeta) {
            const parsed = results.reduce((parsed, result) => emitTransmuxComplete(self, result) || parsed, false);
            if (!parsed) {
              // Emit at least one "transmuxComplete" message even if media is not found to update stream-controller state to PARSING
              self.postMessage({
                event: 'transmuxComplete',
                data: results[0]
              });
            }
            self.postMessage({
              event: 'flush',
              data: chunkMeta
            });
          }
          function isEmptyResult(remuxResult) {
            return !remuxResult.audio && !remuxResult.video && !remuxResult.text && !remuxResult.id3 && !remuxResult.initSegment;
          }

          /***/
        }),

/***/ "./src/demux/transmuxer.ts":
/*!*********************************!*\
  !*** ./src/demux/transmuxer.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "TransmuxConfig": () => (/* binding */ TransmuxConfig),
/* harmony export */   "TransmuxState": () => (/* binding */ TransmuxState),
/* harmony export */   "default": () => (/* binding */ Transmuxer),
/* harmony export */   "isPromise": () => (/* binding */ isPromise)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _crypt_decrypter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../crypt/decrypter */ "./src/crypt/decrypter.ts");
/* harmony import */ var _demux_aacdemuxer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../demux/aacdemuxer */ "./src/demux/aacdemuxer.ts");
/* harmony import */ var _demux_mp4demuxer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../demux/mp4demuxer */ "./src/demux/mp4demuxer.ts");
/* harmony import */ var _demux_tsdemuxer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../demux/tsdemuxer */ "./src/demux/tsdemuxer.ts");
/* harmony import */ var _demux_mp3demuxer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../demux/mp3demuxer */ "./src/demux/mp3demuxer.ts");
/* harmony import */ var _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../remux/mp4-remuxer */ "./src/remux/mp4-remuxer.ts");
/* harmony import */ var _remux_passthrough_remuxer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../remux/passthrough-remuxer */ "./src/remux/passthrough-remuxer.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");










          let now;
          // performance.now() not available on WebWorker, at least on Safari Desktop
          try {
            now = self.performance.now.bind(self.performance);
          } catch (err) {
            _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.debug('Unable to use Performance API on this environment');
            now = self.Date.now;
          }
          const muxConfig = [{
            demux: _demux_tsdemuxer__WEBPACK_IMPORTED_MODULE_5__["default"],
            remux: _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__["default"]
          }, {
            demux: _demux_mp4demuxer__WEBPACK_IMPORTED_MODULE_4__["default"],
            remux: _remux_passthrough_remuxer__WEBPACK_IMPORTED_MODULE_8__["default"]
          }, {
            demux: _demux_aacdemuxer__WEBPACK_IMPORTED_MODULE_3__["default"],
            remux: _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__["default"]
          }, {
            demux: _demux_mp3demuxer__WEBPACK_IMPORTED_MODULE_6__["default"],
            remux: _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_7__["default"]
          }];
          class Transmuxer {
            async = false;
            decryptionPromise = null;
            constructor(observer, typeSupported, config, vendor, id) {
              this.observer = observer;
              this.typeSupported = typeSupported;
              this.config = config;
              this.vendor = vendor;
              this.id = id;
            }
            configure(transmuxConfig) {
              this.transmuxConfig = transmuxConfig;
              if (this.decrypter) {
                this.decrypter.reset();
              }
            }
            push(data, decryptdata, chunkMeta, state) {
              const stats = chunkMeta.transmuxing;
              stats.executeStart = now();
              let uintData = new Uint8Array(data);
              const {
                currentTransmuxState,
                transmuxConfig
              } = this;
              if (state) {
                this.currentTransmuxState = state;
              }
              const {
                contiguous,
                discontinuity,
                trackSwitch,
                accurateTimeOffset,
                timeOffset,
                initSegmentChange
              } = state || currentTransmuxState;
              const {
                audioCodec,
                videoCodec,
                defaultInitPts,
                duration,
                initSegmentData
              } = transmuxConfig;
              const keyData = getEncryptionType(uintData, decryptdata);
              if (keyData && keyData.method === 'AES-128') {
                const decrypter = this.getDecrypter();
                // Software decryption is synchronous; webCrypto is not
                if (decrypter.isSync()) {
                  // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached
                  // data is handled in the flush() call
                  const decryptedData = decrypter.softwareDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer);
                  if (!decryptedData) {
                    stats.executeEnd = now();
                    return emptyResult(chunkMeta);
                  }
                  uintData = new Uint8Array(decryptedData);
                } else {
                  this.decryptionPromise = decrypter.webCryptoDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer).then(decryptedData => {
                    // Calling push here is important; if flush() is called while this is still resolving, this ensures that
                    // the decrypted data has been transmuxed
                    const result = this.push(decryptedData, null, chunkMeta);
                    this.decryptionPromise = null;
                    return result;
                  });
                  return this.decryptionPromise;
                }
              }
              const resetMuxers = this.needsProbing(discontinuity, trackSwitch);
              if (resetMuxers) {
                this.configureTransmuxer(uintData);
              }
              if (discontinuity || trackSwitch || initSegmentChange || resetMuxers) {
                this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration, decryptdata);
              }
              if (discontinuity || initSegmentChange || resetMuxers) {
                this.resetInitialTimestamp(defaultInitPts);
              }
              if (!contiguous) {
                this.resetContiguity();
              }
              const result = this.transmux(uintData, keyData, timeOffset, accurateTimeOffset, chunkMeta);
              const currentState = this.currentTransmuxState;
              currentState.contiguous = true;
              currentState.discontinuity = false;
              currentState.trackSwitch = false;
              stats.executeEnd = now();
              return result;
            }

            // Due to data caching, flush calls can produce more than one TransmuxerResult (hence the Array type)
            flush(chunkMeta) {
              const stats = chunkMeta.transmuxing;
              stats.executeStart = now();
              const {
                decrypter,
                currentTransmuxState,
                decryptionPromise
              } = this;
              if (decryptionPromise) {
                // Upon resolution, the decryption promise calls push() and returns its TransmuxerResult up the stack. Therefore
                // only flushing is required for async decryption
                return decryptionPromise.then(() => {
                  return this.flush(chunkMeta);
                });
              }
              const transmuxResults = [];
              const {
                timeOffset
              } = currentTransmuxState;
              if (decrypter) {
                // The decrypter may have data cached, which needs to be demuxed. In this case we'll have two TransmuxResults
                // This happens in the case that we receive only 1 push call for a segment (either for non-progressive downloads,
                // or for progressive downloads with small segments)
                const decryptedData = decrypter.flush();
                if (decryptedData) {
                  // Push always returns a TransmuxerResult if decryptdata is null
                  transmuxResults.push(this.push(decryptedData, null, chunkMeta));
                }
              }
              const {
                demuxer,
                remuxer
              } = this;
              if (!demuxer || !remuxer) {
                // If probing failed, then Hls.js has been given content its not able to handle
                this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, _events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.FRAG_PARSING_ERROR,
                  fatal: true,
                  reason: 'no demux matching with content found'
                });
                stats.executeEnd = now();
                return [emptyResult(chunkMeta)];
              }
              const demuxResultOrPromise = demuxer.flush(timeOffset);
              if (isPromise(demuxResultOrPromise)) {
                // Decrypt final SAMPLE-AES samples
                return demuxResultOrPromise.then(demuxResult => {
                  this.flushRemux(transmuxResults, demuxResult, chunkMeta);
                  return transmuxResults;
                });
              }
              this.flushRemux(transmuxResults, demuxResultOrPromise, chunkMeta);
              return transmuxResults;
            }
            flushRemux(transmuxResults, demuxResult, chunkMeta) {
              const {
                audioTrack,
                videoTrack,
                id3Track,
                textTrack
              } = demuxResult;
              const {
                accurateTimeOffset,
                timeOffset
              } = this.currentTransmuxState;
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`[transmuxer.ts]: Flushed fragment ${chunkMeta.sn}${chunkMeta.part > -1 ? ' p: ' + chunkMeta.part : ''} of level ${chunkMeta.level}`);
              const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, true, this.id);
              transmuxResults.push({
                remuxResult,
                chunkMeta
              });
              chunkMeta.transmuxing.executeEnd = now();
            }
            resetInitialTimestamp(defaultInitPts) {
              const {
                demuxer,
                remuxer
              } = this;
              if (!demuxer || !remuxer) {
                return;
              }
              demuxer.resetTimeStamp(defaultInitPts);
              remuxer.resetTimeStamp(defaultInitPts);
            }
            resetContiguity() {
              const {
                demuxer,
                remuxer
              } = this;
              if (!demuxer || !remuxer) {
                return;
              }
              demuxer.resetContiguity();
              remuxer.resetNextTimestamp();
            }
            resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration, decryptdata) {
              const {
                demuxer,
                remuxer
              } = this;
              if (!demuxer || !remuxer) {
                return;
              }
              demuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration);
              remuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, decryptdata);
            }
            destroy() {
              if (this.demuxer) {
                this.demuxer.destroy();
                this.demuxer = undefined;
              }
              if (this.remuxer) {
                this.remuxer.destroy();
                this.remuxer = undefined;
              }
            }
            transmux(data, keyData, timeOffset, accurateTimeOffset, chunkMeta) {
              let result;
              if (keyData && keyData.method === 'SAMPLE-AES') {
                result = this.transmuxSampleAes(data, keyData, timeOffset, accurateTimeOffset, chunkMeta);
              } else {
                result = this.transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta);
              }
              return result;
            }
            transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta) {
              const {
                audioTrack,
                videoTrack,
                id3Track,
                textTrack
              } = this.demuxer.demux(data, timeOffset, false, !this.config.progressive);
              const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, false, this.id);
              return {
                remuxResult,
                chunkMeta
              };
            }
            transmuxSampleAes(data, decryptData, timeOffset, accurateTimeOffset, chunkMeta) {
              return this.demuxer.demuxSampleAes(data, decryptData, timeOffset).then(demuxResult => {
                const remuxResult = this.remuxer.remux(demuxResult.audioTrack, demuxResult.videoTrack, demuxResult.id3Track, demuxResult.textTrack, timeOffset, accurateTimeOffset, false, this.id);
                return {
                  remuxResult,
                  chunkMeta
                };
              });
            }
            configureTransmuxer(data) {
              const {
                config,
                observer,
                typeSupported,
                vendor
              } = this;
              // probe for content type
              let mux;
              for (let i = 0, len = muxConfig.length; i < len; i++) {
                if (muxConfig[i].demux.probe(data)) {
                  mux = muxConfig[i];
                  break;
                }
              }
              if (!mux) {
                // If probing previous configs fail, use mp4 passthrough
                _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.warn('Failed to find demuxer by probing frag, treating as mp4 passthrough');
                mux = {
                  demux: _demux_mp4demuxer__WEBPACK_IMPORTED_MODULE_4__["default"],
                  remux: _remux_passthrough_remuxer__WEBPACK_IMPORTED_MODULE_8__["default"]
                };
              }
              // so let's check that current remuxer and demuxer are still valid
              const demuxer = this.demuxer;
              const remuxer = this.remuxer;
              const Remuxer = mux.remux;
              const Demuxer = mux.demux;
              if (!remuxer || !(remuxer instanceof Remuxer)) {
                this.remuxer = new Remuxer(observer, config, typeSupported, vendor);
              }
              if (!demuxer || !(demuxer instanceof Demuxer)) {
                this.demuxer = new Demuxer(observer, config, typeSupported);
                this.probe = Demuxer.probe;
              }
            }
            needsProbing(discontinuity, trackSwitch) {
              // in case of continuity change, or track switch
              // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)
              return !this.demuxer || !this.remuxer || discontinuity || trackSwitch;
            }
            getDecrypter() {
              let decrypter = this.decrypter;
              if (!decrypter) {
                decrypter = this.decrypter = new _crypt_decrypter__WEBPACK_IMPORTED_MODULE_2__["default"](this.config);
              }
              return decrypter;
            }
          }
          function getEncryptionType(data, decryptData) {
            let encryptionType = null;
            if (data.byteLength > 0 && decryptData != null && decryptData.key != null && decryptData.iv !== null && decryptData.method != null) {
              encryptionType = decryptData;
            }
            return encryptionType;
          }
          const emptyResult = chunkMeta => ({
            remuxResult: {},
            chunkMeta
          });
          function isPromise(p) {
            return 'then' in p && p.then instanceof Function;
          }
          class TransmuxConfig {
            constructor(audioCodec, videoCodec, initSegmentData, duration, defaultInitPts) {
              this.audioCodec = audioCodec;
              this.videoCodec = videoCodec;
              this.initSegmentData = initSegmentData;
              this.duration = duration;
              this.defaultInitPts = defaultInitPts;
            }
          }
          class TransmuxState {
            constructor(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange) {
              this.discontinuity = discontinuity;
              this.contiguous = contiguous;
              this.accurateTimeOffset = accurateTimeOffset;
              this.trackSwitch = trackSwitch;
              this.timeOffset = timeOffset;
              this.initSegmentChange = initSegmentChange;
            }
          }

          /***/
        }),

/***/ "./src/demux/tsdemuxer.ts":
/*!********************************!*\
  !*** ./src/demux/tsdemuxer.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _adts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./adts */ "./src/demux/adts.ts");
/* harmony import */ var _mpegaudio__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./mpegaudio */ "./src/demux/mpegaudio.ts");
/* harmony import */ var _exp_golomb__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./exp-golomb */ "./src/demux/exp-golomb.ts");
/* harmony import */ var _sample_aes__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./sample-aes */ "./src/demux/sample-aes.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _types_demuxer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../types/demuxer */ "./src/types/demuxer.ts");
          /**
           * highly optimized TS demuxer:
           * parse PAT, PMT
           * extract PES packet from audio and video PIDs
           * extract AVC/H264 NAL units and AAC/ADTS samples from PES packet
           * trigger the remuxer upon parsing completion
           * it also tries to workaround as best as it can audio codec switch (HE-AAC to AAC and vice versa), without having to restart the MediaSource.
           * it also controls the remuxing process :
           * upon discontinuity or level switch detection, it will also notifies the remuxer so that it can reset its state.
           */










          const PACKET_LENGTH = 188;
          class TSDemuxer {
            sampleAes = null;
            pmtParsed = false;
            _duration = 0;
            _pmtId = -1;
            aacOverFlow = null;
            avcSample = null;
            remainderData = null;
            constructor(observer, config, typeSupported) {
              this.observer = observer;
              this.config = config;
              this.typeSupported = typeSupported;
            }
            static probe(data) {
              const syncOffset = TSDemuxer.syncOffset(data);
              if (syncOffset > 0) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`MPEG2-TS detected but first sync word found @ offset ${syncOffset}`);
              }
              return syncOffset !== -1;
            }
            static syncOffset(data) {
              const scanwindow = Math.min(PACKET_LENGTH * 5, data.length - PACKET_LENGTH * 2) + 1;
              let i = 0;
              while (i < scanwindow) {
                // a TS init segment should contain at least 2 TS packets: PAT and PMT, each starting with 0x47
                if (data[i] === 0x47 && data[i + PACKET_LENGTH] === 0x47) {
                  return i;
                }
                i++;
              }
              return -1;
            }

            /**
             * Creates a track model internal to demuxer used to drive remuxing input
             *
             * @param type 'audio' | 'video' | 'id3' | 'text'
             * @param duration
             * @return TSDemuxer's internal track model
             */
            static createTrack(type, duration) {
              return {
                container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,
                type,
                id: _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_5__.RemuxerTrackIdConfig[type],
                pid: -1,
                inputTimeScale: 90000,
                sequenceNumber: 0,
                samples: [],
                dropped: 0,
                duration: type === 'audio' ? duration : undefined
              };
            }

            /**
             * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)
             * Resets all internal track instances of the demuxer.
             */
            resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {
              this.pmtParsed = false;
              this._pmtId = -1;
              this._avcTrack = TSDemuxer.createTrack('video');
              this._audioTrack = TSDemuxer.createTrack('audio', trackDuration);
              this._id3Track = TSDemuxer.createTrack('id3');
              this._txtTrack = TSDemuxer.createTrack('text');
              this._audioTrack.segmentCodec = 'aac';

              // flush any partial content
              this.aacOverFlow = null;
              this.avcSample = null;
              this.remainderData = null;
              this.audioCodec = audioCodec;
              this.videoCodec = videoCodec;
              this._duration = trackDuration;
            }
            resetTimeStamp() { }
            resetContiguity() {
              const {
                _audioTrack,
                _avcTrack,
                _id3Track
              } = this;
              if (_audioTrack) {
                _audioTrack.pesData = null;
              }
              if (_avcTrack) {
                _avcTrack.pesData = null;
              }
              if (_id3Track) {
                _id3Track.pesData = null;
              }
              this.aacOverFlow = null;
              this.avcSample = null;
              this.remainderData = null;
            }
            demux(data, timeOffset, isSampleAes = false, flush = false) {
              if (!isSampleAes) {
                this.sampleAes = null;
              }
              let pes;
              const videoTrack = this._avcTrack;
              const audioTrack = this._audioTrack;
              const id3Track = this._id3Track;
              const textTrack = this._txtTrack;
              let avcId = videoTrack.pid;
              let avcData = videoTrack.pesData;
              let audioId = audioTrack.pid;
              let id3Id = id3Track.pid;
              let audioData = audioTrack.pesData;
              let id3Data = id3Track.pesData;
              let unknownPID = null;
              let pmtParsed = this.pmtParsed;
              let pmtId = this._pmtId;
              let len = data.length;
              if (this.remainderData) {
                data = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_5__.appendUint8Array)(this.remainderData, data);
                len = data.length;
                this.remainderData = null;
              }
              if (len < PACKET_LENGTH && !flush) {
                this.remainderData = data;
                return {
                  audioTrack,
                  videoTrack,
                  id3Track,
                  textTrack
                };
              }
              const syncOffset = Math.max(0, TSDemuxer.syncOffset(data));
              len -= (len - syncOffset) % PACKET_LENGTH;
              if (len < data.byteLength && !flush) {
                this.remainderData = new Uint8Array(data.buffer, len, data.buffer.byteLength - len);
              }

              // loop through TS packets
              let tsPacketErrors = 0;
              for (let start = syncOffset; start < len; start += PACKET_LENGTH) {
                if (data[start] === 0x47) {
                  const stt = !!(data[start + 1] & 0x40);
                  // pid is a 13-bit field starting at the last bit of TS[1]
                  const pid = ((data[start + 1] & 0x1f) << 8) + data[start + 2];
                  const atf = (data[start + 3] & 0x30) >> 4;

                  // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.
                  let offset;
                  if (atf > 1) {
                    offset = start + 5 + data[start + 4];
                    // continue if there is only adaptation field
                    if (offset === start + PACKET_LENGTH) {
                      continue;
                    }
                  } else {
                    offset = start + 4;
                  }
                  switch (pid) {
                    case avcId:
                      if (stt) {
                        if (avcData && (pes = parsePES(avcData))) {
                          this.parseAVCPES(videoTrack, textTrack, pes, false);
                        }
                        avcData = {
                          data: [],
                          size: 0
                        };
                      }
                      if (avcData) {
                        avcData.data.push(data.subarray(offset, start + PACKET_LENGTH));
                        avcData.size += start + PACKET_LENGTH - offset;
                      }
                      break;
                    case audioId:
                      if (stt) {
                        if (audioData && (pes = parsePES(audioData))) {
                          switch (audioTrack.segmentCodec) {
                            case 'aac':
                              this.parseAACPES(audioTrack, pes);
                              break;
                            case 'mp3':
                              this.parseMPEGPES(audioTrack, pes);
                              break;
                          }
                        }
                        audioData = {
                          data: [],
                          size: 0
                        };
                      }
                      if (audioData) {
                        audioData.data.push(data.subarray(offset, start + PACKET_LENGTH));
                        audioData.size += start + PACKET_LENGTH - offset;
                      }
                      break;
                    case id3Id:
                      if (stt) {
                        if (id3Data && (pes = parsePES(id3Data))) {
                          this.parseID3PES(id3Track, pes);
                        }
                        id3Data = {
                          data: [],
                          size: 0
                        };
                      }
                      if (id3Data) {
                        id3Data.data.push(data.subarray(offset, start + PACKET_LENGTH));
                        id3Data.size += start + PACKET_LENGTH - offset;
                      }
                      break;
                    case 0:
                      if (stt) {
                        offset += data[offset] + 1;
                      }
                      pmtId = this._pmtId = parsePAT(data, offset);
                      break;
                    case pmtId:
                      {
                        if (stt) {
                          offset += data[offset] + 1;
                        }
                        const parsedPIDs = parsePMT(data, offset, this.typeSupported, isSampleAes);

                        // only update track id if track PID found while parsing PMT
                        // this is to avoid resetting the PID to -1 in case
                        // track PID transiently disappears from the stream
                        // this could happen in case of transient missing audio samples for example
                        // NOTE this is only the PID of the track as found in TS,
                        // but we are not using this for MP4 track IDs.
                        avcId = parsedPIDs.avc;
                        if (avcId > 0) {
                          videoTrack.pid = avcId;
                        }
                        audioId = parsedPIDs.audio;
                        if (audioId > 0) {
                          audioTrack.pid = audioId;
                          audioTrack.segmentCodec = parsedPIDs.segmentCodec;
                        }
                        id3Id = parsedPIDs.id3;
                        if (id3Id > 0) {
                          id3Track.pid = id3Id;
                        }
                        if (unknownPID !== null && !pmtParsed) {
                          _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.log(`unknown PID '${unknownPID}' in TS found`);
                          unknownPID = null;
                          // we set it to -188, the += 188 in the for loop will reset start to 0
                          start = syncOffset - 188;
                        }
                        pmtParsed = this.pmtParsed = true;
                        break;
                      }
                    case 17:
                    case 0x1fff:
                      break;
                    default:
                      unknownPID = pid;
                      break;
                  }
                } else {
                  tsPacketErrors++;
                }
              }
              if (tsPacketErrors > 0) {
                this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_4__.Events.ERROR, _events__WEBPACK_IMPORTED_MODULE_4__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_7__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_7__.ErrorDetails.FRAG_PARSING_ERROR,
                  fatal: false,
                  reason: `Found ${tsPacketErrors} TS packet/s that do not start with 0x47`
                });
              }
              videoTrack.pesData = avcData;
              audioTrack.pesData = audioData;
              id3Track.pesData = id3Data;
              const demuxResult = {
                audioTrack,
                videoTrack,
                id3Track,
                textTrack
              };
              if (flush) {
                this.extractRemainingSamples(demuxResult);
              }
              return demuxResult;
            }
            flush() {
              const {
                remainderData
              } = this;
              this.remainderData = null;
              let result;
              if (remainderData) {
                result = this.demux(remainderData, -1, false, true);
              } else {
                result = {
                  videoTrack: this._avcTrack,
                  audioTrack: this._audioTrack,
                  id3Track: this._id3Track,
                  textTrack: this._txtTrack
                };
              }
              this.extractRemainingSamples(result);
              if (this.sampleAes) {
                return this.decrypt(result, this.sampleAes);
              }
              return result;
            }
            extractRemainingSamples(demuxResult) {
              const {
                audioTrack,
                videoTrack,
                id3Track,
                textTrack
              } = demuxResult;
              const avcData = videoTrack.pesData;
              const audioData = audioTrack.pesData;
              const id3Data = id3Track.pesData;
              // try to parse last PES packets
              let pes;
              if (avcData && (pes = parsePES(avcData))) {
                this.parseAVCPES(videoTrack, textTrack, pes, true);
                videoTrack.pesData = null;
              } else {
                // either avcData null or PES truncated, keep it for next frag parsing
                videoTrack.pesData = avcData;
              }
              if (audioData && (pes = parsePES(audioData))) {
                switch (audioTrack.segmentCodec) {
                  case 'aac':
                    this.parseAACPES(audioTrack, pes);
                    break;
                  case 'mp3':
                    this.parseMPEGPES(audioTrack, pes);
                    break;
                }
                audioTrack.pesData = null;
              } else {
                if (audioData?.size) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.log('last AAC PES packet truncated,might overlap between fragments');
                }

                // either audioData null or PES truncated, keep it for next frag parsing
                audioTrack.pesData = audioData;
              }
              if (id3Data && (pes = parsePES(id3Data))) {
                this.parseID3PES(id3Track, pes);
                id3Track.pesData = null;
              } else {
                // either id3Data null or PES truncated, keep it for next frag parsing
                id3Track.pesData = id3Data;
              }
            }
            demuxSampleAes(data, keyData, timeOffset) {
              const demuxResult = this.demux(data, timeOffset, true, !this.config.progressive);
              const sampleAes = this.sampleAes = new _sample_aes__WEBPACK_IMPORTED_MODULE_3__["default"](this.observer, this.config, keyData);
              return this.decrypt(demuxResult, sampleAes);
            }
            decrypt(demuxResult, sampleAes) {
              return new Promise(resolve => {
                const {
                  audioTrack,
                  videoTrack
                } = demuxResult;
                if (audioTrack.samples && audioTrack.segmentCodec === 'aac') {
                  sampleAes.decryptAacSamples(audioTrack.samples, 0, () => {
                    if (videoTrack.samples) {
                      sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {
                        resolve(demuxResult);
                      });
                    } else {
                      resolve(demuxResult);
                    }
                  });
                } else if (videoTrack.samples) {
                  sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {
                    resolve(demuxResult);
                  });
                }
              });
            }
            destroy() {
              this._duration = 0;
            }
            parseAVCPES(track, textTrack, pes, last) {
              const units = this.parseAVCNALu(track, pes.data);
              const debug = false;
              let avcSample = this.avcSample;
              let push;
              let spsfound = false;
              // free pes.data to save up some memory
              pes.data = null;

              // if new NAL units found and last sample still there, let's push ...
              // this helps parsing streams with missing AUD (only do this if AUD never found)
              if (avcSample && units.length && !track.audFound) {
                pushAccessUnit(avcSample, track);
                avcSample = this.avcSample = createAVCSample(false, pes.pts, pes.dts, '');
              }
              units.forEach(unit => {
                switch (unit.type) {
                  // NDR
                  case 1:
                    {
                      push = true;
                      if (!avcSample) {
                        avcSample = this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');
                      }
                      if (debug) {
                        avcSample.debug += 'NDR ';
                      }
                      avcSample.frame = true;
                      const data = unit.data;
                      // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)
                      if (spsfound && data.length > 4) {
                        // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR
                        const sliceType = new _exp_golomb__WEBPACK_IMPORTED_MODULE_2__["default"](data).readSliceType();
                        // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice
                        // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.
                        // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.
                        // I slice: A slice that is not an SI slice that is decoded using intra prediction only.
                        // if (sliceType === 2 || sliceType === 7) {
                        if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {
                          avcSample.key = true;
                        }
                      }
                      break;
                      // IDR
                    }

                  case 5:
                    push = true;
                    // handle PES not starting with AUD
                    if (!avcSample) {
                      avcSample = this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');
                    }
                    if (debug) {
                      avcSample.debug += 'IDR ';
                    }
                    avcSample.key = true;
                    avcSample.frame = true;
                    break;
                  // SEI
                  case 6:
                    {
                      push = true;
                      if (debug && avcSample) {
                        avcSample.debug += 'SEI ';
                      }
                      (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_5__.parseSEIMessageFromNALu)(unit.data, 1, pes.pts, textTrack.samples);
                      break;
                      // SPS
                    }

                  case 7:
                    push = true;
                    spsfound = true;
                    if (debug && avcSample) {
                      avcSample.debug += 'SPS ';
                    }
                    if (!track.sps) {
                      const expGolombDecoder = new _exp_golomb__WEBPACK_IMPORTED_MODULE_2__["default"](unit.data);
                      const config = expGolombDecoder.readSPS();
                      track.width = config.width;
                      track.height = config.height;
                      track.pixelRatio = config.pixelRatio;
                      // TODO: `track.sps` is defined as a `number[]`, but we're setting it to a `Uint8Array[]`.
                      track.sps = [unit.data];
                      track.duration = this._duration;
                      const codecarray = unit.data.subarray(1, 4);
                      let codecstring = 'avc1.';
                      for (let i = 0; i < 3; i++) {
                        let h = codecarray[i].toString(16);
                        if (h.length < 2) {
                          h = '0' + h;
                        }
                        codecstring += h;
                      }
                      track.codec = codecstring;
                    }
                    break;
                  // PPS
                  case 8:
                    push = true;
                    if (debug && avcSample) {
                      avcSample.debug += 'PPS ';
                    }
                    if (!track.pps) {
                      // TODO: `track.pss` is defined as a `number[]`, but we're setting it to a `Uint8Array[]`.
                      track.pps = [unit.data];
                    }
                    break;
                  // AUD
                  case 9:
                    push = false;
                    track.audFound = true;
                    if (avcSample) {
                      pushAccessUnit(avcSample, track);
                    }
                    avcSample = this.avcSample = createAVCSample(false, pes.pts, pes.dts, debug ? 'AUD ' : '');
                    break;
                  // Filler Data
                  case 12:
                    push = true;
                    break;
                  default:
                    push = false;
                    if (avcSample) {
                      avcSample.debug += 'unknown NAL ' + unit.type + ' ';
                    }
                    break;
                }
                if (avcSample && push) {
                  const units = avcSample.units;
                  units.push(unit);
                }
              });
              // if last PES packet, push samples
              if (last && avcSample) {
                pushAccessUnit(avcSample, track);
                this.avcSample = null;
              }
            }
            getLastNalUnit(samples) {
              let avcSample = this.avcSample;
              let lastUnit;
              // try to fallback to previous sample if current one is empty
              if (!avcSample || avcSample.units.length === 0) {
                avcSample = samples[samples.length - 1];
              }
              if (avcSample?.units) {
                const units = avcSample.units;
                lastUnit = units[units.length - 1];
              }
              return lastUnit;
            }
            parseAVCNALu(track, array) {
              const len = array.byteLength;
              let state = track.naluState || 0;
              const lastState = state;
              const units = [];
              let i = 0;
              let value;
              let overflow;
              let unitType;
              let lastUnitStart = -1;
              let lastUnitType = 0;
              // logger.log('PES:' + Hex.hexDump(array));

              if (state === -1) {
                // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet
                lastUnitStart = 0;
                // NALu type is value read from offset 0
                lastUnitType = array[0] & 0x1f;
                state = 0;
                i = 1;
              }
              while (i < len) {
                value = array[i++];
                // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case
                if (!state) {
                  state = value ? 0 : 1;
                  continue;
                }
                if (state === 1) {
                  state = value ? 0 : 2;
                  continue;
                }
                // here we have state either equal to 2 or 3
                if (!value) {
                  state = 3;
                } else if (value === 1) {
                  if (lastUnitStart >= 0) {
                    const unit = {
                      data: array.subarray(lastUnitStart, i - state - 1),
                      type: lastUnitType
                    };
                    // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);
                    units.push(unit);
                  } else {
                    // lastUnitStart is undefined => this is the first start code found in this PES packet
                    // first check if start code delimiter is overlapping between 2 PES packets,
                    // ie it started in last packet (lastState not zero)
                    // and ended at the beginning of this PES packet (i <= 4 - lastState)
                    const lastUnit = this.getLastNalUnit(track.samples);
                    if (lastUnit) {
                      if (lastState && i <= 4 - lastState) {
                        // start delimiter overlapping between PES packets
                        // strip start delimiter bytes from the end of last NAL unit
                        // check if lastUnit had a state different from zero
                        if (lastUnit.state) {
                          // strip last bytes
                          lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);
                        }
                      }
                      // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.
                      overflow = i - state - 1;
                      if (overflow > 0) {
                        // logger.log('first NALU found with overflow:' + overflow);
                        const tmp = new Uint8Array(lastUnit.data.byteLength + overflow);
                        tmp.set(lastUnit.data, 0);
                        tmp.set(array.subarray(0, overflow), lastUnit.data.byteLength);
                        lastUnit.data = tmp;
                        lastUnit.state = 0;
                      }
                    }
                  }
                  // check if we can read unit type
                  if (i < len) {
                    unitType = array[i] & 0x1f;
                    // logger.log('find NALU @ offset:' + i + ',type:' + unitType);
                    lastUnitStart = i;
                    lastUnitType = unitType;
                    state = 0;
                  } else {
                    // not enough byte to read unit type. let's read it on next PES parsing
                    state = -1;
                  }
                } else {
                  state = 0;
                }
              }
              if (lastUnitStart >= 0 && state >= 0) {
                const unit = {
                  data: array.subarray(lastUnitStart, len),
                  type: lastUnitType,
                  state: state
                };
                units.push(unit);
                // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);
              }
              // no NALu found
              if (units.length === 0) {
                // append pes.data to previous NAL unit
                const lastUnit = this.getLastNalUnit(track.samples);
                if (lastUnit) {
                  const tmp = new Uint8Array(lastUnit.data.byteLength + array.byteLength);
                  tmp.set(lastUnit.data, 0);
                  tmp.set(array, lastUnit.data.byteLength);
                  lastUnit.data = tmp;
                }
              }
              track.naluState = state;
              return units;
            }
            parseAACPES(track, pes) {
              let startOffset = 0;
              const aacOverFlow = this.aacOverFlow;
              let data = pes.data;
              if (aacOverFlow) {
                this.aacOverFlow = null;
                const frameMissingBytes = aacOverFlow.missing;
                const sampleLength = aacOverFlow.sample.unit.byteLength;
                // logger.log(`AAC: append overflowing ${sampleLength} bytes to beginning of new PES`);
                if (frameMissingBytes === -1) {
                  const tmp = new Uint8Array(sampleLength + data.byteLength);
                  tmp.set(aacOverFlow.sample.unit, 0);
                  tmp.set(data, sampleLength);
                  data = tmp;
                } else {
                  const frameOverflowBytes = sampleLength - frameMissingBytes;
                  aacOverFlow.sample.unit.set(data.subarray(0, frameMissingBytes), frameOverflowBytes);
                  track.samples.push(aacOverFlow.sample);
                  startOffset = aacOverFlow.missing;
                }
              }
              // look for ADTS header (0xFFFx)
              let offset;
              let len;
              for (offset = startOffset, len = data.length; offset < len - 1; offset++) {
                if (_adts__WEBPACK_IMPORTED_MODULE_0__.isHeader(data, offset)) {
                  break;
                }
              }
              // if ADTS header does not start straight from the beginning of the PES payload, raise an error
              if (offset !== startOffset) {
                let reason;
                let fatal;
                if (offset < len - 1) {
                  reason = `AAC PES did not start with ADTS header,offset:${offset}`;
                  fatal = false;
                } else {
                  reason = 'no ADTS header found in AAC PES';
                  fatal = true;
                }
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`parsing error:${reason}`);
                this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_4__.Events.ERROR, _events__WEBPACK_IMPORTED_MODULE_4__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_7__.ErrorTypes.MEDIA_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_7__.ErrorDetails.FRAG_PARSING_ERROR,
                  fatal,
                  reason
                });
                if (fatal) {
                  return;
                }
              }
              _adts__WEBPACK_IMPORTED_MODULE_0__.initTrackConfig(track, this.observer, data, offset, this.audioCodec);
              let pts;
              if (pes.pts !== undefined) {
                pts = pes.pts;
              } else if (aacOverFlow) {
                // if last AAC frame is overflowing, we should ensure timestamps are contiguous:
                // first sample PTS should be equal to last sample PTS + frameDuration
                const frameDuration = _adts__WEBPACK_IMPORTED_MODULE_0__.getFrameDuration(track.samplerate);
                pts = aacOverFlow.sample.pts + frameDuration;
              } else {
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn('[tsdemuxer]: AAC PES unknown PTS');
                return;
              }

              // scan for aac samples
              let frameIndex = 0;
              let frame;
              while (offset < len) {
                frame = _adts__WEBPACK_IMPORTED_MODULE_0__.appendFrame(track, data, offset, pts, frameIndex);
                offset += frame.length;
                if (!frame.missing) {
                  frameIndex++;
                  for (; offset < len - 1; offset++) {
                    if (_adts__WEBPACK_IMPORTED_MODULE_0__.isHeader(data, offset)) {
                      break;
                    }
                  }
                } else {
                  this.aacOverFlow = frame;
                  break;
                }
              }
            }
            parseMPEGPES(track, pes) {
              const data = pes.data;
              const length = data.length;
              let frameIndex = 0;
              let offset = 0;
              const pts = pes.pts;
              if (pts === undefined) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn('[tsdemuxer]: MPEG PES unknown PTS');
                return;
              }
              while (offset < length) {
                if (_mpegaudio__WEBPACK_IMPORTED_MODULE_1__.isHeader(data, offset)) {
                  const frame = _mpegaudio__WEBPACK_IMPORTED_MODULE_1__.appendFrame(track, data, offset, pts, frameIndex);
                  if (frame) {
                    offset += frame.length;
                    frameIndex++;
                  } else {
                    // logger.log('Unable to parse Mpeg audio frame');
                    break;
                  }
                } else {
                  // nothing found, keep looking
                  offset++;
                }
              }
            }
            parseID3PES(id3Track, pes) {
              if (pes.pts === undefined) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn('[tsdemuxer]: ID3 PES unknown PTS');
                return;
              }
              const id3Sample = Object.assign({}, pes, {
                type: this._avcTrack ? _types_demuxer__WEBPACK_IMPORTED_MODULE_8__.MetadataSchema.emsg : _types_demuxer__WEBPACK_IMPORTED_MODULE_8__.MetadataSchema.audioId3,
                duration: Number.POSITIVE_INFINITY
              });
              id3Track.samples.push(id3Sample);
            }
          }
          function createAVCSample(key, pts, dts, debug) {
            return {
              key,
              frame: false,
              pts,
              dts,
              units: [],
              debug,
              length: 0
            };
          }
          function parsePAT(data, offset) {
            // skip the PSI header and parse the first PMT entry
            return (data[offset + 10] & 0x1f) << 8 | data[offset + 11];
            // logger.log('PMT PID:'  + this._pmtId);
          }

          function parsePMT(data, offset, typeSupported, isSampleAes) {
            const result = {
              audio: -1,
              avc: -1,
              id3: -1,
              segmentCodec: 'aac'
            };
            const sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];
            const tableEnd = offset + 3 + sectionLength - 4;
            // to determine where the table is, we have to figure out how
            // long the program info descriptors are
            const programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11];
            // advance the offset to the first entry in the mapping table
            offset += 12 + programInfoLength;
            while (offset < tableEnd) {
              const pid = (data[offset + 1] & 0x1f) << 8 | data[offset + 2];
              switch (data[offset]) {
                case 0xcf:
                  // SAMPLE-AES AAC
                  if (!isSampleAes) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.log('ADTS AAC with AES-128-CBC frame encryption found in unencrypted stream');
                    break;
                  }
                /* falls through */
                case 0x0f:
                  // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)
                  // logger.log('AAC PID:'  + pid);
                  if (result.audio === -1) {
                    result.audio = pid;
                  }
                  break;

                // Packetized metadata (ID3)
                case 0x15:
                  // logger.log('ID3 PID:'  + pid);
                  if (result.id3 === -1) {
                    result.id3 = pid;
                  }
                  break;
                case 0xdb:
                  // SAMPLE-AES AVC
                  if (!isSampleAes) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.log('H.264 with AES-128-CBC slice encryption found in unencrypted stream');
                    break;
                  }
                /* falls through */
                case 0x1b:
                  // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)
                  // logger.log('AVC PID:'  + pid);
                  if (result.avc === -1) {
                    result.avc = pid;
                  }
                  break;

                // ISO/IEC 11172-3 (MPEG-1 audio)
                // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)
                case 0x03:
                case 0x04:
                  // logger.log('MPEG PID:'  + pid);
                  if (typeSupported.mpeg !== true && typeSupported.mp3 !== true) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.log('MPEG audio found, not supported in this browser');
                  } else if (result.audio === -1) {
                    result.audio = pid;
                    result.segmentCodec = 'mp3';
                  }
                  break;
                case 0x24:
                  _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn('Unsupported HEVC stream type found');
                  break;
                default:
                  // logger.log('unknown stream type:' + data[offset]);
                  break;
              }
              // move to the next table entry
              // skip past the elementary stream descriptors, if present
              offset += ((data[offset + 3] & 0x0f) << 8 | data[offset + 4]) + 5;
            }
            return result;
          }
          function parsePES(stream) {
            let i = 0;
            let frag;
            let pesLen;
            let pesHdrLen;
            let pesPts;
            let pesDts;
            const data = stream.data;
            // safety check
            if (!stream || stream.size === 0) {
              return null;
            }

            // we might need up to 19 bytes to read PES header
            // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes
            // usually only one merge is needed (and this is rare ...)
            while (data[0].length < 19 && data.length > 1) {
              const newData = new Uint8Array(data[0].length + data[1].length);
              newData.set(data[0]);
              newData.set(data[1], data[0].length);
              data[0] = newData;
              data.splice(1, 1);
            }
            // retrieve PTS/DTS from first fragment
            frag = data[0];
            const pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];
            if (pesPrefix === 1) {
              pesLen = (frag[4] << 8) + frag[5];
              // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated
              // minus 6 : PES header size
              if (pesLen && pesLen > stream.size - 6) {
                return null;
              }
              const pesFlags = frag[7];
              if (pesFlags & 0xc0) {
                /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html
                    as PTS / DTS is 33 bit we cannot use bitwise operator in JS,
                    as Bitwise operators treat their operands as a sequence of 32 bits */
                pesPts = (frag[9] & 0x0e) * 536870912 +
                  // 1 << 29
                  (frag[10] & 0xff) * 4194304 +
                  // 1 << 22
                  (frag[11] & 0xfe) * 16384 +
                  // 1 << 14
                  (frag[12] & 0xff) * 128 +
                  // 1 << 7
                  (frag[13] & 0xfe) / 2;
                if (pesFlags & 0x40) {
                  pesDts = (frag[14] & 0x0e) * 536870912 +
                    // 1 << 29
                    (frag[15] & 0xff) * 4194304 +
                    // 1 << 22
                    (frag[16] & 0xfe) * 16384 +
                    // 1 << 14
                    (frag[17] & 0xff) * 128 +
                    // 1 << 7
                    (frag[18] & 0xfe) / 2;
                  if (pesPts - pesDts > 60 * 90000) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`${Math.round((pesPts - pesDts) / 90000)}s delta between PTS and DTS, align them`);
                    pesPts = pesDts;
                  }
                } else {
                  pesDts = pesPts;
                }
              }
              pesHdrLen = frag[8];
              // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension
              let payloadStartOffset = pesHdrLen + 9;
              if (stream.size <= payloadStartOffset) {
                return null;
              }
              stream.size -= payloadStartOffset;
              // reassemble PES packet
              const pesData = new Uint8Array(stream.size);
              for (let j = 0, dataLen = data.length; j < dataLen; j++) {
                frag = data[j];
                let len = frag.byteLength;
                if (payloadStartOffset) {
                  if (payloadStartOffset > len) {
                    // trim full frag if PES header bigger than frag
                    payloadStartOffset -= len;
                    continue;
                  } else {
                    // trim partial frag if PES header smaller than frag
                    frag = frag.subarray(payloadStartOffset);
                    len -= payloadStartOffset;
                    payloadStartOffset = 0;
                  }
                }
                pesData.set(frag, i);
                i += len;
              }
              if (pesLen) {
                // payload size : remove PES header + PES extension
                pesLen -= pesHdrLen + 3;
              }
              return {
                data: pesData,
                pts: pesPts,
                dts: pesDts,
                len: pesLen
              };
            }
            return null;
          }
          function pushAccessUnit(avcSample, avcTrack) {
            if (avcSample.units.length && avcSample.frame) {
              // if sample does not have PTS/DTS, patch with last sample PTS/DTS
              if (avcSample.pts === undefined) {
                const samples = avcTrack.samples;
                const nbSamples = samples.length;
                if (nbSamples) {
                  const lastSample = samples[nbSamples - 1];
                  avcSample.pts = lastSample.pts;
                  avcSample.dts = lastSample.dts;
                } else {
                  // dropping samples, no timestamp found
                  avcTrack.dropped++;
                  return;
                }
              }
              avcTrack.samples.push(avcSample);
            }
            if (avcSample.debug.length) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.log(avcSample.pts + '/' + avcSample.dts + ':' + avcSample.debug);
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TSDemuxer);

          /***/
        }),

/***/ "./src/demux/webworkify-webpack.js":
/*!*****************************************!*\
  !*** ./src/demux/webworkify-webpack.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* export default binding */ __WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          /*
           * Fork of webworkify-webpack with support for Webpack 5
           * https://github.com/wupeng-engineer/webworkify-webpack/blob/db0de7/index.js
          */

          const webpackBootstrapFunc = function () {
            // webpackBootstrap
            /******/
            var __webpack_modules__ = ENTRY_MODULE;
            /************************************************************************/
            /******/ // The module cache
            /******/
            var __webpack_module_cache__ = {};
            /******/
            /******/ // The require function
            /******/
            var __nested_webpack_require_479__ = function __webpack_require__(moduleId) {
    /******/ // Check if module is in cache
    /******/var cachedModule = __webpack_module_cache__[moduleId];
              /******/
              if (cachedModule !== undefined) {
      /******/return cachedModule.exports;
                /******/
              }
              /******/ // Create a new module (and put it into the cache)
              /******/
              var module = __webpack_module_cache__[moduleId] = {
      /******/ // no module.id needed
      /******/ // no module.loaded needed
      /******/exports: {}
                /******/
              };
              /******/
              /******/ // Execute the module function
              /******/
              __webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
              /******/
              /******/ // Return the exports of the module
              /******/
              return module.exports;
              /******/
            };
            /******/
            /******/ // expose the modules object (__webpack_modules__)
            /******/
            __nested_webpack_require_479__.m = __webpack_modules__;
            /******/
            /************************************************************************/
            /******/ /* webpack/runtime/compat get default export */
            /******/
            (() => {
    /******/ // getDefaultExport function for compatibility with non-harmony modules
    /******/__nested_webpack_require_479__.n = module => {
      /******/var getter = module && module.__esModule ? /******/() => module['default'] : /******/() => module;
                /******/
                __nested_webpack_require_479__.d(getter, {
                  a: getter
                });
                /******/
                return getter;
                /******/
              };
              /******/
            })();
            /******/
            /******/ /* webpack/runtime/define property getters */
            /******/
            (() => {
    /******/ // define getter functions for harmony exports
    /******/__nested_webpack_require_479__.d = (exports, definition) => {
      /******/for (var key in definition) {
        /******/if (__nested_webpack_require_479__.o(definition, key) && !__nested_webpack_require_479__.o(exports, key)) {
          /******/Object.defineProperty(exports, key, {
              enumerable: true,
              get: definition[key]
            });
                    /******/
                  }
                  /******/
                }
                /******/
              };
              /******/
            })();
            /******/
            /******/ /* webpack/runtime/hasOwnProperty shorthand */
            /******/
            (() => {
    /******/__nested_webpack_require_479__.o = (obj, prop) => Object.prototype.hasOwnProperty.call(obj, prop);
              /******/
            })();
            /******/
            /******/ /* webpack/runtime/make namespace object */
            /******/
            (() => {
    /******/ // define __esModule on exports
    /******/__nested_webpack_require_479__.r = exports => {
      /******/if (typeof Symbol !== 'undefined' && Symbol.toStringTag) {
        /******/Object.defineProperty(exports, Symbol.toStringTag, {
              value: 'Module'
            });
                  /******/
                }
                /******/
                Object.defineProperty(exports, '__esModule', {
                  value: true
                });
                /******/
              };
              /******/
            })();
            /******/
            /************************************************************************/
            /******/
            /******/ // module factories are used so entry inlining is disabled
            /******/ // startup
            /******/ // Load entry module and return exports
            /******/
            var result = __nested_webpack_require_479__(ENTRY_MODULE);
            /******/
            return result.default || result;
          };
          var webpackBootstrapFuncArr = webpackBootstrapFunc.toString().split('ENTRY_MODULE');
          var moduleNameReqExp = '[\\.|\\-|\\+|\\w|\/|@]+';
          var dependencyRegExp = '\\(\\s*(\/\\*.*?\\*\/)?\\s*.*?(' + moduleNameReqExp + ').*?\\)';
          function quoteRegExp(str) {
            return (str + '').replace(/[.?*+^$[\]\\(){}|-]/g, '\\$&');
          }
          function isNumeric(n) {
            return !isNaN(1 * n);
          }
          function getModuleDependencies(sources, module, queueName) {
            var retval = {};
            retval[queueName] = [];
            var fnString = module.toString().replace(/^"[^"]+"/, 'function');
            ;
            var wrapperSignature = fnString.match(/^function\s?\w*\(\w+,\s*\w+,\s*(\w+)\)/) || fnString.match(/^\(\w+,\s*\w+,\s*(\w+)\)\s?\=\s?\>/);
            if (!wrapperSignature) return retval;
            var webpackRequireName = wrapperSignature[1];
            var re = new RegExp('(\\\\n|\\W)' + quoteRegExp(webpackRequireName) + dependencyRegExp, 'g');
            var match;
            while (match = re.exec(fnString)) {
              if (match[3] === 'dll-reference') continue;
              retval[queueName].push(match[3]);
            }
            re = new RegExp('\\(' + quoteRegExp(webpackRequireName) + '\\("(dll-reference\\s(' + moduleNameReqExp + '))"\\)\\)' + dependencyRegExp, 'g');
            while (match = re.exec(fnString)) {
              if (!sources[match[2]]) {
                retval[queueName].push(match[1]);
                sources[match[2]] = __webpack_require__(match[1]).m;
              }
              retval[match[2]] = retval[match[2]] || [];
              retval[match[2]].push(match[4]);
            }
            var keys = Object.keys(retval);
            for (var i = 0; i < keys.length; i++) {
              for (var j = 0; j < retval[keys[i]].length; j++) {
                if (isNumeric(retval[keys[i]][j])) {
                  retval[keys[i]][j] = 1 * retval[keys[i]][j];
                }
              }
            }
            return retval;
          }
          function hasValuesInQueues(queues) {
            var keys = Object.keys(queues);
            return keys.reduce((hasValues, key) => hasValues || queues[key].length > 0, false);
          }
          function getRequiredModules(sources, moduleId) {
            var modulesQueue = {
              main: [moduleId]
            };
            var requiredModules = {
              main: []
            };
            var seenModules = {
              main: {}
            };
            while (hasValuesInQueues(modulesQueue)) {
              var queues = Object.keys(modulesQueue);
              for (var i = 0; i < queues.length; i++) {
                var queueName = queues[i];
                var queue = modulesQueue[queueName];
                var moduleToCheck = queue.pop();
                seenModules[queueName] = seenModules[queueName] || {};
                if (seenModules[queueName][moduleToCheck] || !sources[queueName][moduleToCheck]) continue;
                seenModules[queueName][moduleToCheck] = true;
                requiredModules[queueName] = requiredModules[queueName] || [];
                requiredModules[queueName].push(moduleToCheck);
                var newModules = getModuleDependencies(sources, sources[queueName][moduleToCheck], queueName);
                var newModulesKeys = Object.keys(newModules);
                for (var j = 0; j < newModulesKeys.length; j++) {
                  modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]] || [];
                  modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]].concat(newModules[newModulesKeys[j]]);
                }
              }
            }
            return requiredModules;
          }
          function getWebpackString(requiredModules, sources, entryModule, key) {
            const moduleString = requiredModules[key].map(id => `"${id}": ${sources[key][id].toString().replace(/^"[^"]+"/, 'function')}`).join(",");
            return `${webpackBootstrapFuncArr[0]}{${moduleString}}${webpackBootstrapFuncArr[1]}"${entryModule}"${webpackBootstrapFuncArr[2]}`;
          }
/* harmony default export */ function __WEBPACK_DEFAULT_EXPORT__(moduleId, options) {
            options = options || {};
            var sources = {
              main: __webpack_require__.m
            };
            var requiredModules = options.all ? {
              main: Object.keys(sources.main)
            } : getRequiredModules(sources, moduleId);
            var src = '';
            Object.keys(requiredModules).filter(m => m !== 'main').forEach(module => {
              var entryModule = 0;
              while (requiredModules[module][entryModule]) {
                entryModule++;
              }
              requiredModules[module].push(entryModule);
              sources[module][entryModule] = '(function(module, exports, __webpack_require__) { module.exports = __webpack_require__; })';
              src = src + `var ${module} = (${getWebpackString(requiredModules, sources, entryModule, modules)})();\n`;
            });
            src = src + `new ((${getWebpackString(requiredModules, sources, moduleId, 'main')})())(self);`;
            var blob = new window.Blob([src], {
              type: 'text/javascript'
            });
            var URL = window.URL || window.webkitURL || window.mozURL || window.msURL;
            var workerUrl = URL.createObjectURL(blob);
            var worker = new window.Worker(workerUrl);
            worker.objectURL = workerUrl;
            return worker;
          }

          /***/
        }),

/***/ "./src/errors.ts":
/*!***********************!*\
  !*** ./src/errors.ts ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "ErrorDetails": () => (/* binding */ ErrorDetails),
/* harmony export */   "ErrorTypes": () => (/* binding */ ErrorTypes)
            /* harmony export */
          });
          let ErrorTypes;

          /**
           * @enum {ErrorDetails}
           * @typedef {string} ErrorDetail
           */
          (function (ErrorTypes) {
            ErrorTypes["NETWORK_ERROR"] = "networkError";
            ErrorTypes["MEDIA_ERROR"] = "mediaError";
            ErrorTypes["KEY_SYSTEM_ERROR"] = "keySystemError";
            ErrorTypes["MUX_ERROR"] = "muxError";
            ErrorTypes["OTHER_ERROR"] = "otherError";
          })(ErrorTypes || (ErrorTypes = {}));
          let ErrorDetails;
          (function (ErrorDetails) {
            ErrorDetails["KEY_SYSTEM_NO_KEYS"] = "keySystemNoKeys";
            ErrorDetails["KEY_SYSTEM_NO_ACCESS"] = "keySystemNoAccess";
            ErrorDetails["KEY_SYSTEM_NO_SESSION"] = "keySystemNoSession";
            ErrorDetails["KEY_SYSTEM_NO_CONFIGURED_LICENSE"] = "keySystemNoConfiguredLicense";
            ErrorDetails["KEY_SYSTEM_LICENSE_REQUEST_FAILED"] = "keySystemLicenseRequestFailed";
            ErrorDetails["KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED"] = "keySystemServerCertificateRequestFailed";
            ErrorDetails["KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED"] = "keySystemServerCertificateUpdateFailed";
            ErrorDetails["KEY_SYSTEM_SESSION_UPDATE_FAILED"] = "keySystemSessionUpdateFailed";
            ErrorDetails["KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED"] = "keySystemStatusOutputRestricted";
            ErrorDetails["KEY_SYSTEM_STATUS_INTERNAL_ERROR"] = "keySystemStatusInternalError";
            ErrorDetails["MANIFEST_LOAD_ERROR"] = "manifestLoadError";
            ErrorDetails["MANIFEST_LOAD_TIMEOUT"] = "manifestLoadTimeOut";
            ErrorDetails["MANIFEST_PARSING_ERROR"] = "manifestParsingError";
            ErrorDetails["MANIFEST_INCOMPATIBLE_CODECS_ERROR"] = "manifestIncompatibleCodecsError";
            ErrorDetails["LEVEL_EMPTY_ERROR"] = "levelEmptyError";
            ErrorDetails["LEVEL_LOAD_ERROR"] = "levelLoadError";
            ErrorDetails["LEVEL_LOAD_TIMEOUT"] = "levelLoadTimeOut";
            ErrorDetails["LEVEL_SWITCH_ERROR"] = "levelSwitchError";
            ErrorDetails["AUDIO_TRACK_LOAD_ERROR"] = "audioTrackLoadError";
            ErrorDetails["AUDIO_TRACK_LOAD_TIMEOUT"] = "audioTrackLoadTimeOut";
            ErrorDetails["SUBTITLE_LOAD_ERROR"] = "subtitleTrackLoadError";
            ErrorDetails["SUBTITLE_TRACK_LOAD_TIMEOUT"] = "subtitleTrackLoadTimeOut";
            ErrorDetails["FRAG_LOAD_ERROR"] = "fragLoadError";
            ErrorDetails["FRAG_LOAD_TIMEOUT"] = "fragLoadTimeOut";
            ErrorDetails["FRAG_DECRYPT_ERROR"] = "fragDecryptError";
            ErrorDetails["FRAG_PARSING_ERROR"] = "fragParsingError";
            ErrorDetails["REMUX_ALLOC_ERROR"] = "remuxAllocError";
            ErrorDetails["KEY_LOAD_ERROR"] = "keyLoadError";
            ErrorDetails["KEY_LOAD_TIMEOUT"] = "keyLoadTimeOut";
            ErrorDetails["BUFFER_ADD_CODEC_ERROR"] = "bufferAddCodecError";
            ErrorDetails["BUFFER_INCOMPATIBLE_CODECS_ERROR"] = "bufferIncompatibleCodecsError";
            ErrorDetails["BUFFER_APPEND_ERROR"] = "bufferAppendError";
            ErrorDetails["BUFFER_APPENDING_ERROR"] = "bufferAppendingError";
            ErrorDetails["BUFFER_STALLED_ERROR"] = "bufferStalledError";
            ErrorDetails["BUFFER_FULL_ERROR"] = "bufferFullError";
            ErrorDetails["BUFFER_SEEK_OVER_HOLE"] = "bufferSeekOverHole";
            ErrorDetails["BUFFER_NUDGE_ON_STALL"] = "bufferNudgeOnStall";
            ErrorDetails["INTERNAL_EXCEPTION"] = "internalException";
            ErrorDetails["INTERNAL_ABORTED"] = "aborted";
            ErrorDetails["UNKNOWN"] = "unknown";
          })(ErrorDetails || (ErrorDetails = {}));

          /***/
        }),

/***/ "./src/events.ts":
/*!***********************!*\
  !*** ./src/events.ts ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "Events": () => (/* binding */ Events)
            /* harmony export */
          });
          /**
           * @readonly
           * @enum {string}
           */
          let Events;
          (function (Events) {
            Events["MEDIA_ATTACHING"] = "hlsMediaAttaching";
            Events["MEDIA_ATTACHED"] = "hlsMediaAttached";
            Events["MEDIA_DETACHING"] = "hlsMediaDetaching";
            Events["MEDIA_DETACHED"] = "hlsMediaDetached";
            Events["BUFFER_RESET"] = "hlsBufferReset";
            Events["BUFFER_CODECS"] = "hlsBufferCodecs";
            Events["BUFFER_CREATED"] = "hlsBufferCreated";
            Events["BUFFER_APPENDING"] = "hlsBufferAppending";
            Events["BUFFER_APPENDED"] = "hlsBufferAppended";
            Events["BUFFER_EOS"] = "hlsBufferEos";
            Events["BUFFER_FLUSHING"] = "hlsBufferFlushing";
            Events["BUFFER_FLUSHED"] = "hlsBufferFlushed";
            Events["MANIFEST_LOADING"] = "hlsManifestLoading";
            Events["MANIFEST_LOADED"] = "hlsManifestLoaded";
            Events["MANIFEST_PARSED"] = "hlsManifestParsed";
            Events["LEVEL_SWITCHING"] = "hlsLevelSwitching";
            Events["LEVEL_SWITCHED"] = "hlsLevelSwitched";
            Events["LEVEL_LOADING"] = "hlsLevelLoading";
            Events["LEVEL_LOADED"] = "hlsLevelLoaded";
            Events["LEVEL_UPDATED"] = "hlsLevelUpdated";
            Events["LEVEL_PTS_UPDATED"] = "hlsLevelPtsUpdated";
            Events["LEVELS_UPDATED"] = "hlsLevelsUpdated";
            Events["AUDIO_TRACKS_UPDATED"] = "hlsAudioTracksUpdated";
            Events["AUDIO_TRACK_SWITCHING"] = "hlsAudioTrackSwitching";
            Events["AUDIO_TRACK_SWITCHED"] = "hlsAudioTrackSwitched";
            Events["AUDIO_TRACK_LOADING"] = "hlsAudioTrackLoading";
            Events["AUDIO_TRACK_LOADED"] = "hlsAudioTrackLoaded";
            Events["SUBTITLE_TRACKS_UPDATED"] = "hlsSubtitleTracksUpdated";
            Events["SUBTITLE_TRACKS_CLEARED"] = "hlsSubtitleTracksCleared";
            Events["SUBTITLE_TRACK_SWITCH"] = "hlsSubtitleTrackSwitch";
            Events["SUBTITLE_TRACK_LOADING"] = "hlsSubtitleTrackLoading";
            Events["SUBTITLE_TRACK_LOADED"] = "hlsSubtitleTrackLoaded";
            Events["SUBTITLE_FRAG_PROCESSED"] = "hlsSubtitleFragProcessed";
            Events["CUES_PARSED"] = "hlsCuesParsed";
            Events["NON_NATIVE_TEXT_TRACKS_FOUND"] = "hlsNonNativeTextTracksFound";
            Events["INIT_PTS_FOUND"] = "hlsInitPtsFound";
            Events["FRAG_LOADING"] = "hlsFragLoading";
            Events["FRAG_LOAD_EMERGENCY_ABORTED"] = "hlsFragLoadEmergencyAborted";
            Events["FRAG_LOADED"] = "hlsFragLoaded";
            Events["FRAG_DECRYPTED"] = "hlsFragDecrypted";
            Events["FRAG_PARSING_INIT_SEGMENT"] = "hlsFragParsingInitSegment";
            Events["FRAG_PARSING_USERDATA"] = "hlsFragParsingUserdata";
            Events["FRAG_PARSING_METADATA"] = "hlsFragParsingMetadata";
            Events["FRAG_PARSED"] = "hlsFragParsed";
            Events["FRAG_BUFFERED"] = "hlsFragBuffered";
            Events["FRAG_CHANGED"] = "hlsFragChanged";
            Events["FPS_DROP"] = "hlsFpsDrop";
            Events["FPS_DROP_LEVEL_CAPPING"] = "hlsFpsDropLevelCapping";
            Events["ERROR"] = "hlsError";
            Events["DESTROYING"] = "hlsDestroying";
            Events["KEY_LOADING"] = "hlsKeyLoading";
            Events["KEY_LOADED"] = "hlsKeyLoaded";
            Events["LIVE_BACK_BUFFER_REACHED"] = "hlsLiveBackBufferReached";
            Events["BACK_BUFFER_REACHED"] = "hlsBackBufferReached";
          })(Events || (Events = {}));

          /***/
        }),

/***/ "./src/hls.ts":
/*!********************!*\
  !*** ./src/hls.ts ***!
  \********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ Hls)
            /* harmony export */
          });
/* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
/* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(url_toolkit__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _loader_playlist_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./loader/playlist-loader */ "./src/loader/playlist-loader.ts");
/* harmony import */ var _controller_id3_track_controller__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./controller/id3-track-controller */ "./src/controller/id3-track-controller.ts");
/* harmony import */ var _controller_latency_controller__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./controller/latency-controller */ "./src/controller/latency-controller.ts");
/* harmony import */ var _controller_level_controller__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./controller/level-controller */ "./src/controller/level-controller.ts");
/* harmony import */ var _controller_fragment_tracker__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./controller/fragment-tracker */ "./src/controller/fragment-tracker.ts");
/* harmony import */ var _loader_key_loader__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./loader/key-loader */ "./src/loader/key-loader.ts");
/* harmony import */ var _controller_stream_controller__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./controller/stream-controller */ "./src/controller/stream-controller.ts");
/* harmony import */ var _is_supported__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./is-supported */ "./src/is-supported.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./config */ "./src/config.ts");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");
/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(eventemitter3__WEBPACK_IMPORTED_MODULE_11__);
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./errors */ "./src/errors.ts");














          /**
           * @module Hls
           * @class
           * @constructor
           */
          class Hls {
            _emitter = new eventemitter3__WEBPACK_IMPORTED_MODULE_11__.EventEmitter();
            _media = null;
            url = null;
            static get version() {
              return undefined;
            }
            static isSupported() {
              return (0, _is_supported__WEBPACK_IMPORTED_MODULE_8__.isSupported)();
            }
            static get Events() {
              return _events__WEBPACK_IMPORTED_MODULE_12__.Events;
            }
            static get ErrorTypes() {
              return _errors__WEBPACK_IMPORTED_MODULE_13__.ErrorTypes;
            }
            static get ErrorDetails() {
              return _errors__WEBPACK_IMPORTED_MODULE_13__.ErrorDetails;
            }
            static get DefaultConfig() {
              if (!Hls.defaultConfig) {
                return _config__WEBPACK_IMPORTED_MODULE_10__.hlsDefaultConfig;
              }
              return Hls.defaultConfig;
            }

            /**
             * @type {HlsConfig}
             */
            static set DefaultConfig(defaultConfig) {
              Hls.defaultConfig = defaultConfig;
            }

            /**
             * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.
             *
             * @constructs Hls
             * @param {HlsConfig} config
             */
            constructor(userConfig = {}) {
              const config = this.config = (0, _config__WEBPACK_IMPORTED_MODULE_10__.mergeConfig)(Hls.DefaultConfig, userConfig);
              this.userConfig = userConfig;
              (0, _utils_logger__WEBPACK_IMPORTED_MODULE_9__.enableLogs)(config.debug, 'Hls instance');
              this._autoLevelCapping = -1;
              if (config.progressive) {
                (0, _config__WEBPACK_IMPORTED_MODULE_10__.enableStreamingMode)(config);
              }

              // core controllers and network loaders
              const {
                abrController: ConfigAbrController,
                bufferController: ConfigBufferController,
                capLevelController: ConfigCapLevelController,
                fpsController: ConfigFpsController
              } = config;
              const abrController = this.abrController = new ConfigAbrController(this);
              const bufferController = this.bufferController = new ConfigBufferController(this);
              const capLevelController = this.capLevelController = new ConfigCapLevelController(this);
              const fpsController = new ConfigFpsController(this);
              const playListLoader = new _loader_playlist_loader__WEBPACK_IMPORTED_MODULE_1__["default"](this);
              const id3TrackController = new _controller_id3_track_controller__WEBPACK_IMPORTED_MODULE_2__["default"](this);

              // network controllers
              const levelController = this.levelController = new _controller_level_controller__WEBPACK_IMPORTED_MODULE_4__["default"](this);
              // FragmentTracker must be defined before StreamController because the order of event handling is important
              const fragmentTracker = new _controller_fragment_tracker__WEBPACK_IMPORTED_MODULE_5__.FragmentTracker(this);
              const keyLoader = new _loader_key_loader__WEBPACK_IMPORTED_MODULE_6__["default"](this.config);
              const streamController = this.streamController = new _controller_stream_controller__WEBPACK_IMPORTED_MODULE_7__["default"](this, fragmentTracker, keyLoader);

              // Cap level controller uses streamController to flush the buffer
              capLevelController.setStreamController(streamController);
              // fpsController uses streamController to switch when frames are being dropped
              fpsController.setStreamController(streamController);
              const networkControllers = [playListLoader, levelController, streamController];
              this.networkControllers = networkControllers;
              const coreComponents = [abrController, bufferController, capLevelController, fpsController, id3TrackController, fragmentTracker];
              this.audioTrackController = this.createController(config.audioTrackController, networkControllers);
              const AudioStreamControllerClass = config.audioStreamController;
              if (AudioStreamControllerClass) {
                networkControllers.push(new AudioStreamControllerClass(this, fragmentTracker, keyLoader));
              }
              // subtitleTrackController must be defined before subtitleStreamController because the order of event handling is important
              this.subtitleTrackController = this.createController(config.subtitleTrackController, networkControllers);
              const SubtitleStreamControllerClass = config.subtitleStreamController;
              if (SubtitleStreamControllerClass) {
                networkControllers.push(new SubtitleStreamControllerClass(this, fragmentTracker, keyLoader));
              }
              this.createController(config.timelineController, coreComponents);
              keyLoader.emeController = this.emeController = this.createController(config.emeController, coreComponents);
              this.cmcdController = this.createController(config.cmcdController, coreComponents);
              this.latencyController = this.createController(_controller_latency_controller__WEBPACK_IMPORTED_MODULE_3__["default"], coreComponents);
              this.coreComponents = coreComponents;
            }
            createController(ControllerClass, components) {
              if (ControllerClass) {
                const controllerInstance = new ControllerClass(this);
                if (components) {
                  components.push(controllerInstance);
                }
                return controllerInstance;
              }
              return null;
            }

            // Delegate the EventEmitter through the public API of Hls.js
            on(event, listener, context = this) {
              this._emitter.on(event, listener, context);
            }
            once(event, listener, context = this) {
              this._emitter.once(event, listener, context);
            }
            removeAllListeners(event) {
              this._emitter.removeAllListeners(event);
            }
            off(event, listener, context = this, once) {
              this._emitter.off(event, listener, context, once);
            }
            listeners(event) {
              return this._emitter.listeners(event);
            }
            emit(event, name, eventObject) {
              return this._emitter.emit(event, name, eventObject);
            }
            trigger(event, eventObject) {
              if (this.config.debug) {
                return this.emit(event, event, eventObject);
              } else {
                try {
                  return this.emit(event, event, eventObject);
                } catch (e) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.error('An internal error happened while handling event ' + event + '. Error message: "' + e.message + '". Here is a stacktrace:', e);
                  this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__.Events.ERROR, {
                    type: _errors__WEBPACK_IMPORTED_MODULE_13__.ErrorTypes.OTHER_ERROR,
                    details: _errors__WEBPACK_IMPORTED_MODULE_13__.ErrorDetails.INTERNAL_EXCEPTION,
                    fatal: false,
                    event: event,
                    error: e
                  });
                }
              }
              return false;
            }
            listenerCount(event) {
              return this._emitter.listenerCount(event);
            }

            /**
             * Dispose of the instance
             */
            destroy() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log('destroy');
              this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__.Events.DESTROYING, undefined);
              this.detachMedia();
              this.removeAllListeners();
              this._autoLevelCapping = -1;
              this.url = null;
              this.networkControllers.forEach(component => component.destroy());
              this.networkControllers.length = 0;
              this.coreComponents.forEach(component => component.destroy());
              this.coreComponents.length = 0;
            }

            /**
             * Attaches Hls.js to a media element
             * @param {HTMLMediaElement} media
             */
            attachMedia(media) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log('attachMedia');
              this._media = media;
              this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__.Events.MEDIA_ATTACHING, {
                media: media
              });
            }

            /**
             * Detach Hls.js from the media
             */
            detachMedia() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log('detachMedia');
              this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__.Events.MEDIA_DETACHING, undefined);
              this._media = null;
            }

            /**
             * Set the source URL. Can be relative or absolute.
             * @param {string} url
             */
            loadSource(url) {
              this.stopLoad();
              const media = this.media;
              const loadedSource = this.url;
              const loadingSource = this.url = url_toolkit__WEBPACK_IMPORTED_MODULE_0__.buildAbsoluteURL(self.location.href, url, {
                alwaysNormalize: true
              });
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`loadSource:${loadingSource}`);
              if (media && loadedSource && loadedSource !== loadingSource && this.bufferController.hasSourceTypes()) {
                this.detachMedia();
                this.attachMedia(media);
              }
              // when attaching to a source URL, trigger a playlist load
              this.trigger(_events__WEBPACK_IMPORTED_MODULE_12__.Events.MANIFEST_LOADING, {
                url: url
              });
            }

            /**
             * Start loading data from the stream source.
             * Depending on default config, client starts loading automatically when a source is set.
             *
             * @param {number} startPosition Set the start position to stream from
             * @default -1 None (from earliest point)
             */
            startLoad(startPosition = -1) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`startLoad(${startPosition})`);
              this.networkControllers.forEach(controller => {
                controller.startLoad(startPosition);
              });
            }

            /**
             * Stop loading of any stream data.
             */
            stopLoad() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log('stopLoad');
              this.networkControllers.forEach(controller => {
                controller.stopLoad();
              });
            }

            /**
             * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)
             */
            swapAudioCodec() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log('swapAudioCodec');
              this.streamController.swapAudioCodec();
            }

            /**
             * When the media-element fails, this allows to detach and then re-attach it
             * as one call (convenience method).
             *
             * Automatic recovery of media-errors by this process is configurable.
             */
            recoverMediaError() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log('recoverMediaError');
              const media = this._media;
              this.detachMedia();
              if (media) {
                this.attachMedia(media);
              }
            }
            removeLevel(levelIndex, urlId = 0) {
              this.levelController.removeLevel(levelIndex, urlId);
            }

            /**
             * @type {Level[]}
             */
            get levels() {
              const levels = this.levelController.levels;
              return levels ? levels : [];
            }

            /**
             * Index of quality level currently played
             * @type {number}
             */
            get currentLevel() {
              return this.streamController.currentLevel;
            }

            /**
             * Set quality level index immediately .
             * This will flush the current buffer to replace the quality asap.
             * That means playback will interrupt at least shortly to re-buffer and re-sync eventually.
             * @type {number} -1 for automatic level selection
             */
            set currentLevel(newLevel) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`set currentLevel:${newLevel}`);
              this.loadLevel = newLevel;
              this.abrController.clearTimer();
              this.streamController.immediateLevelSwitch();
            }

            /**
             * Index of next quality level loaded as scheduled by stream controller.
             * @type {number}
             */
            get nextLevel() {
              return this.streamController.nextLevel;
            }

            /**
             * Set quality level index for next loaded data.
             * This will switch the video quality asap, without interrupting playback.
             * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).
             * @type {number} -1 for automatic level selection
             */
            set nextLevel(newLevel) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`set nextLevel:${newLevel}`);
              this.levelController.manualLevel = newLevel;
              this.streamController.nextLevelSwitch();
            }

            /**
             * Return the quality level of the currently or last (of none is loaded currently) segment
             * @type {number}
             */
            get loadLevel() {
              return this.levelController.level;
            }

            /**
             * Set quality level index for next loaded data in a conservative way.
             * This will switch the quality without flushing, but interrupt current loading.
             * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.
             * @type {number} newLevel -1 for automatic level selection
             */
            set loadLevel(newLevel) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`set loadLevel:${newLevel}`);
              this.levelController.manualLevel = newLevel;
            }

            /**
             * get next quality level loaded
             * @type {number}
             */
            get nextLoadLevel() {
              return this.levelController.nextLoadLevel;
            }

            /**
             * Set quality level of next loaded segment in a fully "non-destructive" way.
             * Same as `loadLevel` but will wait for next switch (until current loading is done).
             * @type {number} level
             */
            set nextLoadLevel(level) {
              this.levelController.nextLoadLevel = level;
            }

            /**
             * Return "first level": like a default level, if not set,
             * falls back to index of first level referenced in manifest
             * @type {number}
             */
            get firstLevel() {
              return Math.max(this.levelController.firstLevel, this.minAutoLevel);
            }

            /**
             * Sets "first-level", see getter.
             * @type {number}
             */
            set firstLevel(newLevel) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`set firstLevel:${newLevel}`);
              this.levelController.firstLevel = newLevel;
            }

            /**
             * Return start level (level of first fragment that will be played back)
             * if not overrided by user, first level appearing in manifest will be used as start level
             * if -1 : automatic start level selection, playback will start from level matching download bandwidth
             * (determined from download of first segment)
             * @type {number}
             */
            get startLevel() {
              return this.levelController.startLevel;
            }

            /**
             * set  start level (level of first fragment that will be played back)
             * if not overrided by user, first level appearing in manifest will be used as start level
             * if -1 : automatic start level selection, playback will start from level matching download bandwidth
             * (determined from download of first segment)
             * @type {number} newLevel
             */
            set startLevel(newLevel) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`set startLevel:${newLevel}`);
              // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel
              if (newLevel !== -1) {
                newLevel = Math.max(newLevel, this.minAutoLevel);
              }
              this.levelController.startLevel = newLevel;
            }

            /**
             * Get the current setting for capLevelToPlayerSize
             *
             * @type {boolean}
             */
            get capLevelToPlayerSize() {
              return this.config.capLevelToPlayerSize;
            }

            /**
             * set  dynamically set capLevelToPlayerSize against (`CapLevelController`)
             *
             * @type {boolean}
             */
            set capLevelToPlayerSize(shouldStartCapping) {
              const newCapLevelToPlayerSize = !!shouldStartCapping;
              if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {
                if (newCapLevelToPlayerSize) {
                  this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.
                } else {
                  this.capLevelController.stopCapping();
                  this.autoLevelCapping = -1;
                  this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.
                }

                this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;
              }
            }

            /**
             * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)
             * @type {number}
             */
            get autoLevelCapping() {
              return this._autoLevelCapping;
            }

            /**
             * get bandwidth estimate
             * @type {number}
             */
            get bandwidthEstimate() {
              const {
                bwEstimator
              } = this.abrController;
              if (!bwEstimator) {
                return NaN;
              }
              return bwEstimator.getEstimate();
            }

            /**
             * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)
             * @type {number}
             */
            set autoLevelCapping(newLevel) {
              if (this._autoLevelCapping !== newLevel) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_9__.logger.log(`set autoLevelCapping:${newLevel}`);
                this._autoLevelCapping = newLevel;
              }
            }

            /**
             * True when automatic level selection enabled
             * @type {boolean}
             */
            get autoLevelEnabled() {
              return this.levelController.manualLevel === -1;
            }

            /**
             * Level set manually (if any)
             * @type {number}
             */
            get manualLevel() {
              return this.levelController.manualLevel;
            }

            /**
             * min level selectable in auto mode according to config.minAutoBitrate
             * @type {number}
             */
            get minAutoLevel() {
              const {
                levels,
                config: {
                  minAutoBitrate
                }
              } = this;
              if (!levels) return 0;
              const len = levels.length;
              for (let i = 0; i < len; i++) {
                if (levels[i].maxBitrate >= minAutoBitrate) {
                  return i;
                }
              }
              return 0;
            }

            /**
             * max level selectable in auto mode according to autoLevelCapping
             * @type {number}
             */
            get maxAutoLevel() {
              const {
                levels,
                autoLevelCapping
              } = this;
              let maxAutoLevel;
              if (autoLevelCapping === -1 && levels && levels.length) {
                maxAutoLevel = levels.length - 1;
              } else {
                maxAutoLevel = autoLevelCapping;
              }
              return maxAutoLevel;
            }

            /**
             * next automatically selected quality level
             * @type {number}
             */
            get nextAutoLevel() {
              // ensure next auto level is between  min and max auto level
              return Math.min(Math.max(this.abrController.nextAutoLevel, this.minAutoLevel), this.maxAutoLevel);
            }

            /**
             * this setter is used to force next auto level.
             * this is useful to force a switch down in auto mode:
             * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)
             * forced value is valid for one fragment. upon successful frag loading at forced level,
             * this value will be resetted to -1 by ABR controller.
             * @type {number}
             */
            set nextAutoLevel(nextLevel) {
              this.abrController.nextAutoLevel = Math.max(this.minAutoLevel, nextLevel);
            }

            /**
             * get the datetime value relative to media.currentTime for the active level Program Date Time if present
             * @type {Date}
             */
            get playingDate() {
              return this.streamController.currentProgramDateTime;
            }
            get mainForwardBufferInfo() {
              return this.streamController.getMainFwdBufferInfo();
            }

            /**
             * @type {AudioTrack[]}
             */
            get audioTracks() {
              const audioTrackController = this.audioTrackController;
              return audioTrackController ? audioTrackController.audioTracks : [];
            }

            /**
             * index of the selected audio track (index in audio track lists)
             * @type {number}
             */
            get audioTrack() {
              const audioTrackController = this.audioTrackController;
              return audioTrackController ? audioTrackController.audioTrack : -1;
            }

            /**
             * selects an audio track, based on its index in audio track lists
             * @type {number}
             */
            set audioTrack(audioTrackId) {
              const audioTrackController = this.audioTrackController;
              if (audioTrackController) {
                audioTrackController.audioTrack = audioTrackId;
              }
            }

            /**
             * get alternate subtitle tracks list from playlist
             * @type {MediaPlaylist[]}
             */
            get subtitleTracks() {
              const subtitleTrackController = this.subtitleTrackController;
              return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];
            }

            /**
             * index of the selected subtitle track (index in subtitle track lists)
             * @type {number}
             */
            get subtitleTrack() {
              const subtitleTrackController = this.subtitleTrackController;
              return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;
            }
            get media() {
              return this._media;
            }

            /**
             * select an subtitle track, based on its index in subtitle track lists
             * @type {number}
             */
            set subtitleTrack(subtitleTrackId) {
              const subtitleTrackController = this.subtitleTrackController;
              if (subtitleTrackController) {
                subtitleTrackController.subtitleTrack = subtitleTrackId;
              }
            }

            /**
             * @type {boolean}
             */
            get subtitleDisplay() {
              const subtitleTrackController = this.subtitleTrackController;
              return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;
            }

            /**
             * Enable/disable subtitle display rendering
             * @type {boolean}
             */
            set subtitleDisplay(value) {
              const subtitleTrackController = this.subtitleTrackController;
              if (subtitleTrackController) {
                subtitleTrackController.subtitleDisplay = value;
              }
            }

            /**
             * get mode for Low-Latency HLS loading
             * @type {boolean}
             */
            get lowLatencyMode() {
              return this.config.lowLatencyMode;
            }

            /**
             * Enable/disable Low-Latency HLS part playlist and segment loading, and start live streams at playlist PART-HOLD-BACK rather than HOLD-BACK.
             * @type {boolean}
             */
            set lowLatencyMode(mode) {
              this.config.lowLatencyMode = mode;
            }

            /**
             * position (in seconds) of live sync point (ie edge of live position minus safety delay defined by ```hls.config.liveSyncDuration```)
             * @type {number}
             */
            get liveSyncPosition() {
              return this.latencyController.liveSyncPosition;
            }

            /**
             * estimated position (in seconds) of live edge (ie edge of live playlist plus time sync playlist advanced)
             * returns 0 before first playlist is loaded
             * @type {number}
             */
            get latency() {
              return this.latencyController.latency;
            }

            /**
             * maximum distance from the edge before the player seeks forward to ```hls.liveSyncPosition```
             * configured using ```liveMaxLatencyDurationCount``` (multiple of target duration) or ```liveMaxLatencyDuration```
             * returns 0 before first playlist is loaded
             * @type {number}
             */
            get maxLatency() {
              return this.latencyController.maxLatency;
            }

            /**
             * target distance from the edge as calculated by the latency controller
             * @type {number}
             */
            get targetLatency() {
              return this.latencyController.targetLatency;
            }

            /**
             * the rate at which the edge of the current live playlist is advancing or 1 if there is none
             * @type {number}
             */
            get drift() {
              return this.latencyController.drift;
            }

            /**
             * set to true when startLoad is called before MANIFEST_PARSED event
             * @type {boolean}
             */
            get forceStartLoad() {
              return this.streamController.forceStartLoad;
            }
          }

          /***/
        }),

/***/ "./src/is-supported.ts":
/*!*****************************!*\
  !*** ./src/is-supported.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "changeTypeSupported": () => (/* binding */ changeTypeSupported),
/* harmony export */   "isSupported": () => (/* binding */ isSupported)
            /* harmony export */
          });
/* harmony import */ var _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils/mediasource-helper */ "./src/utils/mediasource-helper.ts");

          function getSourceBuffer() {
            return self.SourceBuffer || self.WebKitSourceBuffer;
          }
          function isSupported() {
            const mediaSource = (0, _utils_mediasource_helper__WEBPACK_IMPORTED_MODULE_0__.getMediaSource)();
            if (!mediaSource) {
              return false;
            }
            const sourceBuffer = getSourceBuffer();
            const isTypeSupported = mediaSource && typeof mediaSource.isTypeSupported === 'function' && mediaSource.isTypeSupported('video/mp4; codecs="avc1.42E01E,mp4a.40.2"');

            // if SourceBuffer is exposed ensure its API is valid
            // safari and old version of Chrome doe not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible
            const sourceBufferValidAPI = !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';
            return !!isTypeSupported && !!sourceBufferValidAPI;
          }
          function changeTypeSupported() {
            const sourceBuffer = getSourceBuffer();
            return typeof sourceBuffer?.prototype?.changeType === 'function';
          }

          /***/
        }),

/***/ "./src/loader/date-range.ts":
/*!**********************************!*\
  !*** ./src/loader/date-range.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "DateRange": () => (/* binding */ DateRange),
/* harmony export */   "DateRangeAttribute": () => (/* binding */ DateRangeAttribute)
            /* harmony export */
          });
/* harmony import */ var _utils_attr_list__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/attr-list */ "./src/utils/attr-list.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");


          let DateRangeAttribute;
          (function (DateRangeAttribute) {
            DateRangeAttribute["ID"] = "ID";
            DateRangeAttribute["CLASS"] = "CLASS";
            DateRangeAttribute["START_DATE"] = "START-DATE";
            DateRangeAttribute["DURATION"] = "DURATION";
            DateRangeAttribute["END_DATE"] = "END-DATE";
            DateRangeAttribute["END_ON_NEXT"] = "END-ON-NEXT";
            DateRangeAttribute["PLANNED_DURATION"] = "PLANNED-DURATION";
            DateRangeAttribute["SCTE35_OUT"] = "SCTE35-OUT";
            DateRangeAttribute["SCTE35_IN"] = "SCTE35-IN";
          })(DateRangeAttribute || (DateRangeAttribute = {}));
          class DateRange {
            constructor(dateRangeAttr, dateRangeWithSameId) {
              if (dateRangeWithSameId) {
                const previousAttr = dateRangeWithSameId.attr;
                for (const key in previousAttr) {
                  if (Object.prototype.hasOwnProperty.call(dateRangeAttr, key) && dateRangeAttr[key] !== previousAttr[key]) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_1__.logger.warn(`DATERANGE tag attribute: "${key}" does not match for tags with ID: "${dateRangeAttr.ID}"`);
                    this._badValueForSameId = key;
                    break;
                  }
                }
                // Merge DateRange tags with the same ID
                dateRangeAttr = Object.assign(new _utils_attr_list__WEBPACK_IMPORTED_MODULE_0__.AttrList({}), previousAttr, dateRangeAttr);
              }
              this.attr = dateRangeAttr;
              this._startDate = new Date(dateRangeAttr[DateRangeAttribute.START_DATE]);
              if (DateRangeAttribute.END_DATE in this.attr) {
                const endDate = new Date(this.attr[DateRangeAttribute.END_DATE]);
                if (Number.isFinite(endDate.getTime())) {
                  this._endDate = endDate;
                }
              }
            }
            get id() {
              return this.attr.ID;
            }
            get class() {
              return this.attr.CLASS;
            }
            get startDate() {
              return this._startDate;
            }
            get endDate() {
              if (this._endDate) {
                return this._endDate;
              }
              const duration = this.duration;
              if (duration !== null) {
                return new Date(this._startDate.getTime() + duration * 1000);
              }
              return null;
            }
            get duration() {
              if (DateRangeAttribute.DURATION in this.attr) {
                const duration = this.attr.decimalFloatingPoint(DateRangeAttribute.DURATION);
                if (Number.isFinite(duration)) {
                  return duration;
                }
              } else if (this._endDate) {
                return (this._endDate.getTime() - this._startDate.getTime()) / 1000;
              }
              return null;
            }
            get plannedDuration() {
              if (DateRangeAttribute.PLANNED_DURATION in this.attr) {
                return this.attr.decimalFloatingPoint(DateRangeAttribute.PLANNED_DURATION);
              }
              return null;
            }
            get endOnNext() {
              return this.attr.bool(DateRangeAttribute.END_ON_NEXT);
            }
            get isValid() {
              return !!this.id && !this._badValueForSameId && Number.isFinite(this.startDate.getTime()) && (this.duration === null || this.duration >= 0) && (!this.endOnNext || !!this.class);
            }
          }

          /***/
        }),

/***/ "./src/loader/fragment-loader.ts":
/*!***************************************!*\
  !*** ./src/loader/fragment-loader.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "LoadError": () => (/* binding */ LoadError),
/* harmony export */   "default": () => (/* binding */ FragmentLoader)
            /* harmony export */
          });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");

          const MIN_CHUNK_SIZE = Math.pow(2, 17); // 128kb

          class FragmentLoader {
            loader = null;
            partLoadTimeout = -1;
            constructor(config) {
              this.config = config;
            }
            destroy() {
              if (this.loader) {
                this.loader.destroy();
                this.loader = null;
              }
            }
            abort() {
              if (this.loader) {
                // Abort the loader for current fragment. Only one may load at any given time
                this.loader.abort();
              }
            }
            load(frag, onProgress) {
              const url = frag.url;
              if (!url) {
                return Promise.reject(new LoadError({
                  type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.FRAG_LOAD_ERROR,
                  fatal: false,
                  frag,
                  networkDetails: null
                }, `Fragment does not have a ${url ? 'part list' : 'url'}`));
              }
              this.abort();
              const config = this.config;
              const FragmentILoader = config.fLoader;
              const DefaultILoader = config.loader;
              return new Promise((resolve, reject) => {
                if (this.loader) {
                  this.loader.destroy();
                }
                const loader = this.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);
                const loaderContext = createLoaderContext(frag);
                const loaderConfig = {
                  timeout: config.fragLoadingTimeOut,
                  maxRetry: 0,
                  retryDelay: 0,
                  maxRetryDelay: config.fragLoadingMaxRetryTimeout,
                  highWaterMark: frag.sn === 'initSegment' ? Infinity : MIN_CHUNK_SIZE
                };
                // Assign frag stats to the loader's stats reference
                frag.stats = loader.stats;
                loader.load(loaderContext, loaderConfig, {
                  onSuccess: (response, stats, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    let payload = response.data;
                    if (context.resetIV && frag.decryptdata) {
                      frag.decryptdata.iv = new Uint8Array(payload.slice(0, 16));
                      payload = payload.slice(16);
                    }
                    resolve({
                      frag,
                      part: null,
                      payload,
                      networkDetails
                    });
                  },
                  onError: (response, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    reject(new LoadError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.FRAG_LOAD_ERROR,
                      fatal: false,
                      frag,
                      response,
                      networkDetails
                    }));
                  },
                  onAbort: (stats, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    reject(new LoadError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.INTERNAL_ABORTED,
                      fatal: false,
                      frag,
                      networkDetails
                    }));
                  },
                  onTimeout: (response, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    reject(new LoadError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.FRAG_LOAD_TIMEOUT,
                      fatal: false,
                      frag,
                      networkDetails
                    }));
                  },
                  onProgress: (stats, context, data, networkDetails) => {
                    if (onProgress) {
                      onProgress({
                        frag,
                        part: null,
                        payload: data,
                        networkDetails
                      });
                    }
                  }
                });
              });
            }
            loadPart(frag, part, onProgress) {
              this.abort();
              const config = this.config;
              const FragmentILoader = config.fLoader;
              const DefaultILoader = config.loader;
              return new Promise((resolve, reject) => {
                if (this.loader) {
                  this.loader.destroy();
                }
                const loader = this.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);
                const loaderContext = createLoaderContext(frag, part);
                const loaderConfig = {
                  timeout: config.fragLoadingTimeOut,
                  maxRetry: 0,
                  retryDelay: 0,
                  maxRetryDelay: config.fragLoadingMaxRetryTimeout,
                  highWaterMark: MIN_CHUNK_SIZE
                };
                // Assign part stats to the loader's stats reference
                part.stats = loader.stats;
                loader.load(loaderContext, loaderConfig, {
                  onSuccess: (response, stats, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    this.updateStatsFromPart(frag, part);
                    const partLoadedData = {
                      frag,
                      part,
                      payload: response.data,
                      networkDetails
                    };
                    onProgress(partLoadedData);
                    resolve(partLoadedData);
                  },
                  onError: (response, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    reject(new LoadError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.FRAG_LOAD_ERROR,
                      fatal: false,
                      frag,
                      part,
                      response,
                      networkDetails
                    }));
                  },
                  onAbort: (stats, context, networkDetails) => {
                    frag.stats.aborted = part.stats.aborted;
                    this.resetLoader(frag, loader);
                    reject(new LoadError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.INTERNAL_ABORTED,
                      fatal: false,
                      frag,
                      part,
                      networkDetails
                    }));
                  },
                  onTimeout: (response, context, networkDetails) => {
                    this.resetLoader(frag, loader);
                    reject(new LoadError({
                      type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                      details: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.FRAG_LOAD_TIMEOUT,
                      fatal: false,
                      frag,
                      part,
                      networkDetails
                    }));
                  }
                });
              });
            }
            updateStatsFromPart(frag, part) {
              const fragStats = frag.stats;
              const partStats = part.stats;
              const partTotal = partStats.total;
              fragStats.loaded += partStats.loaded;
              if (partTotal) {
                const estTotalParts = Math.round(frag.duration / part.duration);
                const estLoadedParts = Math.min(Math.round(fragStats.loaded / partTotal), estTotalParts);
                const estRemainingParts = estTotalParts - estLoadedParts;
                const estRemainingBytes = estRemainingParts * Math.round(fragStats.loaded / estLoadedParts);
                fragStats.total = fragStats.loaded + estRemainingBytes;
              } else {
                fragStats.total = Math.max(fragStats.loaded, fragStats.total);
              }
              const fragLoading = fragStats.loading;
              const partLoading = partStats.loading;
              if (fragLoading.start) {
                // add to fragment loader latency
                fragLoading.first += partLoading.first - partLoading.start;
              } else {
                fragLoading.start = partLoading.start;
                fragLoading.first = partLoading.first;
              }
              fragLoading.end = partLoading.end;
            }
            resetLoader(frag, loader) {
              frag.loader = null;
              if (this.loader === loader) {
                self.clearTimeout(this.partLoadTimeout);
                this.loader = null;
              }
              loader.destroy();
            }
          }
          function createLoaderContext(frag, part = null) {
            const segment = part || frag;
            const loaderContext = {
              frag,
              part,
              responseType: 'arraybuffer',
              url: segment.url,
              headers: {},
              rangeStart: 0,
              rangeEnd: 0
            };
            const start = segment.byteRangeStartOffset;
            const end = segment.byteRangeEndOffset;
            if (Number.isFinite(start) && Number.isFinite(end)) {
              let byteRangeStart = start;
              let byteRangeEnd = end;
              if (frag.sn === 'initSegment' && frag.decryptdata?.method === 'AES-128') {
                // MAP segment encrypted with method 'AES-128', when served with HTTP Range,
                // has the unencrypted size specified in the range.
                // Ref: https://tools.ietf.org/html/draft-pantos-hls-rfc8216bis-08#section-6.3.6
                const fragmentLen = end - start;
                if (fragmentLen % 16) {
                  byteRangeEnd = end + (16 - fragmentLen % 16);
                }
                if (start !== 0) {
                  loaderContext.resetIV = true;
                  byteRangeStart = start - 16;
                }
              }
              loaderContext.rangeStart = byteRangeStart;
              loaderContext.rangeEnd = byteRangeEnd;
            }
            return loaderContext;
          }
          class LoadError extends Error {
            constructor(data, ...params) {
              super(...params);
              this.data = data;
            }
          }

          /***/
        }),

/***/ "./src/loader/fragment.ts":
/*!********************************!*\
  !*** ./src/loader/fragment.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "BaseSegment": () => (/* binding */ BaseSegment),
/* harmony export */   "ElementaryStreamTypes": () => (/* binding */ ElementaryStreamTypes),
/* harmony export */   "Fragment": () => (/* binding */ Fragment),
/* harmony export */   "Part": () => (/* binding */ Part)
            /* harmony export */
          });
/* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
/* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(url_toolkit__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _load_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./load-stats */ "./src/loader/load-stats.ts");


          let ElementaryStreamTypes;
          (function (ElementaryStreamTypes) {
            ElementaryStreamTypes["AUDIO"] = "audio";
            ElementaryStreamTypes["VIDEO"] = "video";
            ElementaryStreamTypes["AUDIOVIDEO"] = "audiovideo";
          })(ElementaryStreamTypes || (ElementaryStreamTypes = {}));
          class BaseSegment {
            _byteRange = null;
            _url = null;

            // baseurl is the URL to the playlist

            // Holds the types of data this fragment supports
            elementaryStreams = {
              [ElementaryStreamTypes.AUDIO]: null,
              [ElementaryStreamTypes.VIDEO]: null,
              [ElementaryStreamTypes.AUDIOVIDEO]: null
            };
            constructor(baseurl) {
              this.baseurl = baseurl;
            }

            // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array
            setByteRange(value, previous) {
              const params = value.split('@', 2);
              const byteRange = [];
              if (params.length === 1) {
                byteRange[0] = previous ? previous.byteRangeEndOffset : 0;
              } else {
                byteRange[0] = parseInt(params[1]);
              }
              byteRange[1] = parseInt(params[0]) + byteRange[0];
              this._byteRange = byteRange;
            }
            get byteRange() {
              if (!this._byteRange) {
                return [];
              }
              return this._byteRange;
            }
            get byteRangeStartOffset() {
              return this.byteRange[0];
            }
            get byteRangeEndOffset() {
              return this.byteRange[1];
            }
            get url() {
              if (!this._url && this.baseurl && this.relurl) {
                this._url = (0, url_toolkit__WEBPACK_IMPORTED_MODULE_0__.buildAbsoluteURL)(this.baseurl, this.relurl, {
                  alwaysNormalize: true
                });
              }
              return this._url || '';
            }
            set url(value) {
              this._url = value;
            }
          }
          class Fragment extends BaseSegment {
            _decryptdata = null;
            rawProgramDateTime = null;
            programDateTime = null;
            tagList = [];

            // EXTINF has to be present for a m3u8 to be considered valid
            duration = 0;
            // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'
            sn = 0;
            // levelkeys are the EXT-X-KEY tags that apply to this segment for decryption
            // core difference from the private field _decryptdata is the lack of the initialized IV
            // _decryptdata will set the IV for this segment based on the segment number in the fragment

            // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading
            loader = null;
            // A reference to the key loader. Set while the key is loading, and removed afterwards. Used to abort key loading
            keyLoader = null;
            // The level/track index to which the fragment belongs
            level = -1;
            // The continuity counter of the fragment
            cc = 0;
            // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.

            // The start time of the fragment, as listed in the manifest. Updated after transmux complete.
            start = 0;
            // Set by `updateFragPTSDTS` in level-helper

            // Load/parse timing information
            stats = new _load_stats__WEBPACK_IMPORTED_MODULE_1__.LoadStats();
            urlId = 0;
            // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered
            bitrateTest = false;
            // #EXTINF  segment title
            title = null;
            // The Media Initialization Section for this segment
            initSegment = null;
            // Fragment is the last fragment in the media playlist

            constructor(type, baseurl) {
              super(baseurl);
              this.type = type;
            }
            get decryptdata() {
              const {
                levelkeys
              } = this;
              if (!levelkeys && !this._decryptdata) {
                return null;
              }
              if (!this._decryptdata && this.levelkeys && !this.levelkeys.NONE) {
                const key = this.levelkeys.identity;
                if (key) {
                  this._decryptdata = key.getDecryptData(this.sn);
                } else {
                  const keyFormats = Object.keys(this.levelkeys);
                  if (keyFormats.length === 1) {
                    return this._decryptdata = this.levelkeys[keyFormats[0]].getDecryptData(this.sn);
                  } else {
                    // Multiple keys. key-loader to call Fragment.setKeyFormat based on selected key-system.
                  }
                }
              }
              return this._decryptdata;
            }
            get end() {
              return this.start + this.duration;
            }
            get endProgramDateTime() {
              if (this.programDateTime === null) {
                return null;
              }
              if (!Number.isFinite(this.programDateTime)) {
                return null;
              }
              const duration = !Number.isFinite(this.duration) ? 0 : this.duration;
              return this.programDateTime + duration * 1000;
            }
            get encrypted() {
              // At the m3u8-parser level we need to add support for manifest signalled keyformats
              // when we want the fragment to start reporting that it is encrypted.
              // Currently, keyFormat will only be set for identity keys
              if (this._decryptdata?.encrypted) {
                return true;
              } else if (this.levelkeys) {
                const keyFormats = Object.keys(this.levelkeys);
                const len = keyFormats.length;
                if (len > 1 || len === 1 && this.levelkeys[keyFormats[0]].encrypted) {
                  return true;
                }
              }
              return false;
            }
            setKeyFormat(keyFormat) {
              if (this.levelkeys) {
                const key = this.levelkeys[keyFormat];
                if (key && !this._decryptdata) {
                  this._decryptdata = key.getDecryptData(this.sn);
                }
              }
            }
            abortRequests() {
              this.loader?.abort();
              this.keyLoader?.abort();
            }
            setElementaryStreamInfo(type, startPTS, endPTS, startDTS, endDTS, partial = false) {
              const {
                elementaryStreams
              } = this;
              const info = elementaryStreams[type];
              if (!info) {
                elementaryStreams[type] = {
                  startPTS,
                  endPTS,
                  startDTS,
                  endDTS,
                  partial
                };
                return;
              }
              info.startPTS = Math.min(info.startPTS, startPTS);
              info.endPTS = Math.max(info.endPTS, endPTS);
              info.startDTS = Math.min(info.startDTS, startDTS);
              info.endDTS = Math.max(info.endDTS, endDTS);
            }
            clearElementaryStreamInfo() {
              const {
                elementaryStreams
              } = this;
              elementaryStreams[ElementaryStreamTypes.AUDIO] = null;
              elementaryStreams[ElementaryStreamTypes.VIDEO] = null;
              elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;
            }
          }
          class Part extends BaseSegment {
            fragOffset = 0;
            duration = 0;
            gap = false;
            independent = false;
            stats = new _load_stats__WEBPACK_IMPORTED_MODULE_1__.LoadStats();
            constructor(partAttrs, frag, baseurl, index, previous) {
              super(baseurl);
              this.duration = partAttrs.decimalFloatingPoint('DURATION');
              this.gap = partAttrs.bool('GAP');
              this.independent = partAttrs.bool('INDEPENDENT');
              this.relurl = partAttrs.enumeratedString('URI');
              this.fragment = frag;
              this.index = index;
              const byteRange = partAttrs.enumeratedString('BYTERANGE');
              if (byteRange) {
                this.setByteRange(byteRange, previous);
              }
              if (previous) {
                this.fragOffset = previous.fragOffset + previous.duration;
              }
            }
            get start() {
              return this.fragment.start + this.fragOffset;
            }
            get end() {
              return this.start + this.duration;
            }
            get loaded() {
              const {
                elementaryStreams
              } = this;
              return !!(elementaryStreams.audio || elementaryStreams.video || elementaryStreams.audiovideo);
            }
          }

          /***/
        }),

/***/ "./src/loader/key-loader.ts":
/*!**********************************!*\
  !*** ./src/loader/key-loader.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ KeyLoader)
            /* harmony export */
          });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _fragment_loader__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fragment-loader */ "./src/loader/fragment-loader.ts");


          class KeyLoader {
            keyUriToKeyInfo = {};
            emeController = null;
            constructor(config) {
              this.config = config;
            }
            abort() {
              for (const uri in this.keyUriToKeyInfo) {
                const loader = this.keyUriToKeyInfo[uri].loader;
                if (loader) {
                  loader.abort();
                }
              }
            }
            detach() {
              for (const uri in this.keyUriToKeyInfo) {
                const keyInfo = this.keyUriToKeyInfo[uri];
                // Remove cached EME keys on detach
                if (keyInfo.mediaKeySessionContext || keyInfo.decryptdata.isCommonEncryption) {
                  delete this.keyUriToKeyInfo[uri];
                }
              }
            }
            destroy() {
              this.detach();
              for (const uri in this.keyUriToKeyInfo) {
                const loader = this.keyUriToKeyInfo[uri].loader;
                if (loader) {
                  loader.destroy();
                }
              }
              this.keyUriToKeyInfo = {};
            }
            createKeyLoadError(frag, details = _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_ERROR, networkDetails, message) {
              return new _fragment_loader__WEBPACK_IMPORTED_MODULE_1__.LoadError({
                type: _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorTypes.NETWORK_ERROR,
                details,
                fatal: false,
                frag,
                networkDetails
              });
            }
            loadClear(loadingFrag, encryptedFragments) {
              if (this.emeController && this.config.emeEnabled) {
                // access key-system with nearest key on start (loaidng frag is unencrypted)
                const {
                  sn,
                  cc
                } = loadingFrag;
                for (let i = 0; i < encryptedFragments.length; i++) {
                  const frag = encryptedFragments[i];
                  if (cc <= frag.cc && (sn === 'initSegment' || sn < frag.sn)) {
                    this.emeController.selectKeySystemFormat(frag).then(keySystemFormat => {
                      frag.setKeyFormat(keySystemFormat);
                    });
                    break;
                  }
                }
              }
            }
            load(frag) {
              if (!frag.decryptdata && frag.encrypted && this.emeController) {
                // Multiple keys, but none selected, resolve in eme-controller
                return this.emeController.selectKeySystemFormat(frag).then(keySystemFormat => {
                  return this.loadInternal(frag, keySystemFormat);
                });
              }
              return this.loadInternal(frag);
            }
            loadInternal(frag, keySystemFormat) {
              if (keySystemFormat) {
                frag.setKeyFormat(keySystemFormat);
              }
              const decryptdata = frag.decryptdata;
              if (!decryptdata) {
                const errorMessage = keySystemFormat ? `Expected frag.decryptdata to be defined after setting format ${keySystemFormat}` : 'Missing decryption data on fragment in onKeyLoading';
                return Promise.reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_ERROR, null, errorMessage));
              }
              const uri = decryptdata.uri;
              if (!uri) {
                return Promise.reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_ERROR, null, `Invalid key URI: "${uri}"`));
              }
              let keyInfo = this.keyUriToKeyInfo[uri];
              if (keyInfo?.decryptdata.key) {
                decryptdata.key = keyInfo.decryptdata.key;
                return Promise.resolve({
                  frag,
                  keyInfo
                });
              }
              // Return key load promise as long as it does not have a mediakey session with an unusable key status
              if (keyInfo?.keyLoadPromise) {
                switch (keyInfo.mediaKeySessionContext?.keyStatus) {
                  case undefined:
                  case 'status-pending':
                  case 'usable':
                  case 'usable-in-future':
                    return keyInfo.keyLoadPromise;
                }
                // If we have a key session and status and it is not pending or usable, continue
                // This will go back to the eme-controller for expired keys to get a new keyLoadPromise
              }

              // Load the key or return the loading promise
              keyInfo = this.keyUriToKeyInfo[uri] = {
                decryptdata,
                keyLoadPromise: null,
                loader: null,
                mediaKeySessionContext: null
              };
              switch (decryptdata.method) {
                case 'ISO-23001-7':
                case 'SAMPLE-AES':
                case 'SAMPLE-AES-CENC':
                case 'SAMPLE-AES-CTR':
                  if (decryptdata.keyFormat === 'identity') {
                    // loadKeyHTTP handles http(s) and data URLs
                    return this.loadKeyHTTP(keyInfo, frag);
                  }
                  return this.loadKeyEME(keyInfo, frag);
                case 'AES-128':
                  return this.loadKeyHTTP(keyInfo, frag);
                default:
                  return Promise.reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_ERROR, null, `Key supplied with unsupported METHOD: "${decryptdata.method}"`));
              }
            }
            loadKeyEME(keyInfo, frag) {
              const keyLoadedData = {
                frag,
                keyInfo
              };
              if (this.emeController && this.config.emeEnabled) {
                const keySessionContextPromise = this.emeController.loadKey(keyLoadedData);
                if (keySessionContextPromise) {
                  return (keyInfo.keyLoadPromise = keySessionContextPromise.then(keySessionContext => {
                    keyInfo.mediaKeySessionContext = keySessionContext;
                    return keyLoadedData;
                  })).catch(error => {
                    // Remove promise for license renewal or retry
                    keyInfo.keyLoadPromise = null;
                    throw error;
                  });
                }
              }
              return Promise.resolve(keyLoadedData);
            }
            loadKeyHTTP(keyInfo, frag) {
              const config = this.config;
              const Loader = config.loader;
              const keyLoader = new Loader(config);
              frag.keyLoader = keyInfo.loader = keyLoader;
              return keyInfo.keyLoadPromise = new Promise((resolve, reject) => {
                const loaderContext = {
                  keyInfo,
                  frag,
                  responseType: 'arraybuffer',
                  url: keyInfo.decryptdata.uri
                };

                // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,
                // key-loader will trigger an error and rely on stream-controller to handle retry logic.
                // this will also align retry logic with fragment-loader
                const loaderConfig = {
                  timeout: config.fragLoadingTimeOut,
                  maxRetry: 0,
                  retryDelay: config.fragLoadingRetryDelay,
                  maxRetryDelay: config.fragLoadingMaxRetryTimeout,
                  highWaterMark: 0
                };
                const loaderCallbacks = {
                  onSuccess: (response, stats, context, networkDetails) => {
                    const {
                      frag,
                      keyInfo,
                      url: uri
                    } = context;
                    if (!frag.decryptdata || keyInfo !== this.keyUriToKeyInfo[uri]) {
                      return reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_ERROR, networkDetails, 'after key load, decryptdata unset or changed'));
                    }
                    keyInfo.decryptdata.key = frag.decryptdata.key = new Uint8Array(response.data);

                    // detach fragment key loader on load success
                    frag.keyLoader = null;
                    keyInfo.loader = null;
                    resolve({
                      frag,
                      keyInfo
                    });
                  },
                  onError: (error, context, networkDetails) => {
                    this.resetLoader(context);
                    reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_ERROR, networkDetails));
                  },
                  onTimeout: (stats, context, networkDetails) => {
                    this.resetLoader(context);
                    reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.KEY_LOAD_TIMEOUT, networkDetails));
                  },
                  onAbort: (stats, context, networkDetails) => {
                    this.resetLoader(context);
                    reject(this.createKeyLoadError(frag, _errors__WEBPACK_IMPORTED_MODULE_0__.ErrorDetails.INTERNAL_ABORTED, networkDetails));
                  }
                };
                keyLoader.load(loaderContext, loaderConfig, loaderCallbacks);
              });
            }
            resetLoader(context) {
              const {
                frag,
                keyInfo,
                url: uri
              } = context;
              const loader = keyInfo.loader;
              if (frag.keyLoader === loader) {
                frag.keyLoader = null;
                keyInfo.loader = null;
              }
              delete this.keyUriToKeyInfo[uri];
              if (loader) {
                loader.destroy();
              }
            }
          }

          /***/
        }),

/***/ "./src/loader/level-details.ts":
/*!*************************************!*\
  !*** ./src/loader/level-details.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "LevelDetails": () => (/* binding */ LevelDetails)
            /* harmony export */
          });
          const DEFAULT_TARGET_DURATION = 10;
          class LevelDetails {
            PTSKnown = false;
            alignedSliding = false;
            endCC = 0;
            endSN = 0;
            partList = null;
            live = true;
            ageHeader = 0;
            updated = true;
            advanced = true;
            // Manifest reload synchronization
            misses = 0;
            startCC = 0;
            startSN = 0;
            startTimeOffset = null;
            targetduration = 0;
            totalduration = 0;
            type = null;
            m3u8 = '';
            version = null;
            canBlockReload = false;
            canSkipUntil = 0;
            canSkipDateRanges = false;
            skippedSegments = 0;
            partHoldBack = 0;
            holdBack = 0;
            partTarget = 0;
            tuneInGoal = 0;
            driftStartTime = 0;
            driftEndTime = 0;
            driftStart = 0;
            driftEnd = 0;
            constructor(baseUrl) {
              this.fragments = [];
              this.encryptedFragments = [];
              this.dateRanges = {};
              this.url = baseUrl;
            }
            reloaded(previous) {
              if (!previous) {
                this.advanced = true;
                this.updated = true;
                return;
              }
              const partSnDiff = this.lastPartSn - previous.lastPartSn;
              const partIndexDiff = this.lastPartIndex - previous.lastPartIndex;
              this.updated = this.endSN !== previous.endSN || !!partIndexDiff || !!partSnDiff;
              this.advanced = this.endSN > previous.endSN || partSnDiff > 0 || partSnDiff === 0 && partIndexDiff > 0;
              if (this.updated || this.advanced) {
                this.misses = Math.floor(previous.misses * 0.6);
              } else {
                this.misses = previous.misses + 1;
              }
              this.availabilityDelay = previous.availabilityDelay;
            }
            get hasProgramDateTime() {
              if (this.fragments.length) {
                return Number.isFinite(this.fragments[this.fragments.length - 1].programDateTime);
              }
              return false;
            }
            get levelTargetDuration() {
              return this.averagetargetduration || this.targetduration || DEFAULT_TARGET_DURATION;
            }
            get drift() {
              const runTime = this.driftEndTime - this.driftStartTime;
              if (runTime > 0) {
                const runDuration = this.driftEnd - this.driftStart;
                return runDuration * 1000 / runTime;
              }
              return 1;
            }
            get edge() {
              return this.partEnd || this.fragmentEnd;
            }
            get partEnd() {
              if (this.partList?.length) {
                return this.partList[this.partList.length - 1].end;
              }
              return this.fragmentEnd;
            }
            get fragmentEnd() {
              if (this.fragments?.length) {
                return this.fragments[this.fragments.length - 1].end;
              }
              return 0;
            }
            get age() {
              if (this.advancedDateTime) {
                return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;
              }
              return 0;
            }
            get lastPartIndex() {
              if (this.partList?.length) {
                return this.partList[this.partList.length - 1].index;
              }
              return -1;
            }
            get lastPartSn() {
              if (this.partList?.length) {
                return this.partList[this.partList.length - 1].fragment.sn;
              }
              return this.endSN;
            }
          }

          /***/
        }),

/***/ "./src/loader/level-key.ts":
/*!*********************************!*\
  !*** ./src/loader/level-key.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "LevelKey": () => (/* binding */ LevelKey)
            /* harmony export */
          });
/* harmony import */ var _utils_keysystem_util__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/keysystem-util */ "./src/utils/keysystem-util.ts");
/* harmony import */ var _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/mediakeys-helper */ "./src/utils/mediakeys-helper.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _utils_numeric_encoding_utils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/numeric-encoding-utils */ "./src/utils/numeric-encoding-utils.ts");





          let keyUriToKeyIdMap = {};
          class LevelKey {
            iv = null;
            key = null;
            keyId = null;
            pssh = null;
            static clearKeyUriToKeyIdMap() {
              keyUriToKeyIdMap = {};
            }
            constructor(method, uri, format, formatversions = [1], iv = null) {
              this.method = method;
              this.uri = uri;
              this.keyFormat = format;
              this.keyFormatVersions = formatversions;
              this.iv = iv;
              this.encrypted = method ? method !== 'NONE' : false;
              this.isCommonEncryption = this.encrypted && method !== 'AES-128';
            }
            isSupported() {
              // If it's Segment encryption or No encryption, just select that key system
              if (this.method) {
                if (this.method === 'AES-128' || this.method === 'NONE') {
                  return true;
                }
                switch (this.keyFormat) {
                  case 'identity':
                    // Maintain support for clear SAMPLE-AES with MPEG-3 TS
                    return this.method === 'SAMPLE-AES';
                  case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__.KeySystemFormats.FAIRPLAY:
                  case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__.KeySystemFormats.WIDEVINE:
                  case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__.KeySystemFormats.PLAYREADY:
                  case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__.KeySystemFormats.CLEARKEY:
                    return ['ISO-23001-7', 'SAMPLE-AES', 'SAMPLE-AES-CENC', 'SAMPLE-AES-CTR'].indexOf(this.method) !== -1;
                }
              }
              return false;
            }
            getDecryptData(sn) {
              if (!this.encrypted || !this.uri) {
                return null;
              }
              if (this.method === 'AES-128' && this.uri && !this.iv) {
                if (typeof sn !== 'number') {
                  // We are fetching decryption data for a initialization segment
                  // If the segment was encrypted with AES-128
                  // It must have an IV defined. We cannot substitute the Segment Number in.
                  if (this.method === 'AES-128' && !this.iv) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn(`missing IV for initialization segment with method="${this.method}" - compliance issue`);
                  }
                  // Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.
                  sn = 0;
                }
                const iv = createInitializationVector(sn);
                const decryptdata = new LevelKey(this.method, this.uri, 'identity', this.keyFormatVersions, iv);
                return decryptdata;
              }

              // Initialize keyId if possible
              const keyBytes = (0, _utils_keysystem_util__WEBPACK_IMPORTED_MODULE_0__.convertDataUriToArrayBytes)(this.uri);
              if (keyBytes) {
                switch (this.keyFormat) {
                  case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__.KeySystemFormats.WIDEVINE:
                    this.pssh = keyBytes;
                    // In case of widevine keyID is embedded in PSSH box. Read Key ID.
                    if (keyBytes.length >= 22) {
                      this.keyId = keyBytes.subarray(keyBytes.length - 22, keyBytes.length - 6);
                    }
                    break;
                  case _utils_mediakeys_helper__WEBPACK_IMPORTED_MODULE_1__.KeySystemFormats.PLAYREADY:
                    {
                      const PlayReadyKeySystemUUID = new Uint8Array([0x9a, 0x04, 0xf0, 0x79, 0x98, 0x40, 0x42, 0x86, 0xab, 0x92, 0xe6, 0x5b, 0xe0, 0x88, 0x5f, 0x95]);
                      this.pssh = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_2__.mp4pssh)(PlayReadyKeySystemUUID, null, keyBytes);
                      const keyBytesUtf16 = new Uint16Array(keyBytes.buffer, keyBytes.byteOffset, keyBytes.byteLength / 2);
                      const keyByteStr = String.fromCharCode.apply(null, Array.from(keyBytesUtf16));

                      // Parse Playready WRMHeader XML
                      const xmlKeyBytes = keyByteStr.substring(keyByteStr.indexOf('<'), keyByteStr.length);
                      const parser = new DOMParser();
                      const xmlDoc = parser.parseFromString(xmlKeyBytes, 'text/xml');
                      const keyData = xmlDoc.getElementsByTagName('KID')[0];
                      if (keyData) {
                        const keyId = keyData.childNodes[0] ? keyData.childNodes[0].nodeValue : keyData.getAttribute('VALUE');
                        if (keyId) {
                          const keyIdArray = (0, _utils_numeric_encoding_utils__WEBPACK_IMPORTED_MODULE_4__.base64Decode)(keyId).subarray(0, 16);
                          // KID value in PRO is a base64-encoded little endian GUID interpretation of UUID
                          // KID value in ‘tenc’ is a big endian UUID GUID interpretation of UUID
                          (0, _utils_keysystem_util__WEBPACK_IMPORTED_MODULE_0__.changeEndianness)(keyIdArray);
                          this.keyId = keyIdArray;
                        }
                      }
                      break;
                    }
                  default:
                    {
                      let keydata = keyBytes.subarray(0, 16);
                      if (keydata.length !== 16) {
                        const padded = new Uint8Array(16);
                        padded.set(keydata, 16 - keydata.length);
                        keydata = padded;
                      }
                      this.keyId = keydata;
                      break;
                    }
                }
              }

              // Default behavior: assign a new keyId for each uri
              if (!this.keyId || this.keyId.byteLength !== 16) {
                let keyId = keyUriToKeyIdMap[this.uri];
                if (!keyId) {
                  const val = Object.keys(keyUriToKeyIdMap).length % Number.MAX_SAFE_INTEGER;
                  keyId = new Uint8Array(16);
                  const dv = new DataView(keyId.buffer, 12, 4); // Just set the last 4 bytes
                  dv.setUint32(0, val);
                  keyUriToKeyIdMap[this.uri] = keyId;
                }
                this.keyId = keyId;
              }
              return this;
            }
          }
          function createInitializationVector(segmentNumber) {
            const uint8View = new Uint8Array(16);
            for (let i = 12; i < 16; i++) {
              uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;
            }
            return uint8View;
          }

          /***/
        }),

/***/ "./src/loader/load-stats.ts":
/*!**********************************!*\
  !*** ./src/loader/load-stats.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "LoadStats": () => (/* binding */ LoadStats)
            /* harmony export */
          });
          class LoadStats {
            aborted = false;
            loaded = 0;
            retry = 0;
            total = 0;
            chunkCount = 0;
            bwEstimate = 0;
            loading = {
              start: 0,
              first: 0,
              end: 0
            };
            parsing = {
              start: 0,
              end: 0
            };
            buffering = {
              start: 0,
              first: 0,
              end: 0
            };
          }

          /***/
        }),

/***/ "./src/loader/m3u8-parser.ts":
/*!***********************************!*\
  !*** ./src/loader/m3u8-parser.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ M3U8Parser)
            /* harmony export */
          });
/* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! url-toolkit */ "./node_modules/url-toolkit/src/url-toolkit.js");
/* harmony import */ var url_toolkit__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(url_toolkit__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _date_range__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./date-range */ "./src/loader/date-range.ts");
/* harmony import */ var _fragment__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fragment */ "./src/loader/fragment.ts");
/* harmony import */ var _level_details__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./level-details */ "./src/loader/level-details.ts");
/* harmony import */ var _level_key__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./level-key */ "./src/loader/level-key.ts");
/* harmony import */ var _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/attr-list */ "./src/utils/attr-list.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _utils_codecs__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../utils/codecs */ "./src/utils/codecs.ts");








          // https://regex101.com is your friend
          const MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\r\n]*)(?:[\r\n](?:#[^\r\n]*)?)*([^\r\n]+)|#EXT-X-SESSION-DATA:([^\r\n]*)[\r\n]+|#EXT-X-SESSION-KEY:([^\n\r]*)[\r\n]+/g;
          const MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;
          const LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\s*(\d*(?:\.\d+)?)(?:,(.*)\s+)?/.source,
          // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title
          /(?!#) *(\S[\S ]*)/.source,
          // segment URI, group 3 => the URI (note newline is not eaten)
          /#EXT-X-BYTERANGE:*(.+)/.source,
          // next segment's byterange, group 4 => range spec (x@y)
          /#EXT-X-PROGRAM-DATE-TIME:(.+)/.source,
          // next segment's program date/time group 5 => the datetime spec
          /#.*/.source // All other non-segment oriented tags will match with all groups empty
          ].join('|'), 'g');
          const LEVEL_PLAYLIST_REGEX_SLOW = new RegExp([/#(EXTM3U)/.source, /#EXT-X-(DATERANGE|KEY|MAP|PART|PART-INF|PLAYLIST-TYPE|PRELOAD-HINT|RENDITION-REPORT|SERVER-CONTROL|SKIP|START):(.+)/.source, /#EXT-X-(BITRATE|DISCONTINUITY-SEQUENCE|MEDIA-SEQUENCE|TARGETDURATION|VERSION): *(\d+)/.source, /#EXT-X-(DISCONTINUITY|ENDLIST|GAP)/.source, /(#)([^:]*):(.*)/.source, /(#)(.*)(?:.*)\r?\n?/.source].join('|'));
          class M3U8Parser {
            static findGroup(groups, mediaGroupId) {
              for (let i = 0; i < groups.length; i++) {
                const group = groups[i];
                if (group.id === mediaGroupId) {
                  return group;
                }
              }
            }
            static convertAVC1ToAVCOTI(codec) {
              // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported
              const avcdata = codec.split('.');
              if (avcdata.length > 2) {
                let result = avcdata.shift() + '.';
                result += parseInt(avcdata.shift()).toString(16);
                result += ('000' + parseInt(avcdata.shift()).toString(16)).slice(-4);
                return result;
              }
              return codec;
            }
            static resolve(url, baseUrl) {
              return (0, url_toolkit__WEBPACK_IMPORTED_MODULE_0__.buildAbsoluteURL)(baseUrl, url, {
                alwaysNormalize: true
              });
            }
            static parseMasterPlaylist(string, baseurl) {
              const levels = [];
              const levelsWithKnownCodecs = [];
              const sessionData = {};
              const sessionKeys = [];
              let hasSessionData = false;
              MASTER_PLAYLIST_REGEX.lastIndex = 0;
              let result;
              while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {
                if (result[1]) {
                  // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1
                  const attrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(result[1]);
                  const level = {
                    attrs,
                    bitrate: attrs.decimalInteger('AVERAGE-BANDWIDTH') || attrs.decimalInteger('BANDWIDTH'),
                    name: attrs.NAME,
                    url: M3U8Parser.resolve(result[2], baseurl)
                  };
                  const resolution = attrs.decimalResolution('RESOLUTION');
                  if (resolution) {
                    level.width = resolution.width;
                    level.height = resolution.height;
                  }
                  setCodecs((attrs.CODECS || '').split(/[ ,]+/).filter(c => c), level);
                  if (level.videoCodec && level.videoCodec.indexOf('avc1') !== -1) {
                    level.videoCodec = M3U8Parser.convertAVC1ToAVCOTI(level.videoCodec);
                  }
                  if (!level.unknownCodecs?.length) {
                    levelsWithKnownCodecs.push(level);
                  }
                  levels.push(level);
                } else if (result[3]) {
                  // '#EXT-X-SESSION-DATA' is found, parse session data in group 3
                  const sessionAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(result[3]);
                  if (sessionAttrs['DATA-ID']) {
                    hasSessionData = true;
                    sessionData[sessionAttrs['DATA-ID']] = sessionAttrs;
                  }
                } else if (result[4]) {
                  // '#EXT-X-SESSION-KEY' is found
                  const keyTag = result[4];
                  const sessionKey = parseKey(keyTag, baseurl);
                  if (sessionKey.encrypted && sessionKey.isSupported()) {
                    sessionKeys.push(sessionKey);
                  } else {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`[Keys] Ignoring invalid EXT-X-SESSION-KEY tag: "${keyTag}"`);
                  }
                }
              }
              // Filter out levels with unknown codecs if it does not remove all levels
              const stripUnknownCodecLevels = levelsWithKnownCodecs.length > 0 && levelsWithKnownCodecs.length < levels.length;
              return {
                levels: stripUnknownCodecLevels ? levelsWithKnownCodecs : levels,
                sessionData: hasSessionData ? sessionData : null,
                sessionKeys: sessionKeys.length ? sessionKeys : null
              };
            }
            static parseMasterPlaylistMedia(string, baseurl, type, groups = []) {
              let result;
              const medias = [];
              let id = 0;
              MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;
              while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {
                const attrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(result[1]);
                if (attrs.TYPE === type) {
                  const media = {
                    attrs,
                    bitrate: 0,
                    id: id++,
                    groupId: attrs['GROUP-ID'],
                    instreamId: attrs['INSTREAM-ID'],
                    name: attrs.NAME || attrs.LANGUAGE || '',
                    type,
                    default: attrs.bool('DEFAULT'),
                    autoselect: attrs.bool('AUTOSELECT'),
                    forced: attrs.bool('FORCED'),
                    lang: attrs.LANGUAGE,
                    url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : ''
                  };
                  if (groups.length) {
                    // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track
                    // If we don't find the track signalled, lets use the first audio groups codec we have
                    // Acting as a best guess
                    const groupCodec = M3U8Parser.findGroup(groups, media.groupId) || groups[0];
                    assignCodec(media, groupCodec, 'audioCodec');
                    assignCodec(media, groupCodec, 'textCodec');
                  }
                  medias.push(media);
                }
              }
              return medias;
            }
            static parseLevelPlaylist(string, baseurl, id, type, levelUrlId) {
              const level = new _level_details__WEBPACK_IMPORTED_MODULE_3__.LevelDetails(baseurl);
              const fragments = level.fragments;
              // The most recent init segment seen (applies to all subsequent segments)
              let currentInitSegment = null;
              let currentSN = 0;
              let currentPart = 0;
              let totalduration = 0;
              let discontinuityCounter = 0;
              let prevFrag = null;
              let frag = new _fragment__WEBPACK_IMPORTED_MODULE_2__.Fragment(type, baseurl);
              let result;
              let i;
              let levelkeys;
              let firstPdtIndex = -1;
              let createNextFrag = false;
              LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;
              level.m3u8 = string;
              while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {
                if (createNextFrag) {
                  createNextFrag = false;
                  frag = new _fragment__WEBPACK_IMPORTED_MODULE_2__.Fragment(type, baseurl);
                  // setup the next fragment for part loading
                  frag.start = totalduration;
                  frag.sn = currentSN;
                  frag.cc = discontinuityCounter;
                  frag.level = id;
                  if (currentInitSegment) {
                    frag.initSegment = currentInitSegment;
                    frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;
                    currentInitSegment.rawProgramDateTime = null;
                  }
                }
                const duration = result[1];
                if (duration) {
                  // INF
                  frag.duration = parseFloat(duration);
                  // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
                  const title = (' ' + result[2]).slice(1);
                  frag.title = title || null;
                  frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);
                } else if (result[3]) {
                  // url
                  if (Number.isFinite(frag.duration)) {
                    frag.start = totalduration;
                    if (levelkeys) {
                      frag.levelkeys = levelkeys;
                      const {
                        encryptedFragments
                      } = level;
                      if (frag.levelkeys && Object.keys(frag.levelkeys).some(format => frag.levelkeys[format].isCommonEncryption) && (!encryptedFragments.length || encryptedFragments[encryptedFragments.length - 1].levelkeys !== levelkeys)) {
                        encryptedFragments.push(frag);
                      }
                    }
                    frag.sn = currentSN;
                    frag.level = id;
                    frag.cc = discontinuityCounter;
                    frag.urlId = levelUrlId;
                    fragments.push(frag);
                    // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
                    frag.relurl = (' ' + result[3]).slice(1);
                    assignProgramDateTime(frag, prevFrag);
                    prevFrag = frag;
                    totalduration += frag.duration;
                    currentSN++;
                    currentPart = 0;
                    createNextFrag = true;
                  }
                } else if (result[4]) {
                  // X-BYTERANGE
                  const data = (' ' + result[4]).slice(1);
                  if (prevFrag) {
                    frag.setByteRange(data, prevFrag);
                  } else {
                    frag.setByteRange(data);
                  }
                } else if (result[5]) {
                  // PROGRAM-DATE-TIME
                  // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
                  frag.rawProgramDateTime = (' ' + result[5]).slice(1);
                  frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);
                  if (firstPdtIndex === -1) {
                    firstPdtIndex = fragments.length;
                  }
                } else {
                  result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);
                  if (!result) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn('No matches on slow regex match for level playlist!');
                    continue;
                  }
                  for (i = 1; i < result.length; i++) {
                    if (typeof result[i] !== 'undefined') {
                      break;
                    }
                  }

                  // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939
                  const tag = (' ' + result[i]).slice(1);
                  const value1 = (' ' + result[i + 1]).slice(1);
                  const value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : '';
                  switch (tag) {
                    case 'PLAYLIST-TYPE':
                      level.type = value1.toUpperCase();
                      break;
                    case 'MEDIA-SEQUENCE':
                      currentSN = level.startSN = parseInt(value1);
                      break;
                    case 'SKIP':
                      {
                        const skipAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        const skippedSegments = skipAttrs.decimalInteger('SKIPPED-SEGMENTS');
                        if (Number.isFinite(skippedSegments)) {
                          level.skippedSegments = skippedSegments;
                          // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`
                          for (let i = skippedSegments; i--;) {
                            fragments.unshift(null);
                          }
                          currentSN += skippedSegments;
                        }
                        const recentlyRemovedDateranges = skipAttrs.enumeratedString('RECENTLY-REMOVED-DATERANGES');
                        if (recentlyRemovedDateranges) {
                          level.recentlyRemovedDateranges = recentlyRemovedDateranges.split('\t');
                        }
                        break;
                      }
                    case 'TARGETDURATION':
                      level.targetduration = parseFloat(value1);
                      break;
                    case 'VERSION':
                      level.version = parseInt(value1);
                      break;
                    case 'EXTM3U':
                      break;
                    case 'ENDLIST':
                      level.live = false;
                      break;
                    case '#':
                      if (value1 || value2) {
                        frag.tagList.push(value2 ? [value1, value2] : [value1]);
                      }
                      break;
                    case 'DISCONTINUITY':
                      discontinuityCounter++;
                      frag.tagList.push(['DIS']);
                      break;
                    case 'GAP':
                      frag.tagList.push([tag]);
                      break;
                    case 'BITRATE':
                      frag.tagList.push([tag, value1]);
                      break;
                    case 'DATERANGE':
                      {
                        const dateRangeAttr = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        const dateRange = new _date_range__WEBPACK_IMPORTED_MODULE_1__.DateRange(dateRangeAttr, level.dateRanges[dateRangeAttr.ID]);
                        if (dateRange.isValid || level.skippedSegments) {
                          level.dateRanges[dateRange.id] = dateRange;
                        } else {
                          _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`Ignoring invalid DATERANGE tag: "${value1}"`);
                        }
                        // Add to fragment tag list for backwards compatibility (< v1.2.0)
                        frag.tagList.push(['EXT-X-DATERANGE', value1]);
                        break;
                      }
                    case 'DISCONTINUITY-SEQUENCE':
                      discontinuityCounter = parseInt(value1);
                      break;
                    case 'KEY':
                      {
                        const levelKey = parseKey(value1, baseurl);
                        if (levelKey.isSupported()) {
                          if (levelKey.method === 'NONE') {
                            levelkeys = undefined;
                            break;
                          }
                          if (!levelkeys) {
                            levelkeys = {};
                          }
                          if (levelkeys[levelKey.keyFormat]) {
                            levelkeys = Object.assign({}, levelkeys);
                          }
                          levelkeys[levelKey.keyFormat] = levelKey;
                        } else {
                          _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`[Keys] Ignoring invalid EXT-X-KEY tag: "${value1}"`);
                        }
                        break;
                      }
                    case 'START':
                      {
                        const startAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        const startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');
                        // TIME-OFFSET can be 0
                        if (Number.isFinite(startTimeOffset)) {
                          level.startTimeOffset = startTimeOffset;
                        }
                        break;
                      }
                    case 'MAP':
                      {
                        const mapAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        if (frag.duration) {
                          // Initial segment tag is after segment duration tag.
                          //   #EXTINF: 6.0
                          //   #EXT-X-MAP:URI="init.mp4
                          const init = new _fragment__WEBPACK_IMPORTED_MODULE_2__.Fragment(type, baseurl);
                          setInitSegment(init, mapAttrs, id, levelkeys);
                          currentInitSegment = init;
                          frag.initSegment = currentInitSegment;
                          if (currentInitSegment.rawProgramDateTime && !frag.rawProgramDateTime) {
                            frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;
                          }
                        } else {
                          // Initial segment tag is before segment duration tag
                          setInitSegment(frag, mapAttrs, id, levelkeys);
                          currentInitSegment = frag;
                          createNextFrag = true;
                        }
                        break;
                      }
                    case 'SERVER-CONTROL':
                      {
                        const serverControlAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');
                        level.canSkipUntil = serverControlAttrs.optionalFloat('CAN-SKIP-UNTIL', 0);
                        level.canSkipDateRanges = level.canSkipUntil > 0 && serverControlAttrs.bool('CAN-SKIP-DATERANGES');
                        level.partHoldBack = serverControlAttrs.optionalFloat('PART-HOLD-BACK', 0);
                        level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);
                        break;
                      }
                    case 'PART-INF':
                      {
                        const partInfAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');
                        break;
                      }
                    case 'PART':
                      {
                        let partList = level.partList;
                        if (!partList) {
                          partList = level.partList = [];
                        }
                        const previousFragmentPart = currentPart > 0 ? partList[partList.length - 1] : undefined;
                        const index = currentPart++;
                        const part = new _fragment__WEBPACK_IMPORTED_MODULE_2__.Part(new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1), frag, baseurl, index, previousFragmentPart);
                        partList.push(part);
                        frag.duration += part.duration;
                        break;
                      }
                    case 'PRELOAD-HINT':
                      {
                        const preloadHintAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        level.preloadHint = preloadHintAttrs;
                        break;
                      }
                    case 'RENDITION-REPORT':
                      {
                        const renditionReportAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(value1);
                        level.renditionReports = level.renditionReports || [];
                        level.renditionReports.push(renditionReportAttrs);
                        break;
                      }
                    default:
                      _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.warn(`line parsed but not handled: ${result}`);
                      break;
                  }
                }
              }
              if (prevFrag && !prevFrag.relurl) {
                fragments.pop();
                totalduration -= prevFrag.duration;
                if (level.partList) {
                  level.fragmentHint = prevFrag;
                }
              } else if (level.partList) {
                assignProgramDateTime(frag, prevFrag);
                frag.cc = discontinuityCounter;
                level.fragmentHint = frag;
              }
              const fragmentLength = fragments.length;
              const firstFragment = fragments[0];
              const lastFragment = fragments[fragmentLength - 1];
              totalduration += level.skippedSegments * level.targetduration;
              if (totalduration > 0 && fragmentLength && lastFragment) {
                level.averagetargetduration = totalduration / fragmentLength;
                const lastSn = lastFragment.sn;
                level.endSN = lastSn !== 'initSegment' ? lastSn : 0;
                if (!level.live) {
                  lastFragment.endList = true;
                }
                if (firstFragment) {
                  level.startCC = firstFragment.cc;
                }
              } else {
                level.endSN = 0;
                level.startCC = 0;
              }
              if (level.fragmentHint) {
                totalduration += level.fragmentHint.duration;
              }
              level.totalduration = totalduration;
              level.endCC = discontinuityCounter;

              /**
               * Backfill any missing PDT values
               * "If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after
               * one or more Media Segment URIs, the client SHOULD extrapolate
               * backward from that tag (using EXTINF durations and/or media
               * timestamps) to associate dates with those segments."
               * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs
               * computed.
               */
              if (firstPdtIndex > 0) {
                backfillProgramDateTimes(fragments, firstPdtIndex);
              }
              return level;
            }
          }
          function parseKey(keyTag, baseurl) {
            // https://tools.ietf.org/html/rfc8216#section-4.3.2.4
            const keyAttrs = new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList(keyTag);
            const decryptmethod = keyAttrs.enumeratedString('METHOD') ?? '';
            const decrypturi = keyAttrs.URI;
            const decryptiv = keyAttrs.hexadecimalInteger('IV');
            const decryptkeyformatversions = keyAttrs.enumeratedString('KEYFORMATVERSIONS');
            // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of "identity".
            const decryptkeyformat = keyAttrs.enumeratedString('KEYFORMAT') ?? 'identity';
            if (decrypturi && keyAttrs.IV && !decryptiv) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_6__.logger.error(`Invalid IV: ${keyAttrs.IV}`);
            }
            // If decrypturi is a URI with a scheme, then baseurl will be ignored
            // No uri is allowed when METHOD is NONE
            const resolvedUri = decrypturi ? M3U8Parser.resolve(decrypturi, baseurl) : '';
            const keyFormatVersions = (decryptkeyformatversions ? decryptkeyformatversions : '1').split('/').map(Number).filter(Number.isFinite);
            return new _level_key__WEBPACK_IMPORTED_MODULE_4__.LevelKey(decryptmethod, resolvedUri, decryptkeyformat, keyFormatVersions, decryptiv);
          }
          function setCodecs(codecs, level) {
            ['video', 'audio', 'text'].forEach(type => {
              const filtered = codecs.filter(codec => (0, _utils_codecs__WEBPACK_IMPORTED_MODULE_7__.isCodecType)(codec, type));
              if (filtered.length) {
                const preferred = filtered.filter(codec => {
                  return codec.lastIndexOf('avc1', 0) === 0 || codec.lastIndexOf('mp4a', 0) === 0;
                });
                level[`${type}Codec`] = preferred.length > 0 ? preferred[0] : filtered[0];

                // remove from list
                codecs = codecs.filter(codec => filtered.indexOf(codec) === -1);
              }
            });
            level.unknownCodecs = codecs;
          }
          function assignCodec(media, groupItem, codecProperty) {
            const codecValue = groupItem[codecProperty];
            if (codecValue) {
              media[codecProperty] = codecValue;
            }
          }
          function backfillProgramDateTimes(fragments, firstPdtIndex) {
            let fragPrev = fragments[firstPdtIndex];
            for (let i = firstPdtIndex; i--;) {
              const frag = fragments[i];
              // Exit on delta-playlist skipped segments
              if (!frag) {
                return;
              }
              frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;
              fragPrev = frag;
            }
          }
          function assignProgramDateTime(frag, prevFrag) {
            if (frag.rawProgramDateTime) {
              frag.programDateTime = Date.parse(frag.rawProgramDateTime);
            } else if (prevFrag?.programDateTime) {
              frag.programDateTime = prevFrag.endProgramDateTime;
            }
            if (!Number.isFinite(frag.programDateTime)) {
              frag.programDateTime = null;
              frag.rawProgramDateTime = null;
            }
          }
          function setInitSegment(frag, mapAttrs, id, levelkeys) {
            frag.relurl = mapAttrs.URI;
            if (mapAttrs.BYTERANGE) {
              frag.setByteRange(mapAttrs.BYTERANGE);
            }
            frag.level = id;
            frag.sn = 'initSegment';
            if (levelkeys) {
              frag.levelkeys = levelkeys;
            }
            frag.initSegment = null;
          }

          /***/
        }),

/***/ "./src/loader/playlist-loader.ts":
/*!***************************************!*\
  !*** ./src/loader/playlist-loader.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _m3u8_parser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./m3u8-parser */ "./src/loader/m3u8-parser.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../utils/attr-list */ "./src/utils/attr-list.ts");
          /**
           * PlaylistLoader - delegate for media manifest/playlist loading tasks. Takes care of parsing media to internal data-models.
           *
           * Once loaded, dispatches events with parsed data-models of manifest/levels/audio/subtitle tracks.
           *
           * Uses loader(s) set in config to do actual internal loading of resource tasks.
           *
           * @module
           *
           */







          function mapContextToLevelType(context) {
            const {
              type
            } = context;
            switch (type) {
              case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.AUDIO_TRACK:
                return _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistLevelType.AUDIO;
              case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.SUBTITLE_TRACK:
                return _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistLevelType.SUBTITLE;
              default:
                return _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistLevelType.MAIN;
            }
          }
          function getResponseUrl(response, context) {
            let url = response.url;
            // responseURL not supported on some browsers (it is used to detect URL redirection)
            // data-uri mode also not supported (but no need to detect redirection)
            if (url === undefined || url.indexOf('data:') === 0) {
              // fallback to initial URL
              url = context.url;
            }
            return url;
          }
          class PlaylistLoader {
            loaders = Object.create(null);
            constructor(hls) {
              this.hls = hls;
              this.registerListeners();
            }
            startLoad(startPosition) { }
            stopLoad() {
              this.destroyInternalLoaders();
            }
            registerListeners() {
              const {
                hls
              } = this;
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);
              hls.on(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);
            }
            unregisterListeners() {
              const {
                hls
              } = this;
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADING, this.onManifestLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADING, this.onLevelLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);
              hls.off(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);
            }

            /**
             * Returns defaults or configured loader-type overloads (pLoader and loader config params)
             */
            createInternalLoader(context) {
              const config = this.hls.config;
              const PLoader = config.pLoader;
              const Loader = config.loader;
              const InternalLoader = PLoader || Loader;
              const loader = new InternalLoader(config);
              context.loader = loader;
              this.loaders[context.type] = loader;
              return loader;
            }
            getInternalLoader(context) {
              return this.loaders[context.type];
            }
            resetInternalLoader(contextType) {
              if (this.loaders[contextType]) {
                delete this.loaders[contextType];
              }
            }

            /**
             * Call `destroy` on all internal loader instances mapped (one per context type)
             */
            destroyInternalLoaders() {
              for (const contextType in this.loaders) {
                const loader = this.loaders[contextType];
                if (loader) {
                  loader.destroy();
                }
                this.resetInternalLoader(contextType);
              }
            }
            destroy() {
              this.unregisterListeners();
              this.destroyInternalLoaders();
            }
            onManifestLoading(event, data) {
              const {
                url
              } = data;
              this.load({
                id: null,
                groupId: null,
                level: 0,
                responseType: 'text',
                type: _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.MANIFEST,
                url,
                deliveryDirectives: null
              });
            }
            onLevelLoading(event, data) {
              const {
                id,
                level,
                url,
                deliveryDirectives
              } = data;
              this.load({
                id,
                groupId: null,
                level,
                responseType: 'text',
                type: _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.LEVEL,
                url,
                deliveryDirectives
              });
            }
            onAudioTrackLoading(event, data) {
              const {
                id,
                groupId,
                url,
                deliveryDirectives
              } = data;
              this.load({
                id,
                groupId,
                level: null,
                responseType: 'text',
                type: _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.AUDIO_TRACK,
                url,
                deliveryDirectives
              });
            }
            onSubtitleTrackLoading(event, data) {
              const {
                id,
                groupId,
                url,
                deliveryDirectives
              } = data;
              this.load({
                id,
                groupId,
                level: null,
                responseType: 'text',
                type: _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.SUBTITLE_TRACK,
                url,
                deliveryDirectives
              });
            }
            load(context) {
              const config = this.hls.config;

              // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);

              // Check if a loader for this context already exists
              let loader = this.getInternalLoader(context);
              if (loader) {
                const loaderContext = loader.context;
                if (loaderContext && loaderContext.url === context.url) {
                  // same URL can't overlap
                  _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.trace('[playlist-loader]: playlist request ongoing');
                  return;
                }
                _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.log(`[playlist-loader]: aborting previous loader for type: ${context.type}`);
                loader.abort();
              }
              let maxRetry;
              let timeout;
              let retryDelay;
              let maxRetryDelay;

              // apply different configs for retries depending on
              // context (manifest, level, audio/subs playlist)
              switch (context.type) {
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.MANIFEST:
                  maxRetry = config.manifestLoadingMaxRetry;
                  timeout = config.manifestLoadingTimeOut;
                  retryDelay = config.manifestLoadingRetryDelay;
                  maxRetryDelay = config.manifestLoadingMaxRetryTimeout;
                  break;
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.LEVEL:
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.AUDIO_TRACK:
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.SUBTITLE_TRACK:
                  // Manage retries in Level/Track Controller
                  maxRetry = 0;
                  timeout = config.levelLoadingTimeOut;
                  break;
                default:
                  maxRetry = config.levelLoadingMaxRetry;
                  timeout = config.levelLoadingTimeOut;
                  retryDelay = config.levelLoadingRetryDelay;
                  maxRetryDelay = config.levelLoadingMaxRetryTimeout;
                  break;
              }
              loader = this.createInternalLoader(context);

              // Override level/track timeout for LL-HLS requests
              // (the default of 10000ms is counter productive to blocking playlist reload requests)
              if (context.deliveryDirectives?.part) {
                let levelDetails;
                if (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.LEVEL && context.level !== null) {
                  levelDetails = this.hls.levels[context.level].details;
                } else if (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.AUDIO_TRACK && context.id !== null) {
                  levelDetails = this.hls.audioTracks[context.id].details;
                } else if (context.type === _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.SUBTITLE_TRACK && context.id !== null) {
                  levelDetails = this.hls.subtitleTracks[context.id].details;
                }
                if (levelDetails) {
                  const partTarget = levelDetails.partTarget;
                  const targetDuration = levelDetails.targetduration;
                  if (partTarget && targetDuration) {
                    timeout = Math.min(Math.max(partTarget * 3, targetDuration * 0.8) * 1000, timeout);
                  }
                }
              }
              const loaderConfig = {
                timeout,
                maxRetry,
                retryDelay,
                maxRetryDelay,
                highWaterMark: 0
              };
              const loaderCallbacks = {
                onSuccess: this.loadsuccess.bind(this),
                onError: this.loaderror.bind(this),
                onTimeout: this.loadtimeout.bind(this)
              };

              // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);

              loader.load(context, loaderConfig, loaderCallbacks);
            }
            loadsuccess(response, stats, context, networkDetails = null) {
              this.resetInternalLoader(context.type);
              const string = response.data;

              // Validate if it is an M3U8 at all
              if (string.indexOf('#EXTM3U') !== 0) {
                this.handleManifestParsingError(response, context, 'no EXTM3U delimiter', networkDetails);
                return;
              }
              stats.parsing.start = performance.now();
              // Check if chunk-list or master. handle empty chunk list case (first EXTINF not signaled, but TARGETDURATION present)
              if (string.indexOf('#EXTINF:') > 0 || string.indexOf('#EXT-X-TARGETDURATION:') > 0) {
                this.handleTrackOrLevelPlaylist(response, stats, context, networkDetails);
              } else {
                this.handleMasterPlaylist(response, stats, context, networkDetails);
              }
            }
            loaderror(response, context, networkDetails = null) {
              this.handleNetworkError(context, networkDetails, false, response);
            }
            loadtimeout(stats, context, networkDetails = null) {
              this.handleNetworkError(context, networkDetails, true);
            }
            handleMasterPlaylist(response, stats, context, networkDetails) {
              const hls = this.hls;
              const string = response.data;
              const url = getResponseUrl(response, context);
              const {
                levels,
                sessionData,
                sessionKeys
              } = _m3u8_parser__WEBPACK_IMPORTED_MODULE_3__["default"].parseMasterPlaylist(string, url);
              if (!levels.length) {
                this.handleManifestParsingError(response, context, 'no level found in manifest', networkDetails);
                return;
              }

              // multi level playlist, parse level info
              const audioGroups = levels.map(level => ({
                id: level.attrs.AUDIO,
                audioCodec: level.audioCodec
              }));
              const subtitleGroups = levels.map(level => ({
                id: level.attrs.SUBTITLES,
                textCodec: level.textCodec
              }));
              const audioTracks = _m3u8_parser__WEBPACK_IMPORTED_MODULE_3__["default"].parseMasterPlaylistMedia(string, url, 'AUDIO', audioGroups);
              const subtitles = _m3u8_parser__WEBPACK_IMPORTED_MODULE_3__["default"].parseMasterPlaylistMedia(string, url, 'SUBTITLES', subtitleGroups);
              const captions = _m3u8_parser__WEBPACK_IMPORTED_MODULE_3__["default"].parseMasterPlaylistMedia(string, url, 'CLOSED-CAPTIONS');
              if (audioTracks.length) {
                // check if we have found an audio track embedded in main playlist (audio track without URI attribute)
                const embeddedAudioFound = audioTracks.some(audioTrack => !audioTrack.url);

                // if no embedded audio track defined, but audio codec signaled in quality level,
                // we need to signal this main audio track this could happen with playlists with
                // alt audio rendition in which quality levels (main)
                // contains both audio+video. but with mixed audio track not signaled
                if (!embeddedAudioFound && levels[0].audioCodec && !levels[0].attrs.AUDIO) {
                  _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.log('[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one');
                  audioTracks.unshift({
                    type: 'main',
                    name: 'main',
                    default: false,
                    autoselect: false,
                    forced: false,
                    id: -1,
                    attrs: new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList({}),
                    bitrate: 0,
                    url: ''
                  });
                }
              }
              hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADED, {
                levels,
                audioTracks,
                subtitles,
                captions,
                url,
                stats,
                networkDetails,
                sessionData,
                sessionKeys
              });
            }
            handleTrackOrLevelPlaylist(response, stats, context, networkDetails) {
              const hls = this.hls;
              const {
                id,
                level,
                type
              } = context;
              const url = getResponseUrl(response, context);
              const levelUrlId = Number.isFinite(id) ? id : 0;
              const levelId = Number.isFinite(level) ? level : levelUrlId;
              const levelType = mapContextToLevelType(context);
              const levelDetails = _m3u8_parser__WEBPACK_IMPORTED_MODULE_3__["default"].parseLevelPlaylist(response.data, url, levelId, levelType, levelUrlId);
              if (!levelDetails.fragments.length) {
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.NETWORK_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.LEVEL_EMPTY_ERROR,
                  fatal: false,
                  url: url,
                  reason: 'no fragments found in level',
                  level: typeof context.level === 'number' ? context.level : undefined
                });
                return;
              }

              // We have done our first request (Manifest-type) and receive
              // not a master playlist but a chunk-list (track/level)
              // We fire the manifest-loaded event anyway with the parsed level-details
              // by creating a single-level structure for it.
              if (type === _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.MANIFEST) {
                const singleLevel = {
                  attrs: new _utils_attr_list__WEBPACK_IMPORTED_MODULE_5__.AttrList({}),
                  bitrate: 0,
                  details: levelDetails,
                  name: '',
                  url
                };
                hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.MANIFEST_LOADED, {
                  levels: [singleLevel],
                  audioTracks: [],
                  url,
                  stats,
                  networkDetails,
                  sessionData: null,
                  sessionKeys: null
                });
              }

              // save parsing time
              stats.parsing.end = performance.now();

              // extend the context with the new levelDetails property
              context.levelDetails = levelDetails;
              this.handlePlaylistLoaded(response, stats, context, networkDetails);
            }
            handleManifestParsingError(response, context, reason, networkDetails) {
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, {
                type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.NETWORK_ERROR,
                details: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.MANIFEST_PARSING_ERROR,
                fatal: context.type === _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.MANIFEST,
                url: response.url,
                reason,
                response,
                context,
                networkDetails
              });
            }
            handleNetworkError(context, networkDetails, timeout = false, response) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_2__.logger.warn(`[playlist-loader]: A network ${timeout ? 'timeout' : 'error'} occurred while loading ${context.type} level: ${context.level} id: ${context.id} group-id: "${context.groupId}"`);
              let details = _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.UNKNOWN;
              let fatal = false;
              const loader = this.getInternalLoader(context);
              switch (context.type) {
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.MANIFEST:
                  details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.MANIFEST_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.MANIFEST_LOAD_ERROR;
                  fatal = true;
                  break;
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.LEVEL:
                  details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.LEVEL_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.LEVEL_LOAD_ERROR;
                  fatal = false;
                  break;
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.AUDIO_TRACK:
                  details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.AUDIO_TRACK_LOAD_ERROR;
                  fatal = false;
                  break;
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.SUBTITLE_TRACK:
                  details = timeout ? _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT : _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorDetails.SUBTITLE_LOAD_ERROR;
                  fatal = false;
                  break;
              }
              if (loader) {
                this.resetInternalLoader(context.type);
              }
              const errorData = {
                type: _errors__WEBPACK_IMPORTED_MODULE_1__.ErrorTypes.NETWORK_ERROR,
                details,
                fatal,
                url: context.url,
                loader,
                context,
                networkDetails
              };
              if (response) {
                errorData.response = response;
              }
              this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.ERROR, errorData);
            }
            handlePlaylistLoaded(response, stats, context, networkDetails) {
              const {
                type,
                level,
                id,
                groupId,
                loader,
                levelDetails,
                deliveryDirectives
              } = context;
              if (!levelDetails?.targetduration) {
                this.handleManifestParsingError(response, context, 'invalid target duration', networkDetails);
                return;
              }
              if (!loader) {
                return;
              }
              if (levelDetails.live) {
                if (loader.getCacheAge) {
                  levelDetails.ageHeader = loader.getCacheAge() || 0;
                }
                if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {
                  levelDetails.ageHeader = 0;
                }
              }
              switch (type) {
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.MANIFEST:
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.LEVEL:
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.LEVEL_LOADED, {
                    details: levelDetails,
                    level: level || 0,
                    id: id || 0,
                    stats,
                    networkDetails,
                    deliveryDirectives
                  });
                  break;
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.AUDIO_TRACK:
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.AUDIO_TRACK_LOADED, {
                    details: levelDetails,
                    id: id || 0,
                    groupId: groupId || '',
                    stats,
                    networkDetails,
                    deliveryDirectives
                  });
                  break;
                case _types_loader__WEBPACK_IMPORTED_MODULE_4__.PlaylistContextType.SUBTITLE_TRACK:
                  this.hls.trigger(_events__WEBPACK_IMPORTED_MODULE_0__.Events.SUBTITLE_TRACK_LOADED, {
                    details: levelDetails,
                    id: id || 0,
                    groupId: groupId || '',
                    stats,
                    networkDetails,
                    deliveryDirectives
                  });
                  break;
              }
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (PlaylistLoader);

          /***/
        }),

/***/ "./src/remux/aac-helper.ts":
/*!*********************************!*\
  !*** ./src/remux/aac-helper.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          /**
           *  AAC helper
           */

          class AAC {
            static getSilentFrame(codec, channelCount) {
              switch (codec) {
                case 'mp4a.40.2':
                  if (channelCount === 1) {
                    return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);
                  } else if (channelCount === 2) {
                    return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);
                  } else if (channelCount === 3) {
                    return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);
                  } else if (channelCount === 4) {
                    return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);
                  } else if (channelCount === 5) {
                    return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);
                  } else if (channelCount === 6) {
                    return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);
                  }
                  break;
                // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)
                default:
                  if (channelCount === 1) {
                    // ffmpeg -y -f lavfi -i "aevalsrc=0:d=0.05" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
                    return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
                  } else if (channelCount === 2) {
                    // ffmpeg -y -f lavfi -i "aevalsrc=0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
                    return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
                  } else if (channelCount === 3) {
                    // ffmpeg -y -f lavfi -i "aevalsrc=0|0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\n"' -v output.aac
                    return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);
                  }
                  break;
              }
              return undefined;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AAC);

          /***/
        }),

/***/ "./src/remux/mp4-generator.ts":
/*!************************************!*\
  !*** ./src/remux/mp4-generator.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          /**
           * Generate MP4 Box
           */

          const UINT32_MAX = Math.pow(2, 32) - 1;
          class MP4 {
            static init() {
              MP4.types = {
                avc1: [],
                // codingname
                avcC: [],
                btrt: [],
                dinf: [],
                dref: [],
                esds: [],
                ftyp: [],
                hdlr: [],
                mdat: [],
                mdhd: [],
                mdia: [],
                mfhd: [],
                minf: [],
                moof: [],
                moov: [],
                mp4a: [],
                '.mp3': [],
                mvex: [],
                mvhd: [],
                pasp: [],
                sdtp: [],
                stbl: [],
                stco: [],
                stsc: [],
                stsd: [],
                stsz: [],
                stts: [],
                tfdt: [],
                tfhd: [],
                traf: [],
                trak: [],
                trun: [],
                trex: [],
                tkhd: [],
                vmhd: [],
                smhd: []
              };
              let i;
              for (i in MP4.types) {
                if (MP4.types.hasOwnProperty(i)) {
                  MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];
                }
              }
              const videoHdlr = new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x00,
                // pre_defined
                0x76, 0x69, 0x64, 0x65,
                // handler_type: 'vide'
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'
              ]);

              const audioHdlr = new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x00,
                // pre_defined
                0x73, 0x6f, 0x75, 0x6e,
                // handler_type: 'soun'
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'
              ]);

              MP4.HDLR_TYPES = {
                video: videoHdlr,
                audio: audioHdlr
              };
              const dref = new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x01,
                // entry_count
                0x00, 0x00, 0x00, 0x0c,
                // entry_size
                0x75, 0x72, 0x6c, 0x20,
                // 'url' type
                0x00,
                // version 0
                0x00, 0x00, 0x01 // entry_flags
              ]);

              const stco = new Uint8Array([0x00,
                // version
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x00 // entry_count
              ]);

              MP4.STTS = MP4.STSC = MP4.STCO = stco;
              MP4.STSZ = new Uint8Array([0x00,
                // version
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x00,
                // sample_size
                0x00, 0x00, 0x00, 0x00 // sample_count
              ]);

              MP4.VMHD = new Uint8Array([0x00,
                // version
                0x00, 0x00, 0x01,
                // flags
                0x00, 0x00,
                // graphicsmode
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor
              ]);

              MP4.SMHD = new Uint8Array([0x00,
                // version
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00,
                // balance
                0x00, 0x00 // reserved
              ]);

              MP4.STSD = new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x01]); // entry_count

              const majorBrand = new Uint8Array([105, 115, 111, 109]); // isom
              const avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1
              const minorVersion = new Uint8Array([0, 0, 0, 1]);
              MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);
              MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));
            }
            static box(type, ...payload) {
              let size = 8;
              let i = payload.length;
              const len = i;
              // calculate the total size we need to allocate
              while (i--) {
                size += payload[i].byteLength;
              }
              const result = new Uint8Array(size);
              result[0] = size >> 24 & 0xff;
              result[1] = size >> 16 & 0xff;
              result[2] = size >> 8 & 0xff;
              result[3] = size & 0xff;
              result.set(type, 4);
              // copy the payload into the result
              for (i = 0, size = 8; i < len; i++) {
                // copy payload[i] array @ offset size
                result.set(payload[i], size);
                size += payload[i].byteLength;
              }
              return result;
            }
            static hdlr(type) {
              return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);
            }
            static mdat(data) {
              return MP4.box(MP4.types.mdat, data);
            }
            static mdhd(timescale, duration) {
              duration *= timescale;
              const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
              const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
              return MP4.box(MP4.types.mdhd, new Uint8Array([0x01,
                // version 1
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,
                // creation_time
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,
                // modification_time
                timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,
                // timescale
                upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x55, 0xc4,
                // 'und' language (undetermined)
                0x00, 0x00]));
            }
            static mdia(track) {
              return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale, track.duration), MP4.hdlr(track.type), MP4.minf(track));
            }
            static mfhd(sequenceNumber) {
              return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00,
                // flags
                sequenceNumber >> 24, sequenceNumber >> 16 & 0xff, sequenceNumber >> 8 & 0xff, sequenceNumber & 0xff // sequence_number
              ]));
            }

            static minf(track) {
              if (track.type === 'audio') {
                return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));
              } else {
                return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));
              }
            }
            static moof(sn, baseMediaDecodeTime, track) {
              return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));
            }

            /**
             * @param tracks... (optional) {array} the tracks associated with this movie
             */
            static moov(tracks) {
              let i = tracks.length;
              const boxes = [];
              while (i--) {
                boxes[i] = MP4.trak(tracks[i]);
              }
              return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale, tracks[0].duration)].concat(boxes).concat(MP4.mvex(tracks)));
            }
            static mvex(tracks) {
              let i = tracks.length;
              const boxes = [];
              while (i--) {
                boxes[i] = MP4.trex(tracks[i]);
              }
              return MP4.box.apply(null, [MP4.types.mvex, ...boxes]);
            }
            static mvhd(timescale, duration) {
              duration *= timescale;
              const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
              const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
              const bytes = new Uint8Array([0x01,
                // version 1
                0x00, 0x00, 0x00,
                // flags
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,
                // creation_time
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,
                // modification_time
                timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,
                // timescale
                upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x01, 0x00, 0x00,
                // 1.0 rate
                0x01, 0x00,
                // 1.0 volume
                0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,
                // transformation: unity matrix
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                // pre_defined
                0xff, 0xff, 0xff, 0xff // next_track_ID
              ]);

              return MP4.box(MP4.types.mvhd, bytes);
            }
            static sdtp(track) {
              const samples = track.samples || [];
              const bytes = new Uint8Array(4 + samples.length);
              let i;
              let flags;
              // leave the full box header (4 bytes) all zero
              // write the sample table
              for (i = 0; i < samples.length; i++) {
                flags = samples[i].flags;
                bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;
              }
              return MP4.box(MP4.types.sdtp, bytes);
            }
            static stbl(track) {
              return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));
            }
            static avc1(track) {
              let sps = [];
              let pps = [];
              let i;
              let data;
              let len;
              // assemble the SPSs

              for (i = 0; i < track.sps.length; i++) {
                data = track.sps[i];
                len = data.byteLength;
                sps.push(len >>> 8 & 0xff);
                sps.push(len & 0xff);

                // SPS
                sps = sps.concat(Array.prototype.slice.call(data));
              }

              // assemble the PPSs
              for (i = 0; i < track.pps.length; i++) {
                data = track.pps[i];
                len = data.byteLength;
                pps.push(len >>> 8 & 0xff);
                pps.push(len & 0xff);
                pps = pps.concat(Array.prototype.slice.call(data));
              }
              const avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01,
                // version
                sps[3],
                // profile
                sps[4],
                // profile compat
                sps[5],
                // level
                0xfc | 3,
                // lengthSizeMinusOne, hard-coded to 4 bytes
                0xe0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets
              ].concat(sps).concat([track.pps.length // numOfPictureParameterSets
              ]).concat(pps))); // "PPS"
              const width = track.width;
              const height = track.height;
              const hSpacing = track.pixelRatio[0];
              const vSpacing = track.pixelRatio[1];
              return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00,
                // reserved
                0x00, 0x01,
                // data_reference_index
                0x00, 0x00,
                // pre_defined
                0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                // pre_defined
                width >> 8 & 0xff, width & 0xff,
                // width
                height >> 8 & 0xff, height & 0xff,
                // height
                0x00, 0x48, 0x00, 0x00,
                // horizresolution
                0x00, 0x48, 0x00, 0x00,
                // vertresolution
                0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x01,
                // frame_count
                0x12, 0x64, 0x61, 0x69, 0x6c,
                // dailymotion/hls.js
                0x79, 0x6d, 0x6f, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x68, 0x6c, 0x73, 0x2e, 0x6a, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                // compressorname
                0x00, 0x18,
                // depth = 24
                0x11, 0x11]),
                // pre_defined = -1
                avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80,
                  // bufferSizeDB
                  0x00, 0x2d, 0xc6, 0xc0,
                  // maxBitrate
                  0x00, 0x2d, 0xc6, 0xc0])),
                // avgBitrate
                MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24,
                // hSpacing
                hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24,
                // vSpacing
                vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff])));
            }
            static esds(track) {
              const configlen = track.config.length;
              return new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags

                0x03,
                // descriptor_type
                0x17 + configlen,
                // length
                0x00, 0x01,
                // es_id
                0x00,
                // stream_priority

                0x04,
                // descriptor_type
                0x0f + configlen,
                // length
                0x40,
                // codec : mpeg4_audio
                0x15,
                // stream_type
                0x00, 0x00, 0x00,
                // buffer_size
                0x00, 0x00, 0x00, 0x00,
                // maxBitrate
                0x00, 0x00, 0x00, 0x00,
                // avgBitrate

                0x05 // descriptor_type
              ].concat([configlen]).concat(track.config).concat([0x06, 0x01, 0x02])); // GASpecificConfig)); // length + audio config descriptor
            }

            static mp4a(track) {
              const samplerate = track.samplerate;
              return MP4.box(MP4.types.mp4a, new Uint8Array([0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00,
                // reserved
                0x00, 0x01,
                // data_reference_index
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, track.channelCount,
                // channelcount
                0x00, 0x10,
                // sampleSize:16bits
                0x00, 0x00, 0x00, 0x00,
                // reserved2
                samplerate >> 8 & 0xff, samplerate & 0xff,
                //
                0x00, 0x00]), MP4.box(MP4.types.esds, MP4.esds(track)));
            }
            static mp3(track) {
              const samplerate = track.samplerate;
              return MP4.box(MP4.types['.mp3'], new Uint8Array([0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00, 0x00,
                // reserved
                0x00, 0x01,
                // data_reference_index
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, track.channelCount,
                // channelcount
                0x00, 0x10,
                // sampleSize:16bits
                0x00, 0x00, 0x00, 0x00,
                // reserved2
                samplerate >> 8 & 0xff, samplerate & 0xff,
                //
                0x00, 0x00]));
            }
            static stsd(track) {
              if (track.type === 'audio') {
                if (track.segmentCodec === 'mp3' && track.codec === 'mp3') {
                  return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));
                }
                return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));
              } else {
                return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));
              }
            }
            static tkhd(track) {
              const id = track.id;
              const duration = track.duration * track.timescale;
              const width = track.width;
              const height = track.height;
              const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));
              const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));
              return MP4.box(MP4.types.tkhd, new Uint8Array([0x01,
                // version 1
                0x00, 0x00, 0x07,
                // flags
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,
                // creation_time
                0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,
                // modification_time
                id >> 24 & 0xff, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,
                // track_ID
                0x00, 0x00, 0x00, 0x00,
                // reserved
                upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                // reserved
                0x00, 0x00,
                // layer
                0x00, 0x00,
                // alternate_group
                0x00, 0x00,
                // non-audio track volume
                0x00, 0x00,
                // reserved
                0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,
                // transformation: unity matrix
                width >> 8 & 0xff, width & 0xff, 0x00, 0x00,
                // width
                height >> 8 & 0xff, height & 0xff, 0x00, 0x00 // height
              ]));
            }

            static traf(track, baseMediaDecodeTime) {
              const sampleDependencyTable = MP4.sdtp(track);
              const id = track.id;
              const upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));
              const lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));
              return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags
                id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff // track_ID
              ])), MP4.box(MP4.types.tfdt, new Uint8Array([0x01,
                // version 1
                0x00, 0x00, 0x00,
                // flags
                upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0xff, upperWordBaseMediaDecodeTime >> 8 & 0xff, upperWordBaseMediaDecodeTime & 0xff, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0xff, lowerWordBaseMediaDecodeTime >> 8 & 0xff, lowerWordBaseMediaDecodeTime & 0xff])), MP4.trun(track, sampleDependencyTable.length + 16 +
                  // tfhd
                  20 +
                  // tfdt
                  8 +
                  // traf header
                  16 +
                  // mfhd
                  8 +
                  // moof header
                  8),
                // mdat header
                sampleDependencyTable);
            }

            /**
             * Generate a track box.
             * @param track {object} a track definition
             * @return {Uint8Array} the track box
             */
            static trak(track) {
              track.duration = track.duration || 0xffffffff;
              return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));
            }
            static trex(track) {
              const id = track.id;
              return MP4.box(MP4.types.trex, new Uint8Array([0x00,
                // version 0
                0x00, 0x00, 0x00,
                // flags
                id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,
                // track_ID
                0x00, 0x00, 0x00, 0x01,
                // default_sample_description_index
                0x00, 0x00, 0x00, 0x00,
                // default_sample_duration
                0x00, 0x00, 0x00, 0x00,
                // default_sample_size
                0x00, 0x01, 0x00, 0x01 // default_sample_flags
              ]));
            }

            static trun(track, offset) {
              const samples = track.samples || [];
              const len = samples.length;
              const arraylen = 12 + 16 * len;
              const array = new Uint8Array(arraylen);
              let i;
              let sample;
              let duration;
              let size;
              let flags;
              let cts;
              offset += 8 + arraylen;
              array.set([track.type === 'video' ? 0x01 : 0x00,
                // version 1 for video with signed-int sample_composition_time_offset
                0x00, 0x0f, 0x01,
              // flags
              len >>> 24 & 0xff, len >>> 16 & 0xff, len >>> 8 & 0xff, len & 0xff,
              // sample_count
              offset >>> 24 & 0xff, offset >>> 16 & 0xff, offset >>> 8 & 0xff, offset & 0xff // data_offset
              ], 0);
              for (i = 0; i < len; i++) {
                sample = samples[i];
                duration = sample.duration;
                size = sample.size;
                flags = sample.flags;
                cts = sample.cts;
                array.set([duration >>> 24 & 0xff, duration >>> 16 & 0xff, duration >>> 8 & 0xff, duration & 0xff,
                // sample_duration
                size >>> 24 & 0xff, size >>> 16 & 0xff, size >>> 8 & 0xff, size & 0xff,
                // sample_size
                flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xf0 << 8, flags.degradPrio & 0x0f,
                // sample_flags
                cts >>> 24 & 0xff, cts >>> 16 & 0xff, cts >>> 8 & 0xff, cts & 0xff // sample_composition_time_offset
                ], 12 + 16 * i);
              }
              return MP4.box(MP4.types.trun, array);
            }
            static initSegment(tracks) {
              if (!MP4.types) {
                MP4.init();
              }
              const movie = MP4.moov(tracks);
              const result = new Uint8Array(MP4.FTYP.byteLength + movie.byteLength);
              result.set(MP4.FTYP);
              result.set(movie, MP4.FTYP.byteLength);
              return result;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (MP4);

          /***/
        }),

/***/ "./src/remux/mp4-remuxer.ts":
/*!**********************************!*\
  !*** ./src/remux/mp4-remuxer.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ MP4Remuxer),
/* harmony export */   "flushTextTrackMetadataCueSamples": () => (/* binding */ flushTextTrackMetadataCueSamples),
/* harmony export */   "flushTextTrackUserdataCueSamples": () => (/* binding */ flushTextTrackUserdataCueSamples),
/* harmony export */   "normalizePts": () => (/* binding */ normalizePts)
            /* harmony export */
          });
/* harmony import */ var _aac_helper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./aac-helper */ "./src/remux/aac-helper.ts");
/* harmony import */ var _mp4_generator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./mp4-generator */ "./src/remux/mp4-generator.ts");
/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../events */ "./src/events.ts");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../errors */ "./src/errors.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _types_loader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types/loader */ "./src/types/loader.ts");
/* harmony import */ var _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../utils/timescale-conversion */ "./src/utils/timescale-conversion.ts");







          const MAX_SILENT_FRAME_DURATION = 10 * 1000; // 10 seconds
          const AAC_SAMPLES_PER_FRAME = 1024;
          const MPEG_AUDIO_SAMPLE_PER_FRAME = 1152;
          let chromeVersion = null;
          let safariWebkitVersion = null;
          class MP4Remuxer {
            ISGenerated = false;
            nextAvcDts = null;
            nextAudioPts = null;
            videoSampleDuration = null;
            isAudioContiguous = false;
            isVideoContiguous = false;
            constructor(observer, config, typeSupported, vendor = '') {
              this.observer = observer;
              this.config = config;
              this.typeSupported = typeSupported;
              this.ISGenerated = false;
              if (chromeVersion === null) {
                const userAgent = navigator.userAgent || '';
                const result = userAgent.match(/Chrome\/(\d+)/i);
                chromeVersion = result ? parseInt(result[1]) : 0;
              }
              if (safariWebkitVersion === null) {
                const result = navigator.userAgent.match(/Safari\/(\d+)/i);
                safariWebkitVersion = result ? parseInt(result[1]) : 0;
              }
            }
            destroy() { }
            resetTimeStamp(defaultTimeStamp) {
              _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.log('[mp4-remuxer]: initPTS & initDTS reset');
              this._initPTS = this._initDTS = defaultTimeStamp;
            }
            resetNextTimestamp() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.log('[mp4-remuxer]: reset next timestamp');
              this.isVideoContiguous = false;
              this.isAudioContiguous = false;
            }
            resetInitSegment() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.log('[mp4-remuxer]: ISGenerated flag reset');
              this.ISGenerated = false;
            }
            getVideoStartPts(videoSamples) {
              let rolloverDetected = false;
              const startPTS = videoSamples.reduce((minPTS, sample) => {
                const delta = sample.pts - minPTS;
                if (delta < -4294967296) {
                  // 2^32, see PTSNormalize for reasoning, but we're hitting a rollover here, and we don't want that to impact the timeOffset calculation
                  rolloverDetected = true;
                  return normalizePts(minPTS, sample.pts);
                } else if (delta > 0) {
                  return minPTS;
                } else {
                  return sample.pts;
                }
              }, videoSamples[0].pts);
              if (rolloverDetected) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.debug('PTS rollover detected');
              }
              return startPTS;
            }
            remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, flush, playlistType) {
              let video;
              let audio;
              let initSegment;
              let text;
              let id3;
              let independent;
              let audioTimeOffset = timeOffset;
              let videoTimeOffset = timeOffset;

              // If we're remuxing audio and video progressively, wait until we've received enough samples for each track before proceeding.
              // This is done to synchronize the audio and video streams. We know if the current segment will have samples if the "pid"
              // parameter is greater than -1. The pid is set when the PMT is parsed, which contains the tracks list.
              // However, if the initSegment has already been generated, or we've reached the end of a segment (flush),
              // then we can remux one track without waiting for the other.
              const hasAudio = audioTrack.pid > -1;
              const hasVideo = videoTrack.pid > -1;
              const length = videoTrack.samples.length;
              const enoughAudioSamples = audioTrack.samples.length > 0;
              const enoughVideoSamples = flush && length > 0 || length > 1;
              const canRemuxAvc = (!hasAudio || enoughAudioSamples) && (!hasVideo || enoughVideoSamples) || this.ISGenerated || flush;
              if (canRemuxAvc) {
                if (!this.ISGenerated) {
                  initSegment = this.generateIS(audioTrack, videoTrack, timeOffset);
                }
                const isVideoContiguous = this.isVideoContiguous;
                let firstKeyFrameIndex = -1;
                let firstKeyFramePTS;
                if (enoughVideoSamples) {
                  firstKeyFrameIndex = findKeyframeIndex(videoTrack.samples);
                  if (!isVideoContiguous && this.config.forceKeyFrameOnDiscontinuity) {
                    independent = true;
                    if (firstKeyFrameIndex > 0) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`[mp4-remuxer]: Dropped ${firstKeyFrameIndex} out of ${length} video samples due to a missing keyframe`);
                      const startPTS = this.getVideoStartPts(videoTrack.samples);
                      videoTrack.samples = videoTrack.samples.slice(firstKeyFrameIndex);
                      videoTrack.dropped += firstKeyFrameIndex;
                      videoTimeOffset += (videoTrack.samples[0].pts - startPTS) / videoTrack.inputTimeScale;
                      firstKeyFramePTS = videoTimeOffset;
                    } else if (firstKeyFrameIndex === -1) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`[mp4-remuxer]: No keyframe found out of ${length} video samples`);
                      independent = false;
                    }
                  }
                }
                if (this.ISGenerated) {
                  if (enoughAudioSamples && enoughVideoSamples) {
                    // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)
                    // if first audio DTS is not aligned with first video DTS then we need to take that into account
                    // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small
                    // drift between audio and video streams
                    const startPTS = this.getVideoStartPts(videoTrack.samples);
                    const tsDelta = normalizePts(audioTrack.samples[0].pts, startPTS) - startPTS;
                    const audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;
                    audioTimeOffset += Math.max(0, audiovideoTimestampDelta);
                    videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);
                  }

                  // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is calculated in remuxAudio.
                  if (enoughAudioSamples) {
                    // if initSegment was generated without audio samples, regenerate it again
                    if (!audioTrack.samplerate) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn('[mp4-remuxer]: regenerate InitSegment as audio detected');
                      initSegment = this.generateIS(audioTrack, videoTrack, timeOffset);
                    }
                    audio = this.remuxAudio(audioTrack, audioTimeOffset, this.isAudioContiguous, accurateTimeOffset, hasVideo || enoughVideoSamples || playlistType === _types_loader__WEBPACK_IMPORTED_MODULE_5__.PlaylistLevelType.AUDIO ? videoTimeOffset : undefined);
                    if (enoughVideoSamples) {
                      const audioTrackLength = audio ? audio.endPTS - audio.startPTS : 0;
                      // if initSegment was generated without video samples, regenerate it again
                      if (!videoTrack.inputTimeScale) {
                        _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn('[mp4-remuxer]: regenerate InitSegment as video detected');
                        initSegment = this.generateIS(audioTrack, videoTrack, timeOffset);
                      }
                      video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, audioTrackLength);
                    }
                  } else if (enoughVideoSamples) {
                    video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, 0);
                  }
                  if (video) {
                    video.firstKeyFrame = firstKeyFrameIndex;
                    video.independent = firstKeyFrameIndex !== -1;
                    video.firstKeyFramePTS = firstKeyFramePTS;
                  }
                }
              }

              // Allow ID3 and text to remux, even if more audio/video samples are required
              if (this.ISGenerated) {
                if (id3Track.samples.length) {
                  id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, this._initPTS, this._initDTS);
                }
                if (textTrack.samples.length) {
                  text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, this._initPTS);
                }
              }
              return {
                audio,
                video,
                initSegment,
                independent,
                text,
                id3
              };
            }
            generateIS(audioTrack, videoTrack, timeOffset) {
              const audioSamples = audioTrack.samples;
              const videoSamples = videoTrack.samples;
              const typeSupported = this.typeSupported;
              const tracks = {};
              const computePTSDTS = !Number.isFinite(this._initPTS);
              let container = 'audio/mp4';
              let initPTS;
              let initDTS;
              let timescale;
              if (computePTSDTS) {
                initPTS = initDTS = Infinity;
              }
              if (audioTrack.config && audioSamples.length) {
                // let's use audio sampling rate as MP4 time scale.
                // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)
                // using audio sampling rate here helps having an integer MP4 frame duration
                // this avoids potential rounding issue and AV sync issue
                audioTrack.timescale = audioTrack.samplerate;
                switch (audioTrack.segmentCodec) {
                  case 'mp3':
                    if (typeSupported.mpeg) {
                      // Chrome and Safari
                      container = 'audio/mpeg';
                      audioTrack.codec = '';
                    } else if (typeSupported.mp3) {
                      // Firefox
                      audioTrack.codec = 'mp3';
                    }
                    break;
                }
                tracks.audio = {
                  id: 'audio',
                  container: container,
                  codec: audioTrack.codec,
                  initSegment: audioTrack.segmentCodec === 'mp3' && typeSupported.mpeg ? new Uint8Array(0) : _mp4_generator__WEBPACK_IMPORTED_MODULE_1__["default"].initSegment([audioTrack]),
                  metadata: {
                    channelCount: audioTrack.channelCount
                  }
                };
                if (computePTSDTS) {
                  timescale = audioTrack.inputTimeScale;
                  // remember first PTS of this demuxing context. for audio, PTS = DTS
                  initPTS = initDTS = audioSamples[0].pts - Math.round(timescale * timeOffset);
                }
              }
              if (videoTrack.sps && videoTrack.pps && videoSamples.length) {
                // let's use input time scale as MP4 video timescale
                // we use input time scale straight away to avoid rounding issues on frame duration / cts computation
                videoTrack.timescale = videoTrack.inputTimeScale;
                tracks.video = {
                  id: 'main',
                  container: 'video/mp4',
                  codec: videoTrack.codec,
                  initSegment: _mp4_generator__WEBPACK_IMPORTED_MODULE_1__["default"].initSegment([videoTrack]),
                  metadata: {
                    width: videoTrack.width,
                    height: videoTrack.height
                  }
                };
                if (computePTSDTS) {
                  timescale = videoTrack.inputTimeScale;
                  const startPTS = this.getVideoStartPts(videoSamples);
                  const startOffset = Math.round(timescale * timeOffset);
                  initDTS = Math.min(initDTS, normalizePts(videoSamples[0].dts, startPTS) - startOffset);
                  initPTS = Math.min(initPTS, startPTS - startOffset);
                }
              }
              if (Object.keys(tracks).length) {
                this.ISGenerated = true;
                if (computePTSDTS) {
                  this._initPTS = initPTS;
                  this._initDTS = initDTS;
                }
                return {
                  tracks,
                  initPTS,
                  timescale
                };
              }
            }
            remuxVideo(track, timeOffset, contiguous, audioTrackLength) {
              const timeScale = track.inputTimeScale;
              const inputSamples = track.samples;
              const outputSamples = [];
              const nbSamples = inputSamples.length;
              const initPTS = this._initPTS;
              let nextAvcDts = this.nextAvcDts;
              let offset = 8;
              let mp4SampleDuration = this.videoSampleDuration;
              let firstDTS;
              let lastDTS;
              let minPTS = Number.POSITIVE_INFINITY;
              let maxPTS = Number.NEGATIVE_INFINITY;
              let sortSamples = false;

              // if parsed fragment is contiguous with last one, let's use last DTS value as reference
              if (!contiguous || nextAvcDts === null) {
                const pts = timeOffset * timeScale;
                const cts = inputSamples[0].pts - normalizePts(inputSamples[0].dts, inputSamples[0].pts);
                // if not contiguous, let's use target timeOffset
                nextAvcDts = pts - cts;
              }

              // PTS is coded on 33bits, and can loop from -2^32 to 2^32
              // PTSNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value
              for (let i = 0; i < nbSamples; i++) {
                const sample = inputSamples[i];
                sample.pts = normalizePts(sample.pts - initPTS, nextAvcDts);
                sample.dts = normalizePts(sample.dts - initPTS, nextAvcDts);
                if (sample.dts < inputSamples[i > 0 ? i - 1 : i].dts) {
                  sortSamples = true;
                }
              }

              // sort video samples by DTS then PTS then demux id order
              if (sortSamples) {
                inputSamples.sort(function (a, b) {
                  const deltadts = a.dts - b.dts;
                  const deltapts = a.pts - b.pts;
                  return deltadts || deltapts;
                });
              }

              // Get first/last DTS
              firstDTS = inputSamples[0].dts;
              lastDTS = inputSamples[inputSamples.length - 1].dts;

              // Sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS
              // set this constant duration as being the avg delta between consecutive DTS.
              const inputDuration = lastDTS - firstDTS;
              const averageSampleDuration = inputDuration ? Math.round(inputDuration / (nbSamples - 1)) : mp4SampleDuration || track.inputTimeScale / 30;

              // if fragment are contiguous, detect hole/overlapping between fragments
              if (contiguous) {
                // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)
                const delta = firstDTS - nextAvcDts;
                const foundHole = delta > averageSampleDuration;
                const foundOverlap = delta < -1;
                if (foundHole || foundOverlap) {
                  if (foundHole) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`AVC: ${(0, _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_6__.toMsFromMpegTsClock)(delta, true)} ms (${delta}dts) hole between fragments detected, filling it`);
                  } else {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`AVC: ${(0, _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_6__.toMsFromMpegTsClock)(-delta, true)} ms (${delta}dts) overlapping between fragments detected`);
                  }
                  if (!foundOverlap || nextAvcDts > inputSamples[0].pts) {
                    firstDTS = nextAvcDts;
                    const firstPTS = inputSamples[0].pts - delta;
                    inputSamples[0].dts = firstDTS;
                    inputSamples[0].pts = firstPTS;
                    _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.log(`Video: First PTS/DTS adjusted: ${(0, _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_6__.toMsFromMpegTsClock)(firstPTS, true)}/${(0, _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_6__.toMsFromMpegTsClock)(firstDTS, true)}, delta: ${(0, _utils_timescale_conversion__WEBPACK_IMPORTED_MODULE_6__.toMsFromMpegTsClock)(delta, true)} ms`);
                  }
                }
              }
              firstDTS = Math.max(0, firstDTS);
              let nbNalu = 0;
              let naluLen = 0;
              for (let i = 0; i < nbSamples; i++) {
                // compute total/avc sample length and nb of NAL units
                const sample = inputSamples[i];
                const units = sample.units;
                const nbUnits = units.length;
                let sampleLen = 0;
                for (let j = 0; j < nbUnits; j++) {
                  sampleLen += units[j].data.length;
                }
                naluLen += sampleLen;
                nbNalu += nbUnits;
                sample.length = sampleLen;

                // ensure sample monotonic DTS
                sample.dts = Math.max(sample.dts, firstDTS);
                minPTS = Math.min(sample.pts, minPTS);
                maxPTS = Math.max(sample.pts, maxPTS);
              }
              lastDTS = inputSamples[nbSamples - 1].dts;

              /* concatenate the video data and construct the mdat in place
                (need 8 more bytes to fill length and mpdat type) */
              const mdatSize = naluLen + 4 * nbNalu + 8;
              let mdat;
              try {
                mdat = new Uint8Array(mdatSize);
              } catch (err) {
                this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, _events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                  type: _errors__WEBPACK_IMPORTED_MODULE_3__.ErrorTypes.MUX_ERROR,
                  details: _errors__WEBPACK_IMPORTED_MODULE_3__.ErrorDetails.REMUX_ALLOC_ERROR,
                  fatal: false,
                  bytes: mdatSize,
                  reason: `fail allocating video mdat ${mdatSize}`
                });
                return;
              }
              const view = new DataView(mdat.buffer);
              view.setUint32(0, mdatSize);
              mdat.set(_mp4_generator__WEBPACK_IMPORTED_MODULE_1__["default"].types.mdat, 4);
              let stretchedLastFrame = false;
              let minDtsDelta = Number.POSITIVE_INFINITY;
              let minPtsDelta = Number.POSITIVE_INFINITY;
              let maxDtsDelta = Number.NEGATIVE_INFINITY;
              let maxPtsDelta = Number.NEGATIVE_INFINITY;
              for (let i = 0; i < nbSamples; i++) {
                const avcSample = inputSamples[i];
                const avcSampleUnits = avcSample.units;
                let mp4SampleLength = 0;
                // convert NALU bitstream to MP4 format (prepend NALU with size field)
                for (let j = 0, nbUnits = avcSampleUnits.length; j < nbUnits; j++) {
                  const unit = avcSampleUnits[j];
                  const unitData = unit.data;
                  const unitDataLen = unit.data.byteLength;
                  view.setUint32(offset, unitDataLen);
                  offset += 4;
                  mdat.set(unitData, offset);
                  offset += unitDataLen;
                  mp4SampleLength += 4 + unitDataLen;
                }

                // expected sample duration is the Decoding Timestamp diff of consecutive samples
                let ptsDelta;
                if (i < nbSamples - 1) {
                  mp4SampleDuration = inputSamples[i + 1].dts - avcSample.dts;
                  ptsDelta = inputSamples[i + 1].pts - avcSample.pts;
                } else {
                  const config = this.config;
                  const lastFrameDuration = i > 0 ? avcSample.dts - inputSamples[i - 1].dts : averageSampleDuration;
                  ptsDelta = i > 0 ? avcSample.pts - inputSamples[i - 1].pts : averageSampleDuration;
                  if (config.stretchShortVideoTrack && this.nextAudioPts !== null) {
                    // In some cases, a segment's audio track duration may exceed the video track duration.
                    // Since we've already remuxed audio, and we know how long the audio track is, we look to
                    // see if the delta to the next segment is longer than maxBufferHole.
                    // If so, playback would potentially get stuck, so we artificially inflate
                    // the duration of the last frame to minimize any potential gap between segments.
                    const gapTolerance = Math.floor(config.maxBufferHole * timeScale);
                    const deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioPts) - avcSample.pts;
                    if (deltaToFrameEnd > gapTolerance) {
                      // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video
                      // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.
                      mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;
                      if (mp4SampleDuration < 0) {
                        mp4SampleDuration = lastFrameDuration;
                      } else {
                        stretchedLastFrame = true;
                      }
                      _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.log(`[mp4-remuxer]: It is approximately ${deltaToFrameEnd / 90} ms to the next segment; using duration ${mp4SampleDuration / 90} ms for the last video frame.`);
                    } else {
                      mp4SampleDuration = lastFrameDuration;
                    }
                  } else {
                    mp4SampleDuration = lastFrameDuration;
                  }
                }
                const compositionTimeOffset = Math.round(avcSample.pts - avcSample.dts);
                minDtsDelta = Math.min(minDtsDelta, mp4SampleDuration);
                maxDtsDelta = Math.max(maxDtsDelta, mp4SampleDuration);
                minPtsDelta = Math.min(minPtsDelta, ptsDelta);
                maxPtsDelta = Math.max(maxPtsDelta, ptsDelta);
                outputSamples.push(new Mp4Sample(avcSample.key, mp4SampleDuration, mp4SampleLength, compositionTimeOffset));
              }
              if (outputSamples.length) {
                if (chromeVersion) {
                  if (chromeVersion < 70) {
                    // Chrome workaround, mark first sample as being a Random Access Point (keyframe) to avoid sourcebuffer append issue
                    // https://code.google.com/p/chromium/issues/detail?id=229412
                    const flags = outputSamples[0].flags;
                    flags.dependsOn = 2;
                    flags.isNonSync = 0;
                  }
                } else if (safariWebkitVersion) {
                  // Fix for "CNN special report, with CC" in test-streams (Safari browser only)
                  // Ignore DTS when frame durations are irregular. Safari MSE does not handle this leading to gaps.
                  if (maxPtsDelta - minPtsDelta < maxDtsDelta - minDtsDelta && averageSampleDuration / maxDtsDelta < 0.025 && outputSamples[0].cts === 0) {
                    _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn('Found irregular gaps in sample duration. Using PTS instead of DTS to determine MP4 sample duration.');
                    let dts = firstDTS;
                    for (let i = 0, len = outputSamples.length; i < len; i++) {
                      const nextDts = dts + outputSamples[i].duration;
                      const pts = dts + outputSamples[i].cts;
                      if (i < len - 1) {
                        const nextPts = nextDts + outputSamples[i + 1].cts;
                        outputSamples[i].duration = nextPts - pts;
                      } else {
                        outputSamples[i].duration = i ? outputSamples[i - 1].duration : averageSampleDuration;
                      }
                      outputSamples[i].cts = 0;
                      dts = nextDts;
                    }
                  }
                }
              }
              console.assert(mp4SampleDuration !== null, 'mp4SampleDuration must be computed');
              // next AVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)
              mp4SampleDuration = stretchedLastFrame || !mp4SampleDuration ? averageSampleDuration : mp4SampleDuration;
              this.nextAvcDts = nextAvcDts = lastDTS + mp4SampleDuration;
              this.videoSampleDuration = mp4SampleDuration;
              this.isVideoContiguous = true;
              const moof = _mp4_generator__WEBPACK_IMPORTED_MODULE_1__["default"].moof(track.sequenceNumber++, firstDTS, Object.assign({}, track, {
                samples: outputSamples
              }));
              const type = 'video';
              const data = {
                data1: moof,
                data2: mdat,
                startPTS: minPTS / timeScale,
                endPTS: (maxPTS + mp4SampleDuration) / timeScale,
                startDTS: firstDTS / timeScale,
                endDTS: nextAvcDts / timeScale,
                type,
                hasAudio: false,
                hasVideo: true,
                nb: outputSamples.length,
                dropped: track.dropped
              };
              track.samples = [];
              track.dropped = 0;
              console.assert(mdat.length, 'MDAT length must not be zero');
              return data;
            }
            remuxAudio(track, timeOffset, contiguous, accurateTimeOffset, videoTimeOffset) {
              const inputTimeScale = track.inputTimeScale;
              const mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;
              const scaleFactor = inputTimeScale / mp4timeScale;
              const mp4SampleDuration = track.segmentCodec === 'aac' ? AAC_SAMPLES_PER_FRAME : MPEG_AUDIO_SAMPLE_PER_FRAME;
              const inputSampleDuration = mp4SampleDuration * scaleFactor;
              const initPTS = this._initPTS;
              const rawMPEG = track.segmentCodec === 'mp3' && this.typeSupported.mpeg;
              const outputSamples = [];
              const alignedWithVideo = videoTimeOffset !== undefined;
              let inputSamples = track.samples;
              let offset = rawMPEG ? 0 : 8;
              let nextAudioPts = this.nextAudioPts || -1;

              // window.audioSamples ? window.audioSamples.push(inputSamples.map(s => s.pts)) : (window.audioSamples = [inputSamples.map(s => s.pts)]);

              // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),
              // for sake of clarity:
              // consecutive fragments are frags with
              //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR
              //  - less than 20 audio frames distance
              // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)
              // this helps ensuring audio continuity
              // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame
              const timeOffsetMpegTS = timeOffset * inputTimeScale;
              this.isAudioContiguous = contiguous = contiguous || inputSamples.length && nextAudioPts > 0 && (accurateTimeOffset && Math.abs(timeOffsetMpegTS - nextAudioPts) < 9000 || Math.abs(normalizePts(inputSamples[0].pts - initPTS, timeOffsetMpegTS) - nextAudioPts) < 20 * inputSampleDuration);

              // compute normalized PTS
              inputSamples.forEach(function (sample) {
                sample.pts = normalizePts(sample.pts - initPTS, timeOffsetMpegTS);
              });
              if (!contiguous || nextAudioPts < 0) {
                // filter out sample with negative PTS that are not playable anyway
                // if we don't remove these negative samples, they will shift all audio samples forward.
                // leading to audio overlap between current / next fragment
                inputSamples = inputSamples.filter(sample => sample.pts >= 0);

                // in case all samples have negative PTS, and have been filtered out, return now
                if (!inputSamples.length) {
                  return;
                }
                if (videoTimeOffset === 0) {
                  // Set the start to 0 to match video so that start gaps larger than inputSampleDuration are filled with silence
                  nextAudioPts = 0;
                } else if (accurateTimeOffset && !alignedWithVideo) {
                  // When not seeking, not live, and LevelDetails.PTSKnown, use fragment start as predicted next audio PTS
                  nextAudioPts = Math.max(0, timeOffsetMpegTS);
                } else {
                  // if frags are not contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS
                  nextAudioPts = inputSamples[0].pts;
                }
              }

              // If the audio track is missing samples, the frames seem to get "left-shifted" within the
              // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.
              // In an effort to prevent this from happening, we inject frames here where there are gaps.
              // When possible, we inject a silent frame; when that's not possible, we duplicate the last
              // frame.

              if (track.segmentCodec === 'aac') {
                const maxAudioFramesDrift = this.config.maxAudioFramesDrift;
                for (let i = 0, nextPts = nextAudioPts; i < inputSamples.length; i++) {
                  // First, let's see how far off this frame is from where we expect it to be
                  const sample = inputSamples[i];
                  const pts = sample.pts;
                  const delta = pts - nextPts;
                  const duration = Math.abs(1000 * delta / inputTimeScale);

                  // When remuxing with video, if we're overlapping by more than a duration, drop this sample to stay in sync
                  if (delta <= -maxAudioFramesDrift * inputSampleDuration && alignedWithVideo) {
                    if (i === 0) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`Audio frame @ ${(pts / inputTimeScale).toFixed(3)}s overlaps nextAudioPts by ${Math.round(1000 * delta / inputTimeScale)} ms.`);
                      this.nextAudioPts = nextAudioPts = nextPts = pts;
                    }
                  } // eslint-disable-line brace-style

                  // Insert missing frames if:
                  // 1: We're more than maxAudioFramesDrift frame away
                  // 2: Not more than MAX_SILENT_FRAME_DURATION away
                  // 3: currentTime (aka nextPtsNorm) is not 0
                  // 4: remuxing with video (videoTimeOffset !== undefined)
                  else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && alignedWithVideo) {
                    let missing = Math.round(delta / inputSampleDuration);
                    // Adjust nextPts so that silent samples are aligned with media pts. This will prevent media samples from
                    // later being shifted if nextPts is based on timeOffset and delta is not a multiple of inputSampleDuration.
                    nextPts = pts - missing * inputSampleDuration;
                    if (nextPts < 0) {
                      missing--;
                      nextPts += inputSampleDuration;
                    }
                    if (i === 0) {
                      this.nextAudioPts = nextAudioPts = nextPts;
                    }
                    _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn(`[mp4-remuxer]: Injecting ${missing} audio frame @ ${(nextPts / inputTimeScale).toFixed(3)}s due to ${Math.round(1000 * delta / inputTimeScale)} ms gap.`);
                    for (let j = 0; j < missing; j++) {
                      const newStamp = Math.max(nextPts, 0);
                      let fillFrame = _aac_helper__WEBPACK_IMPORTED_MODULE_0__["default"].getSilentFrame(track.manifestCodec || track.codec, track.channelCount);
                      if (!fillFrame) {
                        _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.log('[mp4-remuxer]: Unable to get silent frame for given audio codec; duplicating last frame instead.');
                        fillFrame = sample.unit.subarray();
                      }
                      inputSamples.splice(i, 0, {
                        unit: fillFrame,
                        pts: newStamp
                      });
                      nextPts += inputSampleDuration;
                      i++;
                    }
                  }
                  sample.pts = nextPts;
                  nextPts += inputSampleDuration;
                }
              }
              let firstPTS = null;
              let lastPTS = null;
              let mdat;
              let mdatSize = 0;
              let sampleLength = inputSamples.length;
              while (sampleLength--) {
                mdatSize += inputSamples[sampleLength].unit.byteLength;
              }
              for (let j = 0, nbSamples = inputSamples.length; j < nbSamples; j++) {
                const audioSample = inputSamples[j];
                const unit = audioSample.unit;
                let pts = audioSample.pts;
                if (lastPTS !== null) {
                  // If we have more than one sample, set the duration of the sample to the "real" duration; the PTS diff with
                  // the previous sample
                  const prevSample = outputSamples[j - 1];
                  prevSample.duration = Math.round((pts - lastPTS) / scaleFactor);
                } else {
                  if (contiguous && track.segmentCodec === 'aac') {
                    // set PTS/DTS to expected PTS/DTS
                    pts = nextAudioPts;
                  }
                  // remember first PTS of our audioSamples
                  firstPTS = pts;
                  if (mdatSize > 0) {
                    /* concatenate the audio data and construct the mdat in place
                      (need 8 more bytes to fill length and mdat type) */
                    mdatSize += offset;
                    try {
                      mdat = new Uint8Array(mdatSize);
                    } catch (err) {
                      this.observer.emit(_events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, _events__WEBPACK_IMPORTED_MODULE_2__.Events.ERROR, {
                        type: _errors__WEBPACK_IMPORTED_MODULE_3__.ErrorTypes.MUX_ERROR,
                        details: _errors__WEBPACK_IMPORTED_MODULE_3__.ErrorDetails.REMUX_ALLOC_ERROR,
                        fatal: false,
                        bytes: mdatSize,
                        reason: `fail allocating audio mdat ${mdatSize}`
                      });
                      return;
                    }
                    if (!rawMPEG) {
                      const view = new DataView(mdat.buffer);
                      view.setUint32(0, mdatSize);
                      mdat.set(_mp4_generator__WEBPACK_IMPORTED_MODULE_1__["default"].types.mdat, 4);
                    }
                  } else {
                    // no audio samples
                    return;
                  }
                }
                mdat.set(unit, offset);
                const unitLen = unit.byteLength;
                offset += unitLen;
                // Default the sample's duration to the computed mp4SampleDuration, which will either be 1024 for AAC or 1152 for MPEG
                // In the case that we have 1 sample, this will be the duration. If we have more than one sample, the duration
                // becomes the PTS diff with the previous sample
                outputSamples.push(new Mp4Sample(true, mp4SampleDuration, unitLen, 0));
                lastPTS = pts;
              }

              // We could end up with no audio samples if all input samples were overlapping with the previously remuxed ones
              const nbSamples = outputSamples.length;
              if (!nbSamples) {
                return;
              }

              // The next audio sample PTS should be equal to last sample PTS + duration
              const lastSample = outputSamples[outputSamples.length - 1];
              this.nextAudioPts = nextAudioPts = lastPTS + scaleFactor * lastSample.duration;

              // Set the track samples from inputSamples to outputSamples before remuxing
              const moof = rawMPEG ? new Uint8Array(0) : _mp4_generator__WEBPACK_IMPORTED_MODULE_1__["default"].moof(track.sequenceNumber++, firstPTS / scaleFactor, Object.assign({}, track, {
                samples: outputSamples
              }));

              // Clear the track samples. This also clears the samples array in the demuxer, since the reference is shared
              track.samples = [];
              const start = firstPTS / inputTimeScale;
              const end = nextAudioPts / inputTimeScale;
              const type = 'audio';
              const audioData = {
                data1: moof,
                data2: mdat,
                startPTS: start,
                endPTS: end,
                startDTS: start,
                endDTS: end,
                type,
                hasAudio: true,
                hasVideo: false,
                nb: nbSamples
              };
              this.isAudioContiguous = true;
              console.assert(mdat.length, 'MDAT length must not be zero');
              return audioData;
            }
            remuxEmptyAudio(track, timeOffset, contiguous, videoData) {
              const inputTimeScale = track.inputTimeScale;
              const mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;
              const scaleFactor = inputTimeScale / mp4timeScale;
              const nextAudioPts = this.nextAudioPts;
              // sync with video's timestamp
              const startDTS = (nextAudioPts !== null ? nextAudioPts : videoData.startDTS * inputTimeScale) + this._initDTS;
              const endDTS = videoData.endDTS * inputTimeScale + this._initDTS;
              // one sample's duration value
              const frameDuration = scaleFactor * AAC_SAMPLES_PER_FRAME;
              // samples count of this segment's duration
              const nbSamples = Math.ceil((endDTS - startDTS) / frameDuration);
              // silent frame
              const silentFrame = _aac_helper__WEBPACK_IMPORTED_MODULE_0__["default"].getSilentFrame(track.manifestCodec || track.codec, track.channelCount);
              _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.warn('[mp4-remuxer]: remux empty Audio');
              // Can't remux if we can't generate a silent frame...
              if (!silentFrame) {
                _utils_logger__WEBPACK_IMPORTED_MODULE_4__.logger.trace('[mp4-remuxer]: Unable to remuxEmptyAudio since we were unable to get a silent frame for given audio codec');
                return;
              }
              const samples = [];
              for (let i = 0; i < nbSamples; i++) {
                const stamp = startDTS + i * frameDuration;
                samples.push({
                  unit: silentFrame,
                  pts: stamp,
                  dts: stamp
                });
              }
              track.samples = samples;
              return this.remuxAudio(track, timeOffset, contiguous, false);
            }
          }
          function normalizePts(value, reference) {
            let offset;
            if (reference === null) {
              return value;
            }
            if (reference < value) {
              // - 2^33
              offset = -8589934592;
            } else {
              // + 2^33
              offset = 8589934592;
            }
            /* PTS is 33bit (from 0 to 2^33 -1)
              if diff between value and reference is bigger than half of the amplitude (2^32) then it means that
              PTS looping occured. fill the gap */
            while (Math.abs(value - reference) > 4294967296) {
              value += offset;
            }
            return value;
          }
          function findKeyframeIndex(samples) {
            for (let i = 0; i < samples.length; i++) {
              if (samples[i].key) {
                return i;
              }
            }
            return -1;
          }
          function flushTextTrackMetadataCueSamples(track, timeOffset, initPTS, initDTS) {
            const length = track.samples.length;
            if (!length) {
              return;
            }
            const inputTimeScale = track.inputTimeScale;
            for (let index = 0; index < length; index++) {
              const sample = track.samples[index];
              // setting id3 pts, dts to relative time
              // using this._initPTS and this._initDTS to calculate relative time
              sample.pts = normalizePts(sample.pts - initPTS, timeOffset * inputTimeScale) / inputTimeScale;
              sample.dts = normalizePts(sample.dts - initDTS, timeOffset * inputTimeScale) / inputTimeScale;
            }
            const samples = track.samples;
            track.samples = [];
            return {
              samples
            };
          }
          function flushTextTrackUserdataCueSamples(track, timeOffset, initPTS) {
            const length = track.samples.length;
            if (!length) {
              return;
            }
            const inputTimeScale = track.inputTimeScale;
            for (let index = 0; index < length; index++) {
              const sample = track.samples[index];
              // setting text pts, dts to relative time
              // using this._initPTS and this._initDTS to calculate relative time
              sample.pts = normalizePts(sample.pts - initPTS, timeOffset * inputTimeScale) / inputTimeScale;
            }
            track.samples.sort((a, b) => a.pts - b.pts);
            const samples = track.samples;
            track.samples = [];
            return {
              samples
            };
          }
          class Mp4Sample {
            constructor(isKeyframe, duration, size, cts) {
              this.duration = duration;
              this.size = size;
              this.cts = cts;
              this.flags = new Mp4SampleFlags(isKeyframe);
            }
          }
          class Mp4SampleFlags {
            isLeading = 0;
            isDependedOn = 0;
            hasRedundancy = 0;
            degradPrio = 0;
            dependsOn = 1;
            isNonSync = 1;
            constructor(isKeyframe) {
              this.dependsOn = isKeyframe ? 2 : 1;
              this.isNonSync = isKeyframe ? 0 : 1;
            }
          }

          /***/
        }),

/***/ "./src/remux/passthrough-remuxer.ts":
/*!******************************************!*\
  !*** ./src/remux/passthrough-remuxer.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _mp4_remuxer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./mp4-remuxer */ "./src/remux/mp4-remuxer.ts");
/* harmony import */ var _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");





          class PassThroughRemuxer {
            emitInitSegment = false;
            lastEndTime = null;
            destroy() { }
            resetTimeStamp(defaultInitPTS) {
              this.initPTS = defaultInitPTS;
              this.lastEndTime = null;
            }
            resetNextTimestamp() {
              this.lastEndTime = null;
            }
            resetInitSegment(initSegment, audioCodec, videoCodec, decryptdata) {
              this.audioCodec = audioCodec;
              this.videoCodec = videoCodec;
              this.generateInitSegment((0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.patchEncyptionData)(initSegment, decryptdata));
              this.emitInitSegment = true;
            }
            generateInitSegment(initSegment) {
              let {
                audioCodec,
                videoCodec
              } = this;
              if (!initSegment || !initSegment.byteLength) {
                this.initTracks = undefined;
                this.initData = undefined;
                return;
              }
              const initData = this.initData = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.parseInitSegment)(initSegment);

              // Get codec from initSegment or fallback to default
              if (!audioCodec) {
                audioCodec = getParsedTrackCodec(initData.audio, _loader_fragment__WEBPACK_IMPORTED_MODULE_2__.ElementaryStreamTypes.AUDIO);
              }
              if (!videoCodec) {
                videoCodec = getParsedTrackCodec(initData.video, _loader_fragment__WEBPACK_IMPORTED_MODULE_2__.ElementaryStreamTypes.VIDEO);
              }
              const tracks = {};
              if (initData.audio && initData.video) {
                tracks.audiovideo = {
                  container: 'video/mp4',
                  codec: audioCodec + ',' + videoCodec,
                  initSegment,
                  id: 'main'
                };
              } else if (initData.audio) {
                tracks.audio = {
                  container: 'audio/mp4',
                  codec: audioCodec,
                  initSegment,
                  id: 'audio'
                };
              } else if (initData.video) {
                tracks.video = {
                  container: 'video/mp4',
                  codec: videoCodec,
                  initSegment,
                  id: 'main'
                };
              } else {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('[passthrough-remuxer.ts]: initSegment does not contain moov or trak boxes.');
              }
              this.initTracks = tracks;
            }
            remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset) {
              let {
                initPTS,
                lastEndTime
              } = this;
              const result = {
                audio: undefined,
                video: undefined,
                text: textTrack,
                id3: id3Track,
                initSegment: undefined
              };

              // If we haven't yet set a lastEndDTS, or it was reset, set it to the provided timeOffset. We want to use the
              // lastEndDTS over timeOffset whenever possible; during progressive playback, the media source will not update
              // the media duration (which is what timeOffset is provided as) before we need to process the next chunk.
              if (!Number.isFinite(lastEndTime)) {
                lastEndTime = this.lastEndTime = timeOffset || 0;
              }

              // The binary segment data is added to the videoTrack in the mp4demuxer. We don't check to see if the data is only
              // audio or video (or both); adding it to video was an arbitrary choice.
              const data = videoTrack.samples;
              if (!data || !data.length) {
                return result;
              }
              const initSegment = {
                initPTS: undefined,
                timescale: 1
              };
              let initData = this.initData;
              if (!initData || !initData.length) {
                this.generateInitSegment(data);
                initData = this.initData;
              }
              if (!initData || !initData.length) {
                // We can't remux if the initSegment could not be generated
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('[passthrough-remuxer.ts]: Failed to generate initSegment.');
                return result;
              }
              if (this.emitInitSegment) {
                initSegment.tracks = this.initTracks;
                this.emitInitSegment = false;
              }
              const startDTS = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.getStartDTS)(initData, data);
              if (!Number.isFinite(initPTS)) {
                this.initPTS = initSegment.initPTS = initPTS = startDTS - timeOffset;
              }
              const duration = (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.getDuration)(data, initData);
              const startTime = audioTrack ? startDTS - initPTS : lastEndTime;
              const endTime = startTime + duration;
              (0, _utils_mp4_tools__WEBPACK_IMPORTED_MODULE_1__.offsetStartDTS)(initData, data, initPTS);
              if (duration > 0) {
                this.lastEndTime = endTime;
              } else {
                _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.warn('Duration parsed from mp4 should be greater than zero');
                this.resetNextTimestamp();
              }
              const hasAudio = !!initData.audio;
              const hasVideo = !!initData.video;
              let type = '';
              if (hasAudio) {
                type += 'audio';
              }
              if (hasVideo) {
                type += 'video';
              }
              const track = {
                data1: data,
                startPTS: startTime,
                startDTS: startTime,
                endPTS: endTime,
                endDTS: endTime,
                type,
                hasAudio,
                hasVideo,
                nb: 1,
                dropped: 0
              };
              result.audio = track.type === 'audio' ? track : undefined;
              result.video = track.type !== 'audio' ? track : undefined;
              result.initSegment = initSegment;
              const initPtsNum = this.initPTS ?? 0;
              result.id3 = (0, _mp4_remuxer__WEBPACK_IMPORTED_MODULE_0__.flushTextTrackMetadataCueSamples)(id3Track, timeOffset, initPtsNum, initPtsNum);
              if (textTrack.samples.length) {
                result.text = (0, _mp4_remuxer__WEBPACK_IMPORTED_MODULE_0__.flushTextTrackUserdataCueSamples)(textTrack, timeOffset, initPtsNum);
              }
              return result;
            }
          }
          function getParsedTrackCodec(track, type) {
            const parsedCodec = track?.codec;
            if (parsedCodec && parsedCodec.length > 4) {
              return parsedCodec;
            }
            // Since mp4-tools cannot parse full codec string (see 'TODO: Parse codec details'... in mp4-tools)
            // Provide defaults based on codec type
            // This allows for some playback of some fmp4 playlists without CODECS defined in manifest
            if (parsedCodec === 'hvc1' || parsedCodec === 'hev1') {
              return 'hvc1.1.c.L120.90';
            }
            if (parsedCodec === 'av01') {
              return 'av01.0.04M.08';
            }
            if (parsedCodec === 'avc1' || type === _loader_fragment__WEBPACK_IMPORTED_MODULE_2__.ElementaryStreamTypes.VIDEO) {
              return 'avc1.42e01e';
            }
            return 'mp4a.40.5';
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (PassThroughRemuxer);

          /***/
        }),

/***/ "./src/task-loop.ts":
/*!**************************!*\
  !*** ./src/task-loop.ts ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ TaskLoop)
            /* harmony export */
          });
          /**
           * Sub-class specialization of EventHandler base class.
           *
           * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,
           * scheduled asynchroneously, avoiding recursive calls in the same tick.
           *
           * The task itself is implemented in `doTick`. It can be requested and called for single execution
           * using the `tick` method.
           *
           * It will be assured that the task execution method (`tick`) only gets called once per main loop "tick",
           * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.
           *
           * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,
           * and cancelled with `clearNextTick`.
           *
           * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).
           *
           * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.
           *
           * Further explanations:
           *
           * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously
           * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.
           *
           * When the task execution (`tick` method) is called in re-entrant way this is detected and
           * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further
           * task processing on the next main loop iteration (also known as "next tick" in the Node/JS runtime lingo).
           */
          class TaskLoop {
            _tickTimer = null;
            _tickInterval = null;
            _tickCallCount = 0;
            constructor() {
              this._boundTick = this.tick.bind(this);
            }
            destroy() {
              this.onHandlerDestroying();
              this.onHandlerDestroyed();
            }
            onHandlerDestroying() {
              // clear all timers before unregistering from event bus
              this.clearNextTick();
              this.clearInterval();
            }
            onHandlerDestroyed() { }

            /**
             * @returns {boolean}
             */
            hasInterval() {
              return !!this._tickInterval;
            }

            /**
             * @returns {boolean}
             */
            hasNextTick() {
              return !!this._tickTimer;
            }

            /**
             * @param {number} millis Interval time (ms)
             * @returns {boolean} True when interval has been scheduled, false when already scheduled (no effect)
             */
            setInterval(millis) {
              if (!this._tickInterval) {
                this._tickInterval = self.setInterval(this._boundTick, millis);
                return true;
              }
              return false;
            }

            /**
             * @returns {boolean} True when interval was cleared, false when none was set (no effect)
             */
            clearInterval() {
              if (this._tickInterval) {
                self.clearInterval(this._tickInterval);
                this._tickInterval = null;
                return true;
              }
              return false;
            }

            /**
             * @returns {boolean} True when timeout was cleared, false when none was set (no effect)
             */
            clearNextTick() {
              if (this._tickTimer) {
                self.clearTimeout(this._tickTimer);
                this._tickTimer = null;
                return true;
              }
              return false;
            }

            /**
             * Will call the subclass doTick implementation in this main loop tick
             * or in the next one (via setTimeout(,0)) in case it has already been called
             * in this tick (in case this is a re-entrant call).
             */
            tick() {
              this._tickCallCount++;
              if (this._tickCallCount === 1) {
                this.doTick();
                // re-entrant call to tick from previous doTick call stack
                // -> schedule a call on the next main loop iteration to process this task processing request
                if (this._tickCallCount > 1) {
                  // make sure only one timer exists at any time at max
                  this.tickImmediate();
                }
                this._tickCallCount = 0;
              }
            }
            tickImmediate() {
              this.clearNextTick();
              this._tickTimer = self.setTimeout(this._boundTick, 0);
            }

            /**
             * For subclass to implement task logic
             * @abstract
             */
            doTick() { }
          }

          /***/
        }),

/***/ "./src/types/cmcd.ts":
/*!***************************!*\
  !*** ./src/types/cmcd.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "CMCDObjectType": () => (/* binding */ CMCDObjectType),
/* harmony export */   "CMCDStreamType": () => (/* binding */ CMCDStreamType),
/* harmony export */   "CMCDStreamingFormat": () => (/* binding */ CMCDStreamingFormat),
/* harmony export */   "CMCDVersion": () => (/* binding */ CMCDVersion)
            /* harmony export */
          });
          /**
           * CMCD spec version
           */
          const CMCDVersion = 1;

          /**
           * CMCD Object Type
           */
          let CMCDObjectType;

          /**
           * CMCD Streaming Format
           */
          (function (CMCDObjectType) {
            CMCDObjectType["MANIFEST"] = "m";
            CMCDObjectType["AUDIO"] = "a";
            CMCDObjectType["VIDEO"] = "v";
            CMCDObjectType["MUXED"] = "av";
            CMCDObjectType["INIT"] = "i";
            CMCDObjectType["CAPTION"] = "c";
            CMCDObjectType["TIMED_TEXT"] = "tt";
            CMCDObjectType["KEY"] = "k";
            CMCDObjectType["OTHER"] = "o";
          })(CMCDObjectType || (CMCDObjectType = {}));
          let CMCDStreamingFormat;

          /**
           * CMCD Streaming Type
           */
          (function (CMCDStreamingFormat) {
            CMCDStreamingFormat["DASH"] = "d";
            CMCDStreamingFormat["HLS"] = "h";
            CMCDStreamingFormat["SMOOTH"] = "s";
            CMCDStreamingFormat["OTHER"] = "o";
          })(CMCDStreamingFormat || (CMCDStreamingFormat = {}));
          let CMCDStreamType;

          /**
           * CMCD Headers
           */
          (function (CMCDStreamType) {
            CMCDStreamType["VOD"] = "v";
            CMCDStreamType["LIVE"] = "l";
          })(CMCDStreamType || (CMCDStreamType = {}));

          /***/
        }),

/***/ "./src/types/demuxer.ts":
/*!******************************!*\
  !*** ./src/types/demuxer.ts ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "MetadataSchema": () => (/* binding */ MetadataSchema)
            /* harmony export */
          });
          let MetadataSchema;
          (function (MetadataSchema) {
            MetadataSchema["audioId3"] = "org.id3";
            MetadataSchema["dateRange"] = "com.apple.quicktime.HLS";
            MetadataSchema["emsg"] = "https://aomedia.org/emsg/ID3";
          })(MetadataSchema || (MetadataSchema = {}));

          /***/
        }),

/***/ "./src/types/level.ts":
/*!****************************!*\
  !*** ./src/types/level.ts ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "HlsSkip": () => (/* binding */ HlsSkip),
/* harmony export */   "HlsUrlParameters": () => (/* binding */ HlsUrlParameters),
/* harmony export */   "Level": () => (/* binding */ Level),
/* harmony export */   "getSkipValue": () => (/* binding */ getSkipValue)
            /* harmony export */
          });
          let HlsSkip;
          (function (HlsSkip) {
            HlsSkip["No"] = "";
            HlsSkip["Yes"] = "YES";
            HlsSkip["v2"] = "v2";
          })(HlsSkip || (HlsSkip = {}));
          function getSkipValue(details, msn) {
            const {
              canSkipUntil,
              canSkipDateRanges,
              endSN
            } = details;
            const snChangeGoal = msn !== undefined ? msn - endSN : 0;
            if (canSkipUntil && snChangeGoal < canSkipUntil) {
              if (canSkipDateRanges) {
                return HlsSkip.v2;
              }
              return HlsSkip.Yes;
            }
            return HlsSkip.No;
          }
          class HlsUrlParameters {
            constructor(msn, part, skip) {
              this.msn = msn;
              this.part = part;
              this.skip = skip;
            }
            addDirectives(uri) {
              const url = new self.URL(uri);
              if (this.msn !== undefined) {
                url.searchParams.set('_HLS_msn', this.msn.toString());
              }
              if (this.part !== undefined) {
                url.searchParams.set('_HLS_part', this.part.toString());
              }
              if (this.skip) {
                url.searchParams.set('_HLS_skip', this.skip);
              }
              return url.href;
            }
          }
          class Level {
            fragmentError = 0;
            loadError = 0;
            realBitrate = 0;
            _urlId = 0;
            constructor(data) {
              this.url = [data.url];
              this.attrs = data.attrs;
              this.bitrate = data.bitrate;
              if (data.details) {
                this.details = data.details;
              }
              this.id = data.id || 0;
              this.name = data.name;
              this.width = data.width || 0;
              this.height = data.height || 0;
              this.audioCodec = data.audioCodec;
              this.videoCodec = data.videoCodec;
              this.unknownCodecs = data.unknownCodecs;
              this.codecSet = [data.videoCodec, data.audioCodec].filter(c => c).join(',').replace(/\.[^.,]+/g, '');
            }
            get maxBitrate() {
              return Math.max(this.realBitrate, this.bitrate);
            }
            get uri() {
              return this.url[this._urlId] || '';
            }
            get urlId() {
              return this._urlId;
            }
            set urlId(value) {
              const newValue = value % this.url.length;
              if (this._urlId !== newValue) {
                this.details = undefined;
                this._urlId = newValue;
              }
            }
          }

          /***/
        }),

/***/ "./src/types/loader.ts":
/*!*****************************!*\
  !*** ./src/types/loader.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "PlaylistContextType": () => (/* binding */ PlaylistContextType),
/* harmony export */   "PlaylistLevelType": () => (/* binding */ PlaylistLevelType)
            /* harmony export */
          });
          let PlaylistContextType;
          (function (PlaylistContextType) {
            PlaylistContextType["MANIFEST"] = "manifest";
            PlaylistContextType["LEVEL"] = "level";
            PlaylistContextType["AUDIO_TRACK"] = "audioTrack";
            PlaylistContextType["SUBTITLE_TRACK"] = "subtitleTrack";
          })(PlaylistContextType || (PlaylistContextType = {}));
          let PlaylistLevelType;
          (function (PlaylistLevelType) {
            PlaylistLevelType["MAIN"] = "main";
            PlaylistLevelType["AUDIO"] = "audio";
            PlaylistLevelType["SUBTITLE"] = "subtitle";
          })(PlaylistLevelType || (PlaylistLevelType = {}));

          /***/
        }),

/***/ "./src/types/transmuxer.ts":
/*!*********************************!*\
  !*** ./src/types/transmuxer.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "ChunkMetadata": () => (/* binding */ ChunkMetadata)
            /* harmony export */
          });
          class ChunkMetadata {
            transmuxing = getNewPerformanceTiming();
            buffering = {
              audio: getNewPerformanceTiming(),
              video: getNewPerformanceTiming(),
              audiovideo: getNewPerformanceTiming()
            };
            constructor(level, sn, id, size = 0, part = -1, partial = false) {
              this.level = level;
              this.sn = sn;
              this.id = id;
              this.size = size;
              this.part = part;
              this.partial = partial;
            }
          }
          function getNewPerformanceTiming() {
            return {
              start: 0,
              executeStart: 0,
              executeEnd: 0,
              end: 0
            };
          }

          /***/
        }),

/***/ "./src/utils/attr-list.ts":
/*!********************************!*\
  !*** ./src/utils/attr-list.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "AttrList": () => (/* binding */ AttrList)
            /* harmony export */
          });
          const DECIMAL_RESOLUTION_REGEX = /^(\d+)x(\d+)$/; // eslint-disable-line no-useless-escape
          const ATTR_LIST_REGEX = /\s*(.+?)\s*=((?:\".*?\")|.*?)(?:,|$)/g; // eslint-disable-line no-useless-escape

          // adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js
          class AttrList {
            constructor(attrs) {
              if (typeof attrs === 'string') {
                attrs = AttrList.parseAttrList(attrs);
              }
              for (const attr in attrs) {
                if (attrs.hasOwnProperty(attr)) {
                  this[attr] = attrs[attr];
                }
              }
            }
            decimalInteger(attrName) {
              const intValue = parseInt(this[attrName], 10);
              if (intValue > Number.MAX_SAFE_INTEGER) {
                return Infinity;
              }
              return intValue;
            }
            hexadecimalInteger(attrName) {
              if (this[attrName]) {
                let stringValue = (this[attrName] || '0x').slice(2);
                stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;
                const value = new Uint8Array(stringValue.length / 2);
                for (let i = 0; i < stringValue.length / 2; i++) {
                  value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);
                }
                return value;
              } else {
                return null;
              }
            }
            hexadecimalIntegerAsNumber(attrName) {
              const intValue = parseInt(this[attrName], 16);
              if (intValue > Number.MAX_SAFE_INTEGER) {
                return Infinity;
              }
              return intValue;
            }
            decimalFloatingPoint(attrName) {
              return parseFloat(this[attrName]);
            }
            optionalFloat(attrName, defaultValue) {
              const value = this[attrName];
              return value ? parseFloat(value) : defaultValue;
            }
            enumeratedString(attrName) {
              return this[attrName];
            }
            bool(attrName) {
              return this[attrName] === 'YES';
            }
            decimalResolution(attrName) {
              const res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);
              if (res === null) {
                return undefined;
              }
              return {
                width: parseInt(res[1], 10),
                height: parseInt(res[2], 10)
              };
            }
            static parseAttrList(input) {
              let match;
              const attrs = {};
              const quote = '"';
              ATTR_LIST_REGEX.lastIndex = 0;
              while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {
                let value = match[2];
                if (value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1) {
                  value = value.slice(1, -1);
                }
                attrs[match[1]] = value;
              }
              return attrs;
            }
          }

          /***/
        }),

/***/ "./src/utils/binary-search.ts":
/*!************************************!*\
  !*** ./src/utils/binary-search.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          const BinarySearch = {
            /**
             * Searches for an item in an array which matches a certain condition.
             * This requires the condition to only match one item in the array,
             * and for the array to be ordered.
             *
             * @param {Array<T>} list The array to search.
             * @param {BinarySearchComparison<T>} comparisonFn
             *      Called and provided a candidate item as the first argument.
             *      Should return:
             *          > -1 if the item should be located at a lower index than the provided item.
             *          > 1 if the item should be located at a higher index than the provided item.
             *          > 0 if the item is the item you're looking for.
             *
             * @return {T | null} The object if it is found or null otherwise.
             */
            search: function (list, comparisonFn) {
              let minIndex = 0;
              let maxIndex = list.length - 1;
              let currentIndex = null;
              let currentElement = null;
              while (minIndex <= maxIndex) {
                currentIndex = (minIndex + maxIndex) / 2 | 0;
                currentElement = list[currentIndex];
                const comparisonResult = comparisonFn(currentElement);
                if (comparisonResult > 0) {
                  minIndex = currentIndex + 1;
                } else if (comparisonResult < 0) {
                  maxIndex = currentIndex - 1;
                } else {
                  return currentElement;
                }
              }
              return null;
            }
          };
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (BinarySearch);

          /***/
        }),

/***/ "./src/utils/buffer-helper.ts":
/*!************************************!*\
  !*** ./src/utils/buffer-helper.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "BufferHelper": () => (/* binding */ BufferHelper)
            /* harmony export */
          });
/* harmony import */ var _logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./logger */ "./src/utils/logger.ts");
          /**
           * @module BufferHelper
           *
           * Providing methods dealing with buffer length retrieval for example.
           *
           * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.
           *
           * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered
           */


          const noopBuffered = {
            length: 0,
            start: () => 0,
            end: () => 0
          };
          class BufferHelper {
            /**
             * Return true if `media`'s buffered include `position`
             * @param {Bufferable} media
             * @param {number} position
             * @returns {boolean}
             */
            static isBuffered(media, position) {
              try {
                if (media) {
                  const buffered = BufferHelper.getBuffered(media);
                  for (let i = 0; i < buffered.length; i++) {
                    if (position >= buffered.start(i) && position <= buffered.end(i)) {
                      return true;
                    }
                  }
                }
              } catch (error) {
                // this is to catch
                // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':
                // This SourceBuffer has been removed from the parent media source
              }
              return false;
            }
            static bufferInfo(media, pos, maxHoleDuration) {
              try {
                if (media) {
                  const vbuffered = BufferHelper.getBuffered(media);
                  const buffered = [];
                  let i;
                  for (i = 0; i < vbuffered.length; i++) {
                    buffered.push({
                      start: vbuffered.start(i),
                      end: vbuffered.end(i)
                    });
                  }
                  return this.bufferedInfo(buffered, pos, maxHoleDuration);
                }
              } catch (error) {
                // this is to catch
                // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':
                // This SourceBuffer has been removed from the parent media source
              }
              return {
                len: 0,
                start: pos,
                end: pos,
                nextStart: undefined
              };
            }
            static bufferedInfo(buffered, pos, maxHoleDuration) {
              pos = Math.max(0, pos);
              // sort on buffer.start/smaller end (IE does not always return sorted buffered range)
              buffered.sort(function (a, b) {
                const diff = a.start - b.start;
                if (diff) {
                  return diff;
                } else {
                  return b.end - a.end;
                }
              });
              let buffered2 = [];
              if (maxHoleDuration) {
                // there might be some small holes between buffer time range
                // consider that holes smaller than maxHoleDuration are irrelevant and build another
                // buffer time range representations that discards those holes
                for (let i = 0; i < buffered.length; i++) {
                  const buf2len = buffered2.length;
                  if (buf2len) {
                    const buf2end = buffered2[buf2len - 1].end;
                    // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)
                    if (buffered[i].start - buf2end < maxHoleDuration) {
                      // merge overlapping time ranges
                      // update lastRange.end only if smaller than item.end
                      // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)
                      // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])
                      if (buffered[i].end > buf2end) {
                        buffered2[buf2len - 1].end = buffered[i].end;
                      }
                    } else {
                      // big hole
                      buffered2.push(buffered[i]);
                    }
                  } else {
                    // first value
                    buffered2.push(buffered[i]);
                  }
                }
              } else {
                buffered2 = buffered;
              }
              let bufferLen = 0;

              // bufferStartNext can possibly be undefined based on the conditional logic below
              let bufferStartNext;

              // bufferStart and bufferEnd are buffer boundaries around current video position
              let bufferStart = pos;
              let bufferEnd = pos;
              for (let i = 0; i < buffered2.length; i++) {
                const start = buffered2[i].start;
                const end = buffered2[i].end;
                // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));
                if (pos + maxHoleDuration >= start && pos < end) {
                  // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length
                  bufferStart = start;
                  bufferEnd = end;
                  bufferLen = bufferEnd - pos;
                } else if (pos + maxHoleDuration < start) {
                  bufferStartNext = start;
                  break;
                }
              }
              return {
                len: bufferLen,
                start: bufferStart || 0,
                end: bufferEnd || 0,
                nextStart: bufferStartNext
              };
            }

            /**
             * Safe method to get buffered property.
             * SourceBuffer.buffered may throw if SourceBuffer is removed from it's MediaSource
             */
            static getBuffered(media) {
              try {
                return media.buffered;
              } catch (e) {
                _logger__WEBPACK_IMPORTED_MODULE_0__.logger.log('failed to get media.buffered', e);
                return noopBuffered;
              }
            }
          }

          /***/
        }),

/***/ "./src/utils/cea-608-parser.ts":
/*!*************************************!*\
  !*** ./src/utils/cea-608-parser.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "CaptionScreen": () => (/* binding */ CaptionScreen),
/* harmony export */   "Row": () => (/* binding */ Row),
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");


          /**
           *
           * This code was ported from the dash.js project at:
           *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js
           *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2
           *
           * The original copyright appears below:
           *
           * The copyright in this software is being made available under the BSD License,
           * included below. This software may be subject to other third party and contributor
           * rights, including patent rights, and no such rights are granted under this license.
           *
           * Copyright (c) 2015-2016, DASH Industry Forum.
           * All rights reserved.
           *
           * Redistribution and use in source and binary forms, with or without modification,
           * are permitted provided that the following conditions are met:
           *  1. Redistributions of source code must retain the above copyright notice, this
           *  list of conditions and the following disclaimer.
           *  * Redistributions in binary form must reproduce the above copyright notice,
           *  this list of conditions and the following disclaimer in the documentation and/or
           *  other materials provided with the distribution.
           *  2. Neither the name of Dash Industry Forum nor the names of its
           *  contributors may be used to endorse or promote products derived from this software
           *  without specific prior written permission.
           *
           *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY
           *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
           *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
           *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
           *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
           *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
           *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
           *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
           *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
           *  POSSIBILITY OF SUCH DAMAGE.
           */
          /**
           *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes
           */

          const specialCea608CharsCodes = {
            0x2a: 0xe1,
            // lowercase a, acute accent
            0x5c: 0xe9,
            // lowercase e, acute accent
            0x5e: 0xed,
            // lowercase i, acute accent
            0x5f: 0xf3,
            // lowercase o, acute accent
            0x60: 0xfa,
            // lowercase u, acute accent
            0x7b: 0xe7,
            // lowercase c with cedilla
            0x7c: 0xf7,
            // division symbol
            0x7d: 0xd1,
            // uppercase N tilde
            0x7e: 0xf1,
            // lowercase n tilde
            0x7f: 0x2588,
            // Full block
            // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
            // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F
            // THIS MEANS THAT \x50 MUST BE ADDED TO THE VALUES
            0x80: 0xae,
            // Registered symbol (R)
            0x81: 0xb0,
            // degree sign
            0x82: 0xbd,
            // 1/2 symbol
            0x83: 0xbf,
            // Inverted (open) question mark
            0x84: 0x2122,
            // Trademark symbol (TM)
            0x85: 0xa2,
            // Cents symbol
            0x86: 0xa3,
            // Pounds sterling
            0x87: 0x266a,
            // Music 8'th note
            0x88: 0xe0,
            // lowercase a, grave accent
            0x89: 0x20,
            // transparent space (regular)
            0x8a: 0xe8,
            // lowercase e, grave accent
            0x8b: 0xe2,
            // lowercase a, circumflex accent
            0x8c: 0xea,
            // lowercase e, circumflex accent
            0x8d: 0xee,
            // lowercase i, circumflex accent
            0x8e: 0xf4,
            // lowercase o, circumflex accent
            0x8f: 0xfb,
            // lowercase u, circumflex accent
            // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
            // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F
            0x90: 0xc1,
            // capital letter A with acute
            0x91: 0xc9,
            // capital letter E with acute
            0x92: 0xd3,
            // capital letter O with acute
            0x93: 0xda,
            // capital letter U with acute
            0x94: 0xdc,
            // capital letter U with diaresis
            0x95: 0xfc,
            // lowercase letter U with diaeresis
            0x96: 0x2018,
            // opening single quote
            0x97: 0xa1,
            // inverted exclamation mark
            0x98: 0x2a,
            // asterisk
            0x99: 0x2019,
            // closing single quote
            0x9a: 0x2501,
            // box drawings heavy horizontal
            0x9b: 0xa9,
            // copyright sign
            0x9c: 0x2120,
            // Service mark
            0x9d: 0x2022,
            // (round) bullet
            0x9e: 0x201c,
            // Left double quotation mark
            0x9f: 0x201d,
            // Right double quotation mark
            0xa0: 0xc0,
            // uppercase A, grave accent
            0xa1: 0xc2,
            // uppercase A, circumflex
            0xa2: 0xc7,
            // uppercase C with cedilla
            0xa3: 0xc8,
            // uppercase E, grave accent
            0xa4: 0xca,
            // uppercase E, circumflex
            0xa5: 0xcb,
            // capital letter E with diaresis
            0xa6: 0xeb,
            // lowercase letter e with diaresis
            0xa7: 0xce,
            // uppercase I, circumflex
            0xa8: 0xcf,
            // uppercase I, with diaresis
            0xa9: 0xef,
            // lowercase i, with diaresis
            0xaa: 0xd4,
            // uppercase O, circumflex
            0xab: 0xd9,
            // uppercase U, grave accent
            0xac: 0xf9,
            // lowercase u, grave accent
            0xad: 0xdb,
            // uppercase U, circumflex
            0xae: 0xab,
            // left-pointing double angle quotation mark
            0xaf: 0xbb,
            // right-pointing double angle quotation mark
            // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS
            // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F
            0xb0: 0xc3,
            // Uppercase A, tilde
            0xb1: 0xe3,
            // Lowercase a, tilde
            0xb2: 0xcd,
            // Uppercase I, acute accent
            0xb3: 0xcc,
            // Uppercase I, grave accent
            0xb4: 0xec,
            // Lowercase i, grave accent
            0xb5: 0xd2,
            // Uppercase O, grave accent
            0xb6: 0xf2,
            // Lowercase o, grave accent
            0xb7: 0xd5,
            // Uppercase O, tilde
            0xb8: 0xf5,
            // Lowercase o, tilde
            0xb9: 0x7b,
            // Open curly brace
            0xba: 0x7d,
            // Closing curly brace
            0xbb: 0x5c,
            // Backslash
            0xbc: 0x5e,
            // Caret
            0xbd: 0x5f,
            // Underscore
            0xbe: 0x7c,
            // Pipe (vertical line)
            0xbf: 0x223c,
            // Tilde operator
            0xc0: 0xc4,
            // Uppercase A, umlaut
            0xc1: 0xe4,
            // Lowercase A, umlaut
            0xc2: 0xd6,
            // Uppercase O, umlaut
            0xc3: 0xf6,
            // Lowercase o, umlaut
            0xc4: 0xdf,
            // Esszett (sharp S)
            0xc5: 0xa5,
            // Yen symbol
            0xc6: 0xa4,
            // Generic currency sign
            0xc7: 0x2503,
            // Box drawings heavy vertical
            0xc8: 0xc5,
            // Uppercase A, ring
            0xc9: 0xe5,
            // Lowercase A, ring
            0xca: 0xd8,
            // Uppercase O, stroke
            0xcb: 0xf8,
            // Lowercase o, strok
            0xcc: 0x250f,
            // Box drawings heavy down and right
            0xcd: 0x2513,
            // Box drawings heavy down and left
            0xce: 0x2517,
            // Box drawings heavy up and right
            0xcf: 0x251b // Box drawings heavy up and left
          };

          /**
           * Utils
           */
          const getCharForByte = function (byte) {
            let charCode = byte;
            if (specialCea608CharsCodes.hasOwnProperty(byte)) {
              charCode = specialCea608CharsCodes[byte];
            }
            return String.fromCharCode(charCode);
          };
          const NR_ROWS = 15;
          const NR_COLS = 100;
          // Tables to look up row from PAC data
          const rowsLowCh1 = {
            0x11: 1,
            0x12: 3,
            0x15: 5,
            0x16: 7,
            0x17: 9,
            0x10: 11,
            0x13: 12,
            0x14: 14
          };
          const rowsHighCh1 = {
            0x11: 2,
            0x12: 4,
            0x15: 6,
            0x16: 8,
            0x17: 10,
            0x13: 13,
            0x14: 15
          };
          const rowsLowCh2 = {
            0x19: 1,
            0x1a: 3,
            0x1d: 5,
            0x1e: 7,
            0x1f: 9,
            0x18: 11,
            0x1b: 12,
            0x1c: 14
          };
          const rowsHighCh2 = {
            0x19: 2,
            0x1a: 4,
            0x1d: 6,
            0x1e: 8,
            0x1f: 10,
            0x1b: 13,
            0x1c: 15
          };
          const backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];
          var VerboseLevel;
          (function (VerboseLevel) {
            VerboseLevel[VerboseLevel["ERROR"] = 0] = "ERROR";
            VerboseLevel[VerboseLevel["TEXT"] = 1] = "TEXT";
            VerboseLevel[VerboseLevel["WARNING"] = 2] = "WARNING";
            VerboseLevel[VerboseLevel["INFO"] = 2] = "INFO";
            VerboseLevel[VerboseLevel["DEBUG"] = 3] = "DEBUG";
            VerboseLevel[VerboseLevel["DATA"] = 3] = "DATA";
          })(VerboseLevel || (VerboseLevel = {}));
          class CaptionsLogger {
            time = null;
            verboseLevel = VerboseLevel.ERROR;
            log(severity, msg) {
              if (this.verboseLevel >= severity) {
                const m = typeof msg === 'function' ? msg() : msg;
                _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.log(`${this.time} [${severity}] ${m}`);
              }
            }
          }
          const numArrayToHexArray = function (numArray) {
            const hexArray = [];
            for (let j = 0; j < numArray.length; j++) {
              hexArray.push(numArray[j].toString(16));
            }
            return hexArray;
          };
          class PenState {
            constructor(foreground, underline, italics, background, flash) {
              this.foreground = foreground || 'white';
              this.underline = underline || false;
              this.italics = italics || false;
              this.background = background || 'black';
              this.flash = flash || false;
            }
            reset() {
              this.foreground = 'white';
              this.underline = false;
              this.italics = false;
              this.background = 'black';
              this.flash = false;
            }
            setStyles(styles) {
              const attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];
              for (let i = 0; i < attribs.length; i++) {
                const style = attribs[i];
                if (styles.hasOwnProperty(style)) {
                  this[style] = styles[style];
                }
              }
            }
            isDefault() {
              return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;
            }
            equals(other) {
              return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;
            }
            copy(newPenState) {
              this.foreground = newPenState.foreground;
              this.underline = newPenState.underline;
              this.italics = newPenState.italics;
              this.background = newPenState.background;
              this.flash = newPenState.flash;
            }
            toString() {
              return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;
            }
          }

          /**
           * Unicode character with styling and background.
           * @constructor
           */
          class StyledUnicodeChar {
            constructor(uchar, foreground, underline, italics, background, flash) {
              this.uchar = uchar || ' '; // unicode character
              this.penState = new PenState(foreground, underline, italics, background, flash);
            }
            reset() {
              this.uchar = ' ';
              this.penState.reset();
            }
            setChar(uchar, newPenState) {
              this.uchar = uchar;
              this.penState.copy(newPenState);
            }
            setPenState(newPenState) {
              this.penState.copy(newPenState);
            }
            equals(other) {
              return this.uchar === other.uchar && this.penState.equals(other.penState);
            }
            copy(newChar) {
              this.uchar = newChar.uchar;
              this.penState.copy(newChar.penState);
            }
            isEmpty() {
              return this.uchar === ' ' && this.penState.isDefault();
            }
          }

          /**
           * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.
           * @constructor
           */
          class Row {
            constructor(logger) {
              this.chars = [];
              for (let i = 0; i < NR_COLS; i++) {
                this.chars.push(new StyledUnicodeChar());
              }
              this.logger = logger;
              this.pos = 0;
              this.currPenState = new PenState();
            }
            equals(other) {
              let equal = true;
              for (let i = 0; i < NR_COLS; i++) {
                if (!this.chars[i].equals(other.chars[i])) {
                  equal = false;
                  break;
                }
              }
              return equal;
            }
            copy(other) {
              for (let i = 0; i < NR_COLS; i++) {
                this.chars[i].copy(other.chars[i]);
              }
            }
            isEmpty() {
              let empty = true;
              for (let i = 0; i < NR_COLS; i++) {
                if (!this.chars[i].isEmpty()) {
                  empty = false;
                  break;
                }
              }
              return empty;
            }

            /**
             *  Set the cursor to a valid column.
             */
            setCursor(absPos) {
              if (this.pos !== absPos) {
                this.pos = absPos;
              }
              if (this.pos < 0) {
                this.logger.log(VerboseLevel.DEBUG, 'Negative cursor position ' + this.pos);
                this.pos = 0;
              } else if (this.pos > NR_COLS) {
                this.logger.log(VerboseLevel.DEBUG, 'Too large cursor position ' + this.pos);
                this.pos = NR_COLS;
              }
            }

            /**
             * Move the cursor relative to current position.
             */
            moveCursor(relPos) {
              const newPos = this.pos + relPos;
              if (relPos > 1) {
                for (let i = this.pos + 1; i < newPos + 1; i++) {
                  this.chars[i].setPenState(this.currPenState);
                }
              }
              this.setCursor(newPos);
            }

            /**
             * Backspace, move one step back and clear character.
             */
            backSpace() {
              this.moveCursor(-1);
              this.chars[this.pos].setChar(' ', this.currPenState);
            }
            insertChar(byte) {
              if (byte >= 0x90) {
                // Extended char
                this.backSpace();
              }
              const char = getCharForByte(byte);
              if (this.pos >= NR_COLS) {
                this.logger.log(VerboseLevel.ERROR, () => 'Cannot insert ' + byte.toString(16) + ' (' + char + ') at position ' + this.pos + '. Skipping it!');
                return;
              }
              this.chars[this.pos].setChar(char, this.currPenState);
              this.moveCursor(1);
            }
            clearFromPos(startPos) {
              let i;
              for (i = startPos; i < NR_COLS; i++) {
                this.chars[i].reset();
              }
            }
            clear() {
              this.clearFromPos(0);
              this.pos = 0;
              this.currPenState.reset();
            }
            clearToEndOfRow() {
              this.clearFromPos(this.pos);
            }
            getTextString() {
              const chars = [];
              let empty = true;
              for (let i = 0; i < NR_COLS; i++) {
                const char = this.chars[i].uchar;
                if (char !== ' ') {
                  empty = false;
                }
                chars.push(char);
              }
              if (empty) {
                return '';
              } else {
                return chars.join('');
              }
            }
            setPenStyles(styles) {
              this.currPenState.setStyles(styles);
              const currChar = this.chars[this.pos];
              currChar.setPenState(this.currPenState);
            }
          }

          /**
           * Keep a CEA-608 screen of 32x15 styled characters
           * @constructor
           */
          class CaptionScreen {
            constructor(logger) {
              this.rows = [];
              for (let i = 0; i < NR_ROWS; i++) {
                this.rows.push(new Row(logger));
              } // Note that we use zero-based numbering (0-14)

              this.logger = logger;
              this.currRow = NR_ROWS - 1;
              this.nrRollUpRows = null;
              this.lastOutputScreen = null;
              this.reset();
            }
            reset() {
              for (let i = 0; i < NR_ROWS; i++) {
                this.rows[i].clear();
              }
              this.currRow = NR_ROWS - 1;
            }
            equals(other) {
              let equal = true;
              for (let i = 0; i < NR_ROWS; i++) {
                if (!this.rows[i].equals(other.rows[i])) {
                  equal = false;
                  break;
                }
              }
              return equal;
            }
            copy(other) {
              for (let i = 0; i < NR_ROWS; i++) {
                this.rows[i].copy(other.rows[i]);
              }
            }
            isEmpty() {
              let empty = true;
              for (let i = 0; i < NR_ROWS; i++) {
                if (!this.rows[i].isEmpty()) {
                  empty = false;
                  break;
                }
              }
              return empty;
            }
            backSpace() {
              const row = this.rows[this.currRow];
              row.backSpace();
            }
            clearToEndOfRow() {
              const row = this.rows[this.currRow];
              row.clearToEndOfRow();
            }

            /**
             * Insert a character (without styling) in the current row.
             */
            insertChar(char) {
              const row = this.rows[this.currRow];
              row.insertChar(char);
            }
            setPen(styles) {
              const row = this.rows[this.currRow];
              row.setPenStyles(styles);
            }
            moveCursor(relPos) {
              const row = this.rows[this.currRow];
              row.moveCursor(relPos);
            }
            setCursor(absPos) {
              this.logger.log(VerboseLevel.INFO, 'setCursor: ' + absPos);
              const row = this.rows[this.currRow];
              row.setCursor(absPos);
            }
            setPAC(pacData) {
              this.logger.log(VerboseLevel.INFO, () => 'pacData = ' + JSON.stringify(pacData));
              let newRow = pacData.row - 1;
              if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {
                newRow = this.nrRollUpRows - 1;
              }

              // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows
              if (this.nrRollUpRows && this.currRow !== newRow) {
                // clear all rows first
                for (let i = 0; i < NR_ROWS; i++) {
                  this.rows[i].clear();
                }

                // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location
                // topRowIndex - the start of rows to copy (inclusive index)
                const topRowIndex = this.currRow + 1 - this.nrRollUpRows;
                // We only copy if the last position was already shown.
                // We use the cueStartTime value to check this.
                const lastOutputScreen = this.lastOutputScreen;
                if (lastOutputScreen) {
                  const prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;
                  const time = this.logger.time;
                  if (prevLineTime && time !== null && prevLineTime < time) {
                    for (let i = 0; i < this.nrRollUpRows; i++) {
                      this.rows[newRow - this.nrRollUpRows + i + 1].copy(lastOutputScreen.rows[topRowIndex + i]);
                    }
                  }
                }
              }
              this.currRow = newRow;
              const row = this.rows[this.currRow];
              if (pacData.indent !== null) {
                const indent = pacData.indent;
                const prevPos = Math.max(indent - 1, 0);
                row.setCursor(pacData.indent);
                pacData.color = row.chars[prevPos].penState.foreground;
              }
              const styles = {
                foreground: pacData.color,
                underline: pacData.underline,
                italics: pacData.italics,
                background: 'black',
                flash: false
              };
              this.setPen(styles);
            }

            /**
             * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).
             */
            setBkgData(bkgData) {
              this.logger.log(VerboseLevel.INFO, () => 'bkgData = ' + JSON.stringify(bkgData));
              this.backSpace();
              this.setPen(bkgData);
              this.insertChar(0x20); // Space
            }

            setRollUpRows(nrRows) {
              this.nrRollUpRows = nrRows;
            }
            rollUp() {
              if (this.nrRollUpRows === null) {
                this.logger.log(VerboseLevel.DEBUG, 'roll_up but nrRollUpRows not set yet');
                return; // Not properly setup
              }

              this.logger.log(VerboseLevel.TEXT, () => this.getDisplayText());
              const topRowIndex = this.currRow + 1 - this.nrRollUpRows;
              const topRow = this.rows.splice(topRowIndex, 1)[0];
              topRow.clear();
              this.rows.splice(this.currRow, 0, topRow);
              this.logger.log(VerboseLevel.INFO, 'Rolling up');
              // this.logger.log(VerboseLevel.TEXT, this.get_display_text())
            }

            /**
             * Get all non-empty rows with as unicode text.
             */
            getDisplayText(asOneRow) {
              asOneRow = asOneRow || false;
              const displayText = [];
              let text = '';
              let rowNr = -1;
              for (let i = 0; i < NR_ROWS; i++) {
                const rowText = this.rows[i].getTextString();
                if (rowText) {
                  rowNr = i + 1;
                  if (asOneRow) {
                    displayText.push('Row ' + rowNr + ": '" + rowText + "'");
                  } else {
                    displayText.push(rowText.trim());
                  }
                }
              }
              if (displayText.length > 0) {
                if (asOneRow) {
                  text = '[' + displayText.join(' | ') + ']';
                } else {
                  text = displayText.join('\n');
                }
              }
              return text;
            }
            getTextAndFormat() {
              return this.rows;
            }
          }

          // var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];

          class Cea608Channel {
            constructor(channelNumber, outputFilter, logger) {
              this.chNr = channelNumber;
              this.outputFilter = outputFilter;
              this.mode = null;
              this.verbose = 0;
              this.displayedMemory = new CaptionScreen(logger);
              this.nonDisplayedMemory = new CaptionScreen(logger);
              this.lastOutputScreen = new CaptionScreen(logger);
              this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];
              this.writeScreen = this.displayedMemory;
              this.mode = null;
              this.cueStartTime = null; // Keeps track of where a cue started.
              this.logger = logger;
            }
            reset() {
              this.mode = null;
              this.displayedMemory.reset();
              this.nonDisplayedMemory.reset();
              this.lastOutputScreen.reset();
              this.outputFilter.reset();
              this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];
              this.writeScreen = this.displayedMemory;
              this.mode = null;
              this.cueStartTime = null;
            }
            getHandler() {
              return this.outputFilter;
            }
            setHandler(newHandler) {
              this.outputFilter = newHandler;
            }
            setPAC(pacData) {
              this.writeScreen.setPAC(pacData);
            }
            setBkgData(bkgData) {
              this.writeScreen.setBkgData(bkgData);
            }
            setMode(newMode) {
              if (newMode === this.mode) {
                return;
              }
              this.mode = newMode;
              this.logger.log(VerboseLevel.INFO, () => 'MODE=' + newMode);
              if (this.mode === 'MODE_POP-ON') {
                this.writeScreen = this.nonDisplayedMemory;
              } else {
                this.writeScreen = this.displayedMemory;
                this.writeScreen.reset();
              }
              if (this.mode !== 'MODE_ROLL-UP') {
                this.displayedMemory.nrRollUpRows = null;
                this.nonDisplayedMemory.nrRollUpRows = null;
              }
              this.mode = newMode;
            }
            insertChars(chars) {
              for (let i = 0; i < chars.length; i++) {
                this.writeScreen.insertChar(chars[i]);
              }
              const screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';
              this.logger.log(VerboseLevel.INFO, () => screen + ': ' + this.writeScreen.getDisplayText(true));
              if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {
                this.logger.log(VerboseLevel.TEXT, () => 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));
                this.outputDataUpdate();
              }
            }
            ccRCL() {
              // Resume Caption Loading (switch mode to Pop On)
              this.logger.log(VerboseLevel.INFO, 'RCL - Resume Caption Loading');
              this.setMode('MODE_POP-ON');
            }
            ccBS() {
              // BackSpace
              this.logger.log(VerboseLevel.INFO, 'BS - BackSpace');
              if (this.mode === 'MODE_TEXT') {
                return;
              }
              this.writeScreen.backSpace();
              if (this.writeScreen === this.displayedMemory) {
                this.outputDataUpdate();
              }
            }
            ccAOF() {
              // Reserved (formerly Alarm Off)
            }
            ccAON() {
              // Reserved (formerly Alarm On)
            }
            ccDER() {
              // Delete to End of Row
              this.logger.log(VerboseLevel.INFO, 'DER- Delete to End of Row');
              this.writeScreen.clearToEndOfRow();
              this.outputDataUpdate();
            }
            ccRU(nrRows) {
              // Roll-Up Captions-2,3,or 4 Rows
              this.logger.log(VerboseLevel.INFO, 'RU(' + nrRows + ') - Roll Up');
              this.writeScreen = this.displayedMemory;
              this.setMode('MODE_ROLL-UP');
              this.writeScreen.setRollUpRows(nrRows);
            }
            ccFON() {
              // Flash On
              this.logger.log(VerboseLevel.INFO, 'FON - Flash On');
              this.writeScreen.setPen({
                flash: true
              });
            }
            ccRDC() {
              // Resume Direct Captioning (switch mode to PaintOn)
              this.logger.log(VerboseLevel.INFO, 'RDC - Resume Direct Captioning');
              this.setMode('MODE_PAINT-ON');
            }
            ccTR() {
              // Text Restart in text mode (not supported, however)
              this.logger.log(VerboseLevel.INFO, 'TR');
              this.setMode('MODE_TEXT');
            }
            ccRTD() {
              // Resume Text Display in Text mode (not supported, however)
              this.logger.log(VerboseLevel.INFO, 'RTD');
              this.setMode('MODE_TEXT');
            }
            ccEDM() {
              // Erase Displayed Memory
              this.logger.log(VerboseLevel.INFO, 'EDM - Erase Displayed Memory');
              this.displayedMemory.reset();
              this.outputDataUpdate(true);
            }
            ccCR() {
              // Carriage Return
              this.logger.log(VerboseLevel.INFO, 'CR - Carriage Return');
              this.writeScreen.rollUp();
              this.outputDataUpdate(true);
            }
            ccENM() {
              // Erase Non-Displayed Memory
              this.logger.log(VerboseLevel.INFO, 'ENM - Erase Non-displayed Memory');
              this.nonDisplayedMemory.reset();
            }
            ccEOC() {
              // End of Caption (Flip Memories)
              this.logger.log(VerboseLevel.INFO, 'EOC - End Of Caption');
              if (this.mode === 'MODE_POP-ON') {
                const tmp = this.displayedMemory;
                this.displayedMemory = this.nonDisplayedMemory;
                this.nonDisplayedMemory = tmp;
                this.writeScreen = this.nonDisplayedMemory;
                this.logger.log(VerboseLevel.TEXT, () => 'DISP: ' + this.displayedMemory.getDisplayText());
              }
              this.outputDataUpdate(true);
            }
            ccTO(nrCols) {
              // Tab Offset 1,2, or 3 columns
              this.logger.log(VerboseLevel.INFO, 'TO(' + nrCols + ') - Tab Offset');
              this.writeScreen.moveCursor(nrCols);
            }
            ccMIDROW(secondByte) {
              // Parse MIDROW command
              const styles = {
                flash: false
              };
              styles.underline = secondByte % 2 === 1;
              styles.italics = secondByte >= 0x2e;
              if (!styles.italics) {
                const colorIndex = Math.floor(secondByte / 2) - 0x10;
                const colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];
                styles.foreground = colors[colorIndex];
              } else {
                styles.foreground = 'white';
              }
              this.logger.log(VerboseLevel.INFO, 'MIDROW: ' + JSON.stringify(styles));
              this.writeScreen.setPen(styles);
            }
            outputDataUpdate(dispatch = false) {
              const time = this.logger.time;
              if (time === null) {
                return;
              }
              if (this.outputFilter) {
                if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {
                  // Start of a new cue
                  this.cueStartTime = time;
                } else {
                  if (!this.displayedMemory.equals(this.lastOutputScreen)) {
                    this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);
                    if (dispatch && this.outputFilter.dispatchCue) {
                      this.outputFilter.dispatchCue();
                    }
                    this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;
                  }
                }
                this.lastOutputScreen.copy(this.displayedMemory);
              }
            }
            cueSplitAtTime(t) {
              if (this.outputFilter) {
                if (!this.displayedMemory.isEmpty()) {
                  if (this.outputFilter.newCue) {
                    this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);
                  }
                  this.cueStartTime = t;
                }
              }
            }
          }
          class Cea608Parser {
            currentChannel = 0;
            constructor(field, out1, out2) {
              const logger = new CaptionsLogger();
              this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];
              this.cmdHistory = createCmdHistory();
              this.logger = logger;
            }
            getHandler(channel) {
              return this.channels[channel].getHandler();
            }
            setHandler(channel, newHandler) {
              this.channels[channel].setHandler(newHandler);
            }

            /**
             * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.
             */
            addData(time, byteList) {
              let cmdFound;
              let a;
              let b;
              let charsFound = false;
              this.logger.time = time;
              for (let i = 0; i < byteList.length; i += 2) {
                a = byteList[i] & 0x7f;
                b = byteList[i + 1] & 0x7f;
                if (a === 0 && b === 0) {
                  continue;
                } else {
                  this.logger.log(VerboseLevel.DATA, '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');
                }
                cmdFound = this.parseCmd(a, b);
                if (!cmdFound) {
                  cmdFound = this.parseMidrow(a, b);
                }
                if (!cmdFound) {
                  cmdFound = this.parsePAC(a, b);
                }
                if (!cmdFound) {
                  cmdFound = this.parseBackgroundAttributes(a, b);
                }
                if (!cmdFound) {
                  charsFound = this.parseChars(a, b);
                  if (charsFound) {
                    const currChNr = this.currentChannel;
                    if (currChNr && currChNr > 0) {
                      const channel = this.channels[currChNr];
                      channel.insertChars(charsFound);
                    } else {
                      this.logger.log(VerboseLevel.WARNING, 'No channel found yet. TEXT-MODE?');
                    }
                  }
                }
                if (!cmdFound && !charsFound) {
                  this.logger.log(VerboseLevel.WARNING, "Couldn't parse cleaned data " + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));
                }
              }
            }

            /**
             * Parse Command.
             * @returns {Boolean} Tells if a command was found
             */
            parseCmd(a, b) {
              const {
                cmdHistory
              } = this;
              const cond1 = (a === 0x14 || a === 0x1c || a === 0x15 || a === 0x1d) && b >= 0x20 && b <= 0x2f;
              const cond2 = (a === 0x17 || a === 0x1f) && b >= 0x21 && b <= 0x23;
              if (!(cond1 || cond2)) {
                return false;
              }
              if (hasCmdRepeated(a, b, cmdHistory)) {
                setLastCmd(null, null, cmdHistory);
                this.logger.log(VerboseLevel.DEBUG, 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');
                return true;
              }
              const chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;
              const channel = this.channels[chNr];
              if (a === 0x14 || a === 0x15 || a === 0x1c || a === 0x1d) {
                if (b === 0x20) {
                  channel.ccRCL();
                } else if (b === 0x21) {
                  channel.ccBS();
                } else if (b === 0x22) {
                  channel.ccAOF();
                } else if (b === 0x23) {
                  channel.ccAON();
                } else if (b === 0x24) {
                  channel.ccDER();
                } else if (b === 0x25) {
                  channel.ccRU(2);
                } else if (b === 0x26) {
                  channel.ccRU(3);
                } else if (b === 0x27) {
                  channel.ccRU(4);
                } else if (b === 0x28) {
                  channel.ccFON();
                } else if (b === 0x29) {
                  channel.ccRDC();
                } else if (b === 0x2a) {
                  channel.ccTR();
                } else if (b === 0x2b) {
                  channel.ccRTD();
                } else if (b === 0x2c) {
                  channel.ccEDM();
                } else if (b === 0x2d) {
                  channel.ccCR();
                } else if (b === 0x2e) {
                  channel.ccENM();
                } else if (b === 0x2f) {
                  channel.ccEOC();
                }
              } else {
                // a == 0x17 || a == 0x1F
                channel.ccTO(b - 0x20);
              }
              setLastCmd(a, b, cmdHistory);
              this.currentChannel = chNr;
              return true;
            }

            /**
             * Parse midrow styling command
             * @returns {Boolean}
             */
            parseMidrow(a, b) {
              let chNr = 0;
              if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {
                if (a === 0x11) {
                  chNr = 1;
                } else {
                  chNr = 2;
                }
                if (chNr !== this.currentChannel) {
                  this.logger.log(VerboseLevel.ERROR, 'Mismatch channel in midrow parsing');
                  return false;
                }
                const channel = this.channels[chNr];
                if (!channel) {
                  return false;
                }
                channel.ccMIDROW(b);
                this.logger.log(VerboseLevel.DEBUG, 'MIDROW (' + numArrayToHexArray([a, b]) + ')');
                return true;
              }
              return false;
            }

            /**
             * Parse Preable Access Codes (Table 53).
             * @returns {Boolean} Tells if PAC found
             */
            parsePAC(a, b) {
              let row;
              const cmdHistory = this.cmdHistory;
              const case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1f) && b >= 0x40 && b <= 0x7f;
              const case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5f;
              if (!(case1 || case2)) {
                return false;
              }
              if (hasCmdRepeated(a, b, cmdHistory)) {
                setLastCmd(null, null, cmdHistory);
                return true; // Repeated commands are dropped (once)
              }

              const chNr = a <= 0x17 ? 1 : 2;
              if (b >= 0x40 && b <= 0x5f) {
                row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];
              } else {
                // 0x60 <= b <= 0x7F
                row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];
              }
              const channel = this.channels[chNr];
              if (!channel) {
                return false;
              }
              channel.setPAC(this.interpretPAC(row, b));
              setLastCmd(a, b, cmdHistory);
              this.currentChannel = chNr;
              return true;
            }

            /**
             * Interpret the second byte of the pac, and return the information.
             * @returns {Object} pacData with style parameters.
             */
            interpretPAC(row, byte) {
              let pacIndex;
              const pacData = {
                color: null,
                italics: false,
                indent: null,
                underline: false,
                row: row
              };
              if (byte > 0x5f) {
                pacIndex = byte - 0x60;
              } else {
                pacIndex = byte - 0x40;
              }
              pacData.underline = (pacIndex & 1) === 1;
              if (pacIndex <= 0xd) {
                pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];
              } else if (pacIndex <= 0xf) {
                pacData.italics = true;
                pacData.color = 'white';
              } else {
                pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;
              }
              return pacData; // Note that row has zero offset. The spec uses 1.
            }

            /**
             * Parse characters.
             * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.
             */
            parseChars(a, b) {
              let channelNr;
              let charCodes = null;
              let charCode1 = null;
              if (a >= 0x19) {
                channelNr = 2;
                charCode1 = a - 8;
              } else {
                channelNr = 1;
                charCode1 = a;
              }
              if (charCode1 >= 0x11 && charCode1 <= 0x13) {
                // Special character
                let oneCode;
                if (charCode1 === 0x11) {
                  oneCode = b + 0x50;
                } else if (charCode1 === 0x12) {
                  oneCode = b + 0x70;
                } else {
                  oneCode = b + 0x90;
                }
                this.logger.log(VerboseLevel.INFO, "Special char '" + getCharForByte(oneCode) + "' in channel " + channelNr);
                charCodes = [oneCode];
              } else if (a >= 0x20 && a <= 0x7f) {
                charCodes = b === 0 ? [a] : [a, b];
              }
              if (charCodes) {
                const hexCodes = numArrayToHexArray(charCodes);
                this.logger.log(VerboseLevel.DEBUG, 'Char codes =  ' + hexCodes.join(','));
                setLastCmd(a, b, this.cmdHistory);
              }
              return charCodes;
            }

            /**
             * Parse extended background attributes as well as new foreground color black.
             * @returns {Boolean} Tells if background attributes are found
             */
            parseBackgroundAttributes(a, b) {
              const case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;
              const case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;
              if (!(case1 || case2)) {
                return false;
              }
              let index;
              const bkgData = {};
              if (a === 0x10 || a === 0x18) {
                index = Math.floor((b - 0x20) / 2);
                bkgData.background = backgroundColors[index];
                if (b % 2 === 1) {
                  bkgData.background = bkgData.background + '_semi';
                }
              } else if (b === 0x2d) {
                bkgData.background = 'transparent';
              } else {
                bkgData.foreground = 'black';
                if (b === 0x2f) {
                  bkgData.underline = true;
                }
              }
              const chNr = a <= 0x17 ? 1 : 2;
              const channel = this.channels[chNr];
              channel.setBkgData(bkgData);
              setLastCmd(a, b, this.cmdHistory);
              return true;
            }

            /**
             * Reset state of parser and its channels.
             */
            reset() {
              for (let i = 0; i < Object.keys(this.channels).length; i++) {
                const channel = this.channels[i];
                if (channel) {
                  channel.reset();
                }
              }
              this.cmdHistory = createCmdHistory();
            }

            /**
             * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.
             */
            cueSplitAtTime(t) {
              for (let i = 0; i < this.channels.length; i++) {
                const channel = this.channels[i];
                if (channel) {
                  channel.cueSplitAtTime(t);
                }
              }
            }
          }
          function setLastCmd(a, b, cmdHistory) {
            cmdHistory.a = a;
            cmdHistory.b = b;
          }
          function hasCmdRepeated(a, b, cmdHistory) {
            return cmdHistory.a === a && cmdHistory.b === b;
          }
          function createCmdHistory() {
            return {
              a: null,
              b: null
            };
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Cea608Parser);

          /***/
        }),

/***/ "./src/utils/codecs.ts":
/*!*****************************!*\
  !*** ./src/utils/codecs.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "isCodecSupportedInMp4": () => (/* binding */ isCodecSupportedInMp4),
/* harmony export */   "isCodecType": () => (/* binding */ isCodecType)
            /* harmony export */
          });
          // from http://mp4ra.org/codecs.html
          const sampleEntryCodesISO = {
            audio: {
              a3ds: true,
              'ac-3': true,
              'ac-4': true,
              alac: true,
              alaw: true,
              dra1: true,
              'dts+': true,
              'dts-': true,
              dtsc: true,
              dtse: true,
              dtsh: true,
              'ec-3': true,
              enca: true,
              g719: true,
              g726: true,
              m4ae: true,
              mha1: true,
              mha2: true,
              mhm1: true,
              mhm2: true,
              mlpa: true,
              mp4a: true,
              'raw ': true,
              Opus: true,
              opus: true,
              // browsers expect this to be lowercase despite MP4RA says 'Opus'
              samr: true,
              sawb: true,
              sawp: true,
              sevc: true,
              sqcp: true,
              ssmv: true,
              twos: true,
              ulaw: true
            },
            video: {
              avc1: true,
              avc2: true,
              avc3: true,
              avc4: true,
              avcp: true,
              av01: true,
              drac: true,
              dva1: true,
              dvav: true,
              dvh1: true,
              dvhe: true,
              encv: true,
              hev1: true,
              hvc1: true,
              mjp2: true,
              mp4v: true,
              mvc1: true,
              mvc2: true,
              mvc3: true,
              mvc4: true,
              resv: true,
              rv60: true,
              s263: true,
              svc1: true,
              svc2: true,
              'vc-1': true,
              vp08: true,
              vp09: true
            },
            text: {
              stpp: true,
              wvtt: true
            }
          };
          function isCodecType(codec, type) {
            const typeCodes = sampleEntryCodesISO[type];
            return !!typeCodes && typeCodes[codec.slice(0, 4)] === true;
          }
          function isCodecSupportedInMp4(codec, type) {
            return MediaSource.isTypeSupported(`${type || 'video'}/mp4;codecs="${codec}"`);
          }

          /***/
        }),

/***/ "./src/utils/cues.ts":
/*!***************************!*\
  !*** ./src/utils/cues.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _vttparser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./vttparser */ "./src/utils/vttparser.ts");
/* harmony import */ var _webvtt_parser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./webvtt-parser */ "./src/utils/webvtt-parser.ts");
/* harmony import */ var _texttrack_utils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./texttrack-utils */ "./src/utils/texttrack-utils.ts");



          const WHITESPACE_CHAR = /\s/;
          const Cues = {
            newCue(track, startTime, endTime, captionScreen) {
              const result = [];
              let row;
              // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers
              let cue;
              let indenting;
              let indent;
              let text;
              const Cue = self.VTTCue || self.TextTrackCue;
              for (let r = 0; r < captionScreen.rows.length; r++) {
                row = captionScreen.rows[r];
                indenting = true;
                indent = 0;
                text = '';
                if (!row.isEmpty()) {
                  for (let c = 0; c < row.chars.length; c++) {
                    if (WHITESPACE_CHAR.test(row.chars[c].uchar) && indenting) {
                      indent++;
                    } else {
                      text += row.chars[c].uchar;
                      indenting = false;
                    }
                  }
                  // To be used for cleaning-up orphaned roll-up captions
                  row.cueStartTime = startTime;

                  // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE
                  if (startTime === endTime) {
                    endTime += 0.0001;
                  }
                  if (indent >= 16) {
                    indent--;
                  } else {
                    indent++;
                  }
                  const cueText = (0, _vttparser__WEBPACK_IMPORTED_MODULE_0__.fixLineBreaks)(text.trim());
                  const id = (0, _webvtt_parser__WEBPACK_IMPORTED_MODULE_1__.generateCueId)(startTime, endTime, cueText);

                  // If this cue already exists in the track do not push it
                  if (!track || !track.cues || !track.cues.getCueById(id)) {
                    cue = new Cue(startTime, endTime, cueText);
                    cue.id = id;
                    cue.line = r + 1;
                    cue.align = 'left';
                    // Clamp the position between 10 and 80 percent (CEA-608 PAC indent code)
                    // https://dvcs.w3.org/hg/text-tracks/raw-file/default/608toVTT/608toVTT.html#positioning-in-cea-608
                    // Firefox throws an exception and captions break with out of bounds 0-100 values
                    cue.position = 10 + Math.min(80, Math.floor(indent * 8 / 32) * 10);
                    result.push(cue);
                  }
                }
              }
              if (track && result.length) {
                // Sort bottom cues in reverse order so that they render in line order when overlapping in Chrome
                result.sort((cueA, cueB) => {
                  if (cueA.line === 'auto' || cueB.line === 'auto') {
                    return 0;
                  }
                  if (cueA.line > 8 && cueB.line > 8) {
                    return cueB.line - cueA.line;
                  }
                  return cueA.line - cueB.line;
                });
                result.forEach(cue => (0, _texttrack_utils__WEBPACK_IMPORTED_MODULE_2__.addCueToTrack)(track, cue));
              }
              return result;
            }
          };
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Cues);

          /***/
        }),

/***/ "./src/utils/discontinuities.ts":
/*!**************************************!*\
  !*** ./src/utils/discontinuities.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "adjustSlidingStart": () => (/* binding */ adjustSlidingStart),
/* harmony export */   "alignMediaPlaylistByPDT": () => (/* binding */ alignMediaPlaylistByPDT),
/* harmony export */   "alignPDT": () => (/* binding */ alignPDT),
/* harmony export */   "alignStream": () => (/* binding */ alignStream),
/* harmony export */   "findDiscontinuousReferenceFrag": () => (/* binding */ findDiscontinuousReferenceFrag),
/* harmony export */   "findFirstFragWithCC": () => (/* binding */ findFirstFragWithCC),
/* harmony export */   "shouldAlignOnDiscontinuities": () => (/* binding */ shouldAlignOnDiscontinuities)
            /* harmony export */
          });
/* harmony import */ var _logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./logger */ "./src/utils/logger.ts");
/* harmony import */ var _controller_level_helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../controller/level-helper */ "./src/controller/level-helper.ts");


          function findFirstFragWithCC(fragments, cc) {
            let firstFrag = null;
            for (let i = 0, len = fragments.length; i < len; i++) {
              const currentFrag = fragments[i];
              if (currentFrag && currentFrag.cc === cc) {
                firstFrag = currentFrag;
                break;
              }
            }
            return firstFrag;
          }
          function shouldAlignOnDiscontinuities(lastFrag, lastLevel, details) {
            if (lastLevel.details) {
              if (details.endCC > details.startCC || lastFrag && lastFrag.cc < details.startCC) {
                return true;
              }
            }
            return false;
          }

          // Find the first frag in the previous level which matches the CC of the first frag of the new level
          function findDiscontinuousReferenceFrag(prevDetails, curDetails, referenceIndex = 0) {
            const prevFrags = prevDetails.fragments;
            const curFrags = curDetails.fragments;
            if (!curFrags.length || !prevFrags.length) {
              _logger__WEBPACK_IMPORTED_MODULE_0__.logger.log('No fragments to align');
              return;
            }
            const prevStartFrag = findFirstFragWithCC(prevFrags, curFrags[0].cc);
            if (!prevStartFrag || prevStartFrag && !prevStartFrag.startPTS) {
              _logger__WEBPACK_IMPORTED_MODULE_0__.logger.log('No frag in previous level to align on');
              return;
            }
            return prevStartFrag;
          }
          function adjustFragmentStart(frag, sliding) {
            if (frag) {
              const start = frag.start + sliding;
              frag.start = frag.startPTS = start;
              frag.endPTS = start + frag.duration;
            }
          }
          function adjustSlidingStart(sliding, details) {
            // Update segments
            const fragments = details.fragments;
            for (let i = 0, len = fragments.length; i < len; i++) {
              adjustFragmentStart(fragments[i], sliding);
            }
            // Update LL-HLS parts at the end of the playlist
            if (details.fragmentHint) {
              adjustFragmentStart(details.fragmentHint, sliding);
            }
            details.alignedSliding = true;
          }

          /**
           * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a
           * contiguous stream with the last fragments.
           * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to
           * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time
           * and an extra download.
           * @param lastFrag
           * @param lastLevel
           * @param details
           */
          function alignStream(lastFrag, lastLevel, details) {
            if (!lastLevel) {
              return;
            }
            alignDiscontinuities(lastFrag, details, lastLevel);
            if (!details.alignedSliding && lastLevel.details) {
              // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.
              // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same
              // discontinuity sequence.
              alignPDT(details, lastLevel.details);
            }
            if (!details.alignedSliding && lastLevel.details && !details.skippedSegments) {
              // Try to align on sn so that we pick a better start fragment.
              // Do not perform this on playlists with delta updates as this is only to align levels on switch
              // and adjustSliding only adjusts fragments after skippedSegments.
              (0, _controller_level_helper__WEBPACK_IMPORTED_MODULE_1__.adjustSliding)(lastLevel.details, details);
            }
          }

          /**
           * Computes the PTS if a new level's fragments using the PTS of a fragment in the last level which shares the same
           * discontinuity sequence.
           * @param lastFrag - The last Fragment which shares the same discontinuity sequence
           * @param lastLevel - The details of the last loaded level
           * @param details - The details of the new level
           */
          function alignDiscontinuities(lastFrag, details, lastLevel) {
            if (shouldAlignOnDiscontinuities(lastFrag, lastLevel, details)) {
              const referenceFrag = findDiscontinuousReferenceFrag(lastLevel.details, details);
              if (referenceFrag && Number.isFinite(referenceFrag.start)) {
                _logger__WEBPACK_IMPORTED_MODULE_0__.logger.log(`Adjusting PTS using last level due to CC increase within current level ${details.url}`);
                adjustSlidingStart(referenceFrag.start, details);
              }
            }
          }

          /**
           * Computes the PTS of a new level's fragments using the difference in Program Date Time from the last level.
           * @param details - The details of the new level
           * @param lastDetails - The details of the last loaded level
           */
          function alignPDT(details, lastDetails) {
            // This check protects the unsafe "!" usage below for null program date time access.
            if (!lastDetails.fragments.length || !details.hasProgramDateTime || !lastDetails.hasProgramDateTime) {
              return;
            }
            // if last level sliding is 1000 and its first frag PROGRAM-DATE-TIME is 2017-08-20 1:10:00 AM
            // and if new details first frag PROGRAM DATE-TIME is 2017-08-20 1:10:08 AM
            // then we can deduce that playlist B sliding is 1000+8 = 1008s
            const lastPDT = lastDetails.fragments[0].programDateTime; // hasProgramDateTime check above makes this safe.
            const newPDT = details.fragments[0].programDateTime;
            // date diff is in ms. frag.start is in seconds
            const sliding = (newPDT - lastPDT) / 1000 + lastDetails.fragments[0].start;
            if (sliding && Number.isFinite(sliding)) {
              _logger__WEBPACK_IMPORTED_MODULE_0__.logger.log(`Adjusting PTS using programDateTime delta ${newPDT - lastPDT}ms, sliding:${sliding.toFixed(3)} ${details.url} `);
              adjustSlidingStart(sliding, details);
            }
          }

          /**
           * Ensures appropriate time-alignment between renditions based on PDT. Unlike `alignPDT`, which adjusts
           * the timeline based on the delta between PDTs of the 0th fragment of two playlists/`LevelDetails`,
           * this function assumes the timelines represented in `refDetails` are accurate, including the PDTs,
           * and uses the "wallclock"/PDT timeline as a cross-reference to `details`, adjusting the presentation
           * times/timelines of `details` accordingly.
           * Given the asynchronous nature of fetches and initial loads of live `main` and audio/subtitle tracks,
           * the primary purpose of this function is to ensure the "local timelines" of audio/subtitle tracks
           * are aligned to the main/video timeline, using PDT as the cross-reference/"anchor" that should
           * be consistent across playlists, per the HLS spec.
           * @param details - The details of the rendition you'd like to time-align (e.g. an audio rendition).
           * @param refDetails - The details of the reference rendition with start and PDT times for alignment.
           */
          function alignMediaPlaylistByPDT(details, refDetails) {
            if (!details.hasProgramDateTime || !refDetails.hasProgramDateTime) {
              return;
            }
            const fragments = details.fragments;
            const refFragments = refDetails.fragments;
            if (!fragments.length || !refFragments.length) {
              return;
            }

            // Calculate a delta to apply to all fragments according to the delta in PDT times and start times
            // of a fragment in the reference details, and a fragment in the target details of the same discontinuity.
            // If a fragment of the same discontinuity was not found use the middle fragment of both.
            const middleFrag = Math.round(refFragments.length / 2) - 1;
            const refFrag = refFragments[middleFrag];
            const frag = findFirstFragWithCC(fragments, refFrag.cc) || fragments[Math.round(fragments.length / 2) - 1];
            const refPDT = refFrag.programDateTime;
            const targetPDT = frag.programDateTime;
            if (refPDT === null || targetPDT === null) {
              return;
            }
            const delta = (targetPDT - refPDT) / 1000 - (frag.start - refFrag.start);
            adjustSlidingStart(delta, details);
          }

          /***/
        }),

/***/ "./src/utils/ewma-bandwidth-estimator.ts":
/*!***********************************************!*\
  !*** ./src/utils/ewma-bandwidth-estimator.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _utils_ewma__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/ewma */ "./src/utils/ewma.ts");
          /*
           * EWMA Bandwidth Estimator
           *  - heavily inspired from shaka-player
           * Tracks bandwidth samples and estimates available bandwidth.
           * Based on the minimum of two exponentially-weighted moving averages with
           * different half-lives.
           */


          class EwmaBandWidthEstimator {
            constructor(slow, fast, defaultEstimate) {
              this.defaultEstimate_ = defaultEstimate;
              this.minWeight_ = 0.001;
              this.minDelayMs_ = 50;
              this.slow_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](slow);
              this.fast_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](fast);
            }
            update(slow, fast) {
              const {
                slow_,
                fast_
              } = this;
              if (this.slow_.halfLife !== slow) {
                this.slow_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](slow, slow_.getEstimate(), slow_.getTotalWeight());
              }
              if (this.fast_.halfLife !== fast) {
                this.fast_ = new _utils_ewma__WEBPACK_IMPORTED_MODULE_0__["default"](fast, fast_.getEstimate(), fast_.getTotalWeight());
              }
            }
            sample(durationMs, numBytes) {
              durationMs = Math.max(durationMs, this.minDelayMs_);
              const numBits = 8 * numBytes;
              // weight is duration in seconds
              const durationS = durationMs / 1000;
              // value is bandwidth in bits/s
              const bandwidthInBps = numBits / durationS;
              this.fast_.sample(durationS, bandwidthInBps);
              this.slow_.sample(durationS, bandwidthInBps);
            }
            canEstimate() {
              const fast = this.fast_;
              return fast && fast.getTotalWeight() >= this.minWeight_;
            }
            getEstimate() {
              if (this.canEstimate()) {
                // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));
                // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));
                // Take the minimum of these two estimates.  This should have the effect of
                // adapting down quickly, but up more slowly.
                return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());
              } else {
                return this.defaultEstimate_;
              }
            }
            destroy() { }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (EwmaBandWidthEstimator);

          /***/
        }),

/***/ "./src/utils/ewma.ts":
/*!***************************!*\
  !*** ./src/utils/ewma.ts ***!
  \***************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          /*
           * compute an Exponential Weighted moving average
           * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average
           *  - heavily inspired from shaka-player
           */

          class EWMA {
            //  About half of the estimated value will be from the last |halfLife| samples by weight.
            constructor(halfLife, estimate = 0, weight = 0) {
              this.halfLife = halfLife;
              // Larger values of alpha expire historical data more slowly.
              this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;
              this.estimate_ = estimate;
              this.totalWeight_ = weight;
            }
            sample(weight, value) {
              const adjAlpha = Math.pow(this.alpha_, weight);
              this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;
              this.totalWeight_ += weight;
            }
            getTotalWeight() {
              return this.totalWeight_;
            }
            getEstimate() {
              if (this.alpha_) {
                const zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);
                if (zeroFactor) {
                  return this.estimate_ / zeroFactor;
                }
              }
              return this.estimate_;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (EWMA);

          /***/
        }),

/***/ "./src/utils/fetch-loader.ts":
/*!***********************************!*\
  !*** ./src/utils/fetch-loader.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__),
/* harmony export */   "fetchSupported": () => (/* binding */ fetchSupported)
            /* harmony export */
          });
/* harmony import */ var _loader_load_stats__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../loader/load-stats */ "./src/loader/load-stats.ts");
/* harmony import */ var _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../demux/chunk-cache */ "./src/demux/chunk-cache.ts");


          function fetchSupported() {
            if (
              // @ts-ignore
              self.fetch && self.AbortController && self.ReadableStream && self.Request) {
              try {
                new self.ReadableStream({}); // eslint-disable-line no-new
                return true;
              } catch (e) {
                /* noop */
              }
            }
            return false;
          }
          class FetchLoader {
            config = null;
            callbacks = null;
            loader = null;
            constructor(config /* HlsConfig */) {
              this.fetchSetup = config.fetchSetup || getRequest;
              this.controller = new self.AbortController();
              this.stats = new _loader_load_stats__WEBPACK_IMPORTED_MODULE_0__.LoadStats();
            }
            destroy() {
              this.loader = this.callbacks = null;
              this.abortInternal();
            }
            abortInternal() {
              const response = this.response;
              if (!response || !response.ok) {
                this.stats.aborted = true;
                this.controller.abort();
              }
            }
            abort() {
              this.abortInternal();
              if (this.callbacks?.onAbort) {
                this.callbacks.onAbort(this.stats, this.context, this.response);
              }
            }
            load(context, config, callbacks) {
              const stats = this.stats;
              if (stats.loading.start) {
                throw new Error('Loader can only be used once.');
              }
              stats.loading.start = self.performance.now();
              const initParams = getRequestParameters(context, this.controller.signal);
              const onProgress = callbacks.onProgress;
              const isArrayBuffer = context.responseType === 'arraybuffer';
              const LENGTH = isArrayBuffer ? 'byteLength' : 'length';
              this.context = context;
              this.config = config;
              this.callbacks = callbacks;
              this.request = this.fetchSetup(context, initParams);
              self.clearTimeout(this.requestTimeout);
              this.requestTimeout = self.setTimeout(() => {
                this.abortInternal();
                callbacks.onTimeout(stats, context, this.response);
              }, config.timeout);
              self.fetch(this.request).then(response => {
                this.response = this.loader = response;
                if (!response.ok) {
                  const {
                    status,
                    statusText
                  } = response;
                  throw new FetchError(statusText || 'fetch, bad network response', status, response);
                }
                stats.loading.first = Math.max(self.performance.now(), stats.loading.start);
                stats.total = parseInt(response.headers.get('Content-Length') || '0');
                if (onProgress && Number.isFinite(config.highWaterMark)) {
                  return this.loadProgressively(response, stats, context, config.highWaterMark, onProgress);
                }
                if (isArrayBuffer) {
                  return response.arrayBuffer();
                }
                return response.text();
              }).then(responseData => {
                const {
                  response
                } = this;
                self.clearTimeout(this.requestTimeout);
                stats.loading.end = Math.max(self.performance.now(), stats.loading.first);
                const total = responseData[LENGTH];
                if (total) {
                  stats.loaded = stats.total = total;
                }
                const loaderResponse = {
                  url: response.url,
                  data: responseData
                };
                if (onProgress && !Number.isFinite(config.highWaterMark)) {
                  onProgress(stats, context, responseData, response);
                }
                callbacks.onSuccess(loaderResponse, stats, context, response);
              }).catch(error => {
                self.clearTimeout(this.requestTimeout);
                if (stats.aborted) {
                  return;
                }
                // CORS errors result in an undefined code. Set it to 0 here to align with XHR's behavior
                // when destroying, 'error' itself can be undefined
                const code = !error ? 0 : error.code || 0;
                const text = !error ? null : error.message;
                callbacks.onError({
                  code,
                  text
                }, context, error ? error.details : null);
              });
            }
            getCacheAge() {
              let result = null;
              if (this.response) {
                const ageHeader = this.response.headers.get('age');
                result = ageHeader ? parseFloat(ageHeader) : null;
              }
              return result;
            }
            loadProgressively(response, stats, context, highWaterMark = 0, onProgress) {
              const chunkCache = new _demux_chunk_cache__WEBPACK_IMPORTED_MODULE_1__["default"]();
              const reader = response.body.getReader();
              const pump = () => {
                return reader.read().then(data => {
                  if (data.done) {
                    if (chunkCache.dataLength) {
                      onProgress(stats, context, chunkCache.flush(), response);
                    }
                    return Promise.resolve(new ArrayBuffer(0));
                  }
                  const chunk = data.value;
                  const len = chunk.length;
                  stats.loaded += len;
                  if (len < highWaterMark || chunkCache.dataLength) {
                    // The current chunk is too small to to be emitted or the cache already has data
                    // Push it to the cache
                    chunkCache.push(chunk);
                    if (chunkCache.dataLength >= highWaterMark) {
                      // flush in order to join the typed arrays
                      onProgress(stats, context, chunkCache.flush(), response);
                    }
                  } else {
                    // If there's nothing cached already, and the chache is large enough
                    // just emit the progress event
                    onProgress(stats, context, chunk, response);
                  }
                  return pump();
                }).catch(() => {
                  /* aborted */
                  return Promise.reject();
                });
              };
              return pump();
            }
          }
          function getRequestParameters(context, signal) {
            const initParams = {
              method: 'GET',
              mode: 'cors',
              credentials: 'same-origin',
              signal,
              headers: new self.Headers(Object.assign({}, context.headers))
            };
            if (context.rangeEnd) {
              initParams.headers.set('Range', 'bytes=' + context.rangeStart + '-' + String(context.rangeEnd - 1));
            }
            return initParams;
          }
          function getRequest(context, initParams) {
            return new self.Request(context.url, initParams);
          }
          class FetchError extends Error {
            constructor(message, code, details) {
              super(message);
              this.code = code;
              this.details = details;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FetchLoader);

          /***/
        }),

/***/ "./src/utils/hex.ts":
/*!**************************!*\
  !*** ./src/utils/hex.ts ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          /**
           *  hex dump helper class
           */

          const Hex = {
            hexDump: function (array) {
              let str = '';
              for (let i = 0; i < array.length; i++) {
                let h = array[i].toString(16);
                if (h.length < 2) {
                  h = '0' + h;
                }
                str += h;
              }
              return str;
            }
          };
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Hex);

          /***/
        }),

/***/ "./src/utils/imsc1-ttml-parser.ts":
/*!****************************************!*\
  !*** ./src/utils/imsc1-ttml-parser.ts ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "IMSC1_CODEC": () => (/* binding */ IMSC1_CODEC),
/* harmony export */   "parseIMSC1": () => (/* binding */ parseIMSC1)
            /* harmony export */
          });
/* harmony import */ var _mp4_tools__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./mp4-tools */ "./src/utils/mp4-tools.ts");
/* harmony import */ var _vttparser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./vttparser */ "./src/utils/vttparser.ts");
/* harmony import */ var _vttcue__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./vttcue */ "./src/utils/vttcue.ts");
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
/* harmony import */ var _timescale_conversion__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./timescale-conversion */ "./src/utils/timescale-conversion.ts");
/* harmony import */ var _webvtt_parser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./webvtt-parser */ "./src/utils/webvtt-parser.ts");






          const IMSC1_CODEC = 'stpp.ttml.im1t';

          // Time format: h:m:s:frames(.subframes)
          const HMSF_REGEX = /^(\d{2,}):(\d{2}):(\d{2}):(\d{2})\.?(\d+)?$/;

          // Time format: hours, minutes, seconds, milliseconds, frames, ticks
          const TIME_UNIT_REGEX = /^(\d*(?:\.\d*)?)(h|m|s|ms|f|t)$/;
          const textAlignToLineAlign = {
            left: 'start',
            center: 'center',
            right: 'end',
            start: 'start',
            end: 'end'
          };
          function parseIMSC1(payload, initPTS, timescale, callBack, errorCallBack) {
            const results = (0, _mp4_tools__WEBPACK_IMPORTED_MODULE_0__.findBox)(new Uint8Array(payload), ['mdat']);
            if (results.length === 0) {
              errorCallBack(new Error('Could not parse IMSC1 mdat'));
              return;
            }
            const ttmlList = results.map(mdat => (0, _demux_id3__WEBPACK_IMPORTED_MODULE_3__.utf8ArrayToStr)(mdat));
            const syncTime = (0, _timescale_conversion__WEBPACK_IMPORTED_MODULE_4__.toTimescaleFromScale)(initPTS, 1, timescale);
            try {
              ttmlList.forEach(ttml => callBack(parseTTML(ttml, syncTime)));
            } catch (error) {
              errorCallBack(error);
            }
          }
          function parseTTML(ttml, syncTime) {
            const parser = new DOMParser();
            const xmlDoc = parser.parseFromString(ttml, 'text/xml');
            const tt = xmlDoc.getElementsByTagName('tt')[0];
            if (!tt) {
              throw new Error('Invalid ttml');
            }
            const defaultRateInfo = {
              frameRate: 30,
              subFrameRate: 1,
              frameRateMultiplier: 0,
              tickRate: 0
            };
            const rateInfo = Object.keys(defaultRateInfo).reduce((result, key) => {
              result[key] = tt.getAttribute(`ttp:${key}`) || defaultRateInfo[key];
              return result;
            }, {});
            const trim = tt.getAttribute('xml:space') !== 'preserve';
            const styleElements = collectionToDictionary(getElementCollection(tt, 'styling', 'style'));
            const regionElements = collectionToDictionary(getElementCollection(tt, 'layout', 'region'));
            const cueElements = getElementCollection(tt, 'body', '[begin]');
            return [].map.call(cueElements, cueElement => {
              const cueText = getTextContent(cueElement, trim);
              if (!cueText || !cueElement.hasAttribute('begin')) {
                return null;
              }
              const startTime = parseTtmlTime(cueElement.getAttribute('begin'), rateInfo);
              const duration = parseTtmlTime(cueElement.getAttribute('dur'), rateInfo);
              let endTime = parseTtmlTime(cueElement.getAttribute('end'), rateInfo);
              if (startTime === null) {
                throw timestampParsingError(cueElement);
              }
              if (endTime === null) {
                if (duration === null) {
                  throw timestampParsingError(cueElement);
                }
                endTime = startTime + duration;
              }
              const cue = new _vttcue__WEBPACK_IMPORTED_MODULE_2__["default"](startTime - syncTime, endTime - syncTime, cueText);
              cue.id = (0, _webvtt_parser__WEBPACK_IMPORTED_MODULE_5__.generateCueId)(cue.startTime, cue.endTime, cue.text);
              const region = regionElements[cueElement.getAttribute('region')];
              const style = styleElements[cueElement.getAttribute('style')];

              // Apply styles to cue
              const styles = getTtmlStyles(region, style, styleElements);
              const {
                textAlign
              } = styles;
              if (textAlign) {
                // cue.positionAlign not settable in FF~2016
                const lineAlign = textAlignToLineAlign[textAlign];
                if (lineAlign) {
                  cue.lineAlign = lineAlign;
                }
                cue.align = textAlign;
              }
              Object.assign(cue, styles);
              return cue;
            }).filter(cue => cue !== null);
          }
          function getElementCollection(fromElement, parentName, childName) {
            const parent = fromElement.getElementsByTagName(parentName)[0];
            if (parent) {
              return [].slice.call(parent.querySelectorAll(childName));
            }
            return [];
          }
          function collectionToDictionary(elementsWithId) {
            return elementsWithId.reduce((dict, element) => {
              const id = element.getAttribute('xml:id');
              if (id) {
                dict[id] = element;
              }
              return dict;
            }, {});
          }
          function getTextContent(element, trim) {
            return [].slice.call(element.childNodes).reduce((str, node, i) => {
              if (node.nodeName === 'br' && i) {
                return str + '\n';
              }
              if (node.childNodes?.length) {
                return getTextContent(node, trim);
              } else if (trim) {
                return str + node.textContent.trim().replace(/\s+/g, ' ');
              }
              return str + node.textContent;
            }, '');
          }
          function getTtmlStyles(region, style, styleElements) {
            const ttsNs = 'http://www.w3.org/ns/ttml#styling';
            let regionStyle = null;
            const styleAttributes = ['displayAlign', 'textAlign', 'color', 'backgroundColor', 'fontSize', 'fontFamily'
              // 'fontWeight',
              // 'lineHeight',
              // 'wrapOption',
              // 'fontStyle',
              // 'direction',
              // 'writingMode'
            ];

            const regionStyleName = region?.hasAttribute('style') ? region.getAttribute('style') : null;
            if (regionStyleName && styleElements.hasOwnProperty(regionStyleName)) {
              regionStyle = styleElements[regionStyleName];
            }
            return styleAttributes.reduce((styles, name) => {
              const value = getAttributeNS(style, ttsNs, name) || getAttributeNS(region, ttsNs, name) || getAttributeNS(regionStyle, ttsNs, name);
              if (value) {
                styles[name] = value;
              }
              return styles;
            }, {});
          }
          function getAttributeNS(element, ns, name) {
            if (!element) {
              return null;
            }
            return element.hasAttributeNS(ns, name) ? element.getAttributeNS(ns, name) : null;
          }
          function timestampParsingError(node) {
            return new Error(`Could not parse ttml timestamp ${node}`);
          }
          function parseTtmlTime(timeAttributeValue, rateInfo) {
            if (!timeAttributeValue) {
              return null;
            }
            let seconds = (0, _vttparser__WEBPACK_IMPORTED_MODULE_1__.parseTimeStamp)(timeAttributeValue);
            if (seconds === null) {
              if (HMSF_REGEX.test(timeAttributeValue)) {
                seconds = parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo);
              } else if (TIME_UNIT_REGEX.test(timeAttributeValue)) {
                seconds = parseTimeUnits(timeAttributeValue, rateInfo);
              }
            }
            return seconds;
          }
          function parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo) {
            const m = HMSF_REGEX.exec(timeAttributeValue);
            const frames = (m[4] | 0) + (m[5] | 0) / rateInfo.subFrameRate;
            return (m[1] | 0) * 3600 + (m[2] | 0) * 60 + (m[3] | 0) + frames / rateInfo.frameRate;
          }
          function parseTimeUnits(timeAttributeValue, rateInfo) {
            const m = TIME_UNIT_REGEX.exec(timeAttributeValue);
            const value = Number(m[1]);
            const unit = m[2];
            switch (unit) {
              case 'h':
                return value * 3600;
              case 'm':
                return value * 60;
              case 'ms':
                return value * 1000;
              case 'f':
                return value / rateInfo.frameRate;
              case 't':
                return value / rateInfo.tickRate;
            }
            return value;
          }

          /***/
        }),

/***/ "./src/utils/keysystem-util.ts":
/*!*************************************!*\
  !*** ./src/utils/keysystem-util.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "changeEndianness": () => (/* binding */ changeEndianness),
/* harmony export */   "convertDataUriToArrayBytes": () => (/* binding */ convertDataUriToArrayBytes),
/* harmony export */   "strToUtf8array": () => (/* binding */ strToUtf8array)
            /* harmony export */
          });
/* harmony import */ var _numeric_encoding_utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./numeric-encoding-utils */ "./src/utils/numeric-encoding-utils.ts");

          function getKeyIdBytes(str) {
            const keyIdbytes = strToUtf8array(str).subarray(0, 16);
            const paddedkeyIdbytes = new Uint8Array(16);
            paddedkeyIdbytes.set(keyIdbytes, 16 - keyIdbytes.length);
            return paddedkeyIdbytes;
          }
          function changeEndianness(keyId) {
            const swap = function (array, from, to) {
              const cur = array[from];
              array[from] = array[to];
              array[to] = cur;
            };
            swap(keyId, 0, 3);
            swap(keyId, 1, 2);
            swap(keyId, 4, 5);
            swap(keyId, 6, 7);
          }
          function convertDataUriToArrayBytes(uri) {
            // data:[<media type][;attribute=value][;base64],<data>
            const colonsplit = uri.split(':');
            let keydata = null;
            if (colonsplit[0] === 'data' && colonsplit.length === 2) {
              const semicolonsplit = colonsplit[1].split(';');
              const commasplit = semicolonsplit[semicolonsplit.length - 1].split(',');
              if (commasplit.length === 2) {
                const isbase64 = commasplit[0] === 'base64';
                const data = commasplit[1];
                if (isbase64) {
                  semicolonsplit.splice(-1, 1); // remove from processing
                  keydata = (0, _numeric_encoding_utils__WEBPACK_IMPORTED_MODULE_0__.base64Decode)(data);
                } else {
                  keydata = getKeyIdBytes(data);
                }
              }
            }
            return keydata;
          }
          function strToUtf8array(str) {
            return Uint8Array.from(unescape(encodeURIComponent(str)), c => c.charCodeAt(0));
          }

          /***/
        }),

/***/ "./src/utils/logger.ts":
/*!*****************************!*\
  !*** ./src/utils/logger.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "enableLogs": () => (/* binding */ enableLogs),
/* harmony export */   "logger": () => (/* binding */ logger)
            /* harmony export */
          });
          const noop = function () { };
          const fakeLogger = {
            trace: noop,
            debug: noop,
            log: noop,
            warn: noop,
            info: noop,
            error: noop
          };
          let exportedLogger = fakeLogger;

          // let lastCallTime;
          // function formatMsgWithTimeInfo(type, msg) {
          //   const now = Date.now();
          //   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';
          //   lastCallTime = now;
          //   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';
          //   return msg;
          // }

          function consolePrintFn(type) {
            const func = self.console[type];
            if (func) {
              return func.bind(self.console, `[${type}] >`);
            }
            return noop;
          }
          function exportLoggerFunctions(debugConfig, ...functions) {
            functions.forEach(function (type) {
              exportedLogger[type] = debugConfig[type] ? debugConfig[type].bind(debugConfig) : consolePrintFn(type);
            });
          }
          function enableLogs(debugConfig, id) {
            // check that console is available
            if (self.console && debugConfig === true || typeof debugConfig === 'object') {
              exportLoggerFunctions(debugConfig,
                // Remove out from list here to hard-disable a log-level
                // 'trace',
                'debug', 'log', 'info', 'warn', 'error');
              // Some browsers don't allow to use bind on console object anyway
              // fallback to default if needed
              try {
                exportedLogger.log(`Debug logs enabled for "${id}"`);
              } catch (e) {
                exportedLogger = fakeLogger;
              }
            } else {
              exportedLogger = fakeLogger;
            }
          }
          const logger = exportedLogger;

          /***/
        }),

/***/ "./src/utils/mediakeys-helper.ts":
/*!***************************************!*\
  !*** ./src/utils/mediakeys-helper.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "KeySystemFormats": () => (/* binding */ KeySystemFormats),
/* harmony export */   "KeySystemIds": () => (/* binding */ KeySystemIds),
/* harmony export */   "KeySystems": () => (/* binding */ KeySystems),
/* harmony export */   "getKeySystemsForConfig": () => (/* binding */ getKeySystemsForConfig),
/* harmony export */   "getSupportedMediaKeySystemConfigurations": () => (/* binding */ getSupportedMediaKeySystemConfigurations),
/* harmony export */   "keySystemDomainToKeySystemFormat": () => (/* binding */ keySystemDomainToKeySystemFormat),
/* harmony export */   "keySystemFormatToKeySystemDomain": () => (/* binding */ keySystemFormatToKeySystemDomain),
/* harmony export */   "keySystemIdToKeySystemDomain": () => (/* binding */ keySystemIdToKeySystemDomain),
/* harmony export */   "requestMediaKeySystemAccess": () => (/* binding */ requestMediaKeySystemAccess)
            /* harmony export */
          });
          /**
           * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess
           */
          let KeySystems;

          // Playlist #EXT-X-KEY KEYFORMAT values
          (function (KeySystems) {
            KeySystems["CLEARKEY"] = "org.w3.clearkey";
            KeySystems["FAIRPLAY"] = "com.apple.fps";
            KeySystems["PLAYREADY"] = "com.microsoft.playready";
            KeySystems["WIDEVINE"] = "com.widevine.alpha";
          })(KeySystems || (KeySystems = {}));
          let KeySystemFormats;
          (function (KeySystemFormats) {
            KeySystemFormats["CLEARKEY"] = "org.w3.clearkey";
            KeySystemFormats["FAIRPLAY"] = "com.apple.streamingkeydelivery";
            KeySystemFormats["PLAYREADY"] = "com.microsoft.playready";
            KeySystemFormats["WIDEVINE"] = "urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed";
          })(KeySystemFormats || (KeySystemFormats = {}));
          function keySystemFormatToKeySystemDomain(format) {
            switch (format) {
              case KeySystemFormats.FAIRPLAY:
                return KeySystems.FAIRPLAY;
              case KeySystemFormats.PLAYREADY:
                return KeySystems.PLAYREADY;
              case KeySystemFormats.WIDEVINE:
                return KeySystems.WIDEVINE;
              case KeySystemFormats.CLEARKEY:
                return KeySystems.CLEARKEY;
            }
          }

          // System IDs for which we can extract a key ID from "encrypted" event PSSH
          let KeySystemIds;
          (function (KeySystemIds) {
            KeySystemIds["WIDEVINE"] = "edef8ba979d64acea3c827dcd51d21ed";
          })(KeySystemIds || (KeySystemIds = {}));
          function keySystemIdToKeySystemDomain(systemId) {
            if (systemId === KeySystemIds.WIDEVINE) {
              return KeySystems.WIDEVINE;
              // } else if (systemId === KeySystemIds.PLAYREADY) {
              //   return KeySystems.PLAYREADY;
              // } else if (systemId === KeySystemIds.CENC || systemId === KeySystemIds.CLEARKEY) {
              //   return KeySystems.CLEARKEY;
            }
          }

          function keySystemDomainToKeySystemFormat(keySystem) {
            switch (keySystem) {
              case KeySystems.FAIRPLAY:
                return KeySystemFormats.FAIRPLAY;
              case KeySystems.PLAYREADY:
                return KeySystemFormats.PLAYREADY;
              case KeySystems.WIDEVINE:
                return KeySystemFormats.WIDEVINE;
              case KeySystems.CLEARKEY:
                return KeySystemFormats.CLEARKEY;
            }
          }
          function getKeySystemsForConfig(config) {
            const {
              drmSystems,
              widevineLicenseUrl
            } = config;
            const keySystemsToAttempt = drmSystems ? [KeySystems.FAIRPLAY, KeySystems.WIDEVINE, KeySystems.PLAYREADY, KeySystems.CLEARKEY].filter(keySystem => !!drmSystems[keySystem]) : [];
            if (!keySystemsToAttempt[KeySystems.WIDEVINE] && widevineLicenseUrl) {
              keySystemsToAttempt.push(KeySystems.WIDEVINE);
            }
            return keySystemsToAttempt;
          }
          const requestMediaKeySystemAccess = function () {
            if (typeof self !== 'undefined' && self.navigator && self.navigator.requestMediaKeySystemAccess) {
              return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);
            } else {
              return null;
            }
          }();

          /**
           * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration
           */
          function getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {
            let initDataTypes;
            switch (keySystem) {
              case KeySystems.FAIRPLAY:
                initDataTypes = ['cenc', 'sinf'];
                break;
              case KeySystems.WIDEVINE:
              case KeySystems.PLAYREADY:
                initDataTypes = ['cenc'];
                break;
              case KeySystems.CLEARKEY:
                initDataTypes = ['cenc', 'keyids'];
                break;
              default:
                throw new Error(`Unknown key-system: ${keySystem}`);
            }
            return createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions);
          }
          function createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions) {
            const baseConfig = {
              initDataTypes: initDataTypes,
              persistentState: drmSystemOptions.persistentState || 'not-allowed',
              distinctiveIdentifier: drmSystemOptions.distinctiveIdentifier || 'not-allowed',
              sessionTypes: drmSystemOptions.sessionTypes || [drmSystemOptions.sessionType || 'temporary'],
              audioCapabilities: audioCodecs.map(codec => ({
                contentType: `audio/mp4; codecs="${codec}"`,
                robustness: drmSystemOptions.audioRobustness || '',
                encryptionScheme: drmSystemOptions.audioEncryptionScheme || null
              })),
              videoCapabilities: videoCodecs.map(codec => ({
                contentType: `video/mp4; codecs="${codec}"`,
                robustness: drmSystemOptions.videoRobustness || '',
                encryptionScheme: drmSystemOptions.videoEncryptionScheme || null
              }))
            };
            return [baseConfig];
          }

          /***/
        }),

/***/ "./src/utils/mediasource-helper.ts":
/*!*****************************************!*\
  !*** ./src/utils/mediasource-helper.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "getMediaSource": () => (/* binding */ getMediaSource)
            /* harmony export */
          });
          /**
           * MediaSource helper
           */

          function getMediaSource() {
            return self.MediaSource || self.WebKitMediaSource;
          }

          /***/
        }),

/***/ "./src/utils/mp4-tools.ts":
/*!********************************!*\
  !*** ./src/utils/mp4-tools.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "RemuxerTrackIdConfig": () => (/* binding */ RemuxerTrackIdConfig),
/* harmony export */   "appendUint8Array": () => (/* binding */ appendUint8Array),
/* harmony export */   "bin2str": () => (/* binding */ bin2str),
/* harmony export */   "computeRawDurationFromSamples": () => (/* binding */ computeRawDurationFromSamples),
/* harmony export */   "discardEPB": () => (/* binding */ discardEPB),
/* harmony export */   "findBox": () => (/* binding */ findBox),
/* harmony export */   "getDuration": () => (/* binding */ getDuration),
/* harmony export */   "getStartDTS": () => (/* binding */ getStartDTS),
/* harmony export */   "mp4Box": () => (/* binding */ mp4Box),
/* harmony export */   "mp4pssh": () => (/* binding */ mp4pssh),
/* harmony export */   "offsetStartDTS": () => (/* binding */ offsetStartDTS),
/* harmony export */   "parseEmsg": () => (/* binding */ parseEmsg),
/* harmony export */   "parseInitSegment": () => (/* binding */ parseInitSegment),
/* harmony export */   "parsePssh": () => (/* binding */ parsePssh),
/* harmony export */   "parseSEIMessageFromNALu": () => (/* binding */ parseSEIMessageFromNALu),
/* harmony export */   "parseSamples": () => (/* binding */ parseSamples),
/* harmony export */   "parseSegmentIndex": () => (/* binding */ parseSegmentIndex),
/* harmony export */   "parseSinf": () => (/* binding */ parseSinf),
/* harmony export */   "patchEncyptionData": () => (/* binding */ patchEncyptionData),
/* harmony export */   "readSint32": () => (/* binding */ readSint32),
/* harmony export */   "readUint16": () => (/* binding */ readUint16),
/* harmony export */   "readUint32": () => (/* binding */ readUint32),
/* harmony export */   "segmentValidRange": () => (/* binding */ segmentValidRange),
/* harmony export */   "writeUint32": () => (/* binding */ writeUint32)
            /* harmony export */
          });
/* harmony import */ var _loader_fragment__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../loader/fragment */ "./src/loader/fragment.ts");
/* harmony import */ var _typed_array__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./typed-array */ "./src/utils/typed-array.ts");
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _hex__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./hex */ "./src/utils/hex.ts");





          const UINT32_MAX = Math.pow(2, 32) - 1;
          const push = [].push;

          // We are using fixed track IDs for driving the MP4 remuxer
          // instead of following the TS PIDs.
          // There is no reason not to do this and some browsers/SourceBuffer-demuxers
          // may not like if there are TrackID "switches"
          // See https://github.com/video-dev/hls.js/issues/1331
          // Here we are mapping our internal track types to constant MP4 track IDs
          // With MSE currently one can only have one track of each, and we are muxing
          // whatever video/audio rendition in them.
          const RemuxerTrackIdConfig = {
            video: 1,
            audio: 2,
            id3: 3,
            text: 4
          };
          function bin2str(data) {
            return String.fromCharCode.apply(null, data);
          }
          function readUint16(buffer, offset) {
            const val = buffer[offset] << 8 | buffer[offset + 1];
            return val < 0 ? 65536 + val : val;
          }
          function readUint32(buffer, offset) {
            const val = readSint32(buffer, offset);
            return val < 0 ? 4294967296 + val : val;
          }
          function readSint32(buffer, offset) {
            return buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];
          }
          function writeUint32(buffer, offset, value) {
            buffer[offset] = value >> 24;
            buffer[offset + 1] = value >> 16 & 0xff;
            buffer[offset + 2] = value >> 8 & 0xff;
            buffer[offset + 3] = value & 0xff;
          }

          // Find the data for a box specified by its path
          function findBox(data, path) {
            const results = [];
            if (!path.length) {
              // short-circuit the search for empty paths
              return results;
            }
            const end = data.byteLength;
            for (let i = 0; i < end;) {
              const size = readUint32(data, i);
              const type = bin2str(data.subarray(i + 4, i + 8));
              const endbox = size > 1 ? i + size : end;
              if (type === path[0]) {
                if (path.length === 1) {
                  // this is the end of the path and we've found the box we were
                  // looking for
                  results.push(data.subarray(i + 8, endbox));
                } else {
                  // recursively search for the next box along the path
                  const subresults = findBox(data.subarray(i + 8, endbox), path.slice(1));
                  if (subresults.length) {
                    push.apply(results, subresults);
                  }
                }
              }
              i = endbox;
            }

            // we've finished searching all of data
            return results;
          }
          function parseSegmentIndex(sidx) {
            const references = [];
            const version = sidx[0];

            // set initial offset, we skip the reference ID (not needed)
            let index = 8;
            const timescale = readUint32(sidx, index);
            index += 4;

            // TODO: parse earliestPresentationTime and firstOffset
            // usually zero in our case
            const earliestPresentationTime = 0;
            const firstOffset = 0;
            if (version === 0) {
              index += 8;
            } else {
              index += 16;
            }

            // skip reserved
            index += 2;
            let startByte = sidx.length + firstOffset;
            const referencesCount = readUint16(sidx, index);
            index += 2;
            for (let i = 0; i < referencesCount; i++) {
              let referenceIndex = index;
              const referenceInfo = readUint32(sidx, referenceIndex);
              referenceIndex += 4;
              const referenceSize = referenceInfo & 0x7fffffff;
              const referenceType = (referenceInfo & 0x80000000) >>> 31;
              if (referenceType === 1) {
                // eslint-disable-next-line no-console
                console.warn('SIDX has hierarchical references (not supported)');
                return null;
              }
              const subsegmentDuration = readUint32(sidx, referenceIndex);
              referenceIndex += 4;
              references.push({
                referenceSize,
                subsegmentDuration,
                // unscaled
                info: {
                  duration: subsegmentDuration / timescale,
                  start: startByte,
                  end: startByte + referenceSize - 1
                }
              });
              startByte += referenceSize;

              // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits
              // for |sapDelta|.
              referenceIndex += 4;

              // skip to next ref
              index = referenceIndex;
            }
            return {
              earliestPresentationTime,
              timescale,
              version,
              referencesCount,
              references
            };
          }

          /**
           * Parses an MP4 initialization segment and extracts stream type and
           * timescale values for any declared tracks. Timescale values indicate the
           * number of clock ticks per second to assume for time-based values
           * elsewhere in the MP4.
           *
           * To determine the start time of an MP4, you need two pieces of
           * information: the timescale unit and the earliest base media decode
           * time. Multiple timescales can be specified within an MP4 but the
           * base media decode time is always expressed in the timescale from
           * the media header box for the track:
           * ```
           * moov > trak > mdia > mdhd.timescale
           * moov > trak > mdia > hdlr
           * ```
           * @param initSegment {Uint8Array} the bytes of the init segment
           * @return {InitData} a hash of track type to timescale values or null if
           * the init segment is malformed.
           */

          function parseInitSegment(initSegment) {
            const result = [];
            const traks = findBox(initSegment, ['moov', 'trak']);
            for (let i = 0; i < traks.length; i++) {
              const trak = traks[i];
              const tkhd = findBox(trak, ['tkhd'])[0];
              if (tkhd) {
                let version = tkhd[0];
                let index = version === 0 ? 12 : 20;
                const trackId = readUint32(tkhd, index);
                const mdhd = findBox(trak, ['mdia', 'mdhd'])[0];
                if (mdhd) {
                  version = mdhd[0];
                  index = version === 0 ? 12 : 20;
                  const timescale = readUint32(mdhd, index);
                  const hdlr = findBox(trak, ['mdia', 'hdlr'])[0];
                  if (hdlr) {
                    const hdlrType = bin2str(hdlr.subarray(8, 12));
                    const type = {
                      soun: _loader_fragment__WEBPACK_IMPORTED_MODULE_0__.ElementaryStreamTypes.AUDIO,
                      vide: _loader_fragment__WEBPACK_IMPORTED_MODULE_0__.ElementaryStreamTypes.VIDEO
                    }[hdlrType];
                    if (type) {
                      // Parse codec details
                      const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];
                      let codec;
                      if (stsd) {
                        codec = bin2str(stsd.subarray(12, 16));
                        // TODO: Parse codec details to be able to build MIME type.
                        // stsd.start += 8;
                        // const codecBox = findBox(stsd, [codec])[0];
                        // if (codecBox) {
                        //   TODO: Codec parsing support for avc1, mp4a, hevc, av01...
                        // }
                      }

                      result[trackId] = {
                        timescale,
                        type
                      };
                      result[type] = {
                        timescale,
                        id: trackId,
                        codec
                      };
                    }
                  }
                }
              }
            }
            const trex = findBox(initSegment, ['moov', 'mvex', 'trex']);
            trex.forEach(trex => {
              const trackId = readUint32(trex, 4);
              const track = result[trackId];
              if (track) {
                track.default = {
                  duration: readUint32(trex, 12),
                  flags: readUint32(trex, 20)
                };
              }
            });
            return result;
          }
          function patchEncyptionData(initSegment, decryptdata) {
            if (!initSegment || !decryptdata) {
              return initSegment;
            }
            const keyId = decryptdata.keyId;
            if (keyId && decryptdata.isCommonEncryption) {
              const traks = findBox(initSegment, ['moov', 'trak']);
              traks.forEach(trak => {
                const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];

                // skip the sample entry count
                const sampleEntries = stsd.subarray(8);
                let encBoxes = findBox(sampleEntries, ['enca']);
                const isAudio = encBoxes.length > 0;
                if (!isAudio) {
                  encBoxes = findBox(sampleEntries, ['encv']);
                }
                encBoxes.forEach(enc => {
                  const encBoxChildren = isAudio ? enc.subarray(28) : enc.subarray(78);
                  const sinfBoxes = findBox(encBoxChildren, ['sinf']);
                  sinfBoxes.forEach(sinf => {
                    const tenc = parseSinf(sinf);
                    if (tenc) {
                      // Look for default key id (keyID offset is always 8 within the tenc box):
                      const tencKeyId = tenc.subarray(8, 24);
                      if (!tencKeyId.some(b => b !== 0)) {
                        _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.log(`[eme] Patching keyId in 'enc${isAudio ? 'a' : 'v'}>sinf>>tenc' box: ${_hex__WEBPACK_IMPORTED_MODULE_4__["default"].hexDump(tencKeyId)} -> ${_hex__WEBPACK_IMPORTED_MODULE_4__["default"].hexDump(keyId)}`);
                        tenc.set(keyId, 8);
                      }
                    }
                  });
                });
              });
            }
            return initSegment;
          }
          function parseSinf(sinf) {
            const schm = findBox(sinf, ['schm'])[0];
            if (schm) {
              const scheme = bin2str(schm.subarray(4, 8));
              if (scheme === 'cbcs' || scheme === 'cenc') {
                return findBox(sinf, ['schi', 'tenc'])[0];
              }
            }
            _utils_logger__WEBPACK_IMPORTED_MODULE_3__.logger.error(`[eme] missing 'schm' box`);
            return null;
          }

          /**
           * Determine the base media decode start time, in seconds, for an MP4
           * fragment. If multiple fragments are specified, the earliest time is
           * returned.
           *
           * The base media decode time can be parsed from track fragment
           * metadata:
           * ```
           * moof > traf > tfdt.baseMediaDecodeTime
           * ```
           * It requires the timescale value from the mdhd to interpret.
           *
           * @param initData {InitData} a hash of track type to timescale values
           * @param fmp4 {Uint8Array} the bytes of the mp4 fragment
           * @return {number} the earliest base media decode start time for the
           * fragment, in seconds
           */
          function getStartDTS(initData, fmp4) {
            // we need info from two children of each track fragment box
            return findBox(fmp4, ['moof', 'traf']).reduce((result, traf) => {
              const tfdt = findBox(traf, ['tfdt'])[0];
              const version = tfdt[0];
              const start = findBox(traf, ['tfhd']).reduce((result, tfhd) => {
                // get the track id from the tfhd
                const id = readUint32(tfhd, 4);
                const track = initData[id];
                if (track) {
                  let baseTime = readUint32(tfdt, 4);
                  if (version === 1) {
                    baseTime *= Math.pow(2, 32);
                    baseTime += readUint32(tfdt, 8);
                  }
                  // assume a 90kHz clock if no timescale was specified
                  const scale = track.timescale || 90e3;
                  // convert base time to seconds
                  const startTime = baseTime / scale;
                  if (isFinite(startTime) && (result === null || startTime < result)) {
                    return startTime;
                  }
                }
                return result;
              }, null);
              if (start !== null && isFinite(start) && (result === null || start < result)) {
                return start;
              }
              return result;
            }, null) || 0;
          }

          /*
            For Reference:
            aligned(8) class TrackFragmentHeaderBox
                     extends FullBox(‘tfhd’, 0, tf_flags){
               unsigned int(32)  track_ID;
               // all the following are optional fields
               unsigned int(64)  base_data_offset;
               unsigned int(32)  sample_description_index;
               unsigned int(32)  default_sample_duration;
               unsigned int(32)  default_sample_size;
               unsigned int(32)  default_sample_flags
            }
           */
          function getDuration(data, initData) {
            let rawDuration = 0;
            let videoDuration = 0;
            let audioDuration = 0;
            const trafs = findBox(data, ['moof', 'traf']);
            for (let i = 0; i < trafs.length; i++) {
              const traf = trafs[i];
              // There is only one tfhd & trun per traf
              // This is true for CMAF style content, and we should perhaps check the ftyp
              // and only look for a single trun then, but for ISOBMFF we should check
              // for multiple track runs.
              const tfhd = findBox(traf, ['tfhd'])[0];
              // get the track id from the tfhd
              const id = readUint32(tfhd, 4);
              const track = initData[id];
              if (!track) {
                continue;
              }
              const trackDefault = track.default;
              const tfhdFlags = readUint32(tfhd, 0) | trackDefault?.flags;
              let sampleDuration = trackDefault?.duration;
              if (tfhdFlags & 0x000008) {
                // 0x000008 indicates the presence of the default_sample_duration field
                if (tfhdFlags & 0x000002) {
                  // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration
                  // If present, the default_sample_duration exists at byte offset 12
                  sampleDuration = readUint32(tfhd, 12);
                } else {
                  // Otherwise, the duration is at byte offset 8
                  sampleDuration = readUint32(tfhd, 8);
                }
              }
              // assume a 90kHz clock if no timescale was specified
              const timescale = track.timescale || 90e3;
              const truns = findBox(traf, ['trun']);
              for (let j = 0; j < truns.length; j++) {
                rawDuration = computeRawDurationFromSamples(truns[j]);
                if (!rawDuration && sampleDuration) {
                  const sampleCount = readUint32(truns[j], 4);
                  rawDuration = sampleDuration * sampleCount;
                }
                if (track.type === _loader_fragment__WEBPACK_IMPORTED_MODULE_0__.ElementaryStreamTypes.VIDEO) {
                  videoDuration += rawDuration / timescale;
                } else if (track.type === _loader_fragment__WEBPACK_IMPORTED_MODULE_0__.ElementaryStreamTypes.AUDIO) {
                  audioDuration += rawDuration / timescale;
                }
              }
            }
            if (videoDuration === 0 && audioDuration === 0) {
              // If duration samples are not available in the traf use sidx subsegment_duration
              let sidxDuration = 0;
              const sidxs = findBox(data, ['sidx']);
              for (let i = 0; i < sidxs.length; i++) {
                const sidx = parseSegmentIndex(sidxs[i]);
                if (sidx?.references) {
                  sidxDuration += sidx.references.reduce((dur, ref) => dur + ref.info.duration || 0, 0);
                }
              }
              return sidxDuration;
            }
            if (videoDuration) {
              return videoDuration;
            }
            return audioDuration;
          }

          /*
            For Reference:
            aligned(8) class TrackRunBox
                     extends FullBox(‘trun’, version, tr_flags) {
               unsigned int(32)  sample_count;
               // the following are optional fields
               signed int(32) data_offset;
               unsigned int(32)  first_sample_flags;
               // all fields in the following array are optional
               {
                  unsigned int(32)  sample_duration;
                  unsigned int(32)  sample_size;
                  unsigned int(32)  sample_flags
                  if (version == 0)
                     { unsigned int(32)
                  else
                     { signed int(32)
               }[ sample_count ]
            }
           */
          function computeRawDurationFromSamples(trun) {
            const flags = readUint32(trun, 0);
            // Flags are at offset 0, non-optional sample_count is at offset 4. Therefore we start 8 bytes in.
            // Each field is an int32, which is 4 bytes
            let offset = 8;
            // data-offset-present flag
            if (flags & 0x000001) {
              offset += 4;
            }
            // first-sample-flags-present flag
            if (flags & 0x000004) {
              offset += 4;
            }
            let duration = 0;
            const sampleCount = readUint32(trun, 4);
            for (let i = 0; i < sampleCount; i++) {
              // sample-duration-present flag
              if (flags & 0x000100) {
                const sampleDuration = readUint32(trun, offset);
                duration += sampleDuration;
                offset += 4;
              }
              // sample-size-present flag
              if (flags & 0x000200) {
                offset += 4;
              }
              // sample-flags-present flag
              if (flags & 0x000400) {
                offset += 4;
              }
              // sample-composition-time-offsets-present flag
              if (flags & 0x000800) {
                offset += 4;
              }
            }
            return duration;
          }
          function offsetStartDTS(initData, fmp4, timeOffset) {
            findBox(fmp4, ['moof', 'traf']).forEach(traf => {
              findBox(traf, ['tfhd']).forEach(tfhd => {
                // get the track id from the tfhd
                const id = readUint32(tfhd, 4);
                const track = initData[id];
                if (!track) {
                  return;
                }
                // assume a 90kHz clock if no timescale was specified
                const timescale = track.timescale || 90e3;
                // get the base media decode time from the tfdt
                findBox(traf, ['tfdt']).forEach(tfdt => {
                  const version = tfdt[0];
                  let baseMediaDecodeTime = readUint32(tfdt, 4);
                  if (version === 0) {
                    baseMediaDecodeTime -= timeOffset * timescale;
                    baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);
                    writeUint32(tfdt, 4, baseMediaDecodeTime);
                  } else {
                    baseMediaDecodeTime *= Math.pow(2, 32);
                    baseMediaDecodeTime += readUint32(tfdt, 8);
                    baseMediaDecodeTime -= timeOffset * timescale;
                    baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);
                    const upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));
                    const lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));
                    writeUint32(tfdt, 4, upper);
                    writeUint32(tfdt, 8, lower);
                  }
                });
              });
            });
          }

          // TODO: Check if the last moof+mdat pair is part of the valid range
          function segmentValidRange(data) {
            const segmentedRange = {
              valid: null,
              remainder: null
            };
            const moofs = findBox(data, ['moof']);
            if (!moofs) {
              return segmentedRange;
            } else if (moofs.length < 2) {
              segmentedRange.remainder = data;
              return segmentedRange;
            }
            const last = moofs[moofs.length - 1];
            // Offset by 8 bytes; findBox offsets the start by as much
            segmentedRange.valid = (0, _typed_array__WEBPACK_IMPORTED_MODULE_1__.sliceUint8)(data, 0, last.byteOffset - 8);
            segmentedRange.remainder = (0, _typed_array__WEBPACK_IMPORTED_MODULE_1__.sliceUint8)(data, last.byteOffset - 8);
            return segmentedRange;
          }
          function appendUint8Array(data1, data2) {
            const temp = new Uint8Array(data1.length + data2.length);
            temp.set(data1);
            temp.set(data2, data1.length);
            return temp;
          }
          function parseSamples(timeOffset, track) {
            const seiSamples = [];
            const videoData = track.samples;
            const timescale = track.timescale;
            const trackId = track.id;
            let isHEVCFlavor = false;
            const moofs = findBox(videoData, ['moof']);
            moofs.map(moof => {
              const moofOffset = moof.byteOffset - 8;
              const trafs = findBox(moof, ['traf']);
              trafs.map(traf => {
                // get the base media decode time from the tfdt
                const baseTime = findBox(traf, ['tfdt']).map(tfdt => {
                  const version = tfdt[0];
                  let result = readUint32(tfdt, 4);
                  if (version === 1) {
                    result *= Math.pow(2, 32);
                    result += readUint32(tfdt, 8);
                  }
                  return result / timescale;
                })[0];
                if (baseTime !== undefined) {
                  timeOffset = baseTime;
                }
                return findBox(traf, ['tfhd']).map(tfhd => {
                  const id = readUint32(tfhd, 4);
                  const tfhdFlags = readUint32(tfhd, 0) & 0xffffff;
                  const baseDataOffsetPresent = (tfhdFlags & 0x000001) !== 0;
                  const sampleDescriptionIndexPresent = (tfhdFlags & 0x000002) !== 0;
                  const defaultSampleDurationPresent = (tfhdFlags & 0x000008) !== 0;
                  let defaultSampleDuration = 0;
                  const defaultSampleSizePresent = (tfhdFlags & 0x000010) !== 0;
                  let defaultSampleSize = 0;
                  const defaultSampleFlagsPresent = (tfhdFlags & 0x000020) !== 0;
                  let tfhdOffset = 8;
                  if (id === trackId) {
                    if (baseDataOffsetPresent) {
                      tfhdOffset += 8;
                    }
                    if (sampleDescriptionIndexPresent) {
                      tfhdOffset += 4;
                    }
                    if (defaultSampleDurationPresent) {
                      defaultSampleDuration = readUint32(tfhd, tfhdOffset);
                      tfhdOffset += 4;
                    }
                    if (defaultSampleSizePresent) {
                      defaultSampleSize = readUint32(tfhd, tfhdOffset);
                      tfhdOffset += 4;
                    }
                    if (defaultSampleFlagsPresent) {
                      tfhdOffset += 4;
                    }
                    if (track.type === 'video') {
                      isHEVCFlavor = isHEVC(track.codec);
                    }
                    findBox(traf, ['trun']).map(trun => {
                      const version = trun[0];
                      const flags = readUint32(trun, 0) & 0xffffff;
                      const dataOffsetPresent = (flags & 0x000001) !== 0;
                      let dataOffset = 0;
                      const firstSampleFlagsPresent = (flags & 0x000004) !== 0;
                      const sampleDurationPresent = (flags & 0x000100) !== 0;
                      let sampleDuration = 0;
                      const sampleSizePresent = (flags & 0x000200) !== 0;
                      let sampleSize = 0;
                      const sampleFlagsPresent = (flags & 0x000400) !== 0;
                      const sampleCompositionOffsetsPresent = (flags & 0x000800) !== 0;
                      let compositionOffset = 0;
                      const sampleCount = readUint32(trun, 4);
                      let trunOffset = 8; // past version, flags, and sample count

                      if (dataOffsetPresent) {
                        dataOffset = readUint32(trun, trunOffset);
                        trunOffset += 4;
                      }
                      if (firstSampleFlagsPresent) {
                        trunOffset += 4;
                      }
                      let sampleOffset = dataOffset + moofOffset;
                      for (let ix = 0; ix < sampleCount; ix++) {
                        if (sampleDurationPresent) {
                          sampleDuration = readUint32(trun, trunOffset);
                          trunOffset += 4;
                        } else {
                          sampleDuration = defaultSampleDuration;
                        }
                        if (sampleSizePresent) {
                          sampleSize = readUint32(trun, trunOffset);
                          trunOffset += 4;
                        } else {
                          sampleSize = defaultSampleSize;
                        }
                        if (sampleFlagsPresent) {
                          trunOffset += 4;
                        }
                        if (sampleCompositionOffsetsPresent) {
                          if (version === 0) {
                            compositionOffset = readUint32(trun, trunOffset);
                          } else {
                            compositionOffset = readSint32(trun, trunOffset);
                          }
                          trunOffset += 4;
                        }
                        if (track.type === _loader_fragment__WEBPACK_IMPORTED_MODULE_0__.ElementaryStreamTypes.VIDEO) {
                          let naluTotalSize = 0;
                          while (naluTotalSize < sampleSize) {
                            const naluSize = readUint32(videoData, sampleOffset);
                            sampleOffset += 4;
                            if (isSEIMessage(isHEVCFlavor, videoData[sampleOffset])) {
                              const data = videoData.subarray(sampleOffset, sampleOffset + naluSize);
                              parseSEIMessageFromNALu(data, isHEVCFlavor ? 2 : 1, timeOffset + compositionOffset / timescale, seiSamples);
                            }
                            sampleOffset += naluSize;
                            naluTotalSize += naluSize + 4;
                          }
                        }
                        timeOffset += sampleDuration / timescale;
                      }
                    });
                  }
                });
              });
            });
            return seiSamples;
          }
          function isHEVC(codec) {
            if (!codec) {
              return false;
            }
            const delimit = codec.indexOf('.');
            const baseCodec = delimit < 0 ? codec : codec.substring(0, delimit);
            return baseCodec === 'hvc1' || baseCodec === 'hev1' ||
              // Dolby Vision
              baseCodec === 'dvh1' || baseCodec === 'dvhe';
          }
          function isSEIMessage(isHEVCFlavor, naluHeader) {
            if (isHEVCFlavor) {
              const naluType = naluHeader >> 1 & 0x3f;
              return naluType === 39 || naluType === 40;
            } else {
              const naluType = naluHeader & 0x1f;
              return naluType === 6;
            }
          }
          function parseSEIMessageFromNALu(unescapedData, headerSize, pts, samples) {
            const data = discardEPB(unescapedData);
            let seiPtr = 0;
            // skip nal header
            seiPtr += headerSize;
            let payloadType = 0;
            let payloadSize = 0;
            let endOfCaptions = false;
            let b = 0;
            while (seiPtr < data.length) {
              payloadType = 0;
              do {
                if (seiPtr >= data.length) {
                  break;
                }
                b = data[seiPtr++];
                payloadType += b;
              } while (b === 0xff);

              // Parse payload size.
              payloadSize = 0;
              do {
                if (seiPtr >= data.length) {
                  break;
                }
                b = data[seiPtr++];
                payloadSize += b;
              } while (b === 0xff);
              const leftOver = data.length - seiPtr;
              if (!endOfCaptions && payloadType === 4 && seiPtr < data.length) {
                endOfCaptions = true;
                const countryCode = data[seiPtr++];
                if (countryCode === 181) {
                  const providerCode = readUint16(data, seiPtr);
                  seiPtr += 2;
                  if (providerCode === 49) {
                    const userStructure = readUint32(data, seiPtr);
                    seiPtr += 4;
                    if (userStructure === 0x47413934) {
                      const userDataType = data[seiPtr++];

                      // Raw CEA-608 bytes wrapped in CEA-708 packet
                      if (userDataType === 3) {
                        const firstByte = data[seiPtr++];
                        const totalCCs = 0x1f & firstByte;
                        const enabled = 0x40 & firstByte;
                        const totalBytes = enabled ? 2 + totalCCs * 3 : 0;
                        const byteArray = new Uint8Array(totalBytes);
                        if (enabled) {
                          byteArray[0] = firstByte;
                          for (let i = 1; i < totalBytes; i++) {
                            byteArray[i] = data[seiPtr++];
                          }
                        }
                        samples.push({
                          type: userDataType,
                          payloadType,
                          pts,
                          bytes: byteArray
                        });
                      }
                    }
                  }
                }
              } else if (payloadType === 5 && payloadSize < leftOver) {
                endOfCaptions = true;
                if (payloadSize > 16) {
                  const uuidStrArray = [];
                  for (let i = 0; i < 16; i++) {
                    const b = data[seiPtr++].toString(16);
                    uuidStrArray.push(b.length == 1 ? '0' + b : b);
                    if (i === 3 || i === 5 || i === 7 || i === 9) {
                      uuidStrArray.push('-');
                    }
                  }
                  const length = payloadSize - 16;
                  const userDataBytes = new Uint8Array(length);
                  for (let i = 0; i < length; i++) {
                    userDataBytes[i] = data[seiPtr++];
                  }
                  samples.push({
                    payloadType,
                    pts,
                    uuid: uuidStrArray.join(''),
                    userData: (0, _demux_id3__WEBPACK_IMPORTED_MODULE_2__.utf8ArrayToStr)(userDataBytes),
                    userDataBytes
                  });
                }
              } else if (payloadSize < leftOver) {
                seiPtr += payloadSize;
              } else if (payloadSize > leftOver) {
                break;
              }
            }
          }

          /**
           * remove Emulation Prevention bytes from a RBSP
           */
          function discardEPB(data) {
            const length = data.byteLength;
            const EPBPositions = [];
            let i = 1;

            // Find all `Emulation Prevention Bytes`
            while (i < length - 2) {
              if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {
                EPBPositions.push(i + 2);
                i += 2;
              } else {
                i++;
              }
            }

            // If no Emulation Prevention Bytes were found just return the original
            // array
            if (EPBPositions.length === 0) {
              return data;
            }

            // Create a new array to hold the NAL unit data
            const newLength = length - EPBPositions.length;
            const newData = new Uint8Array(newLength);
            let sourceIndex = 0;
            for (i = 0; i < newLength; sourceIndex++, i++) {
              if (sourceIndex === EPBPositions[0]) {
                // Skip this byte
                sourceIndex++;
                // Remove this position index
                EPBPositions.shift();
              }
              newData[i] = data[sourceIndex];
            }
            return newData;
          }
          function parseEmsg(data) {
            const version = data[0];
            let schemeIdUri = '';
            let value = '';
            let timeScale = 0;
            let presentationTimeDelta = 0;
            let presentationTime = 0;
            let eventDuration = 0;
            let id = 0;
            let offset = 0;
            if (version === 0) {
              while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
                schemeIdUri += bin2str(data.subarray(offset, offset + 1));
                offset += 1;
              }
              schemeIdUri += bin2str(data.subarray(offset, offset + 1));
              offset += 1;
              while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
                value += bin2str(data.subarray(offset, offset + 1));
                offset += 1;
              }
              value += bin2str(data.subarray(offset, offset + 1));
              offset += 1;
              timeScale = readUint32(data, 12);
              presentationTimeDelta = readUint32(data, 16);
              eventDuration = readUint32(data, 20);
              id = readUint32(data, 24);
              offset = 28;
            } else if (version === 1) {
              offset += 4;
              timeScale = readUint32(data, offset);
              offset += 4;
              const leftPresentationTime = readUint32(data, offset);
              offset += 4;
              const rightPresentationTime = readUint32(data, offset);
              offset += 4;
              presentationTime = 2 ** 32 * leftPresentationTime + rightPresentationTime;
              if (!Number.isSafeInteger(presentationTime)) {
                presentationTime = Number.MAX_SAFE_INTEGER;
                // eslint-disable-next-line no-console
                console.warn('Presentation time exceeds safe integer limit and wrapped to max safe integer in parsing emsg box');
              }
              eventDuration = readUint32(data, offset);
              offset += 4;
              id = readUint32(data, offset);
              offset += 4;
              while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
                schemeIdUri += bin2str(data.subarray(offset, offset + 1));
                offset += 1;
              }
              schemeIdUri += bin2str(data.subarray(offset, offset + 1));
              offset += 1;
              while (bin2str(data.subarray(offset, offset + 1)) !== '\0') {
                value += bin2str(data.subarray(offset, offset + 1));
                offset += 1;
              }
              value += bin2str(data.subarray(offset, offset + 1));
              offset += 1;
            }
            const payload = data.subarray(offset, data.byteLength);
            return {
              schemeIdUri,
              value,
              timeScale,
              presentationTime,
              presentationTimeDelta,
              eventDuration,
              id,
              payload
            };
          }
          function mp4Box(type, ...payload) {
            const len = payload.length;
            let size = 8;
            let i = len;
            while (i--) {
              size += payload[i].byteLength;
            }
            const result = new Uint8Array(size);
            result[0] = size >> 24 & 0xff;
            result[1] = size >> 16 & 0xff;
            result[2] = size >> 8 & 0xff;
            result[3] = size & 0xff;
            result.set(type, 4);
            for (i = 0, size = 8; i < len; i++) {
              result.set(payload[i], size);
              size += payload[i].byteLength;
            }
            return result;
          }
          function mp4pssh(systemId, keyids, data) {
            if (systemId.byteLength !== 16) {
              throw new RangeError('Invalid system id');
            }
            let version;
            let kids;
            if (keyids) {
              version = 1;
              kids = new Uint8Array(keyids.length * 16);
              for (let ix = 0; ix < keyids.length; ix++) {
                const k = keyids[ix]; // uint8array
                if (k.byteLength !== 16) {
                  throw new RangeError('Invalid key');
                }
                kids.set(k, ix * 16);
              }
            } else {
              version = 0;
              kids = new Uint8Array();
            }
            let kidCount;
            if (version > 0) {
              kidCount = new Uint8Array(4);
              if (keyids.length > 0) {
                new DataView(kidCount.buffer).setUint32(0, keyids.length, false);
              }
            } else {
              kidCount = new Uint8Array();
            }
            const dataSize = new Uint8Array(4);
            if (data && data.byteLength > 0) {
              new DataView(dataSize.buffer).setUint32(0, data.byteLength, false);
            }
            return mp4Box([112, 115, 115, 104], new Uint8Array([version, 0x00, 0x00, 0x00 // Flags
            ]), systemId,
              // 16 bytes
              kidCount, kids, dataSize, data || new Uint8Array());
          }
          function parsePssh(initData) {
            if (!(initData instanceof ArrayBuffer) || initData.byteLength < 32) {
              return null;
            }
            const result = {
              version: 0,
              systemId: '',
              kids: null,
              data: null
            };
            const view = new DataView(initData);
            const boxSize = view.getUint32(0);
            if (initData.byteLength !== boxSize && boxSize > 44) {
              return null;
            }
            const type = view.getUint32(4);
            if (type !== 0x70737368) {
              return null;
            }
            result.version = view.getUint32(8) >>> 24;
            if (result.version > 1) {
              return null;
            }
            result.systemId = _hex__WEBPACK_IMPORTED_MODULE_4__["default"].hexDump(new Uint8Array(initData, 12, 16));
            const dataSizeOrKidCount = view.getUint32(28);
            if (result.version === 0) {
              if (boxSize - 32 < dataSizeOrKidCount) {
                return null;
              }
              result.data = new Uint8Array(initData, 32, dataSizeOrKidCount);
            } else if (result.version === 1) {
              result.kids = [];
              for (let i = 0; i < dataSizeOrKidCount; i++) {
                result.kids.push(new Uint8Array(initData, 32 + i * 16, 16));
              }
            }
            return result;
          }

          /***/
        }),

/***/ "./src/utils/numeric-encoding-utils.ts":
/*!*********************************************!*\
  !*** ./src/utils/numeric-encoding-utils.ts ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "base64Decode": () => (/* binding */ base64Decode),
/* harmony export */   "base64DecodeToStr": () => (/* binding */ base64DecodeToStr),
/* harmony export */   "base64Encode": () => (/* binding */ base64Encode),
/* harmony export */   "base64ToBase64Url": () => (/* binding */ base64ToBase64Url),
/* harmony export */   "base64UrlEncode": () => (/* binding */ base64UrlEncode),
/* harmony export */   "strToBase64Encode": () => (/* binding */ strToBase64Encode)
            /* harmony export */
          });
          function base64ToBase64Url(base64encodedStr) {
            return base64encodedStr.replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');
          }
          function strToBase64Encode(str) {
            return btoa(str);
          }
          function base64DecodeToStr(str) {
            return atob(str);
          }
          function base64Encode(input) {
            return btoa(String.fromCharCode(...input));
          }
          function base64UrlEncode(input) {
            return base64ToBase64Url(base64Encode(input));
          }
          function base64Decode(base64encodedStr) {
            return Uint8Array.from(atob(base64encodedStr), c => c.charCodeAt(0));
          }

          /***/
        }),

/***/ "./src/utils/output-filter.ts":
/*!************************************!*\
  !*** ./src/utils/output-filter.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (/* binding */ OutputFilter)
            /* harmony export */
          });
          class OutputFilter {
            cueRanges = [];
            startTime = null;
            endTime = null;
            screen = null;
            constructor(timelineController, trackName) {
              this.timelineController = timelineController;
              this.trackName = trackName;
            }
            dispatchCue() {
              if (this.startTime === null) {
                return;
              }
              this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);
              this.startTime = null;
            }
            newCue(startTime, endTime, screen) {
              if (this.startTime === null || this.startTime > startTime) {
                this.startTime = startTime;
              }
              this.endTime = endTime;
              this.screen = screen;
              this.timelineController.createCaptionsTrack(this.trackName);
            }
            reset() {
              this.cueRanges = [];
              this.startTime = null;
            }
          }

          /***/
        }),

/***/ "./src/utils/texttrack-utils.ts":
/*!**************************************!*\
  !*** ./src/utils/texttrack-utils.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "addCueToTrack": () => (/* binding */ addCueToTrack),
/* harmony export */   "clearCurrentCues": () => (/* binding */ clearCurrentCues),
/* harmony export */   "getCuesInRange": () => (/* binding */ getCuesInRange),
/* harmony export */   "removeCuesInRange": () => (/* binding */ removeCuesInRange),
/* harmony export */   "sendAddTrackEvent": () => (/* binding */ sendAddTrackEvent)
            /* harmony export */
          });
/* harmony import */ var _logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./logger */ "./src/utils/logger.ts");

          function sendAddTrackEvent(track, videoEl) {
            let event;
            try {
              event = new Event('addtrack');
            } catch (err) {
              // for IE11
              event = document.createEvent('Event');
              event.initEvent('addtrack', false, false);
            }
            event.track = track;
            videoEl.dispatchEvent(event);
          }
          function addCueToTrack(track, cue) {
            // Sometimes there are cue overlaps on segmented vtts so the same
            // cue can appear more than once in different vtt files.
            // This avoid showing duplicated cues with same timecode and text.
            const mode = track.mode;
            if (mode === 'disabled') {
              track.mode = 'hidden';
            }
            if (track.cues && !track.cues.getCueById(cue.id)) {
              try {
                track.addCue(cue);
                if (!track.cues.getCueById(cue.id)) {
                  throw new Error(`addCue is failed for: ${cue}`);
                }
              } catch (err) {
                _logger__WEBPACK_IMPORTED_MODULE_0__.logger.debug(`[texttrack-utils]: ${err}`);
                const textTrackCue = new self.TextTrackCue(cue.startTime, cue.endTime, cue.text);
                textTrackCue.id = cue.id;
                track.addCue(textTrackCue);
              }
            }
            if (mode === 'disabled') {
              track.mode = mode;
            }
          }
          function clearCurrentCues(track) {
            // When track.mode is disabled, track.cues will be null.
            // To guarantee the removal of cues, we need to temporarily
            // change the mode to hidden
            const mode = track.mode;
            if (mode === 'disabled') {
              track.mode = 'hidden';
            }
            if (track.cues) {
              for (let i = track.cues.length; i--;) {
                track.removeCue(track.cues[i]);
              }
            }
            if (mode === 'disabled') {
              track.mode = mode;
            }
          }
          function removeCuesInRange(track, start, end, predicate) {
            const mode = track.mode;
            if (mode === 'disabled') {
              track.mode = 'hidden';
            }
            if (track.cues && track.cues.length > 0) {
              const cues = getCuesInRange(track.cues, start, end);
              for (let i = 0; i < cues.length; i++) {
                if (!predicate || predicate(cues[i])) {
                  track.removeCue(cues[i]);
                }
              }
            }
            if (mode === 'disabled') {
              track.mode = mode;
            }
          }

          // Find first cue starting after given time.
          // Modified version of binary search O(log(n)).
          function getFirstCueIndexAfterTime(cues, time) {
            // If first cue starts after time, start there
            if (time < cues[0].startTime) {
              return 0;
            }
            // If the last cue ends before time there is no overlap
            const len = cues.length - 1;
            if (time > cues[len].endTime) {
              return -1;
            }
            let left = 0;
            let right = len;
            while (left <= right) {
              const mid = Math.floor((right + left) / 2);
              if (time < cues[mid].startTime) {
                right = mid - 1;
              } else if (time > cues[mid].startTime && left < len) {
                left = mid + 1;
              } else {
                // If it's not lower or higher, it must be equal.
                return mid;
              }
            }
            // At this point, left and right have swapped.
            // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.
            return cues[left].startTime - time < time - cues[right].startTime ? left : right;
          }
          function getCuesInRange(cues, start, end) {
            const cuesFound = [];
            const firstCueInRange = getFirstCueIndexAfterTime(cues, start);
            if (firstCueInRange > -1) {
              for (let i = firstCueInRange, len = cues.length; i < len; i++) {
                const cue = cues[i];
                if (cue.startTime >= start && cue.endTime <= end) {
                  cuesFound.push(cue);
                } else if (cue.startTime > end) {
                  return cuesFound;
                }
              }
            }
            return cuesFound;
          }

          /***/
        }),

/***/ "./src/utils/time-ranges.ts":
/*!**********************************!*\
  !*** ./src/utils/time-ranges.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
          /**
           *  TimeRanges to string helper
           */

          const TimeRanges = {
            toString: function (r) {
              let log = '';
              const len = r.length;
              for (let i = 0; i < len; i++) {
                log += '[' + r.start(i).toFixed(3) + ',' + r.end(i).toFixed(3) + ']';
              }
              return log;
            }
          };
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TimeRanges);

          /***/
        }),

/***/ "./src/utils/timescale-conversion.ts":
/*!*******************************************!*\
  !*** ./src/utils/timescale-conversion.ts ***!
  \*******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "toMpegTsClockFromTimescale": () => (/* binding */ toMpegTsClockFromTimescale),
/* harmony export */   "toMsFromMpegTsClock": () => (/* binding */ toMsFromMpegTsClock),
/* harmony export */   "toTimescaleFromBase": () => (/* binding */ toTimescaleFromBase),
/* harmony export */   "toTimescaleFromScale": () => (/* binding */ toTimescaleFromScale)
            /* harmony export */
          });
          const MPEG_TS_CLOCK_FREQ_HZ = 90000;
          function toTimescaleFromBase(value, destScale, srcBase = 1, round = false) {
            const result = value * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`
            return round ? Math.round(result) : result;
          }
          function toTimescaleFromScale(value, destScale, srcScale = 1, round = false) {
            return toTimescaleFromBase(value, destScale, 1 / srcScale, round);
          }
          function toMsFromMpegTsClock(value, round = false) {
            return toTimescaleFromBase(value, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);
          }
          function toMpegTsClockFromTimescale(value, srcScale = 1) {
            return toTimescaleFromBase(value, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);
          }

          /***/
        }),

/***/ "./src/utils/typed-array.ts":
/*!**********************************!*\
  !*** ./src/utils/typed-array.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "sliceUint8": () => (/* binding */ sliceUint8)
            /* harmony export */
          });
          function sliceUint8(array, start, end) {
            // @ts-expect-error This polyfills IE11 usage of Uint8Array slice.
            // It always exists in the TypeScript definition so fails, but it fails at runtime on IE11.
            return Uint8Array.prototype.slice ? array.slice(start, end) : new Uint8Array(Array.prototype.slice.call(array, start, end));
          }

          /***/
        }),

/***/ "./src/utils/vttcue.ts":
/*!*****************************!*\
  !*** ./src/utils/vttcue.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/**
 * Copyright 2013 vtt.js Contributors
 *
 * Licensed under the Apache License, Version 2.0 (the 'License');
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an 'AS IS' BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ((function () {
            if (typeof self !== 'undefined' && self.VTTCue) {
              return self.VTTCue;
            }
            const AllowedDirections = ['', 'lr', 'rl'];
            const AllowedAlignments = ['start', 'middle', 'end', 'left', 'right'];
            function isAllowedValue(allowed, value) {
              if (typeof value !== 'string') {
                return false;
              }
              // necessary for assuring the generic conforms to the Array interface
              if (!Array.isArray(allowed)) {
                return false;
              }
              // reset the type so that the next narrowing works well
              const lcValue = value.toLowerCase();
              // use the allow list to narrow the type to a specific subset of strings
              if (~allowed.indexOf(lcValue)) {
                return lcValue;
              }
              return false;
            }
            function findDirectionSetting(value) {
              return isAllowedValue(AllowedDirections, value);
            }
            function findAlignSetting(value) {
              return isAllowedValue(AllowedAlignments, value);
            }
            function extend(obj, ...rest) {
              let i = 1;
              for (; i < arguments.length; i++) {
                const cobj = arguments[i];
                for (const p in cobj) {
                  obj[p] = cobj[p];
                }
              }
              return obj;
            }
            function VTTCue(startTime, endTime, text) {
              const cue = this;
              const baseObj = {
                enumerable: true
              };
              /**
               * Shim implementation specific properties. These properties are not in
               * the spec.
               */

              // Lets us know when the VTTCue's data has changed in such a way that we need
              // to recompute its display state. This lets us compute its display state
              // lazily.
              cue.hasBeenReset = false;

              /**
               * VTTCue and TextTrackCue properties
               * http://dev.w3.org/html5/webvtt/#vttcue-interface
               */

              let _id = '';
              let _pauseOnExit = false;
              let _startTime = startTime;
              let _endTime = endTime;
              let _text = text;
              let _region = null;
              let _vertical = '';
              let _snapToLines = true;
              let _line = 'auto';
              let _lineAlign = 'start';
              let _position = 50;
              let _positionAlign = 'middle';
              let _size = 50;
              let _align = 'middle';
              Object.defineProperty(cue, 'id', extend({}, baseObj, {
                get: function () {
                  return _id;
                },
                set: function (value) {
                  _id = '' + value;
                }
              }));
              Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {
                get: function () {
                  return _pauseOnExit;
                },
                set: function (value) {
                  _pauseOnExit = !!value;
                }
              }));
              Object.defineProperty(cue, 'startTime', extend({}, baseObj, {
                get: function () {
                  return _startTime;
                },
                set: function (value) {
                  if (typeof value !== 'number') {
                    throw new TypeError('Start time must be set to a number.');
                  }
                  _startTime = value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'endTime', extend({}, baseObj, {
                get: function () {
                  return _endTime;
                },
                set: function (value) {
                  if (typeof value !== 'number') {
                    throw new TypeError('End time must be set to a number.');
                  }
                  _endTime = value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'text', extend({}, baseObj, {
                get: function () {
                  return _text;
                },
                set: function (value) {
                  _text = '' + value;
                  this.hasBeenReset = true;
                }
              }));

              // todo: implement VTTRegion polyfill?
              Object.defineProperty(cue, 'region', extend({}, baseObj, {
                get: function () {
                  return _region;
                },
                set: function (value) {
                  _region = value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'vertical', extend({}, baseObj, {
                get: function () {
                  return _vertical;
                },
                set: function (value) {
                  const setting = findDirectionSetting(value);
                  // Have to check for false because the setting an be an empty string.
                  if (setting === false) {
                    throw new SyntaxError('An invalid or illegal string was specified.');
                  }
                  _vertical = setting;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {
                get: function () {
                  return _snapToLines;
                },
                set: function (value) {
                  _snapToLines = !!value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'line', extend({}, baseObj, {
                get: function () {
                  return _line;
                },
                set: function (value) {
                  if (typeof value !== 'number' && value !== 'auto') {
                    throw new SyntaxError('An invalid number or illegal string was specified.');
                  }
                  _line = value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {
                get: function () {
                  return _lineAlign;
                },
                set: function (value) {
                  const setting = findAlignSetting(value);
                  if (!setting) {
                    throw new SyntaxError('An invalid or illegal string was specified.');
                  }
                  _lineAlign = setting;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'position', extend({}, baseObj, {
                get: function () {
                  return _position;
                },
                set: function (value) {
                  if (value < 0 || value > 100) {
                    throw new Error('Position must be between 0 and 100.');
                  }
                  _position = value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {
                get: function () {
                  return _positionAlign;
                },
                set: function (value) {
                  const setting = findAlignSetting(value);
                  if (!setting) {
                    throw new SyntaxError('An invalid or illegal string was specified.');
                  }
                  _positionAlign = setting;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'size', extend({}, baseObj, {
                get: function () {
                  return _size;
                },
                set: function (value) {
                  if (value < 0 || value > 100) {
                    throw new Error('Size must be between 0 and 100.');
                  }
                  _size = value;
                  this.hasBeenReset = true;
                }
              }));
              Object.defineProperty(cue, 'align', extend({}, baseObj, {
                get: function () {
                  return _align;
                },
                set: function (value) {
                  const setting = findAlignSetting(value);
                  if (!setting) {
                    throw new SyntaxError('An invalid or illegal string was specified.');
                  }
                  _align = setting;
                  this.hasBeenReset = true;
                }
              }));

              /**
               * Other <track> spec defined properties
               */

              // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state
              cue.displayState = undefined;
            }

            /**
             * VTTCue methods
             */

            VTTCue.prototype.getCueAsHTML = function () {
              // Assume WebVTT.convertCueToDOMTree is on the global.
              const WebVTT = self.WebVTT;
              return WebVTT.convertCueToDOMTree(self, this.text);
            };
            // this is a polyfill hack
            return VTTCue;
          })());

          /***/
        }),

/***/ "./src/utils/vttparser.ts":
/*!********************************!*\
  !*** ./src/utils/vttparser.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "VTTParser": () => (/* binding */ VTTParser),
/* harmony export */   "fixLineBreaks": () => (/* binding */ fixLineBreaks),
/* harmony export */   "parseTimeStamp": () => (/* binding */ parseTimeStamp)
            /* harmony export */
          });
/* harmony import */ var _vttcue__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./vttcue */ "./src/utils/vttcue.ts");
          /*
           * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js
           */


          class StringDecoder {
            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            decode(data, options) {
              if (!data) {
                return '';
              }
              if (typeof data !== 'string') {
                throw new Error('Error - expected string data.');
              }
              return decodeURIComponent(encodeURIComponent(data));
            }
          }

          // Try to parse input as a time stamp.
          function parseTimeStamp(input) {
            function computeSeconds(h, m, s, f) {
              return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + parseFloat(f || 0);
            }
            const m = input.match(/^(?:(\d+):)?(\d{2}):(\d{2})(\.\d+)?/);
            if (!m) {
              return null;
            }
            if (parseFloat(m[2]) > 59) {
              // Timestamp takes the form of [hours]:[minutes].[milliseconds]
              // First position is hours as it's over 59.
              return computeSeconds(m[2], m[3], 0, m[4]);
            }
            // Timestamp takes the form of [hours (optional)]:[minutes]:[seconds].[milliseconds]
            return computeSeconds(m[1], m[2], m[3], m[4]);
          }

          // A settings object holds key/value pairs and will ignore anything but the first
          // assignment to a specific key.
          class Settings {
            values = Object.create(null);

            // Only accept the first assignment to any key.
            set(k, v) {
              if (!this.get(k) && v !== '') {
                this.values[k] = v;
              }
            }
            // Return the value for a key, or a default value.
            // If 'defaultKey' is passed then 'dflt' is assumed to be an object with
            // a number of possible default values as properties where 'defaultKey' is
            // the key of the property that will be chosen; otherwise it's assumed to be
            // a single value.
            get(k, dflt, defaultKey) {
              if (defaultKey) {
                return this.has(k) ? this.values[k] : dflt[defaultKey];
              }
              return this.has(k) ? this.values[k] : dflt;
            }
            // Check whether we have a value for a key.
            has(k) {
              return k in this.values;
            }
            // Accept a setting if its one of the given alternatives.
            alt(k, v, a) {
              for (let n = 0; n < a.length; ++n) {
                if (v === a[n]) {
                  this.set(k, v);
                  break;
                }
              }
            }
            // Accept a setting if its a valid (signed) integer.
            integer(k, v) {
              if (/^-?\d+$/.test(v)) {
                // integer
                this.set(k, parseInt(v, 10));
              }
            }
            // Accept a setting if its a valid percentage.
            percent(k, v) {
              if (/^([\d]{1,3})(\.[\d]*)?%$/.test(v)) {
                const percent = parseFloat(v);
                if (percent >= 0 && percent <= 100) {
                  this.set(k, percent);
                  return true;
                }
              }
              return false;
            }
          }

          // Helper function to parse input into groups separated by 'groupDelim', and
          // interpret each group as a key/value pair separated by 'keyValueDelim'.
          function parseOptions(input, callback, keyValueDelim, groupDelim) {
            const groups = groupDelim ? input.split(groupDelim) : [input];
            for (const i in groups) {
              if (typeof groups[i] !== 'string') {
                continue;
              }
              const kv = groups[i].split(keyValueDelim);
              if (kv.length !== 2) {
                continue;
              }
              const k = kv[0];
              const v = kv[1];
              callback(k, v);
            }
          }
          const defaults = new _vttcue__WEBPACK_IMPORTED_MODULE_0__["default"](0, 0, '');
          // 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244
          //  Safari doesn't yet support this change, but FF and Chrome do.
          const center = defaults.align === 'middle' ? 'middle' : 'center';
          function parseCue(input, cue, regionList) {
            // Remember the original input if we need to throw an error.
            const oInput = input;
            // 4.1 WebVTT timestamp
            function consumeTimeStamp() {
              const ts = parseTimeStamp(input);
              if (ts === null) {
                throw new Error('Malformed timestamp: ' + oInput);
              }

              // Remove time stamp from input.
              input = input.replace(/^[^\sa-zA-Z-]+/, '');
              return ts;
            }

            // 4.4.2 WebVTT cue settings
            function consumeCueSettings(input, cue) {
              const settings = new Settings();
              parseOptions(input, function (k, v) {
                let vals;
                switch (k) {
                  case 'region':
                    // Find the last region we parsed with the same region id.
                    for (let i = regionList.length - 1; i >= 0; i--) {
                      if (regionList[i].id === v) {
                        settings.set(k, regionList[i].region);
                        break;
                      }
                    }
                    break;
                  case 'vertical':
                    settings.alt(k, v, ['rl', 'lr']);
                    break;
                  case 'line':
                    vals = v.split(',');
                    settings.integer(k, vals[0]);
                    if (settings.percent(k, vals[0])) {
                      settings.set('snapToLines', false);
                    }
                    settings.alt(k, vals[0], ['auto']);
                    if (vals.length === 2) {
                      settings.alt('lineAlign', vals[1], ['start', center, 'end']);
                    }
                    break;
                  case 'position':
                    vals = v.split(',');
                    settings.percent(k, vals[0]);
                    if (vals.length === 2) {
                      settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);
                    }
                    break;
                  case 'size':
                    settings.percent(k, v);
                    break;
                  case 'align':
                    settings.alt(k, v, ['start', center, 'end', 'left', 'right']);
                    break;
                }
              }, /:/, /\s/);

              // Apply default values for any missing fields.
              cue.region = settings.get('region', null);
              cue.vertical = settings.get('vertical', '');
              let line = settings.get('line', 'auto');
              if (line === 'auto' && defaults.line === -1) {
                // set numeric line number for Safari
                line = -1;
              }
              cue.line = line;
              cue.lineAlign = settings.get('lineAlign', 'start');
              cue.snapToLines = settings.get('snapToLines', true);
              cue.size = settings.get('size', 100);
              cue.align = settings.get('align', center);
              let position = settings.get('position', 'auto');
              if (position === 'auto' && defaults.position === 50) {
                // set numeric position for Safari
                position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;
              }
              cue.position = position;
            }
            function skipWhitespace() {
              input = input.replace(/^\s+/, '');
            }

            // 4.1 WebVTT cue timings.
            skipWhitespace();
            cue.startTime = consumeTimeStamp(); // (1) collect cue start time
            skipWhitespace();
            if (input.slice(0, 3) !== '-->') {
              // (3) next characters must match '-->'
              throw new Error("Malformed time stamp (time stamps must be separated by '-->'): " + oInput);
            }
            input = input.slice(3);
            skipWhitespace();
            cue.endTime = consumeTimeStamp(); // (5) collect cue end time

            // 4.1 WebVTT cue settings list.
            skipWhitespace();
            consumeCueSettings(input, cue);
          }
          function fixLineBreaks(input) {
            return input.replace(/<br(?: \/)?>/gi, '\n');
          }
          class VTTParser {
            state = 'INITIAL';
            buffer = '';
            decoder = new StringDecoder();
            regionList = [];
            cue = null;
            parse(data) {
              const _this = this;

              // If there is no data then we won't decode it, but will just try to parse
              // whatever is in buffer already. This may occur in circumstances, for
              // example when flush() is called.
              if (data) {
                // Try to decode the data that we received.
                _this.buffer += _this.decoder.decode(data, {
                  stream: true
                });
              }
              function collectNextLine() {
                let buffer = _this.buffer;
                let pos = 0;
                buffer = fixLineBreaks(buffer);
                while (pos < buffer.length && buffer[pos] !== '\r' && buffer[pos] !== '\n') {
                  ++pos;
                }
                const line = buffer.slice(0, pos);
                // Advance the buffer early in case we fail below.
                if (buffer[pos] === '\r') {
                  ++pos;
                }
                if (buffer[pos] === '\n') {
                  ++pos;
                }
                _this.buffer = buffer.slice(pos);
                return line;
              }

              // 3.2 WebVTT metadata header syntax
              function parseHeader(input) {
                parseOptions(input, function (k, v) {
                  // switch (k) {
                  // case 'region':
                  // 3.3 WebVTT region metadata header syntax
                  // console.log('parse region', v);
                  // parseRegion(v);
                  // break;
                  // }
                }, /:/);
              }

              // 5.1 WebVTT file parsing.
              try {
                let line = '';
                if (_this.state === 'INITIAL') {
                  // We can't start parsing until we have the first line.
                  if (!/\r\n|\n/.test(_this.buffer)) {
                    return this;
                  }
                  line = collectNextLine();
                  // strip of UTF-8 BOM if any
                  // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8
                  const m = line.match(/^(ï»¿)?WEBVTT([ \t].*)?$/);
                  if (!m || !m[0]) {
                    throw new Error('Malformed WebVTT signature.');
                  }
                  _this.state = 'HEADER';
                }
                let alreadyCollectedLine = false;
                while (_this.buffer) {
                  // We can't parse a line until we have the full line.
                  if (!/\r\n|\n/.test(_this.buffer)) {
                    return this;
                  }
                  if (!alreadyCollectedLine) {
                    line = collectNextLine();
                  } else {
                    alreadyCollectedLine = false;
                  }
                  switch (_this.state) {
                    case 'HEADER':
                      // 13-18 - Allow a header (metadata) under the WEBVTT line.
                      if (/:/.test(line)) {
                        parseHeader(line);
                      } else if (!line) {
                        // An empty line terminates the header and starts the body (cues).
                        _this.state = 'ID';
                      }
                      continue;
                    case 'NOTE':
                      // Ignore NOTE blocks.
                      if (!line) {
                        _this.state = 'ID';
                      }
                      continue;
                    case 'ID':
                      // Check for the start of NOTE blocks.
                      if (/^NOTE($|[ \t])/.test(line)) {
                        _this.state = 'NOTE';
                        break;
                      }
                      // 19-29 - Allow any number of line terminators, then initialize new cue values.
                      if (!line) {
                        continue;
                      }
                      _this.cue = new _vttcue__WEBPACK_IMPORTED_MODULE_0__["default"](0, 0, '');
                      _this.state = 'CUE';
                      // 30-39 - Check if self line contains an optional identifier or timing data.
                      if (line.indexOf('-->') === -1) {
                        _this.cue.id = line;
                        continue;
                      }
                    // Process line as start of a cue.
                    /* falls through */
                    case 'CUE':
                      // 40 - Collect cue timings and settings.
                      if (!_this.cue) {
                        _this.state = 'BADCUE';
                        continue;
                      }
                      try {
                        parseCue(line, _this.cue, _this.regionList);
                      } catch (e) {
                        // In case of an error ignore rest of the cue.
                        _this.cue = null;
                        _this.state = 'BADCUE';
                        continue;
                      }
                      _this.state = 'CUETEXT';
                      continue;
                    case 'CUETEXT':
                      {
                        const hasSubstring = line.indexOf('-->') !== -1;
                        // 34 - If we have an empty line then report the cue.
                        // 35 - If we have the special substring '-->' then report the cue,
                        // but do not collect the line as we need to process the current
                        // one as a new cue.
                        if (!line || hasSubstring && (alreadyCollectedLine = true)) {
                          // We are done parsing self cue.
                          if (_this.oncue && _this.cue) {
                            _this.oncue(_this.cue);
                          }
                          _this.cue = null;
                          _this.state = 'ID';
                          continue;
                        }
                        if (_this.cue === null) {
                          continue;
                        }
                        if (_this.cue.text) {
                          _this.cue.text += '\n';
                        }
                        _this.cue.text += line;
                      }
                      continue;
                    case 'BADCUE':
                      // 54-62 - Collect and discard the remaining cue.
                      if (!line) {
                        _this.state = 'ID';
                      }
                  }
                }
              } catch (e) {
                // If we are currently parsing a cue, report what we have.
                if (_this.state === 'CUETEXT' && _this.cue && _this.oncue) {
                  _this.oncue(_this.cue);
                }
                _this.cue = null;
                // Enter BADWEBVTT state if header was not parsed correctly otherwise
                // another exception occurred so enter BADCUE state.
                _this.state = _this.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';
              }
              return this;
            }
            flush() {
              const _this = this;
              try {
                // Finish decoding the stream.
                // _this.buffer += _this.decoder.decode();
                // Synthesize the end of the current cue or region.
                if (_this.cue || _this.state === 'HEADER') {
                  _this.buffer += '\n\n';
                  _this.parse();
                }
                // If we've flushed, parsed, and we're still on the INITIAL state then
                // that means we don't have enough of the stream to parse the first
                // line.
                if (_this.state === 'INITIAL' || _this.state === 'BADWEBVTT') {
                  throw new Error('Malformed WebVTT signature.');
                }
              } catch (e) {
                if (_this.onparsingerror) {
                  _this.onparsingerror(e);
                }
              }
              if (_this.onflush) {
                _this.onflush();
              }
              return this;
            }
          }

          /***/
        }),

/***/ "./src/utils/webvtt-parser.ts":
/*!************************************!*\
  !*** ./src/utils/webvtt-parser.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "generateCueId": () => (/* binding */ generateCueId),
/* harmony export */   "parseWebVTT": () => (/* binding */ parseWebVTT)
            /* harmony export */
          });
/* harmony import */ var _vttparser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./vttparser */ "./src/utils/vttparser.ts");
/* harmony import */ var _demux_id3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../demux/id3 */ "./src/demux/id3.ts");
/* harmony import */ var _timescale_conversion__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./timescale-conversion */ "./src/utils/timescale-conversion.ts");
/* harmony import */ var _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../remux/mp4-remuxer */ "./src/remux/mp4-remuxer.ts");




          const LINEBREAKS = /\r\n|\n\r|\n|\r/g;

          // String.prototype.startsWith is not supported in IE11
          const startsWith = function (inputString, searchString, position = 0) {
            return inputString.slice(position, position + searchString.length) === searchString;
          };
          const cueString2millis = function (timeString) {
            let ts = parseInt(timeString.slice(-3));
            const secs = parseInt(timeString.slice(-6, -4));
            const mins = parseInt(timeString.slice(-9, -7));
            const hours = timeString.length > 9 ? parseInt(timeString.substring(0, timeString.indexOf(':'))) : 0;
            if (!Number.isFinite(ts) || !Number.isFinite(secs) || !Number.isFinite(mins) || !Number.isFinite(hours)) {
              throw Error(`Malformed X-TIMESTAMP-MAP: Local:${timeString}`);
            }
            ts += 1000 * secs;
            ts += 60 * 1000 * mins;
            ts += 60 * 60 * 1000 * hours;
            return ts;
          };

          // From https://github.com/darkskyapp/string-hash
          const hash = function (text) {
            let hash = 5381;
            let i = text.length;
            while (i) {
              hash = hash * 33 ^ text.charCodeAt(--i);
            }
            return (hash >>> 0).toString();
          };

          // Create a unique hash id for a cue based on start/end times and text.
          // This helps timeline-controller to avoid showing repeated captions.
          function generateCueId(startTime, endTime, text) {
            return hash(startTime.toString()) + hash(endTime.toString()) + hash(text);
          }
          const calculateOffset = function (vttCCs, cc, presentationTime) {
            let currCC = vttCCs[cc];
            let prevCC = vttCCs[currCC.prevCC];

            // This is the first discontinuity or cues have been processed since the last discontinuity
            // Offset = current discontinuity time
            if (!prevCC || !prevCC.new && currCC.new) {
              vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;
              currCC.new = false;
              return;
            }

            // There have been discontinuities since cues were last parsed.
            // Offset = time elapsed
            while (prevCC?.new) {
              vttCCs.ccOffset += currCC.start - prevCC.start;
              currCC.new = false;
              currCC = prevCC;
              prevCC = vttCCs[currCC.prevCC];
            }
            vttCCs.presentationOffset = presentationTime;
          };
          function parseWebVTT(vttByteArray, initPTS, timescale, vttCCs, cc, timeOffset, callBack, errorCallBack) {
            const parser = new _vttparser__WEBPACK_IMPORTED_MODULE_0__.VTTParser();
            // Convert byteArray into string, replacing any somewhat exotic linefeeds with "\n", then split on that character.
            // Uint8Array.prototype.reduce is not implemented in IE11
            const vttLines = (0, _demux_id3__WEBPACK_IMPORTED_MODULE_1__.utf8ArrayToStr)(new Uint8Array(vttByteArray)).trim().replace(LINEBREAKS, '\n').split('\n');
            const cues = [];
            const initPTS90Hz = (0, _timescale_conversion__WEBPACK_IMPORTED_MODULE_2__.toMpegTsClockFromTimescale)(initPTS, timescale);
            let cueTime = '00:00.000';
            let timestampMapMPEGTS = 0;
            let timestampMapLOCAL = 0;
            let parsingError;
            let inHeader = true;
            parser.oncue = function (cue) {
              // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.
              const currCC = vttCCs[cc];
              let cueOffset = vttCCs.ccOffset;

              // Calculate subtitle PTS offset
              const webVttMpegTsMapOffset = (timestampMapMPEGTS - initPTS90Hz) / 90000;

              // Update offsets for new discontinuities
              if (currCC?.new) {
                if (timestampMapLOCAL !== undefined) {
                  // When local time is provided, offset = discontinuity start time - local time
                  cueOffset = vttCCs.ccOffset = currCC.start;
                } else {
                  calculateOffset(vttCCs, cc, webVttMpegTsMapOffset);
                }
              }
              if (webVttMpegTsMapOffset) {
                // If we have MPEGTS, offset = presentation time + discontinuity offset
                cueOffset = webVttMpegTsMapOffset - vttCCs.presentationOffset;
              }
              const duration = cue.endTime - cue.startTime;
              const startTime = (0, _remux_mp4_remuxer__WEBPACK_IMPORTED_MODULE_3__.normalizePts)((cue.startTime + cueOffset - timestampMapLOCAL) * 90000, timeOffset * 90000) / 90000;
              cue.startTime = Math.max(startTime, 0);
              cue.endTime = Math.max(startTime + duration, 0);

              //trim trailing webvtt block whitespaces
              const text = cue.text.trim();

              // Fix encoding of special characters
              cue.text = decodeURIComponent(encodeURIComponent(text));

              // If the cue was not assigned an id from the VTT file (line above the content), create one.
              if (!cue.id) {
                cue.id = generateCueId(cue.startTime, cue.endTime, text);
              }
              if (cue.endTime > 0) {
                cues.push(cue);
              }
            };
            parser.onparsingerror = function (error) {
              parsingError = error;
            };
            parser.onflush = function () {
              if (parsingError) {
                errorCallBack(parsingError);
                return;
              }
              callBack(cues);
            };

            // Go through contents line by line.
            vttLines.forEach(line => {
              if (inHeader) {
                // Look for X-TIMESTAMP-MAP in header.
                if (startsWith(line, 'X-TIMESTAMP-MAP=')) {
                  // Once found, no more are allowed anyway, so stop searching.
                  inHeader = false;
                  // Extract LOCAL and MPEGTS.
                  line.slice(16).split(',').forEach(timestamp => {
                    if (startsWith(timestamp, 'LOCAL:')) {
                      cueTime = timestamp.slice(6);
                    } else if (startsWith(timestamp, 'MPEGTS:')) {
                      timestampMapMPEGTS = parseInt(timestamp.slice(7));
                    }
                  });
                  try {
                    // Convert cue time to seconds
                    timestampMapLOCAL = cueString2millis(cueTime) / 1000;
                  } catch (error) {
                    parsingError = error;
                  }
                  // Return without parsing X-TIMESTAMP-MAP line.
                  return;
                } else if (line === '') {
                  inHeader = false;
                }
              }
              // Parse line by default.
              parser.parse(line + '\n');
            });
            parser.flush();
          }

          /***/
        }),

/***/ "./src/utils/xhr-loader.ts":
/*!*********************************!*\
  !*** ./src/utils/xhr-loader.ts ***!
  \*********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

          "use strict";
          __webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
            /* harmony export */
          });
/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.ts");
/* harmony import */ var _loader_load_stats__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../loader/load-stats */ "./src/loader/load-stats.ts");


          const AGE_HEADER_LINE_REGEX = /^age:\s*[\d.]+\s*$/m;
          class XhrLoader {
            config = null;
            callbacks = null;
            loader = null;
            constructor(config /* HlsConfig */) {
              this.xhrSetup = config ? config.xhrSetup : null;
              this.stats = new _loader_load_stats__WEBPACK_IMPORTED_MODULE_1__.LoadStats();
              this.retryDelay = 0;
            }
            destroy() {
              this.callbacks = null;
              this.abortInternal();
              this.loader = null;
              this.config = null;
            }
            abortInternal() {
              const loader = this.loader;
              self.clearTimeout(this.requestTimeout);
              self.clearTimeout(this.retryTimeout);
              if (loader) {
                loader.onreadystatechange = null;
                loader.onprogress = null;
                if (loader.readyState !== 4) {
                  this.stats.aborted = true;
                  loader.abort();
                }
              }
            }
            abort() {
              this.abortInternal();
              if (this.callbacks?.onAbort) {
                this.callbacks.onAbort(this.stats, this.context, this.loader);
              }
            }
            load(context, config, callbacks) {
              if (this.stats.loading.start) {
                throw new Error('Loader can only be used once.');
              }
              this.stats.loading.start = self.performance.now();
              this.context = context;
              this.config = config;
              this.callbacks = callbacks;
              this.retryDelay = config.retryDelay;
              this.loadInternal();
            }
            loadInternal() {
              const {
                config,
                context
              } = this;
              if (!config) {
                return;
              }
              const xhr = this.loader = new self.XMLHttpRequest();
              const stats = this.stats;
              stats.loading.first = 0;
              stats.loaded = 0;
              const xhrSetup = this.xhrSetup;
              try {
                if (xhrSetup) {
                  try {
                    xhrSetup(xhr, context.url);
                  } catch (e) {
                    // fix xhrSetup: (xhr, url) => {xhr.setRequestHeader("Content-Language", "test");}
                    // not working, as xhr.setRequestHeader expects xhr.readyState === OPEN
                    xhr.open('GET', context.url, true);
                    xhrSetup(xhr, context.url);
                  }
                }
                if (!xhr.readyState) {
                  xhr.open('GET', context.url, true);
                }
                const headers = this.context.headers;
                if (headers) {
                  for (const header in headers) {
                    xhr.setRequestHeader(header, headers[header]);
                  }
                }
              } catch (e) {
                // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS
                this.callbacks.onError({
                  code: xhr.status,
                  text: e.message
                }, context, xhr);
                return;
              }
              if (context.rangeEnd) {
                xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));
              }
              xhr.onreadystatechange = this.readystatechange.bind(this);
              xhr.onprogress = this.loadprogress.bind(this);
              xhr.responseType = context.responseType;
              // setup timeout before we perform request
              self.clearTimeout(this.requestTimeout);
              this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);
              xhr.send();
            }
            readystatechange() {
              const {
                context,
                loader: xhr,
                stats
              } = this;
              if (!context || !xhr) {
                return;
              }
              const readyState = xhr.readyState;
              const config = this.config;

              // don't proceed if xhr has been aborted
              if (stats.aborted) {
                return;
              }

              // >= HEADERS_RECEIVED
              if (readyState >= 2) {
                // clear xhr timeout and rearm it if readyState less than 4
                self.clearTimeout(this.requestTimeout);
                if (stats.loading.first === 0) {
                  stats.loading.first = Math.max(self.performance.now(), stats.loading.start);
                }
                if (readyState === 4) {
                  xhr.onreadystatechange = null;
                  xhr.onprogress = null;
                  const status = xhr.status;
                  // http status between 200 to 299 are all successful
                  const isArrayBuffer = xhr.responseType === 'arraybuffer';
                  if (status >= 200 && status < 300 && (isArrayBuffer && xhr.response || xhr.responseText !== null)) {
                    stats.loading.end = Math.max(self.performance.now(), stats.loading.first);
                    let data;
                    let len;
                    if (isArrayBuffer) {
                      data = xhr.response;
                      len = data.byteLength;
                    } else {
                      data = xhr.responseText;
                      len = data.length;
                    }
                    stats.loaded = stats.total = len;
                    if (!this.callbacks) {
                      return;
                    }
                    const onProgress = this.callbacks.onProgress;
                    if (onProgress) {
                      onProgress(stats, context, data, xhr);
                    }
                    if (!this.callbacks) {
                      return;
                    }
                    const response = {
                      url: xhr.responseURL,
                      data: data
                    };
                    this.callbacks.onSuccess(response, stats, context, xhr);
                  } else {
                    // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error
                    if (stats.retry >= config.maxRetry || status >= 400 && status < 499) {
                      _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.error(`${status} while loading ${context.url}`);
                      this.callbacks.onError({
                        code: status,
                        text: xhr.statusText
                      }, context, xhr);
                    } else {
                      // retry
                      _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn(`${status} while loading ${context.url}, retrying in ${this.retryDelay}...`);
                      // abort and reset internal state
                      this.abortInternal();
                      this.loader = null;
                      // schedule retry
                      self.clearTimeout(this.retryTimeout);
                      this.retryTimeout = self.setTimeout(this.loadInternal.bind(this), this.retryDelay);
                      // set exponential backoff
                      this.retryDelay = Math.min(2 * this.retryDelay, config.maxRetryDelay);
                      stats.retry++;
                    }
                  }
                } else {
                  // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet
                  self.clearTimeout(this.requestTimeout);
                  this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);
                }
              }
            }
            loadtimeout() {
              _utils_logger__WEBPACK_IMPORTED_MODULE_0__.logger.warn(`timeout while loading ${this.context.url}`);
              const callbacks = this.callbacks;
              if (callbacks) {
                this.abortInternal();
                callbacks.onTimeout(this.stats, this.context, this.loader);
              }
            }
            loadprogress(event) {
              const stats = this.stats;
              stats.loaded = event.loaded;
              if (event.lengthComputable) {
                stats.total = event.total;
              }
            }
            getCacheAge() {
              let result = null;
              if (this.loader && AGE_HEADER_LINE_REGEX.test(this.loader.getAllResponseHeaders())) {
                const ageHeader = this.loader.getResponseHeader('age');
                result = ageHeader ? parseFloat(ageHeader) : null;
              }
              return result;
            }
          }
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (XhrLoader);

          /***/
        }),

/***/ "./node_modules/eventemitter3/index.js":
/*!*********************************************!*\
  !*** ./node_modules/eventemitter3/index.js ***!
  \*********************************************/
/***/ ((module) => {

          "use strict";


          var has = Object.prototype.hasOwnProperty
            , prefix = '~';

          /**
           * Constructor to create a storage for our `EE` objects.
           * An `Events` instance is a plain object whose properties are event names.
           *
           * @constructor
           * @private
           */
          function Events() { }

          //
          // We try to not inherit from `Object.prototype`. In some engines creating an
          // instance in this way is faster than calling `Object.create(null)` directly.
          // If `Object.create(null)` is not supported we prefix the event names with a
          // character to make sure that the built-in object properties are not
          // overridden or used as an attack vector.
          //
          if (Object.create) {
            Events.prototype = Object.create(null);

            //
            // This hack is needed because the `__proto__` property is still inherited in
            // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
            //
            if (!new Events().__proto__) prefix = false;
          }

          /**
           * Representation of a single event listener.
           *
           * @param {Function} fn The listener function.
           * @param {*} context The context to invoke the listener with.
           * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
           * @constructor
           * @private
           */
          function EE(fn, context, once) {
            this.fn = fn;
            this.context = context;
            this.once = once || false;
          }

          /**
           * Add a listener for a given event.
           *
           * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
           * @param {(String|Symbol)} event The event name.
           * @param {Function} fn The listener function.
           * @param {*} context The context to invoke the listener with.
           * @param {Boolean} once Specify if the listener is a one-time listener.
           * @returns {EventEmitter}
           * @private
           */
          function addListener(emitter, event, fn, context, once) {
            if (typeof fn !== 'function') {
              throw new TypeError('The listener must be a function');
            }

            var listener = new EE(fn, context || emitter, once)
              , evt = prefix ? prefix + event : event;

            if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
            else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
            else emitter._events[evt] = [emitter._events[evt], listener];

            return emitter;
          }

          /**
           * Clear event by name.
           *
           * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
           * @param {(String|Symbol)} evt The Event name.
           * @private
           */
          function clearEvent(emitter, evt) {
            if (--emitter._eventsCount === 0) emitter._events = new Events();
            else delete emitter._events[evt];
          }

          /**
           * Minimal `EventEmitter` interface that is molded against the Node.js
           * `EventEmitter` interface.
           *
           * @constructor
           * @public
           */
          function EventEmitter() {
            this._events = new Events();
            this._eventsCount = 0;
          }

          /**
           * Return an array listing the events for which the emitter has registered
           * listeners.
           *
           * @returns {Array}
           * @public
           */
          EventEmitter.prototype.eventNames = function eventNames() {
            var names = []
              , events
              , name;

            if (this._eventsCount === 0) return names;

            for (name in (events = this._events)) {
              if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
            }

            if (Object.getOwnPropertySymbols) {
              return names.concat(Object.getOwnPropertySymbols(events));
            }

            return names;
          };

          /**
           * Return the listeners registered for a given event.
           *
           * @param {(String|Symbol)} event The event name.
           * @returns {Array} The registered listeners.
           * @public
           */
          EventEmitter.prototype.listeners = function listeners(event) {
            var evt = prefix ? prefix + event : event
              , handlers = this._events[evt];

            if (!handlers) return [];
            if (handlers.fn) return [handlers.fn];

            for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
              ee[i] = handlers[i].fn;
            }

            return ee;
          };

          /**
           * Return the number of listeners listening to a given event.
           *
           * @param {(String|Symbol)} event The event name.
           * @returns {Number} The number of listeners.
           * @public
           */
          EventEmitter.prototype.listenerCount = function listenerCount(event) {
            var evt = prefix ? prefix + event : event
              , listeners = this._events[evt];

            if (!listeners) return 0;
            if (listeners.fn) return 1;
            return listeners.length;
          };

          /**
           * Calls each of the listeners registered for a given event.
           *
           * @param {(String|Symbol)} event The event name.
           * @returns {Boolean} `true` if the event had listeners, else `false`.
           * @public
           */
          EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
            var evt = prefix ? prefix + event : event;

            if (!this._events[evt]) return false;

            var listeners = this._events[evt]
              , len = arguments.length
              , args
              , i;

            if (listeners.fn) {
              if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

              switch (len) {
                case 1: return listeners.fn.call(listeners.context), true;
                case 2: return listeners.fn.call(listeners.context, a1), true;
                case 3: return listeners.fn.call(listeners.context, a1, a2), true;
                case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;
                case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
                case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
              }

              for (i = 1, args = new Array(len - 1); i < len; i++) {
                args[i - 1] = arguments[i];
              }

              listeners.fn.apply(listeners.context, args);
            } else {
              var length = listeners.length
                , j;

              for (i = 0; i < length; i++) {
                if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

                switch (len) {
                  case 1: listeners[i].fn.call(listeners[i].context); break;
                  case 2: listeners[i].fn.call(listeners[i].context, a1); break;
                  case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;
                  case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;
                  default:
                    if (!args) for (j = 1, args = new Array(len - 1); j < len; j++) {
                      args[j - 1] = arguments[j];
                    }

                    listeners[i].fn.apply(listeners[i].context, args);
                }
              }
            }

            return true;
          };

          /**
           * Add a listener for a given event.
           *
           * @param {(String|Symbol)} event The event name.
           * @param {Function} fn The listener function.
           * @param {*} [context=this] The context to invoke the listener with.
           * @returns {EventEmitter} `this`.
           * @public
           */
          EventEmitter.prototype.on = function on(event, fn, context) {
            return addListener(this, event, fn, context, false);
          };

          /**
           * Add a one-time listener for a given event.
           *
           * @param {(String|Symbol)} event The event name.
           * @param {Function} fn The listener function.
           * @param {*} [context=this] The context to invoke the listener with.
           * @returns {EventEmitter} `this`.
           * @public
           */
          EventEmitter.prototype.once = function once(event, fn, context) {
            return addListener(this, event, fn, context, true);
          };

          /**
           * Remove the listeners of a given event.
           *
           * @param {(String|Symbol)} event The event name.
           * @param {Function} fn Only remove the listeners that match this function.
           * @param {*} context Only remove the listeners that have this context.
           * @param {Boolean} once Only remove one-time listeners.
           * @returns {EventEmitter} `this`.
           * @public
           */
          EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
            var evt = prefix ? prefix + event : event;

            if (!this._events[evt]) return this;
            if (!fn) {
              clearEvent(this, evt);
              return this;
            }

            var listeners = this._events[evt];

            if (listeners.fn) {
              if (
                listeners.fn === fn &&
                (!once || listeners.once) &&
                (!context || listeners.context === context)
              ) {
                clearEvent(this, evt);
              }
            } else {
              for (var i = 0, events = [], length = listeners.length; i < length; i++) {
                if (
                  listeners[i].fn !== fn ||
                  (once && !listeners[i].once) ||
                  (context && listeners[i].context !== context)
                ) {
                  events.push(listeners[i]);
                }
              }

              //
              // Reset the array, or remove it completely if we have no more listeners.
              //
              if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
              else clearEvent(this, evt);
            }

            return this;
          };

          /**
           * Remove all listeners, or those of the specified event.
           *
           * @param {(String|Symbol)} [event] The event name.
           * @returns {EventEmitter} `this`.
           * @public
           */
          EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
            var evt;

            if (event) {
              evt = prefix ? prefix + event : event;
              if (this._events[evt]) clearEvent(this, evt);
            } else {
              this._events = new Events();
              this._eventsCount = 0;
            }

            return this;
          };

          //
          // Alias methods names because people roll like that.
          //
          EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
          EventEmitter.prototype.addListener = EventEmitter.prototype.on;

          //
          // Expose the prefix.
          //
          EventEmitter.prefixed = prefix;

          //
          // Allow `EventEmitter` to be imported as module namespace.
          //
          EventEmitter.EventEmitter = EventEmitter;

          //
          // Expose the module.
          //
          if (true) {
            module.exports = EventEmitter;
          }


          /***/
        }),

/***/ "./node_modules/url-toolkit/src/url-toolkit.js":
/*!*****************************************************!*\
  !*** ./node_modules/url-toolkit/src/url-toolkit.js ***!
  \*****************************************************/
/***/ (function (module) {

          // see https://tools.ietf.org/html/rfc1808

          (function (root) {
            var URL_REGEX =
              /^(?=((?:[a-zA-Z0-9+\-.]+:)?))\1(?=((?:\/\/[^\/?#]*)?))\2(?=((?:(?:[^?#\/]*\/)*[^;?#\/]*)?))\3((?:;[^?#]*)?)(\?[^#]*)?(#[^]*)?$/;
            var FIRST_SEGMENT_REGEX = /^(?=([^\/?#]*))\1([^]*)$/;
            var SLASH_DOT_REGEX = /(?:\/|^)\.(?=\/)/g;
            var SLASH_DOT_DOT_REGEX = /(?:\/|^)\.\.\/(?!\.\.\/)[^\/]*(?=\/)/g;

            var URLToolkit = {
              // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //
              // E.g
              // With opts.alwaysNormalize = false (default, spec compliant)
              // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g
              // With opts.alwaysNormalize = true (not spec compliant)
              // http://a.com/b/cd + /e/f/../g => http://a.com/e/g
              buildAbsoluteURL: function (baseURL, relativeURL, opts) {
                opts = opts || {};
                // remove any remaining space and CRLF
                baseURL = baseURL.trim();
                relativeURL = relativeURL.trim();
                if (!relativeURL) {
                  // 2a) If the embedded URL is entirely empty, it inherits the
                  // entire base URL (i.e., is set equal to the base URL)
                  // and we are done.
                  if (!opts.alwaysNormalize) {
                    return baseURL;
                  }
                  var basePartsForNormalise = URLToolkit.parseURL(baseURL);
                  if (!basePartsForNormalise) {
                    throw new Error('Error trying to parse base URL.');
                  }
                  basePartsForNormalise.path = URLToolkit.normalizePath(
                    basePartsForNormalise.path
                  );
                  return URLToolkit.buildURLFromParts(basePartsForNormalise);
                }
                var relativeParts = URLToolkit.parseURL(relativeURL);
                if (!relativeParts) {
                  throw new Error('Error trying to parse relative URL.');
                }
                if (relativeParts.scheme) {
                  // 2b) If the embedded URL starts with a scheme name, it is
                  // interpreted as an absolute URL and we are done.
                  if (!opts.alwaysNormalize) {
                    return relativeURL;
                  }
                  relativeParts.path = URLToolkit.normalizePath(relativeParts.path);
                  return URLToolkit.buildURLFromParts(relativeParts);
                }
                var baseParts = URLToolkit.parseURL(baseURL);
                if (!baseParts) {
                  throw new Error('Error trying to parse base URL.');
                }
                if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {
                  // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc
                  // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'
                  var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);
                  baseParts.netLoc = pathParts[1];
                  baseParts.path = pathParts[2];
                }
                if (baseParts.netLoc && !baseParts.path) {
                  baseParts.path = '/';
                }
                var builtParts = {
                  // 2c) Otherwise, the embedded URL inherits the scheme of
                  // the base URL.
                  scheme: baseParts.scheme,
                  netLoc: relativeParts.netLoc,
                  path: null,
                  params: relativeParts.params,
                  query: relativeParts.query,
                  fragment: relativeParts.fragment,
                };
                if (!relativeParts.netLoc) {
                  // 3) If the embedded URL's <net_loc> is non-empty, we skip to
                  // Step 7.  Otherwise, the embedded URL inherits the <net_loc>
                  // (if any) of the base URL.
                  builtParts.netLoc = baseParts.netLoc;
                  // 4) If the embedded URL path is preceded by a slash "/", the
                  // path is not relative and we skip to Step 7.
                  if (relativeParts.path[0] !== '/') {
                    if (!relativeParts.path) {
                      // 5) If the embedded URL path is empty (and not preceded by a
                      // slash), then the embedded URL inherits the base URL path
                      builtParts.path = baseParts.path;
                      // 5a) if the embedded URL's <params> is non-empty, we skip to
                      // step 7; otherwise, it inherits the <params> of the base
                      // URL (if any) and
                      if (!relativeParts.params) {
                        builtParts.params = baseParts.params;
                        // 5b) if the embedded URL's <query> is non-empty, we skip to
                        // step 7; otherwise, it inherits the <query> of the base
                        // URL (if any) and we skip to step 7.
                        if (!relativeParts.query) {
                          builtParts.query = baseParts.query;
                        }
                      }
                    } else {
                      // 6) The last segment of the base URL's path (anything
                      // following the rightmost slash "/", or the entire path if no
                      // slash is present) is removed and the embedded URL's path is
                      // appended in its place.
                      var baseURLPath = baseParts.path;
                      var newPath =
                        baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +
                        relativeParts.path;
                      builtParts.path = URLToolkit.normalizePath(newPath);
                    }
                  }
                }
                if (builtParts.path === null) {
                  builtParts.path = opts.alwaysNormalize
                    ? URLToolkit.normalizePath(relativeParts.path)
                    : relativeParts.path;
                }
                return URLToolkit.buildURLFromParts(builtParts);
              },
              parseURL: function (url) {
                var parts = URL_REGEX.exec(url);
                if (!parts) {
                  return null;
                }
                return {
                  scheme: parts[1] || '',
                  netLoc: parts[2] || '',
                  path: parts[3] || '',
                  params: parts[4] || '',
                  query: parts[5] || '',
                  fragment: parts[6] || '',
                };
              },
              normalizePath: function (path) {
                // The following operations are
                // then applied, in order, to the new path:
                // 6a) All occurrences of "./", where "." is a complete path
                // segment, are removed.
                // 6b) If the path ends with "." as a complete path segment,
                // that "." is removed.
                path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');
                // 6c) All occurrences of "<segment>/../", where <segment> is a
                // complete path segment not equal to "..", are removed.
                // Removal of these path segments is performed iteratively,
                // removing the leftmost matching pattern on each iteration,
                // until no matching pattern remains.
                // 6d) If the path ends with "<segment>/..", where <segment> is a
                // complete path segment not equal to "..", that
                // "<segment>/.." is removed.
                while (
                  path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length
                ) { }
                return path.split('').reverse().join('');
              },
              buildURLFromParts: function (parts) {
                return (
                  parts.scheme +
                  parts.netLoc +
                  parts.path +
                  parts.params +
                  parts.query +
                  parts.fragment
                );
              },
            };

            if (true)
              module.exports = URLToolkit;
            else { }
          })(this);


          /***/
        })

      /******/
    });
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
        /******/
      }
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
        /******/
      };
/******/
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
      /******/
    }
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = __webpack_modules__;
/******/
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
        /******/
      };
      /******/
    })();
/******/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for (var key in definition) {
/******/ 				if (__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
            /******/
          }
          /******/
        }
        /******/
      };
      /******/
    })();
/******/
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
      /******/
    })();
/******/
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if (typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
          /******/
        }
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
        /******/
      };
      /******/
    })();
/******/
/************************************************************************/
/******/
/******/ 	// module factories are used so entry inlining is disabled
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	var __webpack_exports__ = __webpack_require__("./src/hls.ts");
/******/ 	__webpack_exports__ = __webpack_exports__["default"];
/******/
/******/ 	return __webpack_exports__;
    /******/
  })()
    ;
});
//# sourceMappingURL=hls.js.map

export const Hls = hls;